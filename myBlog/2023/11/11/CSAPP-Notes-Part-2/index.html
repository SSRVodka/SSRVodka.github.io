<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>CSAPP Notes Part 2 | SJTU-XHW's blog</title><meta name="author" content="SJTU-XHW,sjtuxhw12345@sjtu.edu.cn"><meta name="copyright" content="SJTU-XHW"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Chapter 8. The Memory Hierarchy 本章将介绍系统的内存分层架构。  之前几章，我们对于内存的理解就是一个很大的字节数组，可以用地址作为下标进行访问。但事实上，真正的计算机的存储系统背后的设备层次结构设计远比这层抽象要复杂。 正是计算机的存储系统的层次结构对有限、离散资源的管理和抽象，才能让程序的内存看起来呈现出这种线性的数组结构。本章就来讨论计算机存储系统背后的层次结">
<meta property="og:type" content="article">
<meta property="og:title" content="CSAPP Notes Part 2">
<meta property="og:url" content="https://sjtuxhw.top/2023/11/11/CSAPP-Notes-Part-2/index.html">
<meta property="og:site_name" content="SJTU-XHW&#39;s blog">
<meta property="og:description" content="Chapter 8. The Memory Hierarchy 本章将介绍系统的内存分层架构。  之前几章，我们对于内存的理解就是一个很大的字节数组，可以用地址作为下标进行访问。但事实上，真正的计算机的存储系统背后的设备层次结构设计远比这层抽象要复杂。 正是计算机的存储系统的层次结构对有限、离散资源的管理和抽象，才能让程序的内存看起来呈现出这种线性的数组结构。本章就来讨论计算机存储系统背后的层次结">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.sjtuxhw.top/cover_imgs/csapp_p2.png">
<meta property="article:published_time" content="2023-11-11T01:18:11.000Z">
<meta property="article:modified_time" content="2023-12-10T01:36:19.000Z">
<meta property="article:author" content="SJTU-XHW">
<meta property="article:tag" content="GNU">
<meta property="article:tag" content="CSAPP">
<meta property="article:tag" content="ICS">
<meta property="article:tag" content="Programming">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.sjtuxhw.top/cover_imgs/csapp_p2.png"><link rel="shortcut icon" href="/myBlog/img/favicon.ico"><link rel="canonical" href="https://sjtuxhw.top/2023/11/11/CSAPP-Notes-Part-2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/myBlog/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?64dd3b0c09c8af7b916f8249d32097e2";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = {
  root: '/myBlog/',
  algolia: undefined,
  localSearch: {"path":"/myBlog/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CSAPP Notes Part 2',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-12-10 09:36:19'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/myBlog/css/mouseConfig.css"><link rel="stylesheet" href="/myBlog/css/valineBg.css"><link rel="stylesheet" href="/myBlog/css/rightmenu.css"><link rel="stylesheet" href="/myBlog/css/custom_music.css"><link rel="stylesheet" href="/myBlog/css/addFonts.css"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/myBlog/atom.xml" title="SJTU-XHW's blog" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (true) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/myBlog/img/favicon.ico" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/myBlog/archives/"><div class="headline">文章</div><div class="length-num">31</div></a><a href="/myBlog/tags/"><div class="headline">标签</div><div class="length-num">49</div></a><a href="/myBlog/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/myBlog/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/dailyQ/"><i class="fa-fw fa-solid fa-pen-to-square"></i><span> DailyQuestion</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fa-solid fa-gamepad"></i><span> ACG-Lab</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/myBlog/ACGLab/MikuTap/"><i class="fa-fw fas fa-music"></i><span> MikuTap</span></a></li><li><a class="site-page child" href="/myBlog/ACGLab/Live2D/"><i class="fa-fw fa-solid fa-face-kiss-wink-heart"></i><span> Live2D</span></a></li><li><a class="site-page child" href="/myBlog/ACGLab/Folio-2019/"><i class="fa-fw fa-solid fa-car-side"></i><span> Folio-2019</span></a></li><li><a class="site-page child" href="/myBlog/ACGLab/Cube/"><i class="fa-fw fa-solid fa-cube"></i><span> Cube</span></a></li><li><a class="site-page child" href="/myBlog/ACGLab/TowerBlocks/"><i class="fa-fw fa-solid fa-gopuram"></i><span> TBlocks</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/myBlog/friend-links/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/gallery/"><i class="fa-fw fa fa-camera"></i><span> Gallery</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/update-log/v0.3.0-Beta.html"><i class="fa-fw fa fa-arrow-circle-up"></i><span> Update</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.sjtuxhw.top/cover_imgs/csapp_p2.png')"><nav id="nav"><span id="blog-info"><a href="/myBlog/" title="SJTU-XHW's blog"><img class="site-icon" src="/myBlog/img/head_icon.png"/><span class="site-name">SJTU-XHW's blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/myBlog/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/dailyQ/"><i class="fa-fw fa-solid fa-pen-to-square"></i><span> DailyQuestion</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fa-solid fa-gamepad"></i><span> ACG-Lab</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/myBlog/ACGLab/MikuTap/"><i class="fa-fw fas fa-music"></i><span> MikuTap</span></a></li><li><a class="site-page child" href="/myBlog/ACGLab/Live2D/"><i class="fa-fw fa-solid fa-face-kiss-wink-heart"></i><span> Live2D</span></a></li><li><a class="site-page child" href="/myBlog/ACGLab/Folio-2019/"><i class="fa-fw fa-solid fa-car-side"></i><span> Folio-2019</span></a></li><li><a class="site-page child" href="/myBlog/ACGLab/Cube/"><i class="fa-fw fa-solid fa-cube"></i><span> Cube</span></a></li><li><a class="site-page child" href="/myBlog/ACGLab/TowerBlocks/"><i class="fa-fw fa-solid fa-gopuram"></i><span> TBlocks</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/myBlog/friend-links/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/gallery/"><i class="fa-fw fa fa-camera"></i><span> Gallery</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/update-log/v0.3.0-Beta.html"><i class="fa-fw fa fa-arrow-circle-up"></i><span> Update</span></a></div><div class="menus_item"><a class="site-page" href="/myBlog/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CSAPP Notes Part 2</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-11-11T01:18:11.000Z" title="发表于 2023-11-11 09:18:11">2023-11-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-12-10T01:36:19.000Z" title="更新于 2023-12-10 09:36:19">2023-12-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/myBlog/categories/review/">review</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">48k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>161分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/myBlog/2023/11/11/CSAPP-Notes-Part-2/#post-comment"><span id="twikoo-count"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="Chapter-8-The-Memory-Hierarchy"><a href="#Chapter-8-The-Memory-Hierarchy" class="headerlink" title="Chapter 8. The Memory Hierarchy"></a>Chapter 8. The Memory Hierarchy</h2><blockquote>
<p>本章将介绍系统的内存分层架构。</p>
</blockquote>
<p>之前几章，我们对于内存的理解就是一个很大的字节数组，可以用地址作为下标进行访问。但事实上，真正的计算机的存储系统背后的设备层次结构设计远比这层抽象要复杂。</p>
<p>正是计算机的存储系统的层次结构对有限、离散资源的管理和抽象，才能让程序的内存看起来呈现出这种线性的数组结构。本章就来讨论计算机存储系统背后的层次结构。</p>
<h3 id="8-1-Storage-Technologies-amp-Trends"><a href="#8-1-Storage-Technologies-amp-Trends" class="headerlink" title="8.1 Storage Technologies &amp; Trends"></a>8.1 Storage Technologies &amp; Trends</h3><p>在正式学习存储系统的层次结构前，有必要稍微弄清楚底层硬件的情况。</p>
<h4 id="8-1-1-Random-Access-Memory-RAM"><a href="#8-1-1-Random-Access-Memory-RAM" class="headerlink" title="8.1.1 Random-Access Memory (RAM)"></a>8.1.1 Random-Access Memory (RAM)</h4><p>当前大多数人所熟知的 “内存” 的一部分就是<strong>随机访问存储器（RAM）</strong>，它具有以下的特征：</p>
<ul>
<li><p>RAM 是个存储元件，I/O 吞吐速率快于绝大多数硬盘固件/磁盘（称为 “外存”）；</p>
</li>
<li><p>RAM 常常被打包放在 CPU 芯片中；</p>
</li>
<li><p>RAM 中每一个基本的存储单元被称为 <strong>单元胞</strong>（Cell），一个单元胞中存放 1 bit 数据；</p>
</li>
<li><p>很多个 RAM 芯片共同工作，组成了计算机的 <strong>主存</strong>（主存储器）。</p>
</li>
<li><p>RAM 分为 2 类，它们之间<strong>根据存储单元胞的实现方式来区分</strong>：</p>
<ul>
<li>SRAM（Static RAM），静态随机存储器；</li>
<li>DRAM（Dynamic RAM），动态随机存储器；</li>
</ul>
<table>
    <tr>
        <td></td>
        <td>Trans. per bit</td>
        <td>Access time</td>
        <td>Needs refresh?</td>
        <td>Needs EDC?</td>
        <td>Cost</td>
        <td>Applications</td>
    </tr>
    <tr>
        <td>SRAM</td>
        <td>4 or 6</td>
        <td>1 ×</td>
        <td>No</td>
        <td>Maybe</td>
        <td>100 ×</td>
        <td>Cache Memories</td>
    </tr>
    <tr>
        <td>DRAM</td>
        <td>1</td>
        <td>10 ×</td>
        <td>Yes</td>
        <td>Yes</td>
        <td>1 ×</td>
        <td>Main memories, frame buffers</td>
    </tr>
</table>


</li>
</ul>
<blockquote>
<p>注：<code>Trans. per bit</code> 表示每 bit 需要多少根晶体管，<code>EDC</code> 指电子数据捕获。</p>
<p>从上面这张表可以得知，SRAM 比 DRAM 成本高很多，因为 SRAM 的每个储存单元胞都更加复杂。正因如此，SRAM 的访问速度远远快于 DRAM，因此常被用在 Cache Memories（高速缓存器）中（成本也是高速缓存通常大小比较小的原因之一）。</p>
<p><strong>Needs EDC</strong> 的含义是指，必须用一定的电压作用在存储单元胞的两端，否则一断电就会丢失电荷，数据也会丢失（<strong>又称 Volatile Memories</strong>）。这也是 RAM 需要插电用的原因（当然，如果把它从电源上拔下后迅速扔进液氮中，可以保留其中数据，因为电荷散失速度可以忽略）。</p>
<p>DRAM 被广泛应用于主存、图形显卡的 <strong>帧缓存（frame buffer）</strong>中。</p>
</blockquote>
<h4 id="8-1-2-Nonvolatile-Memories"><a href="#8-1-2-Nonvolatile-Memories" class="headerlink" title="8.1.2 Nonvolatile Memories"></a>8.1.2 Nonvolatile Memories</h4><p><strong>ROMs</strong></p>
<p>除了 RAM，计算机存储系统中另一类存储器是 <strong>非易失性存储器</strong>，它们在计算机断电后仍然能保存数据。请回忆数电中介绍的几种电子元件：</p>
<ul>
<li><strong>ROM</strong>（Read-Only Memory，只读存储器），出厂时就编程完成，通常电路烧在板子上不可更改；</li>
<li><strong>PROM</strong>（Programmable ROM，可编程只读存储器），只能对电路编程一遍；</li>
<li><strong>EPROM</strong>（Erasable PROM，可清除可编程只读存储器），可以被特殊作用清除电路信息（UV / X-rays）；</li>
<li><strong>EEPROM</strong>（Electrically Erasable PROM，电驱动可清除可编程只读存储器），可以使用电路、电子清除其中信息，但只能反复清除重写 100,000 次。</li>
</ul>
<blockquote>
<p>它们的电路结构想必各位脑海中都非常清楚对吧？</p>
</blockquote>
<p>其中，大家所熟知的 <strong>闪存（Flash Memory）</strong>，就是许多 EEPROM 元件组成的。</p>
<blockquote>
<p>Tips. 计算机存储系统中的<strong>主存</strong>包括了 <strong>ROM 和 RAM</strong>，但闪存作为 ROM 的一种，<strong>也是现代最常用的 ROM</strong>，也可以和机械硬盘一起被用在<strong>外存</strong>中。</p>
</blockquote>
<p>这些 ROM 的作用很广泛，主要有以下几个方面：</p>
<ul>
<li>普通 ROM <strong>常被用作重要的、不应该被更改的数据的存储</strong>，例如 BIOS（存储计算机系统启动时的指令 + boot 引导程序）、Controllers for disks（硬盘控制器）、Network Cards（网卡）、Graphics accelerator（图形加速器）、Security subsystem（安全子系统）；</li>
<li>它们（闪存）还会被用在 <strong>固态硬盘</strong>（SSD，Solid State Disk，代替转圈易坏的机械硬盘，用在笔记本电脑、手机、mp3 播放器、平板等设备，系统会把 SSD 看成机械硬盘）中；</li>
</ul>
<p><strong>机械硬盘</strong></p>
<p>除了 ROM 一类的非易失性存储器，还有 <strong>外存</strong>（外部存储器）也是非易失性存储器。我们这里介绍有代表性的机械硬盘：</p>
<ul>
<li><p>结构包括传动臂、SCSI 连接口、盘片、盘片轴……</p>
</li>
<li><p>硬盘中包含一系列盘片（platter），每个盘片有两个面，每个面上涂有磁性材料，并且存在一圈圈同心圆（concentric rings），被称为 <strong>磁道（tracks）</strong>，每个磁道包含若干 <strong>扇区（sectors）</strong>，扇区之间会有空隙间隔（gaps），<strong>一个扇区通常的大小是 512 bytes</strong>；</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/disk_geometry.png" height="240px"></p>
<p>盘片轴（spindle）连接一系列盘片，<strong>每个盘片相同位置对齐的磁道称为 Aligned tracks，在垂直方向组成一个圆柱</strong>，这个相同位置的磁道所组成的元素称为 <strong>柱面</strong>，数据按照不同柱面进行存储，同一柱面的数据连续（为啥按柱面存？因为方便机械臂访问）。</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/disk_geometry_multi_platter.png" height="240px"></p>
</li>
<li><p>传动臂悬浮在盘片上方，隔着一层薄薄的空气。其末端读写头可以感知编码位的磁场变化；</p>
</li>
<li><p>机械磁盘内置电子设备，用于控制传动臂的移动等操作，其驱动程序一般存于 ROM 中；</p>
</li>
<li><p>机械性质决定了机械硬盘的读写速率慢于 RAM 和 ROM；</p>
</li>
<li><p>硬盘承载量取决于 <strong>数据记录密度（recording density，1 inch 磁道段中能存放多少 bit 信息）、磁道密度（track density）、面密度（Areal density，前面二者的乘积）</strong>；</p>
</li>
</ul>
<blockquote>
<p>⚠ 易错点警告：对于硬盘来说，它的承载量单位 GB 是特殊的：<strong>1 GB = $10^9$ Bytes</strong>，这与之前我们见到的衡量二进制数据大小的单位 GiB（<strong>其简称也叫 GB，1 GiB = $2^{30}$ Bytes</strong>）是不一样的。</p>
<p>这么说就明白了：<strong>承载量单位应该分开来看</strong>：1 G | B，1 吉 (Giga) = $10^9$；</p>
<p>而<strong>衡量二进制数据大小的单位是个整体</strong>： 1 | GiB，GiB 本身是 gibibyte（giga-binary byte），是 byte 单位的 $2^{30}$ 倍；</p>
<p>最常见的是计网的考题：<strong>1 MB/s 在 1 s 内传输的数据量略小于 1 MB</strong>，因为承载量速率单位 1 MB/s 是 $10^6$ Bytes / s，而数据大小 1 MiB 是 $2^{20}=1024^2$ Bytes；</p>
</blockquote>
<ul>
<li><p>在很早以前的机械硬盘中，每个磁道的扇区数目固定，这会导致大量的空间浪费。所以现代的机械磁盘<strong>将许多磁道划分为一个个不相交子集，称为记录区（recording zones）</strong>：</p>
<ul>
<li>每个处于同一记录区中的磁道含有相同的扇区数，它取决于最内侧磁道；</li>
<li>每个记录区中的磁道的扇区数不同，越靠近内圈的记录区中磁道的扇区数越少；</li>
<li><strong>因此我们使用平均扇区数 / 磁道数来计算承载量</strong>；</li>
</ul>
<p>如下图，阴影部分为一个记录区，含有许多扇区数相同的磁道：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/recording_zone.png" height="200px"></p>
<blockquote>
<p>题型：计算磁盘承载量</p>
<p><strong>承载量 = 每个扇区的 byte 数（通常 512 bytes）× 一个磁道中平均扇区数 × 一个盘面中的磁道数 × 一个盘片上表面数目（对三维生物来说=2）× 每个磁盘的盘片数</strong>；</p>
</blockquote>
</li>
<li><p>机械硬盘借助悬浮在盘面上方的传动臂进行读取，许多传动臂在磁盘同一半径处读写，其搜索读取读取速度取决于三个因素：<strong>寻道时间（一般最长，大约 3~9 ms）、旋转延迟、传输时间</strong>。</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/disk_op.png" height="200px"><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/disk_access_time.png" height="200px"></p>
</li>
<li><p>关于数据访问的耗时，有一些数字可以了解一下：</p>
<ul>
<li><p>一般情况下机械硬盘的 <strong>寻道时间 &gt; 旋转延迟 ≈ 4 ms &gt;&gt; 传输时间</strong>；</p>
<blockquote>
<p>机械硬盘访问扇区的第一个 bit 耗时最多，其他几乎不耗时；</p>
</blockquote>
</li>
<li><p>SRAM 访问 8 bytes 数据平均需要 4 ns，DRAM 需要 60 ns，<strong>而机械磁盘比 SRAM 慢 40000 倍，比 DRAM 慢 2500 倍</strong>；</p>
</li>
</ul>
</li>
<li><p>硬盘（机械 / SSD）的<strong>逻辑块（Logical Disk Blocks）</strong>：现代硬盘提供了一个面向 CPU 的更简单的抽象。硬盘的可用扇区被抽象为一组 b-sized 的逻辑块（编号从 0 开始）；</p>
<ul>
<li><p>每个逻辑块是<strong>扇区大小的整数倍</strong>（跳过 gaps），最简单的情况下，一个逻辑块就是一个扇区；</p>
</li>
<li><p>磁盘控制器来保持从物理扇区到逻辑块之间的<strong>映射</strong>（间接层面、抽象层面）；</p>
<blockquote>
<p>这允许磁盘控制器保留一部分 <strong>柱面</strong>（前面提到的存储信息按照同心磁道组成的柱面） 不进行映射，作为 <strong>备用柱面</strong>。</p>
<p>当某一柱面上的一个扇区损坏，那么磁盘控制器可以直接将数据复制到备用柱面，然后磁盘就能继续正常工作。</p>
<p><strong>这就是为什么磁盘的 “格式容量”（formatted capacity）比实际容量小</strong>。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p><strong>固态硬盘</strong></p>
<p>固态硬盘作为一种更新的、用来代替机械磁盘的外存形式，其控制器接口和机械磁盘一样，所以 CPU 一视同仁，不过它的速度介于 DRAM 和 机械硬盘之间。</p>
<p>其内部<strong>全部由闪存构建</strong>，并且由一个固件（firmware）称为闪存翻译层（<strong>flash translation layer</strong>）充当控制器（其作用和机械硬盘的磁盘控制器相当）；</p>
<p>数据在 SSD 中是以 <strong>页（page）</strong> 为单位从闪存中读取和写入的。页的大小 512 KB ~ 4 KB，块（block，和之前提到的 CPU 所认为的逻辑块<strong>不同</strong>，下面解释）一般包含 32 ~ 128 页，<strong>取决于 SSD 实现的技术</strong>；</p>
<blockquote>
<p>这里所说的 “块” 为啥和之前的 “逻辑块” 不同？</p>
<p>首先明确，这是个术语重叠的现象。这里的 SSD 中的 “块” 是闪存的性质导致的。目前技术下闪存的数据擦除是<strong>成块成块擦除</strong>，这意味着一次会同时擦除多个页。因此，人们把<strong>闪存一次擦除的一组页集合称为 “块”</strong>。</p>
<p>因此，想要修改某个块中的某个页，需要 <strong>将该块全部擦除（之前应该复制到其他位置）</strong> / <strong>找到一个已被擦除的块</strong> 才能写入；</p>
<p>现代的闪存翻译层中实现了很多专有算法，能够延长 SSD 的使用寿命，例如缓存技术。</p>
</blockquote>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/ssd_struct.png" height=240></p>
<p>固态硬盘的读写效率大致是 <strong>随机访问 300 MB/s 左右，顺序访问 500 MB/s 左右</strong>（Intel SSD 730 的数据），可以说<strong>在计算机的存储系统的层次结构中，随机访问总是比顺序访问更耗时</strong>。其中 SSD 写入速度都略低于读取速度，这是因为闪存写入前需要擦除原先数据。总的来说，SSD 的访问速度大约比机械硬盘快 10 倍左右。</p>
<p>其实，SSD 和机械硬盘各有优劣，相较于机械硬盘，SSD 具有以下特征：</p>
<ul>
<li>（优势）没有机械移动，更快、耗能更低、更结实（较不易摔坏），适合用在便携设备中；</li>
<li>（劣势）可能磨损，但问题不大，一般生命周期中可以写 100 PB+ 的数据（足够用多年）；</li>
</ul>
<p>最后看一下各种存储介质和 CPU 时钟频率的关系：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/CPU_memory_gap.png" height="400px"></p>
<blockquote>
<p>2003 年，CPU 设计达到性能能源瓶颈，其发展从增大时钟频率转向增大 CPU 内核数。</p>
</blockquote>
<h4 id="8-1-3-Traditional-Bus-Structure-Connecting-CPU-and-Memory"><a href="#8-1-3-Traditional-Bus-Structure-Connecting-CPU-and-Memory" class="headerlink" title="8.1.3 Traditional Bus Structure Connecting CPU and Memory"></a>8.1.3 Traditional Bus Structure Connecting CPU and Memory</h4><p>说完计算机存储系统的硬件，那么它们是怎么与 CPU 建立连接，进而抽象出 “内存空间” 和 “存储空间” 的呢？</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/io_bus.png" width="600px"></p>
<blockquote>
<p>其中 I/O 桥是另外的一些芯片组，另一些芯片的集合。</p>
</blockquote>
<p><strong>CPU 访问主存</strong></p>
<p>上面的图仅仅是比较简单粗略的抽象，不要较真。在比较老的计算机架构中（因为现代系统有专有的总线设计，非常复杂），采用 <strong>总线（bus）</strong>来连接 CPU 和主存的，数据通过总线在主存和 CPU 间来回传输。<strong>并且总线通常与其他多种设备共享</strong>。</p>
<p>正常情况下，CPU 中的 ALU 根据汇编机器指令只需访问最近的寄存器就行；如果指令要求它访问内存，那么 ALU 会交由总线接口（Bus Interface）去从主存中取出相应位置的数据。</p>
<p>大家可以思考一下，在上面这幅图中，<code>movq %rax, $A</code> （A 为内存地址）和 <code>movq $A, %rax</code> 应该如何形象表示？</p>
<p>大家不难发现，<strong>寄存器离 CPU 很近，所以访问速度很快</strong>，通常在 3 个时钟周期左右就能读写到值。但是内存（图中 Memory Devices 芯片组）离 CPU 相当远，中间的步骤相当多，所以<strong>对内存读写所消耗的时间大约是对寄存器读写耗时的 100 倍左右</strong>。这就是计算机内存系统引入所发现的其中一个性能损耗。</p>
<p><strong>CPU 访问外部设备（以外存: 磁盘为例）</strong></p>
<p>再来看 I/O 总线（I/O Bus），它将各个设备与 I/O 桥连接，<strong>使得外部设备能和主存一样被 CPU 访问</strong>。I/O Bus 看起来是一条线，可实际不是如此。因为在老式的计算机中，它被称为 PCI 总线（广播总线），主干连接到各个设备，任何设备只要更改其上的数据，其他设备就能发现。</p>
<p>但现代的 I/O 总线并不是一条线了，它采用了 PCI Express 的总线结构，并不像上面画的一样，它是 <strong>点对点地连接两个设备</strong>，实现不同（我们不会深入讨论），但提供的功能就像图上画的一样。所以可以把 I/O Bus 看作一组电子线路即可。</p>
<p>其中 Disk、Mouse、Keyboard、Monitor 等设备使用细双箭头，表示它们不是焊在主板上，而是插入主板上的控制器（adapter、controller）来连接。</p>
<p>考虑如果 CPU 想要访问某个磁盘设备的某个扇区，那么会进行如下步骤：</p>
<ul>
<li>CPU 生成一个三元组（triple）：<strong>指令</strong>（read / write）、<strong>逻辑块编号</strong>、该块中的数据要放到哪个<strong>内存地址</strong>中（CPU 先从磁盘读入内存，再从内存读入 CPU 寄存器，反方向亦然），并且当前线程的程序暂停执行（如果是 I/O 阻塞的话），等待数据传输；</li>
<li>三元组通过总线接口、I / O 桥、I / O 总线传给磁盘控制器；</li>
<li>磁盘控制器通过读取与该逻辑块对应的任何扇区（一个逻辑块可能包含很多扇区）读入磁盘缓存；</li>
<li>磁盘控制器取得总线控制权，并且<strong>将数据通过 I/O 总线、I/O 桥和内存总线直接送往指定内存地址，而无需将数据传给 CPU</strong>；</li>
<li>数据传输结束后，磁盘控制器借助 “I/O 总线 - I/O 桥” 从<strong>新的通路</strong>（不经过总线接口）直接用电信号触发 CPU 的某个<strong>引脚</strong>，这个信号代表一种<strong>中断（interrupt）</strong>，通知 CPU 该扇区已被复制，此时暂停的程序继续执行；</li>
</ul>
<h3 id="8-2-Locality"><a href="#8-2-Locality" class="headerlink" title="8.2 Locality"></a>8.2 Locality</h3><p>无论是 8.1.2 中介绍的各自存储介质在物理层面上的性能约束，还是 8.1.3 中介绍的数据读取流程上的性能限制，都是计算机存储系统需要解决的重要问题，否则，在硬件上计算机就难以继续提升运行速度了。</p>
<p>其实，弥补 CPU 和内外存读写速率之间差距的机制之一就是<strong>程序的基本属性之一：局部性（locality）</strong>。</p>
<p>局部性原则：程序倾向于使用 “<strong>内存地址接近或等于最近使用过的数据/指令地址的</strong>” 那些数据和指令。</p>
<blockquote>
<p>原文：Programs tend to use data and instructions with addresses near or equal to those they have used recently.</p>
</blockquote>
<p>这个原则来源于程序编写的逻辑——<strong>当程序访问到某个内存地址上的数据，那么在不久的将来，有很大的可能程序会访问该数据项或者附近的数据项</strong>。</p>
<p>这种局部性有两种表现形式：</p>
<ul>
<li><p>时间局部性（Temporal Locality）：最近引用的存储器位置可能在不久的将来再次被引用；</p>
</li>
<li><p>空间局部性（Spatial Locality）：如果访问了一个存储器的位置，那么有很大可能在将来会访问一个临近的位置；</p>
</li>
</ul>
<blockquote>
<p>例子：识别代码中的局部性</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line"> sum += a[i];</span><br><span class="line"><span class="keyword">return</span> sum;</span><br></pre></td></tr></table></figure>
<p>这串代码中，有对<strong>数据的引用</strong>（Data references，转为汇编后会引用数据，通常只要有变量就有数据的引用）。</p>
<p>例如上面的数组 <code>a</code>，其元素在内存上连续，索引 i 每自增一个单位就访问一下（称为 stride-1 reference pattern），属于空间局部性；上面的变量 <code>sum</code> 在循环的每次迭代中都会被引用，属于时间局部性；</p>
<p>还有对<strong>指令的引用（Instruction references）</strong>，例如循环中每一次都会执行循环体的内容，属于时间局部性；再比如程序代码顺序执行，本身就属于空间局部性。</p>
</blockquote>
<p>不同编写方法的代码，其局部性不同。这就需要开发者训练观看的能力。举一个很简单的例子：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">sum_array1</span><span class="params">(<span class="type">int</span> a[M][N])</span> &#123;</span><br><span class="line">    <span class="type">int</span> i, j, sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; M; i++)</span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; N; j++)</span><br><span class="line">            sum += a[i][j];</span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">sum_array2</span><span class="params">(<span class="type">int</span> a[M][N])</span> &#123;</span><br><span class="line">    <span class="type">int</span> i, j, sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; N; j++)</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; M; i++)</span><br><span class="line">            sum += a[i][j];</span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们考虑对数据的引用，<strong>回忆 6.1 中对于 Nested Array 的内存排列的知识</strong>，数组数据连续排列且<strong>行优先</strong>，所以我们发现，使用 <code>sum_array2</code> 方式遍历数组，其<strong>数据相距距离很远</strong>，这意味着程序的局部性差于 <code>sum_array1</code>。而事实上，<code>sum_array2</code> 也真的会比 <code>sum_array1</code> 慢一个数量级；</p>
<blockquote>
<p>例题：请修改以下代码，使得它满足 stride-1 reference pattern（即更优的程序局部性）</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">sum_array_3d</span><span class="params">(<span class="type">int</span> a[M][N][N])</span> &#123;</span><br><span class="line"> <span class="type">int</span> i, j, k, sum = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; M; i++)</span><br><span class="line">     <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; N; j++)</span><br><span class="line">         <span class="keyword">for</span> (k = <span class="number">0</span>; k &lt; N; k++)</span><br><span class="line">             sum += a[k][i][j];</span><br><span class="line"> <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="8-3-Conclusions-for-8-1-amp-8-2"><a href="#8-3-Conclusions-for-8-1-amp-8-2" class="headerlink" title="8.3 Conclusions for 8.1 &amp; 8.2"></a>8.3 Conclusions for 8.1 &amp; 8.2</h3><p>没错，前面两节全部在为存储系统的层次结构<strong>做准备</strong>，之后我们才开始正式讨论 Memory Hierarchy。在此之前，我们先小总结一下前面的内容。</p>
<p>在本章开始，我们认识了计算机存储系统在硬件层面的两大组成：主存和外存。主存由 RAM（又分为 SRAM 和 DRAM）组成；外存则是硬盘（又分为机械硬盘、SSD）、可移动磁盘为主。</p>
<blockquote>
<p>广义的内存包括：主存（RAM）、全部 ROM、Cache（高速缓存存储器）；</p>
</blockquote>
<p>我们紧接着比较了 SRAM 和 DRAM 的特征、异同，以及它们所使用的场合；对于 ROM，我们了解了不同的 ROM 类型，还有闪存的定义。</p>
<p>在外存方面，我们详细介绍了机械磁盘的物理结构（磁盘控制器、盘面、柱面、磁道、扇区、记录区、承载量计算、访问耗时分析、逻辑块），并类比出功能相同、实现不同的固态硬盘物理结构（闪存翻译层、页、块）。</p>
<p>于是，我们从上面存储介质的物理结构中分析并得出 <strong>其数据访问模式的性能限制和优劣</strong>。</p>
<p>最后，我们分析了 <strong>CPU 访问主存</strong> 和 <strong>CPU 访问外存</strong> 的情况和流程，从中我们得知了在内存读取的流程中也存在着性能的限制或者说损失。</p>
<p>基于这些物理结构的限制，我们讨论出代码结构层面能够在一定程度上弥补这些性能鸿沟的性质：<strong>局部性</strong>。我们根据 <strong>存储设备的物理结构</strong> 和 <strong>数据存放的方式</strong>，可以设计写出更符合程序局部性的代码，这在一定程度上可以缓解 CPU 和内存之间访问的性能差距。</p>
<p>而观察代码的局部性，就需要对数据在内存中的 layout，还有储存设备的工作原理有一个很好的认识，这就是前几章、前几节的内容。</p>
<p><strong>这些存储介质的物理特性，和程序的局部性相辅相成，相得益彰，为人们提供一种 “怎样设计存储系统” 的建议和信息。</strong></p>
<p>接下来，我们将基于这些存储介质的物理性质，讨论在其上所建立的层次结构，和这些层次结构是如何抽象硬件，尽可能地为上层的计算机软件提供更连续完整的资源的。</p>
<h3 id="8-4-Memory-Hierarchy-amp-Idea-of-Caching"><a href="#8-4-Memory-Hierarchy-amp-Idea-of-Caching" class="headerlink" title="8.4 Memory Hierarchy &amp; Idea of Caching"></a>8.4 Memory Hierarchy &amp; Idea of Caching</h3><p>下图是计算机存储系统的一个层次结构图。</p>
<p>其中，寄存器是访问速度最快的存储结构，它在每个 CPU 时钟周期内都可以直接访问到（大小最小、数量很少、价格最贵、速度最快）；</p>
<p>接下来的是由 SRAM 组成的高速缓存存储器（Cache Memory），也处于 CPU 芯片内部，既不是主存，也不是寄存器；大小虽然是 MB 级，但已经比寄存器大多了。其中 3 层 Cache Memory 的具体结构将在下一章进行深入讨论；</p>
<p>再向下是 DRAM 组成的计算机的主存，一般你能看到的 “内存条” 就是它的组合结构，也是普通人经常说的 “内存”（狭义内存），一般从几个 G 到 几十 G 不等，程序运行内存（或者说后面要提到的<strong>虚拟内存</strong>）就是它的一部分；</p>
<p>最底层的像本地硬盘结构，甚至云端存储结构，空间一般都很大，但访问效率低下。</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/memory_hierarchy_example.png" height="400px"></p>
<p><strong>设计的核心：在 Memory Hierarchy 中，每一层都包含着从下一层所检索的数据</strong>（例如 CPU 寄存器保存着从 L1 高速缓存中取出的数据，依此类推）；</p>
<p>这样设计的原因是为了充分利用各个层级资源的特征，将整体数据访问效率最大化（<strong>底层是极大的数据池，却能够以极快的速度进行访问</strong>）。</p>
<p>这么做之所以有效，是因为 <strong>缓存思想（Caching）的存在</strong>。</p>
<p>这里所说的缓存，<strong>不是高速缓存存储器（Cache memories），而是一种思想</strong>。<strong>作为一个更小、更快的存储设备，充当更慢设备中数据的暂存区域、能更快访问的数据子集</strong>。例如，主存 可以看成是本地硬盘的 缓存，这样一旦从磁盘获取数据，就无需在磁盘上访问它，在上一个层级内存中访问，速度得到提升。依此类推，<strong>缓存的思想在 Memory Hierarchy 中逐级传播</strong>。</p>
<blockquote>
<p>第 k 层更快、更小的存储设备，就是第 k+1 层更慢、更大存储设备的 缓存。</p>
</blockquote>
<p>在真实场景中，每当程序访问一个不在缓存设备（第 k 层）中的数据，都会从第 k+1 层检索，并复制到第 k 层缓存起来。这是因为，<strong>根据程序的局部性</strong>，相较于第 k+1 层的设备，会更经常访问第 k 层设备中的数据，这就是 Memory Hierarchy 能最大化数据访问效率的原因。</p>
<hr>
<p>在详细介绍高速缓存存储器（狭义的 Cache）前，我们简单介绍一下<strong>缓存的实现</strong>，因为缓存思想存在于存储层次结构的每一层。</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/general_cache_concept.png" height="240px"></p>
<p>储存数据的下层设备的空间（k+1 层）通常被分为一个个固定大小的块（blocks），缓存设备和下层设备间传输的数据以块为单位进行。</p>
<blockquote>
<p>如果第 k+1 层是 Web 云端存储介质，那么 blocks 通常以文件形式传给磁盘（第 k 层，缓存设备）；</p>
<p>如果第 k+1 层是主存，那么 blocks 可能是以某个特定大小的数据块传给高速缓存存储器（第 k 层，缓存设备）；</p>
<p>……</p>
</blockquote>
<p>在任意时间点，第 k 层的缓存设备中的数据都是第 k+1 层设备数据的一个子集。</p>
<p>对于 CPU 请求一个位于第 k+1 层的某个位置的数据这种情况，则 CPU 会先去层级最高的设备中寻找（假设找到第 k 层），则有两种情况：</p>
<ul>
<li><p>如果恰好找到了（假设请求如下图绿色块 14 的数据），那么 CPU 就直接从缓存（第 k 层）中读走这个数据，无需向下请求数据，总体提升了效率。这种情况称为 <strong>Cache Hit</strong>（缓存命中）；</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/cache_hit.png" height="240px"></p>
</li>
<li><p>如果没有找到，那么 CPU 就需要从更下一层取得此数据块，并<strong>将它存放在缓存设备中</strong>。这种情况称为 <strong>Cache Miss</strong>（缓存不命中）；其本身又分为 3 个类型：</p>
<ul>
<li><p>Cold（compulsory）Miss：缓存为空，所以 Miss，不可避免；</p>
</li>
<li><p>Capacity Miss：由于较小的缓存空间而导致的不命中，通常是因为程序的工作集大于缓存空间所致。可以由增大缓存空间而减少；</p>
<blockquote>
<p>工作集（working set）：当前不断被程序访问的块，也即活跃的缓存块（active cache block）；</p>
</blockquote>
</li>
<li><p>Conflict Miss：由于大部分缓存设备（尤其硬件缓存）必须设计的比较简单，它限制了缓存块的放置位置（例如第 i 块必须放在 <code>i mod sizeof(Cache)</code> 的位置，很类似 hash table 的碰撞），这与缓存实现方式有关，也在下一章进一步讨论；</p>
</li>
</ul>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/cache_miss.png" height="240px"></p>
</li>
</ul>
<p>最后，我们总结一下缓存在存储系统各层级的实现情况：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/caching_in_hierarchy.png" height="400px"></p>
<blockquote>
<p>注：TLB（Translation Lookaside Buffer，后备缓冲）是一个在虚拟内存中使用的缓存，<strong>是虚拟地址翻译为物理地址的翻译过程的缓存</strong>；</p>
</blockquote>
<p>需要注意的是，<strong>各个层级的缓存究竟是由谁实现和管理的</strong>，这是缓存思想的一个重点，也能解释早在第 3 章的疑问——<strong>汇编代码中找不到管理高速缓存存储器的代码</strong> 的原因。</p>
<p>例如，当寄存器看作缓存设备时，是编译器决定用哪个寄存器、用多少个寄存器（怎么用的 conventions 是 ABI 决定的）；</p>
<p>综上，缓存思想存在于计算机系统的几乎每个用到数据 I/O 的地方。</p>
<p>下一章将讨论 Memory Hierarchy 中一个具体的部分 <strong>高速缓存存储器</strong>，来深入了解缓存思想。</p>
<h2 id="Chapter-9-Cache-Memories"><a href="#Chapter-9-Cache-Memories" class="headerlink" title="Chapter 9. Cache Memories"></a>Chapter 9. Cache Memories</h2><blockquote>
<p>本章讲述 Memory Hierarchy 缓存思想中的重要一个体现：高速缓存存储器（Cache memories），它介于寄存器和内存之间，充当缓存设备的角色。</p>
</blockquote>
<p>回忆上一章的内容，高速缓存器本质上是一种由 SRAM 组成的、由硬件直接管理的小型缓存存储设备：<strong>Cache memories are small, fast SRAM-based memories managed automatically in hardware</strong>.</p>
<p>它一般封装于 CPU 芯片中，几乎和寄存器距离 CPU 核心同样近（只是由于电路存取特性导致其慢于寄存器），存储主存中被频繁引用的数据块。</p>
<h3 id="9-1-General-Cache-Organization"><a href="#9-1-General-Cache-Organization" class="headerlink" title="9.1 General Cache Organization"></a>9.1 General Cache Organization</h3><p>那么硬件是如何管理高速缓存存储器中的数据，在 CPU 需要的时候进行寻找呢？我们首先需要借鉴<strong>层次架构中一般的缓存模型</strong>，它们共同有一种缓存的管理方式和 layout；</p>
<p>首先，缓存本身就需要极速，这意味着设计缓存机制必须<strong>以非常严格且简单的方式去组织缓存模型</strong>，便于各个设备层级间进行查找。于是人们设计了下面的缓存数据组织形式：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/general_cache_organization.png" height="350px"></p>
<p>缓存空间中一般包含 $S=2^s$ 个数据组（set），每一组又包含 $E=2^e$ 个数据行（line，图中<strong>横着排列</strong>），每一数据行由大小为 $B=2^b$ bytes（B binary digits）的数据区块和一个 tag 区、一个 valid bit 组成；现在解释一下目前可能有的疑惑：</p>
<ul>
<li>valid bit 指示当前缓存数据行中的数据实际上也真实存在于下层的存储介质中，可以直接使用（例如第一次打开机器的时候，这些数据区块位置上是随机 bits，因此这些 valid bit 会提示数据区块无效）；</li>
<li>tag 位（标记位）编码了这串数据位于下层存储介质的位置，在 CPU 搜索时有用；</li>
<li>为何无论是组数、数据行数还是每个数据行中的字节数都是 2 的幂次呢？<strong>这是一个非常重要的点。因为，缓存空间按照 内存地址的数码的各个位 来直接对应该内存数据应该存放的位置</strong>。这个比较抽象，后面的例子就会慢慢理解。</li>
</ul>
<h3 id="9-2-Read-Cache"><a href="#9-2-Read-Cache" class="headerlink" title="9.2 Read Cache"></a>9.2 Read Cache</h3><p>那么缓存是如何被读取的？详细数据结构（和具体存储设备有关）又是什么样子的？</p>
<p>实际上，程序在运行中可能请求了下层存储介质中某个位置的数据，我们<strong>以高速缓存存储器和主存间查找数据的关系为例</strong>。步骤如下：</p>
<ul>
<li>假设程序指令要求引用主存中虚拟内存的某个地址（设为 <code>X</code>）的数据，那么 CPU 会向高速缓存存储器请求 <code>X</code> 地址下的值；</li>
<li>这个请求的地址会被 高速缓存存储器 <strong>直接用来查找缓存存放的位置（即这个地址的数据存放在）</strong>。其中 <code>X</code> 会被 高速缓存存储器 <strong>解析成</strong>如下图所示的结构（<strong>这就是为什么上面的 <code>S</code>、<code>E</code>、<code>B</code> 都是 2 的幂</strong>。看着这张图你能想明白吗？还不能明白的话，后面会有更具体的例子）：</li>
</ul>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/addr_B.png" height="125px"></p>
<ul>
<li>高速缓存存储器 <strong>首先 extract <code>X</code> 中 s bits 的 <code>set index</code></strong>（缓存组索引）看作为 unsigned int，用它找到缓存空间中特定的组（和数组索引很像）；</li>
<li>高速缓存存储器 接着<strong>并行检查（依赖于硬件电路的检查机制）</strong>该组中所有的数据行，将 tag 字段与每个数据行中的 tag 进行比较。如果找到了相同的 tag，那么再检查 valid bit 是否指示有效。所以会出现以下情况：<ul>
<li><strong>情况一</strong>：该组的数据行中不存在 tag 与 <code>X</code> 一致的行，<strong>说明请求的数据块不在缓存中（Cache miss）</strong>；</li>
<li><strong>情况二</strong>：该组的数据行找到了 tag 与 <code>X</code> 一致的行，但 valid bit 指示无效，<strong>说明请求的数据块无效，当前也不在缓存中（Cache miss）</strong>；</li>
<li><strong>情况三</strong>：该组的数据行找到了 tag 与 <code>X</code> 一致的行，并且 valid bit 指示有效，<strong>Cache hit</strong>！</li>
</ul>
</li>
<li>如果是 cache hit，那么<strong>extract</strong> <code>X</code> 中 b bits 的 <code>block offset</code>，从该数据行的数据区块开头地址加上这个 offset，将得到的地址再数据行中剩余部分规定大小读出，直接传给 CPU，结束查找过程；</li>
<li>如果是 cache miss，那么高速缓存存储器会放弃查找，将原本的请求地址 <code>X</code> 传给下一级存储设备（主存），那么查找工作交给主存（重复上面类似的步骤）。<strong>注意，当主存找到数据向上提交时，再次给到高速缓存存储器</strong>，将数据放在高速缓存存储器的应该是 <code>X</code> 的位置<strong>缓存起来</strong>（通常会覆盖相同位置的其他数据），然后高速缓存存储器再将数据向上提交给 CPU；</li>
</ul>
<p>总体呈现出 <strong>“逐层向上缓存数据，逐层向下查找数据”</strong> 的形式。</p>
<h4 id="9-2-1-Direct-Mapped-Cache-Simulation"><a href="#9-2-1-Direct-Mapped-Cache-Simulation" class="headerlink" title="9.2.1 Direct-Mapped Cache Simulation"></a>9.2.1 Direct-Mapped Cache Simulation</h4><p>下面详细解释上面的步骤。为了便于理解，我们首先从简单的情况讨论，<strong>当每一个缓存组只包含一个数据行的情况，这种情况被称为 “直接映射”（Direct-Mapped Cache Simulation）</strong>：</p>
<p>假设某个机器的内存空间大小 M = 16 bytes（可以用 4-bit digit 代表地址），缓存空间中含有 4 个组（S = 4），每个组含有一个数据行（E = 1），每个数据行含有 2 bytes 的数据区块（B = 2）。</p>
<p>在数据区块中，block offset 的长度为 1 byte（b = 1，因为数据区块只有 2 bytes，一般有 $B=2^b$），set index 的长度为 2 bytes（s = 2，因为缓冲区只有 4 组数据组，有 $S=2^s$）；</p>
<p>现在程序开始运行的时候，分别请求内存地址（$X$）为 0、1、7、8、0 的 1 byte 数据；</p>
<p>现在，高速缓存存储器中的所有数据行的 valid bit 都是 0（假设 0 代表无效，1 代表有效），并且开始接受 CPU 请求内存地址 $X = 0 = 0000_2$ 的数据 的请求。</p>
<p>首先，$X$ 的 block offset <strong>就是中间 2 bit</strong>，<code>00</code>，所以在 <code>set 0</code>（第 0 组）中寻找；然后，将 $X$ 的 tag 位（即最左边的 1 bit，0）与 <code>set 0</code> 的 tag 比较（是随机数），再看 valid bit 是 0，所以 cache miss（cold miss），如下动画（本人不会 Acrobat Animate，比较粗糙）：</p>
<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">
    <iframe src="imgs/directMappedCacheSimulation_part1.mp4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" allowfullscreen="true" style="position: absolute; width: 50%; height: 50%; left: 0; top: 0;"> </iframe>
</div>


<p>思考两个问题，第一个，为什这里的 tag 是 0 ？这是因为，我们在给定的 set offset 下（组相同），前面的 t bit（t=1）的 tag 位<strong>只是用来区分数据行</strong>的，<strong>借助了原内存地址 <code>X</code> 的前 t bits 数据</strong>而已，没有实际意义。</p>
<p>第二个，为什么这里要从 main memories 中同时读入 0、1 地址的数据？也就是说，为什么设定 <code>B == 2</code> 呢？<strong>这是因为，除去 set offset 的 2 bits、tag 的 1 bit，剩下内存地址 <code>X</code> 数码还有 1 bit 留给 block offset</strong>，因此 <code>X</code> 只能在该组的数据行中索引 2 bytes 的数据。</p>
<p>细细体会上面的话，你会发现这就是缓存空间如此设置、<code>X</code> 如此解析的原因（这里设计的和 IEEE 浮点数表示法一样巧妙，不容易用语言描述）。</p>
<hr>
<p>好了，又有同学会好奇了，既然这些索引本身没有意义，只是借助了原地址的数码，<strong>那为什么设计缓存索引的人一定要 <code>set index</code> 在中间、tag 在最前面、block index 在最后面呢</strong>？</p>
<p>这个问题非常有水平，这和<strong>二进制数码的变化方式有关</strong>。我们这里就分析对比 2 种解释 <code>X</code> 地址的方式：</p>
<ul>
<li>Middle Bits Indexing：就是上面的 <code>X</code> 的结构，Tag 在前、<code>Set index</code> 在中间、<code>Block index</code> 在最后；</li>
<li>High Bits Indexing：<code>Set index</code> 在前、Tag 在中间、<code>Block index</code> 在最后；</li>
</ul>
<p>我们接下来<strong>将缓存空间的组标为不同颜色，再把内存中将要分配到哪一组的数据块填上相同的颜色</strong>，发现结果如下：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/middle_bits_indexing.png" width="360px"><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/high_bits_indexing.png" width="360px"></p>
<p>我们发现，<strong>如果用 high bits indexing，那么内存地址相近的内存区域很容易被分配到相同的缓存组中，根据<u>空间局部性</u>，这样做会导致发生 conflict miss 的概率大大增加</strong>。所以，在缓存效率上，middle bits indexing 是优于 high bits indexing 的。其他情况同理。</p>
<p>这就是设计者们为什么要如此设计内存地址 <code>X</code> 在缓存中的这种解析方法。</p>
<hr>
<p>继续看接下来的过程动画：</p>
<div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;">
    <iframe src="imgs/directMappedCacheSimulation_part2.mp4" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" allowfullscreen="true" style="position: absolute; width: 50%; height: 50%; left: 0; top: 0;"> </iframe>
</div>



<p>我们发现，5 次访问中，有<strong>高达 4 次的 cache miss</strong>。后面 2 次的 cache miss 都是 conflict miss，完全能够由 提高每组的数据行数（<code>E</code> 的大小）来避免。<strong>因此，缓存结构中 <code>E</code> 的大小越大越好（也就是每组中的数据行越多越好）</strong>。但是我们前面提到，一个组中各个数据行<strong>使用并行比较</strong>，这个操作依赖硬件的多路判断——<strong>也就是说，<code>E</code> 越大，硬件电路越复杂，硬件越贵</strong>。所以真实计算机硬件中会进行取舍，选择一个特定的 <code>E</code> 值。</p>
<blockquote>
<p>当代（21 世纪初）市面上的常见的单组中数据行数目取值 <code>E = 8</code>，最大有 <code>E = 16</code>，是 Intel 的 16 路相联 L3 三级缓存。</p>
</blockquote>
<p>事实上，<code>B</code>（数据区块的大小，block size）也是越大越好，因为越大越可以利用局部性，提升缓存命中概率。但 <code>B</code> 受限于<strong>两个因素</strong>：一是<strong>硬件成本</strong>（例如 Cache memories 由 昂贵的 SRAM 组成），二是<strong>块复制的时间代价</strong>，因为如果想要把很大的数据区块从内存挪至缓存中，也是一个不小的开销。</p>
<p>综合上面的考虑，设计者真正确定缓存空间各个参数的步骤如下：</p>
<ol>
<li><strong>确定合适的数据区块（就是在数据行中的那个字段）大小 <code>B</code></strong>（通常被称为<strong>固定的缓存高级设计参数</strong>。Intel 一般 64 bytes）；</li>
<li>根据实际应用场景和硬件成本情况<strong>确定大致的缓存空间总大小</strong>（也是固定的缓存高级设计参数之一）；</li>
<li>根据硬件和实际情况<strong>确定数据组的关联性（associativity，即一个数据组中有多少数据行）<code>E</code></strong>；</li>
<li>由 1、2、3 就能计算出大致的<strong>缓存数据组数（<code>S</code>）</strong>。</li>
</ol>
<blockquote>
<p>最极端的情况是 <strong>全相关联高速缓存（Fully Associative Caches）</strong>，缓存空间中只有一个组（<code>S = 1</code>，所有数据行在一个组中），这个时候如果能够并行比较，那么缓存效率是极高的。但是通常由于上述原因，我们大多数时候只能在<strong>软件级别的缓存 或者 在主存和硬盘之间的缓存模式（因为硬盘读取时间开销很大，值得我们使用复杂算法来获得更高的缓存效率，我们在“虚拟内存”一章会讨论）</strong>中找到这种组织形式。</p>
</blockquote>
<h4 id="9-2-2-E-Way-Set-Associative-Cache-Simulation"><a href="#9-2-2-E-Way-Set-Associative-Cache-Simulation" class="headerlink" title="9.2.2 E-Way Set Associative Cache Simulation"></a>9.2.2 E-Way Set Associative Cache Simulation</h4><p>除了直接映射，还有一个稍微复杂点的例子，<strong>当不改变上面例子中的缓存空间大小，讨论每个缓存组包含 2 个数据行的情况，这也被称为 “2-Way Set Associative Cache（2 路相连高速缓存）Simulation”</strong>。</p>
<p>这个时候 tag 变为 2-bit，set index 变为 1-bit，block index 还是 1-bit；</p>
<p>我们有类似上面 Directed-Mapped Cache Simulation 相近的步骤，如下图：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/2_way_associative_cache_sim.png" height="300px"></p>
<blockquote>
<p>注意到一点，当关联性大于 1 的时候，同一个数据组中可能不同的数据行的 tag 可能是相同的，那么当我们想要覆盖数据的时候，就涉及到了<strong>选择覆盖</strong>的问题，它可以通过设计算法来完成。</p>
<p>根据<strong>局部性原理的逆定理（通常成立）</strong>，如果一个数据长时间不被引用，那么它在未来的某个时间也不太可能被引用。所以，最常见的算法是 <strong>“最近最少使用” 策略（Least Recently Used Strategy）</strong>，这种算法一般不需要额外的 bit 存储数据，只是从硬件层面跟踪在缓存中数据的使用频率（如按序保存虚拟时间戳），确保无效的数据行最先被覆盖，然后是使用频次更低的数据先被覆盖。</p>
</blockquote>
<h3 id="9-3-Write-Cache"><a href="#9-3-Write-Cache" class="headerlink" title="9.3 Write Cache"></a>9.3 Write Cache</h3><p>事实上，真正要更改某些数据恐怕比读数据更难，因为我们的缓存机制通常会产生多份数据的复制品。例如层级从低到高：硬盘、主存、L1 / L2 / L3 高速缓存，其中可能包含了同一份数据的副本。</p>
<p>于是在程序要求修改内存（仍然以 高速缓存存储器 和 内存 这对存储同样有 2 种情况 <strong>write-hit</strong> 和 <strong>write-miss</strong>：</p>
<p>如果遇到 <strong>write-hit</strong>（要写的内存数据就在缓存设备中）的情况，由于数据分布特殊性，那么有两种处理方法：</p>
<ul>
<li><p><strong>Write-through</strong>：立即将数据写入缓存（即覆盖当前行）并主动刷新（flush）到内存；</p>
<ul>
<li>优势：内存始终是缓存的镜像，二者数据同步；</li>
<li>劣势：从 CPU 到 内存，时间开销必然很大；</li>
</ul>
</li>
<li><p><strong>Write-back</strong>：先把数据写入缓存，但不立即刷新，直到下一个数据要覆盖这个数据行的时候，才更新到内存中（defer write to memory until replacement of line，<strong>只是尽可能推迟了写入内存的时间</strong>）；</p>
<ul>
<li><p>优点：如果数据的 dirty bit 指示没有被污染时，那么覆盖这一行就不用执行 write 操作；</p>
</li>
<li><p>特点：<strong>这种方法需要一个标记（dirty bit），用来指示当前数据和内存中是否相同，即是否有被修改过</strong>；</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/dirty_bit.png" height="100px"></p>
</li>
<li><p>劣势：必然存在 <strong>write-miss</strong> 现象，因为如果修改的内存数据不在缓存中，那么就需要与内存交互；</p>
</li>
</ul>
</li>
</ul>
<p>如果遇到的是 <strong>write-miss</strong>，那么也有 2 种方法（<strong>和 write-hint 是对称的操作</strong>）：</p>
<ul>
<li><strong>Write-allocate</strong>：写分配，在 write-miss 后，<strong>先将原数据从内存读入缓存，转换为 write-hit 的情况，再 write-back（仅修改缓存 + dirty bit）</strong>；</li>
<li><strong>No-write-allocate</strong>：直接写入内存，不加载到缓存（缓存中没有这个数据所在的数据行，因为本来就是 write-miss）；</li>
</ul>
<p>一般情况下，由于对称性，人们一般选择 “<strong>write-back + write-allocate</strong>” 或 “write-through + no-write-allocate” 的策略中的其中一对（根据实际情况）；</p>
<h3 id="9-3-The-Hierarchy-of-Cache-Memories"><a href="#9-3-The-Hierarchy-of-Cache-Memories" class="headerlink" title="9.3 The Hierarchy of Cache Memories"></a>9.3 The Hierarchy of Cache Memories</h3><p>讨论完了缓存读写的具体的逻辑实现，我们再来看看实际上硬件是如何对应这些实现的。同样以 高速缓存存储器 为例。<strong>到目前为止，我们都假设计算机系统中只有一个高速缓存存储器的缓存空间</strong>，但是实际上，早在前面第 8 章中就介绍了，一般计算机中有 L1、L2、L3 3 类 Cache memories。它们在硬件上是如何设置和协调的呢？</p>
<p>以 Intel Core i7 芯片为例，它的高速缓存层次结构如下：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/intel_i7_cache_hierarchy.png" height="300px"></p>
<p>如图，一般情况下，现代 CPU 有 4（桌面系统）/ 8 ~ 12（服务器类系统）个核，<strong>每个核可以各自并行，独立执行各自的指令流</strong>，每个处理器内核可以包含<strong>各自的</strong>通用寄存器（位于存储系统层次结构 L0）.</p>
<p>在其中，每个核还会有 2 种 L1 Cache。其中一种是 <strong>d-cache（data cache，1 级数据高速缓存器）</strong>，另一种是 <strong>i-cache（instruction cache，1 级指令高速缓存器</strong>）。它们的读取时延（4 个时钟周期）仅次于寄存器，正因速度和成本的关系，它们的大小非常小，只有约 32 KB；它们的关联性一般是 8 路（一个缓存组中有 8 个数据行）；</p>
<p>在 L1 Cache 的下一层是 L2 Cache（L1 和），只有一种联合的高速缓存器（unified cache，同时包含某个核的数据和指令的缓存），读取速度稍慢（10 个时钟周期）于 L1 Cache，也是 8 路关联性，不过大小稍微大一点，有 256 KB；</p>
<p>再下层的 L3 Cache 不在 CPU 的核内，是被所有核心所共享的联合高速缓存存储器。8 bytes 大小、16 路关联性，但访问时延长达 40 ~ 75 个时钟周期；</p>
<p><strong>它们间的关系和之前所说的各个层级的缓存设备一模一样，都是 “逐层向上缓存数据，逐层向下查找数据”</strong>。</p>
<p>根据这些实际的物理结构，我们考虑一下高速缓存存储器的性能和损耗情况。我们建立如下的衡量指标（Cache Performance Metrics）：</p>
<ul>
<li>Miss Rate:  cache memories 不可避免的会发生 cache miss，这就是 cache memories 性能可能产生损耗的原因之一；<ul>
<li>定义：缓存未命中次数 / 总访问次数（ = <strong>1 - hit rate</strong>）；</li>
<li>一般情况下，L1 Cache 的 未命中率在 3 ~ 10%，L2 Cache 在 1% 左右，<strong>和缓存大小紧密相关</strong>（<strong>如此低的 Miss Rate 得益于 程序局部性</strong>）；</li>
</ul>
</li>
<li>Hit Time：虽然有时缓存成功命中，但从缓存的数据行中传输到处理器中仍然需要时间。<ul>
<li>定义：从检查标志位，到 hit 直接返回 block 中的缓存数据所需时间；</li>
</ul>
</li>
<li>Miss Penalty：由于 Miss Rate，从内存传输到缓存和 CPU 中通常会花费更多时间；<ul>
<li>定义：从检查标志位，到 miss、从内存读取数据，直到数据传回 CPU 所需时间；</li>
<li>一般情况下从主存中读取数据大约花费 50 ~ 200 个时钟周期（如果在其他的存储系统的层次中，花费可能大得多）；</li>
</ul>
</li>
</ul>
<p><strong>事实上，这些一次两次看似影响不大的 Cache miss 和 hit，对系统性能影响相当大！数学证明表明，99% 的 hit rate 的系统性能比 97% 的 hit rate 对应的系统性能迅速 2 倍</strong>！</p>
<h3 id="9-4-Performance-Impact-of-Cache"><a href="#9-4-Performance-Impact-of-Cache" class="headerlink" title="9.4 Performance Impact of Cache"></a>9.4 Performance Impact of Cache</h3><h4 id="9-4-1-Writing-Cache-Friendly-Code-Ⅰ"><a href="#9-4-1-Writing-Cache-Friendly-Code-Ⅰ" class="headerlink" title="9.4.1 Writing Cache Friendly Code Ⅰ"></a>9.4.1 Writing Cache Friendly Code Ⅰ</h4><p>考虑上一节惊人的缓存性能的情况，我们确实应该写出一些 Cache Friendly 的代码，<strong>这是优化代码性能的一个重要方面</strong>。在分析了缓存的特性和程序局部性之后，我们可以这样来充分利用高速缓存带给程序的性能提升：</p>
<ul>
<li><p>关注<strong>经常被调用的</strong>函数中<strong>执行次数最多的内层循环</strong>的性质，积极对它进行算法层面优化；</p>
</li>
<li><p>尽量使用重复的变量引用，而不是很多的全局变量（利用了时间局部性，减少 cache miss 的可能）；</p>
<blockquote>
<p>它和 第 15. 章的 CSE 优化不冲突，后者是尽量避免 Memory Alias；</p>
</blockquote>
</li>
<li><p>尽量使用 stride-1 reference patterns（或者说<strong>程序循环的步长尽量小</strong>，尤其是逐个访问数组元素，这就将 cache block 的优点发挥了出来，利用了空间局部性，减小 cache miss 的可能）；</p>
</li>
</ul>
<p><strong>总结：我们分析缓存的组织原理和特性，是进一步定量地（如上面的指标）去体现、印证程序局部性的概念</strong>。</p>
<h4 id="9-4-2-The-Memory-Mountain"><a href="#9-4-2-The-Memory-Mountain" class="headerlink" title="9.4.2 The Memory Mountain"></a>9.4.2 The Memory Mountain</h4><p>之前简单地对缓存组成的分析，让我们看到了关注缓存能够对程序带来较显著地性能影响。那么这节我们更深入地去探究缓存对程序性能的影响。</p>
<p>首先引入一个概念：</p>
<ul>
<li>Read throughput（吞吐量，或者说 read bandwidth，读带宽）：<strong>单位时间内从内存中读取数据的最大字节数</strong>，单位 MB/s；</li>
</ul>
<p>于是，我们可以绘制一个 <strong>时间局部性、空间局部性 关于 机器吞吐量的三维坐标图（存储器山）</strong>，以此展示缓存对程序性能的重要影响。</p>
<p>其中，我们以访问数组的程序为例。我们将遍历数组的步长作为衡量程序空间局部性的指标（步长越大，空间局部性越小），将一次读取数组元素数量作为衡量程序时间局部性的指标（一次取出的数据越多，访问到相同地址数据的机会越小，时间局部性越小）；</p>
<p>如图：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/memory_mountain.png" height="350px"></p>
<p>我们<strong>从读取数据量 size 的方向</strong>看图，会发现 memory mountain 有一个个像山脊一样的结构，这恰好对应了从 L1 到 Memories 的数据引用的平均性能（小的数据量更有可能在每次遍历时放在同一个缓存的 block 中，发生 cache miss 的机会就更小，只需要依靠更接近寄存器层级的缓存设备就能得到答案）；</p>
<p>而<strong>从数组访问步长 stride 的方向</strong>看图，会发现随着步长的增加，整体有一个负向的斜率。而随着步长大到一定程度，负向的斜率趋于平缓，这是因为<strong>步长大过了缓存 block size，导致几乎每次都会存在 Cache miss，就很难得到缓存的增益了</strong>。</p>
<h4 id="9-4-3-Writing-Cache-Friendly-Code-Ⅱ-Rearranging-loops-to-improve-spacial-locality"><a href="#9-4-3-Writing-Cache-Friendly-Code-Ⅱ-Rearranging-loops-to-improve-spacial-locality" class="headerlink" title="9.4.3 Writing Cache Friendly Code Ⅱ - Rearranging loops to improve spacial locality"></a>9.4.3 Writing Cache Friendly Code Ⅱ - Rearranging loops to improve spacial locality</h4><p>借助上面对于 memory mountain 的进一步分析，我们还可以想到更多的具体<strong>利用缓存来优化程序性能的方法</strong>。</p>
<p>例如，我们<strong>以矩阵乘法运算为例</strong>，我们假定以下的条件：</p>
<ul>
<li>N × N 方阵，元素为 double（8 bytes）类型；</li>
</ul>
<p>那么按照正确的一般矩阵相乘的方法，总单位运算次数 $O(N^3)$；</p>
<p>事实上，计算的一般方法有许多种（但都是 结果矩阵 $C=(c_{ij})_{N\times N}$ 的元素 $c_{ij}=a_{ik}\cdot b_{kj}$），我们<strong>这里着重讨论缓存的效率受代码安排的影响，也即，什么样的矩阵乘法最能充分利用缓存</strong>。</p>
<p>首先来对不同策略的矩阵乘法分析 Miss Rate：</p>
<ul>
<li>前提假设<ul>
<li>机器缓存空间的 <strong>块大小（<code>B</code>）为 32 Bytes（能够一次性放下 4 个 double 数据）</strong>；</li>
<li>矩阵维度 <code>N</code> 非常大（$\dfrac{1}{N}\approx0$）;</li>
<li>缓存空间的总大小不足以装下矩阵的多个行；</li>
</ul>
</li>
<li>分析方法：<strong>检查内层循环的函数访问模式</strong>（因为外层循环次数不可避免）；</li>
</ul>
<p>由于运算的方式固定，我们可以通过更换内外层循环顺序（共 $3!=6$ 种）来看究竟哪种方法最好。</p>
<p>在分析前，先再次回顾一下 C 中数组的 memory layout：</p>
<ul>
<li>二维数组的<strong>至少每一行的数据空间是 contiguous 的</strong>，并且<strong>行优先（row major）</strong>；</li>
<li>stride-1 逐个访问数组行的方法最能利用 spacial locality，它的 $miss\space rate=\dfrac{sizeof(a_{ij})}{B}$，其中 $B$ 是缓存空间的块大小；</li>
<li>stride-1 逐个访问较大数组列的方法完全无法利用 spacial locality，因为 每一列同一行的元素一定不在同一个缓存数据块中（之前已经假设 “缓存空间的总大小不足以装下矩阵的多个行”），因此 miss rate = 1（100% cache miss）；</li>
</ul>
<p><strong>情况 1：先固定 i（A 的行），再固定 j（B 的列），最后遍历 k（A 第 i 行每一列、B 第 j 列每一行）</strong></p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/cache_analysis_matrix_multiply_ijk.png" height="200px"></p>
<p>这种情况下，<strong>对每一个最内层循环</strong>：</p>
<ul>
<li>每次要求从内存中取出 A 矩阵的同行相邻元素，<strong>miss rate = 8 / 32 = 0.25</strong>；</li>
<li>每次要求从内存中取出 B 矩阵的同列相邻元素，<strong>miss rate = 1</strong>；</li>
<li>每次要求从内存中取出 C 矩阵的一个元素，所以对单个元素而言 <strong>miss rate 近似为 0</strong>；</li>
</ul>
<p>ℹ 平均每次内层循环<strong>约加载 2 次数据，存储 0 次，cache miss 次数 1.25 次</strong>；</p>
<p>这种情况与 <strong><code>jik</code></strong> 顺序的情况相同；</p>
<p> <strong>情况 2：先固定 k（B 的行），再固定 i（A 固定位置 第 i 行 第 k 列），最后遍历 j（C 的第 i 行每一列）</strong></p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/cache_analysis_matrix_multiply_kij.png" height="175px"></p>
<p>这种情况下，<strong>对每一个最内层循环</strong>：</p>
<table>
    <tr>
        <th>Op Matrix</th>
        <td>A</td>
        <td>B</td>
        <td>C</td>
    </tr>
    <tr>
        <th>Miss Rate</th>
        <td>0.0</td>
        <td>0.25</td>
        <td>0.25</td>
    </tr>
</table>


<p>ℹ 平均每次内层循环<strong>约加载 2 次数据，存储 1 次，cache miss 次数 0.5 次</strong>；</p>
<p>这种情况与 <strong><code>ikj</code></strong> 顺序的情况相同；</p>
<p><strong>情况 3：先固定 j（C 的第 j 列每一行），再固定 k（A 的第 k 列），最后遍历 i（固定 B 遍历 C 的 列）</strong></p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/cache_analysis_matrix_multiply_jki.png" height="175px"></p>
<p>这种情况下，<strong>对每一个最内层循环</strong>：</p>
<table>
    <tr>
        <th>Op Matrix</th>
        <td>A</td>
        <td>B</td>
        <td>C</td>
    </tr>
    <tr>
        <th>Miss Rate</th>
        <td>1.0</td>
        <td>0.0</td>
        <td>1.0</td>
    </tr>
</table>


<p>ℹ 平均每次内层循环<strong>约加载 2 次数据，存储 1 次，cache miss 次数 2.0 次</strong>；</p>
<p>这种情况与 <strong><code>kji</code></strong> 顺序的情况相同；</p>
<hr>
<p>综合上面的三种情况，我们进行实际的测试，发现结果如我们所料：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/core_i7_matrix_multiply_perf.png" height="300px"></p>
<p>事实证明，<strong><code>kij/ikj</code> 遍历方法（固定 A / B 的位置，遍历剩下一个运算矩阵的行，来得到结果矩阵的行）是最能利用 cache memories 的优势的方法</strong>，而我们最常用的 <code>ijk</code> 方法却不是最好的方法。</p>
<h4 id="9-4-4-Writing-Cache-Friendly-Code-Ⅲ-Using-blocking-to-improve-temporal-locality"><a href="#9-4-4-Writing-Cache-Friendly-Code-Ⅲ-Using-blocking-to-improve-temporal-locality" class="headerlink" title="9.4.4 Writing Cache Friendly Code Ⅲ - Using blocking to improve temporal locality"></a>9.4.4 Writing Cache Friendly Code Ⅲ - Using blocking to improve temporal locality</h4><p>上一节的例子主要以矩阵乘法为例，从提升<strong>空间局部性</strong>的层面来充分利用缓存、提示程序缓存效率。本节将从另一个角度——提升程序<strong>时间局部性</strong>来讨论如何写出缓存友好的代码。</p>
<p>再举一个针对矩阵乘法的例子。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">c = (<span class="type">double</span> *) <span class="built_in">calloc</span>(<span class="keyword">sizeof</span>(<span class="type">double</span>), n*n);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Multiply n x n matrices a and b */</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">mmm</span><span class="params">(<span class="type">double</span> *a, <span class="type">double</span> *b, <span class="type">double</span> *c, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i, j, k;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j++)</span><br><span class="line">            <span class="keyword">for</span> (k = <span class="number">0</span>; k &lt; n; k++)</span><br><span class="line">                c[i*n + j] += a[i*n + k] * b[k*n + j];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于上面的乘法而言，我们作如下假设：</p>
<ul>
<li>机器缓存空间的 <strong>块大小（<code>B</code>）为 64 Bytes（能够一次性放下 8 个 double 数据）</strong>；</li>
<li>矩阵维度 <code>N</code> 非常大（$\dfrac{1}{N}\approx0$）;</li>
<li>缓存空间的总大小不足以装下矩阵的多个行；</li>
</ul>
<p>在这种情况下，最内层的循环中，每一个循环的 cache miss 平均次数为：$\dfrac{n}{8}+n=\dfrac{9}{8}n$，于是总的 cache miss 的数量在 $\dfrac{9n^3}{8}$ 左右，显然，这样的 cache miss 数量会显著影响程序性能和对缓存的利用。于是，一种利用时间局部性的方法就出现了：</p>
<p><strong>我们在每次内存循环取矩阵乘法的 $C$ 的单元的时候，将单独取一个改为选取一个 block（小型块），如图所示，block 的宽度为 $B$：</strong></p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/multi_simple.png" height="150px"></p>
<p>改为：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/multi_block.png" height="150px"></p>
<p>即计算代码改为：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">c = (<span class="type">double</span> *) <span class="built_in">calloc</span>(<span class="keyword">sizeof</span>(<span class="type">double</span>), n*n);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Multiply n x n matrices a and b */</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">mmm</span><span class="params">(<span class="type">double</span> *a, <span class="type">double</span> *b, <span class="type">double</span> *c, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> i, j, k;</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; i+=B)</span><br><span class="line">            <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j+=B)</span><br><span class="line">                <span class="keyword">for</span> (k = <span class="number">0</span>; k &lt; n; k+=B)</span><br><span class="line">                    <span class="comment">/* B x B mini matrix multiplications */</span></span><br><span class="line">                    <span class="keyword">for</span> (i1 = i; i1 &lt; i+B; i1++)</span><br><span class="line">                        <span class="keyword">for</span> (j1 = j; j1 &lt; j+B; j1++)</span><br><span class="line">                            <span class="keyword">for</span> (k1 = k; k1 &lt; k+B; k1++)</span><br><span class="line">                                c[i1*n+j1] += a[i1*n + k1]*b[k1*n + j1];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个时候我们再次分析 cache miss 的情况。</p>
<p>假设选取的 $B$ 的大小能够被缓存利用：$3B^2\lt C$，那么：</p>
<ul>
<li><p>每一个 sub-block（子块）内部的 cache miss 数量：$\dfrac{B^2}{8}$；</p>
</li>
<li><p>每一次行循环的 cache miss 数：$\dfrac{2n}{B}\cdot\dfrac{B^2}{8}=\dfrac{nB}{4}\sim O(nB)$；</p>
</li>
<li>总的 cache miss 数：$\dfrac{nB}{4}\cdot(\dfrac{n}{B})^2=\dfrac{n^3}{4B}$；</li>
</ul>
<p>总而言之，这样的改进并没有根本上提升算法的时间复杂度，但是它却能确确实实地减少常数级别的 cache miss 数量（$\dfrac{9}{8}n^3\rightarrow\dfrac{1}{4B}n^3$），在一定程度上达到提升时间局部性的效果。这样，只要我们选择满足 $3B^3\lt C$ 的最大的 $B$ 的取值，就能找到这种思路的最优计算方法。</p>
<p>为什么能够引起如此大的常数优化呢？主要是以下原因：</p>
<ul>
<li>我们在选取 block 的时候，相当于加载了一个地址上更相邻的、之后能被反复使用的变量，因为我们缩小了矩阵乘法的 $N$，逐个 block 攻破，这样的矩阵乘法更能利用时间局部性；<ul>
<li>输入数据 $3n^2$，计算 $2n^3$，而每个元素需要被使用 $O(n)$ 次；</li>
</ul>
</li>
</ul>
<h4 id="9-4-5-Cache-Performance-Summary"><a href="#9-4-5-Cache-Performance-Summary" class="headerlink" title="9.4.5 Cache Performance Summary"></a>9.4.5 Cache Performance Summary</h4><p>在 9.4 节中，我们通过几个例子了解到，<strong>虽然我们无法显式控制 cache 的存储方式，但是通过对于程序局部性的分析，我们可以更高效地利用 cache，从而提升程序允许效率。</strong>这主要可以从两个方面下手：</p>
<ul>
<li>使用 stride-1 reference pattern、关注内层循环的步长和方式，以提升程序的空间局部性；</li>
<li>多次使用相同的局部变量、分块访问，以提升程序的时间局部性；</li>
</ul>
<blockquote>
<p>注：中间 10 ~ 14 章单独作为一部分呈现，此处略过</p>
</blockquote>
<h2 id="Chapter-15-Program-Optimization"><a href="#Chapter-15-Program-Optimization" class="headerlink" title="Chapter 15. Program Optimization"></a>Chapter 15. Program Optimization</h2><blockquote>
<p>One of the themes for this chapter:</p>
<ul>
<li>去除程序不必要的工作、编写编译器友好代码、提升运行速度；</li>
<li>利用机器代码特性，针对特定机器对程序优化；</li>
</ul>
</blockquote>
<p>编译器无法理解一些内容，例如 int 数据类型可能只用到相当小的范围、procedure call 究竟是什么意思，等待。编译器只是针对一些特定情况，对照 “cookbook” 进行有选择地优化。其遇到复杂或者特殊情况的 “保底” 方案是不对代码进行优化。</p>
<p>初始思路：查看程序汇编代码哪些地方没被优化，找到对应的源码部分进行重写，直至重构成编译器友好代码（只要不过度牺牲程序可读性就行）。</p>
<h3 id="15-1-Goals-of-Optimization"><a href="#15-1-Goals-of-Optimization" class="headerlink" title="15.1 Goals of Optimization"></a>15.1 Goals of Optimization</h3><ul>
<li>Minimize number of instructions<ul>
<li>避免重复计算；</li>
<li>避免不必要的计算；</li>
<li>避免较大计算量的操作（例如乘、除）；</li>
</ul>
</li>
<li>Avoid waiting for memory<ul>
<li>尽量将数据和运算过程放在 register 中，而非内存中；</li>
<li>使用 cache-friendly 的方式访问内存；</li>
<li>尽早从内存加载数据，并且加载次数越少越好；</li>
</ul>
</li>
<li>Avoid branching<ul>
<li>不要写出不必要的判断结构；</li>
<li>写成让 CPU 容易预测分支的代码（流水线）；</li>
<li>尽量解开循环，分摊分支的开销；</li>
</ul>
</li>
<li>Make good use of locality &amp; cache: 写出程序局部性良好的代码、充分利用缓存机制（8.2 &amp; 9.X）；</li>
</ul>
<h3 id="15-2-Limits-to-Compiler-Optimization"><a href="#15-2-Limits-to-Compiler-Optimization" class="headerlink" title="15.2 Limits to Compiler Optimization"></a>15.2 Limits to Compiler Optimization</h3><ul>
<li><p>无法优化算法的渐进时间复杂度；</p>
</li>
<li><p>绝不会改变程序语义、行为；</p>
</li>
<li><p>编译时仅仅分析每个函数一次（inline 函数除外）；</p>
<blockquote>
<p>目前 Whole-program analysis (“LTO”) 比较受欢迎，尽管开销很大；</p>
</blockquote>
</li>
<li><p>无法很好地针对运行时的输入内容进行优化</p>
<ul>
<li>可能出现最坏情况，尤其是面对非法输入的时候；</li>
</ul>
</li>
</ul>
<h3 id="15-3-Generally-Useful-Optimizations"><a href="#15-3-Generally-Useful-Optimizations" class="headerlink" title="15.3 Generally Useful Optimizations"></a>15.3 Generally Useful Optimizations</h3><blockquote>
<p>本部分的优化技巧不针对特定的编译器或者处理器，具有普适性。</p>
<p>绝大多数编译器在一定的优化等级下，都能优化本节的情况，但是我们应该学习这些方法。</p>
<p>注：一个能看到优化过程的网站：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://godbolt.org/z/Es5s8qsvj">COMPILER EXPLORER</a></p>
</blockquote>
<p>根据 15.1 中的目标，我们可以整理出一些常见的情况，这些情况下编译器能够优化，或者说具有普适性的优化策略，主要有以下两类：</p>
<ul>
<li>Local Optimizations (<strong>work inside a single basic block</strong>)<ul>
<li>Constant folding（常数折叠）</li>
<li>Strength reduction（计算强度削减）</li>
<li>Dead code elimination（死代码剔除）</li>
<li>Local CSE（Local Common Subexpression Elimination，局部的相似子表达式复用）</li>
<li>……</li>
</ul>
</li>
<li>Global Optimizations (<strong>process the entire control flow graph of a function</strong>)<ul>
<li>Loop transformations（循环结构转换）</li>
<li>Code motion（代码移动）</li>
<li>Inlining（内联化）</li>
<li>Global CSE（全局的相似子表达式复用）</li>
</ul>
</li>
</ul>
<p>这章仅仅叙述它们的思路，不涉及具体实现，因为具体实现就涉及到编译原理（AST 语法树等知识）；</p>
<h4 id="15-3-1-Constant-Folding"><a href="#15-3-1-Constant-Folding" class="headerlink" title="15.3.1 Constant Folding"></a>15.3.1 Constant Folding</h4><p>常数折叠的方法主要有以下几个方面：</p>
<ul>
<li><p>直接运算代码中的常数表达式</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">long</span> mask = <span class="number">0xFF</span> &lt;&lt; <span class="number">8</span>;</span><br><span class="line"><span class="comment">// 优化为：</span></span><br><span class="line"><span class="type">long</span> mask = <span class="number">0xFF00</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>直接运算一切可以常量化的表达式，例如针对常量调用的库函数、常量输入等</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">size_t</span> namelen = <span class="built_in">strlen</span>(<span class="string">&quot;Harry Bovik&quot;</span>);</span><br><span class="line"><span class="comment">// 优化为：</span></span><br><span class="line"><span class="type">size_t</span> namelen = <span class="number">11</span>;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="15-3-2-Dead-Code-Elimination"><a href="#15-3-2-Dead-Code-Elimination" class="headerlink" title="15.3.2 Dead Code Elimination"></a>15.3.2 Dead Code Elimination</h4><p>死代码删除方法的思路主要来源于 15.1 中的 “Avoid Branching” 和 “Minimize number of instructions”，分为以下几种情况：</p>
<ul>
<li><p>删除语义上不可能执行到的代码（无效代码）：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="number">0</span>) &#123; <span class="built_in">puts</span>(<span class="string">&quot;Hello, 0&quot;</span>); &#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="number">1</span>) &#123; <span class="built_in">puts</span>(<span class="string">&quot;Hello, 1&quot;</span>); &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 改为：</span></span><br><span class="line"><span class="built_in">puts</span>(<span class="string">&quot;Hello, 1&quot;</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除结果被覆盖的代码（也是无效代码）：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">23</span>; x = <span class="number">42</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 改为：</span></span><br><span class="line">x = <span class="number">42</span>;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>这类优化方式看起来很蠢，但也很重要，因为有时候这些死代码不容易被肉眼识别，或者在编译器进行其他优化过程中，在语义树上出现了，那么就需要这种方法来清理。</p>
<h4 id="15-3-3-Common-Subexpression-Elimination"><a href="#15-3-3-Common-Subexpression-Elimination" class="headerlink" title="15.3.3 Common Subexpression Elimination"></a>15.3.3 Common Subexpression Elimination</h4><p>CSE 的思路就是根据 AST 树的特征，约去<strong>重复计算</strong>，从而降低运算量，例子如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 此处展示的是 Local CSE */</span></span><br><span class="line"></span><br><span class="line">up = val[(i<span class="number">-1</span>)*n + j];</span><br><span class="line">down = val[(i+<span class="number">1</span>)*n + j];</span><br><span class="line">left = val[i*n + j - <span class="number">1</span>];</span><br><span class="line">right = val[i*n + j + <span class="number">1</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// 可以改为：</span></span><br><span class="line"><span class="type">long</span> inj = i*n + j;</span><br><span class="line">up = val[inj - n];</span><br><span class="line">down = val[inj + n];</span><br><span class="line">left = val[inj - <span class="number">1</span>];</span><br><span class="line">right = val[inj + <span class="number">1</span>];</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">norm[i] = v[i].x * v[i].x + v[i].y * v[i].y;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 改为：</span></span><br><span class="line">elt = &amp;v[i];</span><br><span class="line">x = elt-&gt;x;</span><br><span class="line">y = elt-&gt;y;</span><br><span class="line">norm[i] = x * x + y * y;</span><br></pre></td></tr></table></figure>
<h4 id="15-3-4-Code-Motion"><a href="#15-3-4-Code-Motion" class="headerlink" title="15.3.4 Code Motion"></a>15.3.4 Code Motion</h4><p>I.e., reduce frequency with which computation performed（也是降低代码重复运算频率，不过是在 global 范围进行）</p>
<ul>
<li><p>If it will always produce same result（这种改动<strong>语义不变</strong>）；</p>
</li>
<li><p>Especially moving code out of loop（常见于将代码移出循环结构，但为了保持语义，要求移动的代码在每次循环中的结果不变）；</p>
</li>
<li><p>Example：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">set_row</span><span class="params">(<span class="type">double</span>* a, <span class="type">double</span>* b, <span class="type">long</span> i, <span class="type">long</span> n)</span> &#123;</span><br><span class="line">    <span class="type">long</span> j;</span><br><span class="line">    <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j++)</span><br><span class="line">        a[n*i + j] = b[j];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 改为（将 n*i 这个与循环无关的变量提出循环，避免重复运算）：</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">set_row</span><span class="params">(<span class="type">double</span>* a, <span class="type">double</span>* b, <span class="type">long</span> i, <span class="type">long</span> n)</span> &#123;</span><br><span class="line">    <span class="type">long</span> j;</span><br><span class="line">    <span class="type">int</span> ni = n * i;</span><br><span class="line">    <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j++)</span><br><span class="line">        a[ni + j] = b[j];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="15-3-5-Inlining"><a href="#15-3-5-Inlining" class="headerlink" title="15.3.5 Inlining"></a>15.3.5 Inlining</h4><p>I.e., copy body of a function into its caller(s);</p>
<p>对于一些短的、计算开销小的非递归函数，即便编程人员不指定 <code>inline</code> 关键字，编译器也应该识别到并且内联操作。这样做的好处有两点：</p>
<ul>
<li>消除函数调用的栈帧分配开销；</li>
<li>为其他许多优化方法<strong>创造条件</strong>。例如，对代码中的一些函数内联，可以被编译器找到例如 dead code elimination、constant fold 的机会；</li>
</ul>
<p>这是个例子：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/inlining_example1.png"></p>
<p>缺点：这种优化方法在某些情况下（内联函数很长、开销很大）会导致整体代码空间占用变大、速度降低；</p>
<h4 id="15-3-6-Strength-Reduction"><a href="#15-3-6-Strength-Reduction" class="headerlink" title="15.3.6 Strength Reduction"></a>15.3.6 Strength Reduction</h4><p>I.e., replace costly operation with simpler one.（计算量减小）</p>
<ul>
<li>可以用移位、加法尽量代替乘法、除法（优化的比例取决于不同的机器）；</li>
</ul>
<h3 id="15-4-Obstacles-for-Compiler-to-Optimization"><a href="#15-4-Obstacles-for-Compiler-to-Optimization" class="headerlink" title="15.4 Obstacles for Compiler to Optimization"></a>15.4 Obstacles for Compiler to Optimization</h3><p>现在反过来看，有哪些操作会阻碍编译器优化？</p>
<p>阻碍编译器优化的原因之一就是期间调用了其他函数，这样 gcc 可能就无法识别到优化方法。还有一个主要原因就是 “内存别名” 的存在。</p>
<h4 id="15-4-1-Optimization-Blocker-1-Procedure-Calls"><a href="#15-4-1-Optimization-Blocker-1-Procedure-Calls" class="headerlink" title="15.4.1 Optimization Blocker #1: Procedure Calls"></a>15.4.1 Optimization Blocker #1: Procedure Calls</h4><p>典型例子：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">lower</span><span class="params">(<span class="type">char</span>* s)</span> &#123;</span><br><span class="line">    <span class="type">size_t</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="built_in">strlen</span>(s); i++)</span><br><span class="line">        <span class="keyword">if</span> (s[i] &gt;= <span class="string">&#x27;A&#x27;</span> &amp;&amp; s[i] &lt;= <span class="string">&#x27;Z&#x27;</span>)</span><br><span class="line">            s[i] -= (<span class="string">&#x27;A&#x27;</span> - <span class="string">&#x27;a&#x27;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以注意到，循环判断条件中有一个函数 <code>strlen(s)</code>，我们都知道这是计算字符串长度的函数。但是<strong>编译器不知道</strong>，它认为<strong>这个函数有可能在每次循环中，返回值可能改变</strong>，所以不会把它优化为一个常数，而是保持<strong>每次循环判断时，都重新调用 <code>strlen(s)</code></strong>。</p>
<p>可是，<code>strlen(s)</code> 的复杂度是  $O(n)$ 啊！这样好端端的 $O(n)$ 能实现的函数被硬生生干成了 $O(n^2)$ ……</p>
<p>所以，正确的做法是，先把 <code>strlen(s)</code> 算出来。更好的主意是，<strong>干脆不使用 <code>strlen()</code>，因为判断字符串结束原本就是能在循环中发现的情况</strong>，并且把数组索引改成指针取值，这样还能再节省常数时间：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">lower</span><span class="params">(<span class="type">char</span>* s)</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (*s != <span class="string">&#x27;\0&#x27;</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (*s &gt;= <span class="string">&#x27;A&#x27;</span> &amp;&amp; *s &lt;= <span class="string">&#x27;Z&#x27;</span>)</span><br><span class="line">            *s -= (<span class="string">&#x27;A&#x27;</span> - <span class="string">&#x27;a&#x27;</span>);</span><br><span class="line">        s++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>回过头来，为什么绝大多数的编译器没法优化这种 procedure calls 的情况？主要有几点原因：</p>
<ul>
<li>Procedure may have side effects; 就像前面说的，编译器不知道运行这个 procedure 会不会改变当前环境中其他变量的值，所以不敢贸然改变 procedure 运行顺序；</li>
<li>Procedure 会出现重载、重写的情况，这些函数有不同版本，可能分布在不同文件中，只有编译结束，链接的时候才知道最终用的函数是谁。对于虚函数而言，甚至要在运行时才知道调用的是哪一个同名函数；所以更不敢随意判断某个 procedure 的作用，也就无法解决上面的问题；</li>
<li>如果全面分析所有同名 procedure，并且找到它们的含义、作用，那么编译开销过大，非常不现实；</li>
</ul>
<p>综上，编译器一般的做法是<strong>将 procedure 看作一个黑盒，行为不确定，所以一般不会优化它的执行顺序</strong>。因此，开发者应该清楚意识到函数的作用，并且重视它执行的位置对代码性能的影响。</p>
<h4 id="15-4-2-Optimization-Blocker-2-Memory-Aliasing"><a href="#15-4-2-Optimization-Blocker-2-Memory-Aliasing" class="headerlink" title="15.4.2 Optimization Blocker #2: Memory Aliasing"></a>15.4.2 Optimization Blocker #2: Memory Aliasing</h4><p>先看示例：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Sum rows is of n x n matrix a and store in vector b */</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">sum_rows1</span><span class="params">(<span class="type">double</span>* a, <span class="type">double</span>* b, <span class="type">long</span> n)</span> &#123;</span><br><span class="line">    <span class="type">long</span> i, j;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">        b[i] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j++)</span><br><span class="line">               b[i] += a[i*n + j];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码看起来性能上没什么问题，大多数人都会如此实现代码。但是我们看看对应的 x86-64 汇编码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># sum_rows1 inner loop</span><br><span class="line">.L4:</span><br><span class="line">    movsd	(%rsi,%rax,8), %xmm0	# FP load</span><br><span class="line">    addsd	(%rdi), %xmm0			# FP add</span><br><span class="line">    movsd	%xmm0, (%rsi, %rax, 8)	# FP store</span><br><span class="line">    addq	$8, %rdi</span><br><span class="line">    cmpq	%rcx, %rdi</span><br><span class="line">    jne		.L4</span><br></pre></td></tr></table></figure>
<p>我们发现，小小的 <code>b[i] += a[i*n + j]</code> 竟然有两次对内存的操作（从内存读到寄存器，计算后再写回内存），为什么会这样？为什么不直接在内存中计算？</p>
<p>这是因为 <strong>Memory Alias（内存别名）在 C 中是允许的</strong>。比如，如果我这么调用 <code>sum_rows1</code>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">double</span> A[<span class="number">9</span>] =</span><br><span class="line">    &#123; 	<span class="number">0</span>,	<span class="number">1</span>,	<span class="number">2</span>,</span><br><span class="line">          <span class="number">4</span>,	<span class="number">8</span>,	<span class="number">16</span>,</span><br><span class="line">         <span class="number">32</span>,	<span class="number">64</span>,	<span class="number">128</span>	&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">double</span>* B = A+<span class="number">3</span>;</span><br><span class="line"></span><br><span class="line">sum_rows1(A, B, <span class="number">3</span>);</span><br></pre></td></tr></table></figure>
<p>那么，第二参数 <code>B</code> 就是 <code>A</code> 的一部分的<strong>内存别名</strong>，也就是说，程序有两个指针指向一块内存地址，这样的话，在每次 <code>B[i] = 0</code> 后，就会改变 <code>A</code> 的内容，从而改变求和的值。因此编译器仍然不敢直接优化。</p>
<p>问题在于，我们知道这个函数的作用是数组列求和，我们不会传入两个内存别名。但是编译器不知道——因为要检查所有的 memory alias 开销也非常大，所以编译器默认程序中都存在内存别名。</p>
<p><strong>所以解决方法是</strong>，我们暗示编译器这里不会有内存别名导致循环中数组值的更改：<strong>在求和时不直接加到 <code>b</code> 中，而是以临时局部变量存储，求和循环结束后同一赋值给 <code>b</code></strong>，这样在一次求和循环中编译器就不会重复从内存读取信息了：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Sum rows is of n x n matrix a and store in vector b */</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">sum_rows1</span><span class="params">(<span class="type">double</span>* a, <span class="type">double</span>* b, <span class="type">long</span> n)</span> &#123;</span><br><span class="line">    <span class="type">long</span> i, j;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">        <span class="type">double</span> val = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j++)</span><br><span class="line">               val += a[i*n + j];</span><br><span class="line">        b[i] = val;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样内层求和循环的汇编码就变得简单了：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># sum_rows1 inner loop</span><br><span class="line">.L10:</span><br><span class="line">    addsd	(%rdi), %xmm0	# FP load + add</span><br><span class="line">    addq	$8, %rdi</span><br><span class="line">    cmpq	%rax, %rdi</span><br><span class="line">    jne		.L10</span><br></pre></td></tr></table></figure>
<blockquote>
<p>实际上，内存读写仍然是耗时大头，所以改写后性能提升不会非常明显。</p>
</blockquote>
<p>对开发者而言，应该习惯于在循环前引入一些局部变量（<strong>Accumulate in temporary</strong>），尤其是含有数组索引的循环，这样能够暗示编译器按照没有内存别名的情况处理。</p>
<p>总结一下就是：</p>
<ul>
<li>多使用临时局部变量来存放中间值，尤其是在循环中；</li>
<li>使用更严格的关键字，例如 <code>int[]</code> 好过 <code>int*</code> 来让编译器知道不会有 memory alias；</li>
</ul>
<p>上面的几种优化技巧都是比较简单和零碎的，不宜死记硬背，应该贯通在实践当中。下面从另一个角度考虑优化问题。</p>
<h3 id="15-5-Machine-Dependent-Optimization"><a href="#15-5-Machine-Dependent-Optimization" class="headerlink" title="15.5 Machine-Dependent Optimization"></a>15.5 Machine-Dependent Optimization</h3><blockquote>
<p>这类优化取决于处理器机器和系统，根据汇编处理方式进行优化。</p>
</blockquote>
<p>表面上与机器无关的优化方法都考虑得差不多了，但在机器层面还有一些优化的方法。为了考虑这些方法，我们需要先了解机器的简单组成和基本运作原理。下面是上个世纪末的处理器的大概的设计样式：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/modern_CPU_design.png" height="400px"></p>
<p>底层机制过于复杂，一般人短时间内几乎不可能理解，所以这里仅仅浅浅介绍一下。</p>
<p>CPU 执行代码时，借助了多种方法和技术，构建了健全的硬件设施，使得其执行指令的速度远远快于一条一条读取执行的速度。其中一种技术被称为 “超标量乱序执行” 技术（superscalar out of order execution），它的思路可以理解为：CPU 一次性读入大量机器指令，再将顺序的指令拆开，发现逻辑上某两句间不相互依赖，于是 CPU 可以不按顺序、尽可能多地同时执行这些代码。</p>
<p>指令的这种特性被称为 <strong>指令级并行性（instruction level parallelism）</strong>；</p>
<p>上图的 Instruction Control 展示了 CPU 如何从高速缓存中抓取指令，并放入运算单元的。<strong>注意，这里所有的操作都使用缓存和寄存器</strong>，因为其他储存介质（包括内存）都太慢了。</p>
<p>上面<strong>在一个时钟周期中处理、执行多条指令的处理器</strong>被称为 Superscalar Processor，它们通常一次性获取一串指令流，并动态地进行调度和执行。它的好处是 <strong>充分利用了代码中的指令级并行性</strong>，所以大多数现代 CPU 都是超标量的，并且现代 CPU 的执行模型也几乎都是乱序执行的模型。</p>
<p>现代 CPU 的策略是乱序执行，固然非常复杂，但是它的功能实现单元更加复杂——<strong>流水线（piplining）</strong>。</p>
<p>流水线的基本思想是，<strong>处理器将每个计算分解为一系列不同阶段，每个阶段都有一个专用硬件可以独立完成。于是，当一个计算阶段的硬件空闲下来时，就可以接受下一个数据的计算工作</strong>。</p>
<p>其中，除法运算无法被分解在流水线上进行，一次操作 3 ~ 30 个时钟周期，所以是一个昂贵的操作。</p>
<blockquote>
<p>这些并行性都是单个 CPU 的单核的并行性，不涉及多核并行。</p>
</blockquote>
<p>按照这些思路，我们可以发现在机器层面的优化方法：</p>
<h4 id="15-5-1-Branch-Misprediction-Recovery"><a href="#15-5-1-Branch-Misprediction-Recovery" class="headerlink" title="15.5.1 Branch Misprediction Recovery"></a>15.5.1 Branch Misprediction Recovery</h4><p>我们在 4.2.2 中提到过，机器层面的分支预测技术（Branch Prediction）就是为了让 CPU 流水线的效率得到充分利用而诞生的。在很多情况下，如果我们不使用条件移动的话，那么在分支预测错误的时候，很有可能整个流水线的指令和数据全部需要重新载入，这将耗费大量的运算资源和时间。</p>
<p>所以第一个思路就是从降低 <strong>Branch Misprediction Penalty</strong> 方面着手。首先了解一下分支预测技术的大概原理是啥。分支预测技术在早期使用的是简单的 heuristic：向后分支（backwards branches）经常是判断（if），向前分支（forwards branches）经常是循环（loop）。我们可以通过一些算法<strong>跟踪这些分支（尤其是循环）的历史行为，如果它经常通过某一分支，那么以后预测该分支的可能性会大一点</strong>。</p>
<p>这种预测方法在有些代码中效果显著，但是另一些代码（<strong>例如强数据依赖、强随机数据</strong>）中效果极差，甚至导致更多的 Branch Misprediction Penalty；</p>
<p>因此接近这个方面问题的可能途径如下：</p>
<ul>
<li>减少分支结构的数量：<ul>
<li>Transform loops（尽量转换、消除不必要的循环）</li>
<li>Unroll loops（下面介绍）</li>
<li>Use Conditional Moves（4.2.2）</li>
</ul>
</li>
<li>使得分支<strong>更容易被分支预测器预测</strong><ul>
<li>为循环中的数据排序（需要权衡）</li>
<li>尽量避免间接的分支结构（因为间接分支基本上都没有预测依据）<ul>
<li>函数指针判断跳转</li>
<li>虚函数运行时判断跳转</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>这里介绍一下 unroll loops 的思路。unroll loops 就是<strong>将循环中的代码成倍数展开，达到均摊 Branch Misprediction Penalty 的目的</strong>。同时，这种方法还能为其他的优化方法创造条件（例如 CSE、Code Motion、Scheduling 等）。方法的示例如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; nelts; i++)</span><br><span class="line">    A[i] = B[i]*k + C[i];</span><br><span class="line"></span><br><span class="line"><span class="comment">// 改为：</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; nelts - <span class="number">4</span>; i += <span class="number">4</span>) &#123;</span><br><span class="line">    A[i  ] = B[i  ]*k + C[i  ];</span><br><span class="line">    A[i+<span class="number">1</span>] = B[i+<span class="number">1</span>]*k + C[i+<span class="number">1</span>];</span><br><span class="line">    A[i+<span class="number">2</span>] = B[i+<span class="number">2</span>]*k + C[i+<span class="number">2</span>];</span><br><span class="line">    A[i+<span class="number">3</span>] = B[i+<span class="number">3</span>]*k + C[i+<span class="number">3</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但这种方法有两个明显的缺陷，一是如果过度展开，会增长代码长度，同样会影响性能。所以需要根据数据量进行权衡；二是在某些循环中，依赖 i 进行判断的场合，这种展开就不适用了。</p>
<h4 id="15-5-2-Scheduling"><a href="#15-5-2-Scheduling" class="headerlink" title="15.5.2 Scheduling"></a>15.5.2 Scheduling</h4><p>在上面的流程中，除了 Branch Misprediction Penalty，还有一种会影响 CPU 运算性能的情况——数据读取和写入。I/O 操作的开销一直是处理器设计者头疼的地方，尽管现在有高速缓存器来进行弥补，但数据的存取在运算过程中还是尽量能少就少。</p>
<p>因此，<strong>将源代码中读取、写入的部分和运算的部分分开（最好在运算前就读入所有必需的数据、在所有运算后才写入必要的数据），能够让处理器的性能发挥到最大</strong>（这个优化也可以由编译器完成）。这种方法就称为代码调度（Scheduling）。</p>
<p>例如 15.5.1 中的代码还可以继续优化：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; nelts - <span class="number">4</span>; i += <span class="number">4</span>) &#123;</span><br><span class="line">    B0 = B[i]; B1 = B[i + <span class="number">1</span>]; B2 = B[i + <span class="number">2</span>]; B3 = B[i + <span class="number">3</span>];</span><br><span class="line">    C0 = C[i]; C1 = C[i + <span class="number">1</span>]; C2 = C[i + <span class="number">2</span>]; C3 = C[i + <span class="number">3</span>];</span><br><span class="line">    A[i  ] = B0*k + C0;</span><br><span class="line">    A[i+<span class="number">1</span>] = B1*k + C1;</span><br><span class="line">    A[i+<span class="number">2</span>] = B2*k + C2;</span><br><span class="line">    A[i+<span class="number">3</span>] = B3*k + C3;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同样，这样的操作对于有些情况也不适用，比如在一些业务逻辑下，读取操作必须在一群算数运算之间出现。</p>
<h4 id="15-5-3-Benchmark-Example"><a href="#15-5-3-Benchmark-Example" class="headerlink" title="15.5.3 Benchmark Example"></a>15.5.3 Benchmark Example</h4><p>为了展示上面所有优化方法的效果，我们举个例子。</p>
<p>先以一个结构体数据类型为例：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* data structure for vectors */</span></span><br><span class="line"><span class="comment">/* we can use different declarations for data_t */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="type">size_t</span> len;</span><br><span class="line">    <span class="type">data_t</span> *data;</span><br><span class="line">&#125; vec;</span><br></pre></td></tr></table></figure>
<p>其中的一个函数是：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Retrieve vector element and store at val. */</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">get_vec_element</span><span class="params">(vec* v, <span class="type">size_t</span>, idx, <span class="type">data_t</span>* val)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (idx &gt;= v-&gt;len) <span class="keyword">return</span> <span class="number">0</span>;    <span class="comment">/* Out of range. */</span></span><br><span class="line">    *val = v-&gt;data[idx];</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对这个函数进行<strong>基准测试（Benchmark Computation）</strong>：</p>
<ul>
<li><p>测试函数：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">combine1</span><span class="params">(vec* v, <span class="type">data_t</span>* dest)</span> &#123;</span><br><span class="line">    <span class="type">long</span> i;</span><br><span class="line">    *dest = IDENT;                        <span class="comment">/* IDENT macro */</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; v-&gt;len; i++) &#123;</span><br><span class="line">        <span class="type">data_t</span> val;</span><br><span class="line">        get_vec_element(v, i, &amp;val);</span><br><span class="line">        *dest = *dest OP val;            <span class="comment">/* OP macro */</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们将使用不同数据类型（<code>data_t</code> 分别是 <code>int</code>、<code>long</code>、<code>float</code>、<code>double</code>），针对不同运算和值（<code>OP</code> 分别是 <code>+</code>、<code>*</code>，<code>IDENT</code> 分别是 0、1）；</p>
</li>
<li><p>测试指标：<strong>CPE (Cycle Per Element)</strong></p>
<ul>
<li>Convenient way to express performance of program that operates on vectors or lists.</li>
<li><strong>在这里，CPE 就是一个时钟周期中的进行 <code>OP</code> 运算的次数，总时长指标 <code>T = CPE * n + Overhead</code></strong>（这里 overhead 就是 n = 0 时的基础开销）；</li>
<li>tips: 在检查代码性能时，不应该以真实时间做单位（例如 nanosecond），应该使用处理器内部时钟周期作为单位更有用。因为开发者无法控制处理器频率，但是可以控制并衡量操作的时钟周期。</li>
</ul>
</li>
<li><p>基准测试结果：</p>
<ul>
<li><code>-O0</code> 级别下，平均每个元素花费约 20 个时钟周期（T-n 图斜率）；</li>
<li><code>-O1</code> 级别下，平均每个元素花费约 10 个时钟周期；</li>
</ul>
</li>
</ul>
<p>现在进行在 15.3 中出现的与机器无关的基础优化：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">combine4</span><span class="params">(vec* v, <span class="type">data_t</span>* dest)</span> &#123;</span><br><span class="line">    <span class="type">long</span> i;</span><br><span class="line">    <span class="type">long</span> length = v-&gt;len;        <span class="comment">/* 将可能重复计算的部分提出循环 */</span></span><br><span class="line">    <span class="type">data_t</span>* d = v-&gt;data;</span><br><span class="line">    <span class="type">data_t</span> t = IDENT;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; length; i++)    <span class="comment">/* 不使用额外的 procedure 来重复检查 v-&gt;len */</span></span><br><span class="line">        t = t OP d[i];</span><br><span class="line">    *dest = t;                    <span class="comment">/* 不直接在循环内给数组赋值，使用 local variable */</span></span><br><span class="line">&#125;                                <span class="comment">/* 暗示编译器没有 memory alias */</span></span><br></pre></td></tr></table></figure>
<p>结果在 <code>-O1</code> 级别下，<strong>加法平均每个元素花费的时钟周期降至 1.2 左右，整数乘法降低至 3 左右，浮点数乘法降低至 5 左右</strong>；</p>
<p>这个时候，我们再考虑与机器相关的优化，比如 unrolling loops：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">unroll2a_combine</span><span class="params">(vec* v, <span class="type">data_t</span>* dest)</span> &#123;</span><br><span class="line">    <span class="type">long</span> i;</span><br><span class="line">    <span class="type">long</span> length = v-&gt;len;</span><br><span class="line">    <span class="type">long</span> limit = length - <span class="number">1</span>;</span><br><span class="line">    <span class="type">data_t</span>* d = v-&gt;data;</span><br><span class="line">    <span class="type">data_t</span> t = IDENT;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; limit; i+=<span class="number">2</span>)</span><br><span class="line">        t = (t OP d[i]) OP d[i+<span class="number">1</span>];        <span class="comment">/* Loop Unrolling (2x1). */</span></span><br><span class="line">    *dest = t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可惜的是，只有加法运算获得了比较明显的提速（平均每个元素花费的时钟周期降至 1 个时钟周期），但是其他的 3 则运算没有获得显著提升。这可能是原来的代码在计数循环上的开销比较大，而现在的加法运算更加接近计算机性能利用的极限范围了；对于其他运算（乘除等），还是逐级运算，即后一阶段依赖前一阶段的结果，所以速率仍没有提升。</p>
<p>但是，如果做出如下 “优化”：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">unroll2aa_combine</span><span class="params">(vec* v, <span class="type">data_t</span>* dest)</span> &#123;</span><br><span class="line">    <span class="type">long</span> i;</span><br><span class="line">    <span class="type">long</span> length = v-&gt;len;</span><br><span class="line">    <span class="type">long</span> limit = length - <span class="number">1</span>;</span><br><span class="line">    <span class="type">data_t</span>* d = v-&gt;data;</span><br><span class="line">    <span class="type">data_t</span> t = IDENT;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; limit; i+=<span class="number">2</span>)</span><br><span class="line">        t = t OP (d[i] OP d[i+<span class="number">1</span>]);        <span class="comment">/* ??? */</span></span><br><span class="line">    *dest = t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>交换了循环中的运算次序，会发现整型加法性能提升到 0.5，整型乘法、除法更是提升到 1 左右（<strong>实际上，浮点数乘法和整型加法一样快，这是因为在 6.3.2 中介绍的 “浮点数寄存器的结构” 导致的</strong>：一个浮点数寄存器可以同时处理 2 个乘法、1 个加法）。因为，这里我们交换的运算次序有点特殊，它改变了整体的运算流程（如图），使得整体的运算效率可以提高 1 倍：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/seq1.png" width="350px"><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/seq2.png" width=350px></p>
<p>因为 <code>d[i] * d[i + 1]</code> 的无依赖性，所以这二者的积运算在 CPU 中可以更早地运算，节省下来大量时间。</p>
<p><strong>但对于这种转换而言，编译器通常不会对浮点数进行优化。这是因为这种转换改变了语义——如果是浮点数运算，并且存在舍入的情况，那么是不满足分配律的</strong>。这就意味着，在存在浮点数舍入的情况下，这种“优化方法”会导致错误的结果，所以应该由编程人员自行判断舍入情况，并优化。</p>
<hr>
<p>其实，我们除了这种 unrolling 的方式以外，还可以更进一步，使用 <strong>Separate Accumulators</strong>，将偶数和奇数索引的数据分开，减少值依赖的情况：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">unroll2a_combine</span><span class="params">(vec* v, <span class="type">data_t</span>* dest)</span> &#123;</span><br><span class="line">    <span class="type">long</span> i;</span><br><span class="line">    <span class="type">long</span> length = v-&gt;len;</span><br><span class="line">    <span class="type">long</span> limit = length - <span class="number">1</span>;</span><br><span class="line">    <span class="type">data_t</span>* d = v-&gt;data;</span><br><span class="line">    <span class="type">data_t</span> x0 = IDENT;</span><br><span class="line">    <span class="type">data_t</span> x1 = IDENT;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Combine 2 elements at a time. */</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; limit; i+=<span class="number">2</span>) &#123;</span><br><span class="line">        x0 = x0 OP d[i];</span><br><span class="line">        x1 = x1 OP d[i + <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* Finish any remaining elements. */</span></span><br><span class="line">    <span class="keyword">for</span> (; i &lt; length; i++)z</span><br><span class="line">        x0 = x0 OP d[i];</span><br><span class="line">    *dest = x0 OP x1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/seq3.png" height="400px"></p>
<p>这就是两个临时变量的分段累计（unrolling loops 2x2）。所以，更一般的思路是：</p>
<ul>
<li>unrolling to degree L；</li>
<li>accumulate K results and <strong><code>K mod L == 0</code></strong>；</li>
</ul>
<p>在考虑完这种情况下的限制之后，接下来更基本的限制就是 <strong>程序基本开销</strong> 和 <strong>吞吐量限制</strong>，后者是在硬件数量和性能层面——某些硬件的 I/O 速度最大只有那么快，我们依靠源码和汇编层面的小修小改是没有办法继续提升的。</p>
<p>不过在更新的 CPU 上，我们在浮点数寄存器 <code>%xmm</code>（16 bytes，128 bits）的基础上，增添了16 个 <code>%ymm</code>（32 bytes，256 bytes）大小的浮点数寄存器，这类寄存器不使用 <code>SSE3</code> 指令，而是用 <code>AVX2</code> 指令，整体数据承载量、并行运算量都大于原来的情况。</p>
<p>所以我们可以根据 AVX 指令的特征，对上面代码继续进行修正（向量化代码），充分利用其并行运算的特点，理论上还能得到提升。</p>
<p>这些根据 AVX 指令来编写向量化的代码（unrolling loops），就是在一些游戏、音视频处理软件的领域内，对于框架中的代码做的优化的一种方式。</p>
<h3 id="15-6-Summary"><a href="#15-6-Summary" class="headerlink" title="15.6 Summary"></a>15.6 Summary</h3><p>本章讲述了一些程序优化的基本思路，主要从两个方向描述。</p>
<p>一个是与机器无关方向的优化小技巧，而这些技巧也常常会内置在编译器中，成为编译工作的一个部分。它们大致可以分为以下几类：</p>
<ul>
<li>局部的优化：例如 <strong>常数折叠、计算强度减小（通过更换运算符实现）、死代码剔除、局部的相近表达式复用消除</strong>；</li>
<li>全局的优化：例如 <strong>循环结构转换、代码移动（减少不必要的运算）、内联化、全局的相近表达式复用消除</strong>；</li>
</ul>
<p>在这个方面，我们考虑了相反的情况——什么样的编码会阻碍编译器帮助我们进行上面的优化。</p>
<ul>
<li>Procedure Calls：我们应该在代码设计时，充分考虑函数调用的位置对于性能影响；</li>
<li>Memory Alias：尤其是在循环结构中，多使用局部变量暂存中间结果，或者使用更严格的关键字；</li>
</ul>
<p>这都在提醒我们编码时，能尽早确定的定值，尽量存在局部变量中，以防编译器认为中间存在变数，而不敢于进行优化。</p>
<p>另一个是与具体机器有关方向的优化技巧（但是目前世界上的机器种类就这些，所以理论上也有一定的普适性，例如 ARM 架构和 x86 架构都能使用这种优化来提升性能），编译器不一定会帮你做这些优化，这是因为这些方法有着各自的局限性。</p>
<p>我们分析了现代 CPU 的结构特性，找到了 2 处可以进行优化的地方，一个是分支预测的部分，另一个是代码中的 I/O 调度。</p>
<p>首先我们了解了分支预测器的原理和性质，我们发现想要弥补 Branch Misprediction Penalty，就需要从两个方面入手：</p>
<ol>
<li>让它少预测点，就少错一点（减少分支结构）。这方面的方法大致有 <strong>循环转换、unrolling loops 和 conditional moves</strong>；</li>
<li>提升它预测的正确率。依从分支预测器的原理，我们可以让每次产生的分支判断的结果有迹可循。总的来说，我们可以通过<strong>为需要的判断数据排序</strong>（局限性强）、<strong>减少编码一些难以预测的结构</strong>（例如函数指针判断、虚函数）。</li>
</ol>
<p>在 I/O 调度方面我们发现，CPU 频繁地从高速缓存器中读入和写出数据也会降低程序性能，因此在编码过程中写出能够让汇编码中读内存次数越少的源码越好。因此，这里的重要建议是<strong>将源代码中读取、写入的部分和运算的部分分开（最好在运算前就读入所有必需的数据、在所有运算后才写入必要的数据）</strong>。</p>
<p>本章最后举了一个对矢量行进行基准运算的例子，说明了上面方法所能够带来的性能提升。尤其是介绍了 unrolling loops 和 流水线的思想。</p>
<h2 id="Chapter-16-Exceptional-Control-Flow"><a href="#Chapter-16-Exceptional-Control-Flow" class="headerlink" title="Chapter 16. Exceptional Control Flow"></a>Chapter 16. Exceptional Control Flow</h2><blockquote>
<p>对应书中第 8 章。</p>
</blockquote>
<p>异常控制流是现代计算机系统的一个相当重要的部分。</p>
<h3 id="16-1-Control-Flow"><a href="#16-1-Control-Flow" class="headerlink" title="16.1 Control Flow"></a>16.1 Control Flow</h3><ul>
<li><p>控制流：从机器打开到关闭的过程中，处理器只做一件事：<strong>读指令、执行指令，一个周期做一个指令</strong>。多核的机器则每个核心依次交替执行指令。这些<strong>指令序列</strong>被称为控制流。硬件正在执行的<strong>实际指令序列</strong>就被称为<strong>物理控制流</strong>。</p>
</li>
<li><p>改变内存中控制流的方法：<strong>分支 &amp; 跳转</strong>，<strong>过程调用 &amp; 返回</strong>（Branches &amp; Jumps &amp; Procedure call and return）；</p>
<blockquote>
<p><strong>都是对于程序状态变化的处理</strong>。</p>
</blockquote>
</li>
</ul>
<p>但以上的简单的改变控制流的方法对于处理复杂的系统级别的状态变化时，就显得非常拙劣。（例如 OS 协同软硬件的通信，如果还是以 if-else 的方法，那将会非常差劲）；</p>
<p>什么是 “系统级别的状态变化”？</p>
<ul>
<li>数据从磁盘 / 网卡到达内存中；</li>
<li>I/O 设备输入 Ctrl+C；</li>
<li>系统分时复用的时钟到期了，接下来要打断当前执行的进程；</li>
<li>除零指令；</li>
<li>……</li>
</ul>
<p>这些事件不能指望应用程序的开发者来解决（应用程序的开发者只负责开发正常的程序控制流），而这应该是 OS 需要处理的事情。为了高效处理以上在执行程序中出现的或意外、或故意的系统级状态变更的情况，OS 有一套策略：<strong>异常控制流（Exception control flow，简称 ECF）</strong>来处理上述情况，这样很多事件就无需应用开发者来考虑了。</p>
<h3 id="16-2-Exception-Control-Flow-Overview"><a href="#16-2-Exception-Control-Flow-Overview" class="headerlink" title="16.2 Exception Control Flow: Overview"></a>16.2 Exception Control Flow: Overview</h3><p>异常控制流的重要特征之一在于，它们会改变系统级别的状态，<strong>而且存在于计算机系统的各个层级</strong>：</p>
<p>首先是底层级 ECF 的机制：</p>
<ol>
<li><strong>Exception</strong>（异常，又称 <strong>Hardware ECF（硬件异常控制流）</strong>，和我们平时编程的软件异常处理不是一个概念）<ul>
<li>作用：<strong>响应某些底层系统事件（A System Event）的控制流的变化</strong>；</li>
<li>实现方法：硬件与操作系统的配合；</li>
</ul>
</li>
</ol>
<p>再看高级别（既指抽象层面，又指逻辑层面，这意味着下面的机制可能利用到，或者包含了上面的 Exception）的 ECF 的机制：</p>
<ol>
<li><strong>Process Context Switch</strong>（进程上下文切换）<ul>
<li>作用：使操作系统在两个进程间无缝切换；</li>
<li>实现方法：硬件时钟和操作系统的配合；</li>
</ul>
</li>
<li><strong>Signals</strong>（信号）<ul>
<li>作用：应用、操作系统、硬件三者之间的异常（不是错误，而是指在上层应用程序正常控制流以外的部分）通信；</li>
<li>实现方法：操作系统控制；</li>
</ul>
</li>
<li><strong>Nonlocal Jumps</strong>（非本地跳转）<ul>
<li>作用：<strong>应用程序开发者层面（而非操作系统层面）主动更改程序正常控制流（上面介绍的分支跳转、调用返回），无视正常控制流的规则</strong>（例如不需要等到一个函数返回，就跳到另一个函数执行）；</li>
<li>实现方法：因为是用户级别，所以由 C library 提供：<code>setjmp()</code>、<code>longjmp()</code>；</li>
</ul>
</li>
</ol>
<p>了解完计算机中各个层面的 <strong>4 大类 ECF 机制</strong>，我们开始深入探讨各个机制的运作原理。</p>
<h3 id="16-3-Exception-Control-Flow-Exception"><a href="#16-3-Exception-Control-Flow-Exception" class="headerlink" title="16.3 Exception Control Flow: Exception"></a>16.3 Exception Control Flow: Exception</h3><h4 id="16-3-1-Definitions"><a href="#16-3-1-Definitions" class="headerlink" title="16.3.1 Definitions"></a>16.3.1 Definitions</h4><p>一个异常就是<strong>为了应对一些（软件 / 硬件的）事件，控制流由程序转移到 OS kernel 的过程</strong>。</p>
<blockquote>
<ol>
<li>什么是操作系统内核（OS Kernel）？</li>
</ol>
<p>内核是<strong>操作系统在内存中驻留的部分</strong>，你可以理解成当前加载到内存的、运行中的操作系统代码；</p>
<ol>
<li>Exception 定义中的 “事件” 具体有哪些？</li>
</ol>
<ul>
<li>除零、算数溢出、page fault（页错误）、I/O 请求完成、键盘设备输入 Ctrl + C；</li>
<li>……</li>
</ul>
</blockquote>
<h4 id="16-3-2-Process-Procedure"><a href="#16-3-2-Process-Procedure" class="headerlink" title="16.3.2 Process Procedure"></a>16.3.2 Process Procedure</h4><p>Exception 的处理过程如下：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/exception_flow.png" height="200px"></p>
<ol>
<li><p>如图所示，因为以上的事件（event）而改变了系统状态，执行到 $I_{current}$ 的用户代码被立即暂停，此时 exception 将控制权从用户代码转移到内核态代码。这部分内核代码被称为 <strong>exception handler（异常处理程序）</strong>；</p>
</li>
<li><p>接着，内核执行异常处理程序代码来处理这个事件，过程被称为 <strong>exception processing（异常处理）</strong>；</p>
</li>
<li><p>处理结束后，通常有 3 种情况：返回到原先被打断的指令位置（$I_{current}$，已执行）、返回到被打断的指令的下一条（$I_{next}$，未执行）、终止原用户程序执行。</p>
</li>
</ol>
<h4 id="16-3-3-Implementations-of-Exception"><a href="#16-3-3-Implementations-of-Exception" class="headerlink" title="16.3.3 Implementations of Exception"></a>16.3.3 Implementations of Exception</h4><p>前面介绍过，Exception 是由 OS 和硬件共同实现的，那么具体实现是什么？</p>
<p>事实上，控制流想要改变，必须依靠硬件改变程序计数器（PC，或者说前面提到的 <code>%rip</code>）。由于 Exception handler 的代码又位于 Kernel code 中，所以实现就很清楚了：</p>
<ol>
<li><p><strong>OS 负责组织 Exception Handler 的代码，来处理可能的 Exception</strong>；</p>
</li>
<li><p><strong>硬件负责在 Event 出现的时候改变 <code>%rip</code>，使控制流转向 Exception Handler</strong>；</p>
</li>
</ol>
<p>等等，还有一个问题，OS 会预先编写很多类 Exception Handler 以应对不同 Exception 的情况，那么硬件在 Event 发生时，怎么知道转向哪一个 Exception Handler？所以还有一条、再改正一条：</p>
<ol>
<li><p><strong>硬件负责在 Event 出现时按种类改变 Exception Table Base Register，通过这个寄存器取得 Exception Table 中存放的 Exception Handler 的地址（硬件规定是虚拟地址），把取得的地址置于 <code>%rip</code> 中，完成转向</strong>；</p>
</li>
<li><p>OS 负责在 Kernel 中组织 <strong>Exception Table（异常表）</strong>，告诉硬件何种 event 对应何种 Exception Handler 的地址；</p>
</li>
</ol>
<blockquote>
<p>什么是 异常表？</p>
<p>OS 为了将每种 Event 产生的 Exception 与 Exception Handler 对应起来，将每种类型的事件进行编号。<strong>每种类型的事件对应位于的 异常编号（Exception Number，又称为中断向量，Interrupt Vector）</strong>，这个编号被作为一个跳表的索引，而表中装的是各个对应的 Exception Handler 的地址。这个表就称为 <strong>异常表</strong>。</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/exception_table.png" height="300px"></p>
</blockquote>
<h4 id="16-3-4-Types-of-Exceptions"><a href="#16-3-4-Types-of-Exceptions" class="headerlink" title="16.3.4 Types of Exceptions"></a>16.3.4 Types of Exceptions</h4><p>上面我们提到过，在 Exception 的处理过程中，最后可能会发生 3 种情况（$I_{current}$、$I_{next}$、abort），这是因为具体发生的 event 不同，其 Exception Handler 的处理方式也不同。所以，我们有必要了解一下 Exception（或者说对应的 event）有哪些种类，exception handler 的默认行为又有哪些。</p>
<p><strong>Asynchronous Exceptions（异步异常）：又称 Interrupt（中断）</strong></p>
<ul>
<li>引发的 Event 的种类：<strong>来自处理器外的事件。通常是 I/O 设备发出的</strong>；</li>
<li>例子：<ul>
<li>I/O 设备中断事件（数据从磁盘、网卡等外部设备已到达内存的通知，键盘 Ctrl+C 等）；</li>
<li>系统分时复用时钟中断（Timer Interrupt），OS 在硬件时钟中定时，要求从用户程序切换到内核中，以便让 OS 取得控制权（这个是<strong>为进程上下文切换提供条件</strong>，让系统决定是否要进行进程上下文切换）；</li>
</ul>
</li>
<li>触发方法 / 系统状态如何改变：电脉冲通知处理器的 <strong>中断引脚</strong>；</li>
<li>触发后默认行为：<ul>
<li>可能与当前运行程序无关事件，从 $I_{next}$ 继续向下运行（<strong>recoverable</strong>）；</li>
</ul>
</li>
</ul>
<p><strong>Synchronous Exceptions（同步异常）</strong></p>
<ul>
<li>引发的 Event 的种类：<strong>因为处理器执行某条指令而造成的事件</strong>；</li>
</ul>
<p>而同步异常又可以分为几个种类：</p>
<ol>
<li><p>Traps（陷阱）</p>
<ul>
<li><p>触发方法：<strong>执行程序故意触发系统级别 Exception</strong>；</p>
</li>
<li><p>例子：<strong>system calls（系统调用）、breakpoint traps（程序断点）、特殊指令</strong>；</p>
<blockquote>
<p><strong>什么是系统调用？</strong></p>
<p>应用程序的某些功能可能需要使用一些硬件设备，例如 I/O 设备。而这些驱动硬件的程序则嵌在 OS Kernel 中。</p>
<p>但另一方面，由于安全问题，人们在系统中划分了若干特权级：Ring 0 ~ Ring 3，数字越大，权限越低。应用程序运行在 Ring 3 级别，因此不能直接调用内核函数、无法访问内核数据（位于 Ring 0 级别），因此无法直接使用 I/O 设备。</p>
<p>那么应用程序为了完成一项使用 I/O 设备的工作，只能调用 OS 准备的专门的接口（称为系统服务）来通知 OS 协助完成。这个过程被称为 <strong>系统调用</strong>。</p>
<p><strong>系统调用的详细过程？</strong></p>
<p>首先，系统调用就是调用系统接口的过程，咱首先得了解 x86-64 架构下系统调用有哪些接口。以 x86-64 Linux 为例：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/system_calls.png" height="250px"></p>
<p>每一个系统调用接口都有一个唯一的编号，这个编号由 OS 分配，例如 <code>read</code> 是 0 号；</p>
<p>以打开文件这个 I/O 操作为例，应用程序想要将磁盘中的数据读到内存中，那么：</p>
<ol>
<li><p>程序先调用 C library 封装好的函数 <code>open/fopen</code>；</p>
</li>
<li><p>C library 的 <code>open/fopen</code> 经过几层包装，接着调用系统接口 <code>__open</code>（上面的 2 号系统调用），其汇编代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">00000000000e5d70 &lt;__open&gt;:</span><br><span class="line">...</span><br><span class="line">e5d79: b8 02 00 00 00         mov $0x2,%eax 	# openis syscall #2</span><br><span class="line">e5d7e: 0f 05                 syscall 		# Return value in %rax</span><br><span class="line">e5d80: 48 3d 01 f0 ff ff     cmp $0xfffffffffffff001,%rax</span><br><span class="line">...</span><br><span class="line">e5dfa: c3 retq</span><br></pre></td></tr></table></figure>
<p>我们可以看到，系统调用的 calling conventions 与普通函数不一样：</p>
<ul>
<li><strong>第一传入参数必须是 系统调用编号，并且存放在 <code>%rax</code> 中</strong>，这里是 2，表示 2 号系统调用；</li>
<li><strong>其他传入参数依此放在：<code>%rdi</code>、<code>%rsi</code>、<code>%rdx</code>、<code>%r10</code>、<code>%r8</code>、<code>%r9</code></strong>；</li>
<li><strong>返回值也放在 <code>%rax</code> 中</strong>；</li>
<li><strong>使用 <code>errno</code> 宏来记录系统调用的状态或错误情况</strong>；</li>
<li><strong><code>%rcx</code> 、<code>%r11</code> 可能被破坏：<code>%rcx</code> 存放 $I_{next}$ 地址方便返回，<code>%r11</code> 用于存放 <code>rflags</code>，也即当前程序的 conditional codes</strong>；</li>
</ul>
</li>
<li><p>当处理器执行到系统调用汇编指令时，触发 <code>Trap</code>（Exception），相应值传入 Exception Table Base Register；硬件通过该寄存器找到 Exception table 中的相应 Exception handler（x86-64 通常是 software interrupt exception handler），将 <code>%rip</code> 地址改为该 handler 的地址，于是控制流转向 OS Kernel；</p>
</li>
<li><p>OS Kernel 处理系统调用的 exception handler 会按之前的 conventions 读取各参数值，执行对应系统调用服务。完成后，先切换特权级等信息，再读取 <code>%rcx</code> 和 <code>%r11</code> 中的信息，将控制流转交给 user mode 中原程序的 $I_{next}$；</p>
</li>
<li><p>最终系统调用成功返回的话，open 返回一个 <strong>file descriptor（文件描述符，一个区别已打开文件的小整数编号）</strong>，以供后续读写调用使用。</p>
</li>
</ol>
</blockquote>
</li>
<li><p>触发后默认行为：从 $I_{next}$ 继续向下执行（<strong>recoverable</strong>）；</p>
</li>
</ul>
</li>
<li><p>Faults（错误）</p>
<ul>
<li><p>触发方法：程序执行了一条指令，<strong>无意引发了硬件或软件层面的问题</strong>，从而产生 Exception；</p>
</li>
<li><p>例子：<strong>page fault（页错误，possibly recoverable）</strong>、<strong>protection fault（访问权限错误，unrecoverable）</strong>，<strong>floating point exceptions（浮点异常，例如除零错，unrecoverable）</strong>；</p>
<blockquote>
<p><strong>什么是页错误 和 访问权限错误？</strong></p>
<p>首先在 10 ~ 14 章中，我们介绍了物理内存和虚拟内存。操作系统为了将离散、有限的资源抽象为连续、近乎无限的资源给应用程序使用，并将各个程序隔离开，使用了复杂的策略。</p>
<p>在<strong>内存的使用</strong>层面，操作系统和硬件配合引入了 “虚拟内存” 的概念，操作系统维护了一个从物理内存（简称 PM）到虚拟内存（简称 VM）的映射（还记得 Chapter 8 最后介绍的 TLB cache 吗？就是为这个准备的），<strong>将主存（main memory）上离散的空间映射到连续的虚拟内存空间上</strong>。</p>
<p>这个 “映射” 存在处理器芯片的 MMU（Memory Managing Unit） 中，这个映射的数据结构被称为 <strong>页表</strong>。为了充分利用主存（物理内存）的空间，页表将 PM 和 VM 切分为很小的块（大家能懂往瓶子里装石子、沙子、水的道理吧？），这些很小的数据块被称为 <strong>页</strong>，而页表就是将这些虚拟内存页映射到物理内存页，如下：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/page_table.png" height="300px"></p>
<p>那么这样能同时完成两个目标：</p>
<ul>
<li>充分利用有限物理空间，为应用程序提供连续的虚拟空间；</li>
<li>每个应用程序间的虚拟内存很容易实现隔离（页表数据不同就行，这样哪怕相同的虚拟地址，映射到的物理地址也不同），相互不影响对物理内存的访问。</li>
</ul>
<p>每个应用程序所能看到的就是完整的虚拟内存，其中有独立的运行时栈。运行在 CPU 上的应用程序也直接使用虚拟地址，因为 VMA 出 CPU 前会经过 MMU 转换为物理地址，再向硬件请求。</p>
<p>但是！为了节约空间，操作系统不会一次性将全部的虚拟内存（地址 0 ~ FFFFFFFF）全部用页表映射上物理内存（一来大小不够，二来浪费资源），只是先为虚拟内存的必要部分（例如程序栈的 data 段、code 段、shared libraries 段、stack 段等）分配物理内存、记录在页表上。其余部分被称为<strong>未被分配的段</strong>。这个有 2 种可能：</p>
<ul>
<li>应用程序没有权限（执行 kernel space 段，或执行了标记为不可执行的栈区），或这里确实不应该有数据；</li>
<li>应用程序确实向操作系统申请了大量空间，不过有些还没使用过，OS 自己还<strong>没有</strong>将这段区域通过页表建立与物理内存的映射。</li>
</ul>
<p>所以，当程序指令访问上述 2 种段的时候，硬件发现在页表中找不到对应的物理地址，于是发出一个 Synchronous Exception，其类型是 Page Fault。</p>
<p>如果是因为访问了上面第一种情况的 “未分配的段”，那么在进入 Exception Handler 后，操作系统发现程序确实不应该访问这里，那么操作系统向原进程<strong>发送 SIGSEGV 信号 / SIGGPF 信号（Segmentation Fault 软件信号，或者 Protection Fault 软件信号，前面介绍过，这些信号是另一种 ECF 机制，下下节讨论）</strong>，控制流直接离开原程序（abort），属于 <strong>unrecoverable</strong> 类型；</p>
<p>如果是因为访问了上面第二种情况的 “未分配的段”，那么操作系统发现是自己没分配，于是在 Exception Handler 中，OS 会将一段新的物理地址分配给虚拟内存，记录在页表中，<strong>回到 $I_{current}$ 的位置</strong>，属于 <strong>recoverable</strong> 类型；</p>
</blockquote>
</li>
<li><p>触发后默认的行为：回到 $I_{current}$（recoverable），或者终止（unrecoverable）；</p>
</li>
</ul>
</li>
<li><p>Aborts（终止）</p>
<ul>
<li><p>触发方法：程序执行了一条神奇的指令，硬件层面严重错误，操作系统对应的 Exception Handler  也没辙，默认行为就是终止程序；</p>
</li>
<li><p>例子：<strong>illegal instruction（非法指令，通常因为低特权程序执行了高特权指令，或者压根汇编指令就有问题）、parity error（硬件奇偶校验错误）、machine check（硬件检查未知错误）</strong>；</p>
<blockquote>
<p>后两种可能是机器被宇宙射线击中，发生了 bits flop，或者硬件电路出问题了；</p>
</blockquote>
</li>
<li><p>默认行为：<strong>abort（unrecoverable）</strong>；</p>
</li>
</ul>
</li>
</ol>
<h4 id="16-3-5-Summary-of-Exception"><a href="#16-3-5-Summary-of-Exception" class="headerlink" title="16.3.5 Summary of Exception"></a>16.3.5 Summary of Exception</h4><p>16.3 中，我们介绍了非常底层级的一种硬件 ECF 机制：Exceptions，请大家回忆：<strong>Exception 的 概念、处理过程、实现方法、种类以及各种类之间的处理模式</strong>。</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/exception_taxonomy.png" height="200px"></p>
<table>
    <tr>
        <th>Exception Type</th>
        <td>Interrupt</td>
        <td>Traps</td>
        <td>Faults</td>
        <td>Aborts</td>
    </tr>
    <tr>
        <th>Recoverable</th>
        <td>✔</td>
        <td>✔</td>
        <td>Possibly</td>
        <td>❌</td>
    </tr>
    <tr>
        <th>Return to</th>
        <td>I next</td>
        <td>I next</td>
        <td>I current / abort</td>
        <td>abort</td>
    </tr>
</table>


<p>这种低层级的控制转移可以由操作系统和硬件联合实现，也是其他高级 ECF 机制的基础。</p>
<h3 id="16-4-Exception-Control-Flow-Process-Context-Switch"><a href="#16-4-Exception-Control-Flow-Process-Context-Switch" class="headerlink" title="16.4 Exception Control Flow: Process Context Switch"></a>16.4 Exception Control Flow: Process Context Switch</h3><p>要了解进程上下文切换，首先要了解什么是进程。</p>
<h4 id="16-4-1-Process"><a href="#16-4-1-Process" class="headerlink" title="16.4.1 Process"></a>16.4.1 Process</h4><ul>
<li><p>定义：一个进程是一个正在运行的程序的实例。</p>
<blockquote>
<p>与程序（program）不同，程序可以看作存在于 <code>*.c</code> 文件中的、存在于二进制文件的 <code>.text</code> 区域的、存在于已加载内存的字节中。</p>
<p>进程是计算机科学中最为影响深远的思想之一。</p>
</blockquote>
</li>
<li><p>进程的 3 种状态：Running、Blocked（Stopped）、Terminated</p>
</li>
<li><p><strong>进程提供的 2 个关键抽象</strong>：</p>
<ol>
<li><p>Logical Control Flow：</p>
<ul>
<li>每个进程都感觉自己独占了 CPU 资源，不用担心寄存器、CPU 的重要数据被更改；</li>
<li>这种逻辑上的控制流的隔离机制来源于 <strong>OS 内核和硬件提供的重要 ECF —— Process  Contest Switching</strong>；</li>
</ul>
<blockquote>
<p>啥是 Logical Control Flow，在本节结束后你就会知道。</p>
</blockquote>
</li>
<li><p>Private Address Space：</p>
<ul>
<li>每个进程都感觉自己独占了主存资源，不用担心别的程序未经同意访问自己的资源；</li>
<li>这种隔离机制来源于 <strong>OS 和硬件提供的重要抽象：Virtual Memory</strong>（前面说过）；</li>
</ul>
</li>
</ol>
<p>以上的两个抽象为操作系统提供了<strong>多进程执行与并发（Multiprocessing &amp; Concurrency）的能力</strong>。</p>
</li>
<li><p>基于上面 2 条关键抽象，我们的进程满足：</p>
<ol>
<li>有整套独立的虚拟内存空间，互不干扰；</li>
<li>有看起来能够持续执行的 CPU 及稳定的寄存器资源；</li>
</ol>
</li>
</ul>
<h4 id="16-4-2-How-does-Multiprocessing-work-on-single-processor"><a href="#16-4-2-How-does-Multiprocessing-work-on-single-processor" class="headerlink" title="16.4.2 How does Multiprocessing work on single processor ?"></a>16.4.2 How does Multiprocessing work on single processor ?</h4><p>那么，操作系统是如何同时运行多个进程的呢？我们以仅有一个处理器核为例。</p>
<p>我们在 16.3.4 中曾经提到过 “系统时钟中断和分时复用”。操作系统想要随时能够取得控制权，就需要<strong>借助硬件时钟，每隔一段时间触发一次时钟中断（interrupt）的 exception，让程序从用户态回到内核态</strong>，由操作系统判断情况，是否要进行一些调度或者切换等处理操作。</p>
<p>为了充分利用 CPU 等资源，同时运行多个进程，操作系统对每个进程的单次执行时间设置较短（大约 1 ms 量级），<strong>一旦该进程执行时间片耗尽</strong>，那么操作系统会<strong>借助时钟中断的机会</strong>触发一种高级的 ECF: Process Context Switch，将处理器上下文数据切换到另一个进程继续执行。</p>
<p>这里 “进程的上下文数据” 就是 <strong>能够让系统处理器从其他进程回到当前进程所需额外的数据</strong>。由于每个进程独享一段虚拟内存，所以原本在虚拟内存中的上下文数据无需另外保存。所以，进程的上下文数据一般指 <strong>处理器芯片中的各个寄存器的值、内核数据结构（页表、进程表、文件表等，都放在 kernel space 中）以及各进程虚拟内存总体的物理位置</strong>。</p>
<p>那么这样也不难理解为什么 OS 和硬件能做到在各个进程之间的无缝切换了。我们小小总结一下：</p>
<ul>
<li><p>什么是 Process Context Switch？</p>
<p>进程上下文切换是指 OS 和硬件 控制处理器保存在当前进程的上下文数据，并切换到另一个进程继续执行的过程。这种交替执行的方式被称为 <strong>interleaving</strong>；</p>
</li>
<li><p>为什么需要 Process Context Switch？</p>
<p>这能够让操作系统利用有限的 CPU 执行多进程任务（multiprocessing），充分利用系统资源，也不至于让一个进程卡死就波及到其他进程的执行。也就是说，<strong>interleaving 可以实现 multiprocessing</strong>；</p>
</li>
<li><p>什么时候出现 Process Context Switch？</p>
<ol>
<li><strong>（必定）当 Hardware Timer 触发了时钟中断 Exception</strong>；</li>
<li><strong>（必定）当该进程出现耗时的系统调用</strong>（通常是类似 <code>read/write/sleep</code> 的系统调用）时，哪怕该进程时间片没耗尽，操作系统依然会 suspend 这个进程（进程转为 blocked 状态）；</li>
<li><strong>（可能）当该进程出现了普通的系统调用</strong>，控制权流转到 OS Kernel 中，操作系统会根据情况（例如优先级等情况）选择是否进行进程上下文切换。</li>
</ol>
<blockquote>
<p>我们发现，这三种原因全都是 <strong>Exception</strong>，因此说底层 Hardware ECF 为高级 ECF 提供了基础条件。</p>
</blockquote>
</li>
<li><p>底层的 Process Context Switch 如何实现 / 进行的？</p>
<p>step 1. 因为上面所述的 3 种原因之一，当前进程执行到某一位置时暂停，并暂时转移到内核态，控制流交给 OS；</p>
<p>step 2. OS 判断当前是否应该进行 Process Context Switch，如果不是，则退出内核态，恢复原程序执行。不过大部分情况是应该进行切换的，因此进入下一步；</p>
<p>step 3. 确认要进行进程切换后，操作系统会评估各个进程的<strong>优先级、进程状态等信息</strong>，按照评估结果决定切换到哪个进程上，这个做出决定的内核程序段被称为 <strong>scheduler</strong>；</p>
<p>step 4. 操作系统在切换前找到原进程的信息，将上下文的处理器中的各个寄存器值存入该进程的虚拟内存中，然后转到 scheduled process 中，从 scheduled process 的虚拟内存中读出处理器的上下文数据，继续执行 scheduled process，过程如下：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/context_switch.png" height="200px"></p>
</li>
<li><p>在 Context Switch 中需要注意的是：</p>
<ul>
<li>OS Kernel 并不是一个单独的进程，OS Kernel 的数据存在于每个进程中，作为它们的一部分。通常数据位于各进程虚拟内存 <strong>栈区的下层（用户态不可访问）</strong>；</li>
</ul>
</li>
</ul>
<h4 id="16-4-3-Concurrency-amp-Parallelism-amp-Interleaving"><a href="#16-4-3-Concurrency-amp-Parallelism-amp-Interleaving" class="headerlink" title="16.4.3 Concurrency &amp; Parallelism &amp; Interleaving"></a>16.4.3 Concurrency &amp; Parallelism &amp; Interleaving</h4><p>之前我们讨论的实现 multiprocessing 的方式是 interleaving，而计算机科学中还有两个概念叫 <strong>并发（concurrency）和 并行（parallelism）</strong>，它们之间的关系是什么？我们来对比一下：</p>
<ul>
<li>并发：指<strong>在一个较短的时间内同时执行多条任务或进程</strong>，它是一种<strong>执行策略</strong>，我们可以由多种方案来实现这个策略；</li>
<li>交织（interleaving）：指<strong>交替（在时间上 sequential）执行多条任务或进程，但 “appeals to”（看起来像是）同时在执行所有任务</strong>，这个名词通常被用作多任务或分时复用的系统中，表明<strong>处理器短时间内在不同任务间切换以达到同时执行的效果</strong>。</li>
<li>并行：指<strong>严格同时地执行多条任务或进程</strong>，主要的目标是利用<strong>多核 / 多处理器</strong>共同工作的杠杆作用来同时地执行任务，提升系统性能；</li>
</ul>
<p>我们将上面的概念解析成几个容易理解的观点：</p>
<ol>
<li>并发是一个很广的概念，它可以通过多种机制实现，比如 并行（simultaneous execution）、交织（sequential execution with rapid switching），所以说 <strong>并行和交织都是实现并发的途径</strong>；</li>
<li>交织则强调在一个处理器上，充分利用有限资源执行多个任务，而并行则强调在多个处理器相互协作，同时处理不同的任务，达到 1+1 &gt; 2 的效果；</li>
</ol>
<p>可能还有同学会问，那多进程（multiprocessing）和它们又有啥关系？</p>
<p>实际上，我们上面讨论的都是抽象层面的策略和方案，它们可以针对计算机系统中的进程，也可以针对其他的任务。所以<strong>并发、并行、交织都是实现多进程的思路之一</strong>。</p>
<h4 id="16-4-4-Concurrent-Process"><a href="#16-4-4-Concurrent-Process" class="headerlink" title="16.4.4 Concurrent Process"></a>16.4.4 Concurrent Process</h4><p>理解了并行、并发、交织的概念后，我们再来看<strong>进程的并发</strong>。进程的并发有以下重要的概念：</p>
<p>首先我们在 16.1 中介绍过，物理控制流（大家回忆一下）是指硬件上正在执行的实际指令序列。现在，我们将每一个进程都看作一个 <strong>Logical Control Flow</strong>（逻辑控制流），所谓逻辑控制流就是<strong>从这个进程的开始到最终 terminated 的全过程</strong>（包括中间 blocked 的部分）。画一对图大家就理解了：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/physical_control_flow.png" height="200px"></p>
<p>如上图，假设在一个处理器上，进程 A、B、C 的物理控制流如图所示。我们可以看到这采取了一种多进程交替执行的方式实现了进程的并发。所以它所对应的逻辑控制流是：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/logical_control_flow.png" height="200px"></p>
<p>我们可以形象地理解，进程逻辑控制流就是将它的物理控制流从头至尾连接起来。</p>
<blockquote>
<p>注意：如果 <code>graph 2</code> 是物理控制流，那么这个行为就是多核并行了。</p>
</blockquote>
<p>在这个基础上，我们做出如下定义：</p>
<ul>
<li>如果两个进程的逻辑控制流在时间上相互重叠（overlap in time），那么称这两个进程是<strong>并发执行</strong>（concurrently）的；</li>
<li>否则称这两个进程是<strong>顺序执行</strong>（sequentially）的；</li>
</ul>
<h4 id="16-4-5-Process-Control"><a href="#16-4-5-Process-Control" class="headerlink" title="16.4.5 Process Control"></a>16.4.5 Process Control</h4><p>在了解很多进程的理论后，我们需要转向实践层面的学习。现代 Linux 系统提供了很多控制进程的<strong>系统级函数</strong>，这些函数操作进程的过程称为 “<strong>进程控制</strong>”，而这些<strong>系统级函数最终大多数都会进行系统调用</strong>。</p>
<p>以 x86-64 Linux 为例，大多数系统函数的规范是：</p>
<ul>
<li><p>如果执行出错，则返回 <strong>-1</strong>，同时设定全局宏 <code>errno</code> 来提示出错的原因。</p>
<blockquote>
<p>因此在使用系统级函数时，有一个约定俗成的硬性规定（hard and fast rule）：<strong>当调用系统级函数后，必须检查其返回值，已确认其是否正确执行</strong>。</p>
<p>某些特别的系统级函数除外，例如 <code>exit</code>、<code>free</code> 返回 <code>void</code> 类型；</p>
</blockquote>
</li>
</ul>
<p>首先遇到的第一个进程控制的系统级函数，用于<strong>复制 / 创建进程</strong>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">pid_t</span> <span class="title function_">fork</span><span class="params">(<span class="type">void</span>)</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>作用：复制一个与当前进程一模一样的进程。复制出的进程被称为原进程的<strong>子进程</strong>，父进程的含义不解释。</p>
</li>
<li><p><strong>注意，一模一样是进程的虚拟内存中的几乎所有数据都一致，但父进程和子进程虚拟内存相互独立（相当于 deep copy）</strong>；</p>
<ul>
<li>虚拟地址、进程总体程序栈数据都一样；</li>
<li>文件标识符直接可以继承使用，也就是可以访问任何父进程已打开的文件；</li>
<li>父、子进程间 PID、页表等信息不一致；</li>
</ul>
</li>
<li><p>返回值：<strong>在父、子进程中分别返回一次。</strong></p>
<ul>
<li>当创建进程失败后，返回 -1；</li>
<li>当进程创建成功，且当前进程为父进程时，返回<strong>子进程的 PID（正整数）</strong>；</li>
<li>当进程创建成功，且当前进程为子进程时，返回 <strong>0</strong>；</li>
</ul>
</li>
<li><p>⚠ 使用提示：</p>
<ol>
<li><p>此方法创建的新进程与原进程的<strong>运行的顺序和同步性完全不能保证</strong>（即在逻辑控制流中没有明确先后关系）。因此输出时序具有随机性，在编程时不应该假设二者的执行顺序；</p>
</li>
<li><p>适宜使用<strong>树状拓扑图的结构</strong>（这被称为 <strong>进程图，process graph</strong>）分析存在多个 fork 进程控制的情况；</p>
<blockquote>
<p><strong>进程图的使用方法</strong></p>
<p>一个进程图是分析<strong>并发程序</strong>的语句<strong>部分执行顺序</strong>的有力工具。</p>
<ul>
<li>进程图是一个有向无环图（DAG，没有自环、重边），图的每个顶点代表每条语句的执行情况；</li>
<li><code>a -&gt; b</code> 表示 a 语句发生在 b 语句之前，二者<strong>在逻辑控制流上有明确先后关系</strong>；</li>
<li>进程图的<strong>边</strong>可以标注当前情况下<strong>变量的值</strong>；</li>
<li>进程图的<strong>点</strong>可以标注当前语句的<strong>输出或其他信息</strong>；</li>
<li>进程图的<strong>任意一种拓扑排序与一种可能的执行顺序</strong><u><strong>一一对应</strong></u>（所有拓扑排序则代表所有所有可能的执行顺序）；</li>
</ul>
<p>这里一个常见考题：给出一个含有很多 <code>fork()</code> 的程序，要求写出输出情况；</p>
</blockquote>
</li>
</ol>
</li>
</ul>
<p>其次，我们还可以<strong>获取进程号（PID）</strong>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">pid_t</span> <span class="title function_">getpid</span><span class="params">(<span class="type">void</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">pid_t</span> <span class="title function_">getppid</span><span class="params">(<span class="type">void</span>)</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>二者作用：获取当前进程 / 获取父进程 PID；</li>
<li>返回值：当前进程 / 父进程 PID；</li>
</ul>
<p>系统级函数还可以<strong>终止一个进程</strong>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">exit</span><span class="params">(<span class="type">int</span> status)</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>作用：以 <code>status</code> 状态数终止这个进程；</li>
<li>约定：<code>status</code> 状态数 0 表示正常退出，非零代表异常退出；</li>
<li>返回值：不返回任何值，一个进程只会执行一次；</li>
</ul>
<p>系统级函数还可以<strong>让一个进程主动进入 stopped 状态并持续一段时间</strong>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">unsigned</span> <span class="type">int</span> <span class="title function_">sleep</span><span class="params">(<span class="type">unsigned</span> <span class="type">int</span> secs)</span>;    <span class="comment">/* in &lt;unistd.h&gt; */</span></span><br></pre></td></tr></table></figure>
<ul>
<li>作用：让当前进程进入 stopped 状态 suspend 起来，不接受 OS 调度，直到 <code>sec</code> 秒后恢复 running 状态；</li>
<li>返回值：进程实际<strong>还剩多少秒没有 sleep</strong>（因为中途可能会被信号等 ECF 机制打断）；</li>
</ul>
<p>系统级函数也可以<strong>让一个进程无限期进入 stopped 状态，直到向其传入任意信号</strong>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">pause</span><span class="params">(<span class="type">void</span>)</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>作用：当前进程进行系统调用，直接进入 stopped 状态；</li>
<li>返回值：如果控制流能回来，那么总是返回 -1；</li>
</ul>
<hr>
<p>此外，系统函数还提供了 <strong>回收子进程（Reaping Child Process）</strong> 的能力。</p>
<p>为了了解这是什么意思，我们有必要 recap 一下在 16.4.1 中介绍的 Process 的概念。从编程人员的角度来看，一个进程具有 3 种状态（运行、阻塞 和 终止）。现在我们结合之前了解到的 Process Context Switch 和进程调度的基础知识，再重新认识一下这 3 种状态：</p>
<ul>
<li><p>Running：处于该状态的进程<strong>可能正在被执行</strong>，<strong>也可能是退出了阻塞状态，等待被 OS 调度执行</strong>；</p>
</li>
<li><p>Stopped：处于该状态的进程<strong>已挂起（suspended），并且无法被 OS 调度，除非有信号通知</strong>；</p>
</li>
<li><p>Terminated：处于该状态的进程<strong>已经永久结束运行</strong>；</p>
<blockquote>
<p>进程终止的 3 点原因：</p>
<ol>
<li>收到一个<strong>默认行为是终止进程的信号</strong>；</li>
<li><code>main</code> 流程执行完毕；</li>
<li>进程种的程序主动调用 <code>exit</code> 函数；</li>
</ol>
</blockquote>
</li>
</ul>
<p>我们发现，改变进程状态的方法是<strong>操作系统与应用程序间的</strong>高级 ECF：<strong>信号</strong>；而信号的发出又需要 硬件 ECF（Exception）作为条件。</p>
<blockquote>
<p>下一节会提及高级 ECF 信号的机制，举个例子，Ctrl + C -&gt; Interrupt Exception -&gt; Kernel 发出 SIGINT -&gt; 信号提醒进程进行默认行为）。</p>
</blockquote>
<p>除此之外，我们还看到，进程的状态中有一个是 terminated，这说明<strong>操作系统在一个进程终止后，会一直保存这个进程的状态和部分数据（包括退出状态、多种 OS 表），直到它被 “回收（reaped）”</strong>。那么为什么进程结束了还需要等待回收？为何不直接清除这个进程的数据？</p>
<p>这是因为，我们通常需要知道<strong>进程退出的一些状态信息（正常退出，还是因为其他原因退出）</strong>，如果 OS 在进程结束后就直接清除数据，那么我们无从知晓其中的信息。</p>
<p>通常情况下，在一个进程从永久退出执行，直到被回收的时间段内，我们将这个进程称为 <strong>zombie</strong>（僵尸进程，在 <code>ps</code> 命令下显示 <code>&lt;defunct&gt;</code>）。</p>
<p>那么进程最终应该由谁回收？答案是<strong>父进程或者是系统根进程 <code>init</code> (PID = 1)</strong>。父进程如果想要等待在子进程退出后获取子进程的退出状态，那么就需要使用系统级函数 <code>wait</code> 和 <code>waitpid</code>。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">pid_t</span> <span class="title function_">wait</span><span class="params">(<span class="type">int</span> *child_status)</span>;    <span class="comment">/* Equivalent to waitpid(-1, &amp;s, 0); */</span></span><br><span class="line"><span class="type">pid_t</span> <span class="title function_">waitpid</span><span class="params">(<span class="type">pid_t</span> pid, <span class="type">int</span>* child_status, <span class="type">int</span> options)</span>;</span><br></pre></td></tr></table></figure>
<p>由于 <code>wait</code> 是对 <code>waitpid</code> 的默认包装，因此我们这里仅介绍 <code>waitpid</code>；</p>
<ul>
<li><p>第一参数 <code>pid</code>指定父进程要等待的子进程的 PID；如果传入 <strong>-1</strong>，则表示<strong>等待任意一个子进程状态改变即返回</strong>；</p>
<blockquote>
<p>“状态改变”，而不是永久终止（terminated）。</p>
</blockquote>
</li>
<li><p>第二参数 <code>child_status</code> 应该传入一个整型地址，函数返回时会将子进程的状态码（<strong>和退出码不一样，需要专门的宏进行读取</strong>）填写进去；如果传入 <strong>NULL</strong>，则表示不关心子进程的状态，只是等待指定的子进程状态改变；</p>
<blockquote>
<p>读取该参数的宏位于 <code>&lt;sys/wait.h&gt;</code> 头文件中：</p>
<p><code>WIFEXITED(child_status)</code>：返回子进程是否被正常终止（调用了 <code>_exit(2)/exit(3)</code> 或从 <code>main</code> 返回）；</p>
<p><code>WEXITSTATUS(child_status)</code>：返回子进程的退出状态（当且仅当 <code>WIFEXISTED</code> 为真的时候有效）；</p>
<p><code>WIFSIGNALED(child_status)</code>：返回子进程是否被信号终止；</p>
<p><code>WTERMSIG(child_status)</code>：返回终止子进程信号的编号（当且仅当 <code>WIFSIGNALED(child_status)</code> 为真时有效）；</p>
<p>还有 <code>WCOREDUMP(child_status)</code>、<code>WIFSTOPPED(child_status)</code>、<code>WSTOPSIG(child_status)</code>、<code>WIFCONTINUED(child_status)</code> 等，大家可以用到再查；</p>
</blockquote>
</li>
<li><p>第三参数 <code>options</code> 常用的参数有 4 个，可以由按位或运算符连接：</p>
<ul>
<li><p>0：指定 <code>waitpid</code> 函数<strong>阻塞</strong>，直到子进程状态改变、获取信息后才返回；</p>
</li>
<li><p><code>WNOHANG</code>：指定 <code>waitpid</code> 函数<strong>非阻塞</strong>，如果子进程状态还没改变，那么立即返回；</p>
</li>
<li><p><code>WUNTRACED</code>：指定 <code>waitpid</code> 在子进程<strong>不是因为 <code>ptrace</code> 而进入 stopped 状态时</strong>也直接返回；</p>
<blockquote>
<p>什么是 <code>ptrace</code> ?</p>
<p><code>ptrace</code> 是 Linux 的<strong>另一个系统调用</strong>，为一个进程提供了<strong>观察</strong>和<strong>控制</strong>另一个进程的执行过程的能力，同时也提供<strong>检查</strong>和<strong>改变</strong>另一个进程的内存值以及相关寄存器信息。</p>
<p>大名鼎鼎的 <code>gdb</code> 和系统工具 <code>strace</code> 都是基于 <code>ptrace</code> 完成调试工作 和 逆向工程的。</p>
<p>这里的 <code>ptrace</code> 的系统级函数签名如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/ptrace.h&gt;</span>       </span></span><br><span class="line"><span class="type">long</span> <span class="title function_">ptrace</span><span class="params">(<span class="keyword">enum</span> __ptrace_request request, <span class="type">pid_t</span> pid, <span class="type">void</span> *addr, <span class="type">void</span> *data)</span>;</span><br></pre></td></tr></table></figure>
<p>事实上，当 <code>ptrace</code> 被调用来 attach 一个进程时，首先进入 syscall（Exception），操作系统在 exception handler 中的默认行为是通过<strong>信号</strong>沟通 <code>ptrace</code> 所在进程 和 attach 的进程，最后该进程会进入 <strong><code>Traced</code> 状态</strong>（一个与 Stopped 状态几乎相同的状态，都是暂时中止进程执行和调度），等待 <code>ptrace</code> 所在进程的调试工作。</p>
</blockquote>
</li>
<li><p><code>WCONTINUED</code>：指定 <code>waitpid</code> 在子进程接受到信号 <code>SIGCONT</code> 而从 stopped 状态恢复为 running 状态时，也直接返回；</p>
</li>
</ul>
</li>
<li><p>返回值：如果成功执行，则返回状态改变的子进程 PID（<strong>如果指定了 <code>WNOHANG</code>，并且指定的子进程存在，但是子进程还没改变状态，那么直接返回 0</strong>）；如果执行错误，那么返回 -1，错误码位于 <code>errno</code>；</p>
</li>
</ul>
<p>这两个函数不仅可以查看子进程的退出状态，而且也告诉操作系统，“如果子进程结束，则可以直接回收该进程了”。</p>
<p>如果父进程不想了解子进程的退出情况（<strong>没有调用上述两个函数</strong>），或者<strong>在子进程结束前就退出了（那么这时，子进程被称为孤儿进程，orphaned child process）</strong>，那么操作系统<strong>会自动将回收权交给 <code>init</code> 根进程，等待孤儿进程结束后直接回收</strong>。</p>
<p>这种回收的流程可以总结为：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/reap_process.png"></p>
<blockquote>
<p>⚠ 一种可能的内存泄漏的情形：</p>
<p>在一个长期运行的服务器上，系统可能运行了大量的进程。对于一些服务程序，<code>init</code> 根进程不会回收这些 zombie 进程，因为服务器是长期运行的，也等不到父进程结束的情况。如果父进程不显式回收子进程，那么会导致 zombie 进程堆积，内存溢出，甚至内核崩溃。</p>
</blockquote>
<p>⚠ <strong>另外，还有一个要点，即 <code>waitpid</code> 只能等待父进程的直接子进程（immediate child process），它无法等待子进程的子进程的结束并返回信息的</strong>。</p>
<hr>
<p>最后，系统级函数还提供了<strong>更改当前进程运行的程序</strong>的功能（毕竟之前只提供了 <code>fork()</code> 通过复制创建进程）。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">execve</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *pathname, <span class="type">char</span> *<span class="type">const</span> _Nullable argv[],</span></span><br><span class="line"><span class="params">           <span class="type">char</span> *<span class="type">const</span> _Nullable envp[])</span>;</span><br></pre></td></tr></table></figure>
<p>这条系统级函数也是系统调用的接口，可以在<strong>当前进程中加载并运行指定程序</strong>。</p>
<ul>
<li><p>第一参数 <code>pathname</code>：可执行文件名，它可以是二进制文件，也可以是由 <code>#!interpreter</code> 开头的脚本（Linux 约定俗成，在脚本文件前注释解释器名，例如 <code>#!/bin/bash</code>）；</p>
</li>
<li><p>第二、参数 <code>argv[]</code> 和 <code>envp[]</code> 分别是参数列表和环境变量列表，可以为空；</p>
<p><code>envp</code> 的设置就是简单字符串：<code>&quot;&lt;name&gt;=&lt;value&gt; ...&quot;</code>，或者使用 <code>getenv</code>、<code>putenv</code>、<code>printenv</code> 进行解析和设置环境变量字符串；</p>
<blockquote>
<p>注：<code>envp[]</code> 会在执行前由 OS append 几个参数，参数就是系统环境变量；</p>
</blockquote>
</li>
<li><p>返回值：<strong>仅在执行错误（找不到指定文件）时返回 -1</strong>；</p>
</li>
</ul>
<p>⚠ 注意，在当前进程运行该指令后，<strong>如果正确执行，那么程序控制流永远不会回到该指令的下一行，程序整体会在虚拟内存中完全被替换为新运行的程序，即完全覆盖当前程序虚拟空间，包括 code 区、data 区、stack 区等等</strong>，仅保留 PID、file descriptor 和 signal context（信号上下文）。</p>
<p>这意味着，正确执行的情况下，<strong><code>execve</code> 不会有返回值</strong>。</p>
<p>这还意味着，如果你想开发一个 Linux bash，那么你使用 <code>execve</code> 时，应该 <code>fork</code> 一个子进程出来，然后在子进程中执行该命令。否则当前程序会被覆盖。</p>
<p>当新的程序被从可执行文件加载到虚拟内存后，程序的虚拟内存的结构应该是这样（不包括 kernel space）：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/new_user_stack.png" height="350px"></p>
<blockquote>
<p>有同学可能会问，为啥不做一个<strong>同时创建一个进程并运行指定程序的系统调用呢？</strong>实际上，设计者从实用性和冗余性两个方面考虑，<code>fork</code> 非常有用，例如对于一个并发服务器而言，想要创建多个副本来响应 client，那么只需要 fork 就行；</p>
<p>而且你可以在运行指定程序前、fork 之后的时间内可以做一些其他自定义的准备工作，非常灵活。</p>
</blockquote>
<h4 id="16-4-6-Summary-of-Process-amp-Process-Control"><a href="#16-4-6-Summary-of-Process-amp-Process-Control" class="headerlink" title="16.4.6 Summary of Process &amp; Process Control"></a>16.4.6 Summary of Process &amp; Process Control</h4><p>在本节中，我们学习了一种高级的 ECF 机制：Process Context Switch。为了深入讨论这个话题，我们首先了解了进程的概念（一个正在运行的程序的实例），以及进程重要的 2 个抽象——对 CPU（logical control flow 是连续的）和 主存（private address space 是独享的）的抽象。</p>
<p>另外，我们从 “系统如何充分利用有限资源实现多进程并发” 的问题入手，了解了当今 Linux 操作系统<strong>利用 Timer Interrupt Exception</strong>（分时复用和时间片轮转）<strong>和 系统调用</strong> 达到 Process Context Switch 的目的，进而实现多进程执行的 interleaving。于是 进程上下文切换的 <strong>What、Why、When、How</strong> 四个问题都得到了解答。</p>
<p>其中，我们还详细比较了 interleaving、parallelism、concurrency、multiprocessing 的概念的异同，分析了怎么看 Physical Control Flow、怎么画 Logical Control Flow、怎么判断进程是 concurrent 还是 sequential 执行的。</p>
<p>最后一部分，在实际编程层面，我们介绍了控制 process 的、包装了系统调用的<strong>系统级函数</strong>，它们分别有：<code>fork</code>、<code>getpid</code>、<code>getppid</code>、<code>exit</code>、<code>sleep</code>、<code>waitpid(wait)</code>、<code>execve</code>。我们重点分析了这些函数的参数、返回值的含义，以及调用时的注意事项和技巧。</p>
<p>例如分析多重 <code>fork</code> 的进程图，<code>fork</code> 和 <code>execve</code> 的独特返回方式，<code>waitpid</code> 的复杂参数，最重要的点之一还是 “<strong>为什么要有进程回收、怎么进行进程回收</strong>” 的问题。</p>
<p>不过，我们在这节多次提到信号的概念，足以说明信号在操作系统与应用程序间的 ECF 的重要性。下节我们就讨论高级 ECF 中的信号（signal）机制。</p>
<h3 id="16-5-Exception-Control-Flow-Signals"><a href="#16-5-Exception-Control-Flow-Signals" class="headerlink" title="16.5 Exception Control Flow: Signals"></a>16.5 Exception Control Flow: Signals</h3><p>信号是由 OS 进行管理的软件信号，信号的种类和规范都由 OS 制定，完成 OS 和应用程序间的通信，实现高级的 Exception Control Flow；因此，我们需要先了解一下 OS（以 x86-64 Linux 为例）进程的继承结构，这样有助于在分析信号的时候不至于晕头转向。</p>
<h4 id="16-5-1-Linux-Process-Hierarchy-amp-Shell-Example"><a href="#16-5-1-Linux-Process-Hierarchy-amp-Shell-Example" class="headerlink" title="16.5.1 Linux Process Hierarchy &amp; Shell Example"></a>16.5.1 Linux Process Hierarchy &amp; Shell Example</h4><p>在 Linux 中，只有一种方法创建新的进程 —— <code>fork</code>；而由 <code>fork</code> 创建的进程有明确的父子关系，因此，Linux 中的所有程序所在进程实际上形成了一个层次结构：<strong>进程树</strong>。</p>
<p>在 Linux 启动的第一个进程是 <code>init</code> 根进程（PID = 1），其后所有生成的进程均为 <code>init</code> 的子进程。<code>init</code> 进程一般会创建 2 类进程：</p>
<ul>
<li><p><code>Daemon</code>：守护进程，是一类长期运行的程序，用来提供服务（例如对于一个 web 服务器，那么可能运行的服务是 apache 服务 <code>httpd</code>）；</p>
</li>
<li><p><code>login shell</code>：登录进程，这个进程运行的是命令行程序，为用户提供命令行接口，这样用户在登录后，可以以特定用户的身份，通过输入命令的方式与程序进行交互；</p>
<blockquote>
<p>例如用户输入 <code>echo &quot;Hello, Linux.&quot;</code> 的指令并回车，发生的是如下情况：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/login_shell.png" height="200px"></p>
</blockquote>
</li>
</ul>
<p>知道了这个道理，再结合上一节我们接触到的 process control 的系统级函数，我们就可以开始自己尝试用 C 写一个系统命令行了。我们来看看这个小型的命令行程序：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAXLINE 1024</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAXARGS 100</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">unix_error</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* msg)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">Fgets</span><span class="params">(<span class="type">char</span>* dst, <span class="type">int</span> cnt, FILE* input)</span>;    <span class="comment">/* 定义略，就是对 fgets 的包装 */</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">parseline</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* line, <span class="type">char</span>* argv[])</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">eval</span><span class="params">(<span class="type">char</span>* cmd)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">char</span> cmdline[MAXLINE];    <span class="comment">/* command line */</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">/* read */</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;&gt; &quot;</span>);</span><br><span class="line">        Fgets(cmdline, MAXLINE, <span class="built_in">stdin</span>);</span><br><span class="line">        <span class="keyword">if</span> (feof(<span class="built_in">stdin</span>))</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">/* evaluate */</span></span><br><span class="line">        eval(cmdline);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">eval</span><span class="params">(<span class="type">char</span>* cmd)</span> &#123;</span><br><span class="line">    <span class="type">char</span> *argv[MAXARGS];    <span class="comment">/* Argument list execve() */</span></span><br><span class="line">    <span class="type">char</span> buf[MAXLINE];        <span class="comment">/* Holds modifiled command line */</span></span><br><span class="line">    <span class="type">int</span> bg;                    <span class="comment">/* Should the job run in bg or fg ? */</span></span><br><span class="line">    <span class="type">pid_t</span> pid;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">strcpy</span>(buf, cmdline);</span><br><span class="line">    bg = parseline(buf, argv);</span><br><span class="line">    <span class="keyword">if</span> (argv[<span class="number">0</span>] == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span>;        <span class="comment">/* Ignore empty lines */</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (!builtin_command(argv)) &#123;    <span class="comment">/* Check if it is a builtin command */</span></span><br><span class="line">        <span class="keyword">if</span> ((pid = Fork()) == <span class="number">0</span>) &#123;    <span class="comment">/* Child runs user job */</span></span><br><span class="line">            <span class="keyword">if</span> (execve(argv[<span class="number">0</span>], argv, environ) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;%s: Command not found.\n&quot;</span>, atgv[<span class="number">0</span>]);</span><br><span class="line">                <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">/* Parent waits for foreground job to terminate */</span></span><br><span class="line">        <span class="keyword">if</span> (!bg) &#123;</span><br><span class="line">            <span class="type">int</span> status;</span><br><span class="line">            <span class="keyword">if</span> (waitpid(pid, &amp;status, <span class="number">0</span>) &lt; <span class="number">0</span>)</span><br><span class="line">                unix_error(<span class="string">&quot;waitfg: waitpid error&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%d %s&quot;</span>, pid, cmdline);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>细心的同学会发现，这个程序有个严重的 bug —— 它只对运行在 foreground（前台）的程序进行回收，对运行在 background（后台）的程序则仅仅是打印一条信息，就不再关心了。前一节我们讨论过，像 shell 这样长期运行的程序如果不回收其子进程，会导致 zombie 的堆积，引发内存泄漏的问题。</p>
<p>那么问题来了，对于运行在后台的子进程，我们不想等待，但该如何知道它何时结束，并且回收呢？这个问题的解决方案就是<strong>利用 Exception Control Flow</strong>，因为只有它能够不按照应用程序原先控制流，而是转向 OS Kernel，让 OS Kernel 配合通知我们的 shell 后台子进程的情况。这就是本节的主角，也是这类问题的解决方案 —— 信号（高级的 ECF 机制之一）。</p>
<h4 id="16-5-2-The-Features-of-Signals"><a href="#16-5-2-The-Features-of-Signals" class="headerlink" title="16.5.2 The Features of Signals"></a>16.5.2 The Features of Signals</h4><ul>
<li>定义：信号是一种软件产生的，<strong>用来通知进程，系统中某一种事件发生的小型信息</strong>。</li>
</ul>
<p>我们发现，信号的定义很像之前的 Hardware ECF（Exception），它们都是某种事件发生时触发的信息通知机制，但是后者是<strong>硬件和操作系统层面</strong>（包括 Asynchronous Exception 的硬件引脚 Interrupt 和 Synchronous Exception 的处理器触发进入 Exception table），前者则完全是<strong>由操作系统软件产生的软件层面的信息</strong>，抽象层级更高。</p>
<ul>
<li><p>发送方：通常是 <strong>OS Kernel</strong>，有时是<strong>一个 Process 请求内核（利用 <code>syscall</code> 这个 Exception）来向另一个进程发送</strong>（所以本质上<strong>只有</strong> OS Kernel 有权限发送信号）；</p>
</li>
<li><p>接收方：总是一个 Process；</p>
</li>
<li><p>发送时机：<strong>总是因为</strong>处理器触发了一个 Hardware ECF，进入某个 Exception Handler 中的行为，可能有以下两个原因：</p>
<ol>
<li>System call（<code>trap</code>）：有几种<strong>向另一个进程发送特定信号的系统调用</strong>：<code>kill -&lt;sigNum&gt;</code>（不是专门 terminated 进程的系统调用，而是用来发信号的，名字起的不好！），和之前我们接触过的 <code>ptrace</code> 等；</li>
<li>其他 unintended hardware ECF（例如 Interrupt（典型是 <code>Ctrl+C/D/Z</code> 键盘 I/O）、Fault（常见是 Page Fault、Floating Point Exception）等等）；</li>
</ol>
</li>
<li><p>接收时机：？？？（<strong>我们在下一节介绍</strong>）</p>
</li>
<li><p>内容：它真的很小，<strong>仅仅是一个小整型 ID（1 ~ 30）</strong>，来代表信号的种类；</p>
<p>不过每个整型在 OS 中对应唯一的信号类型和含义。下面是常见的几个信号：</p>
<table>
    <tr style="text-align: center;">
        <th>ID</th>
        <th>Name</th>
        <th>Default Action</th>
        <th>Corresponding Event</th>
    </tr>
    <tr>
        <td>2</td>
        <td>SIGINT</td>
        <td>Terminate</td>
        <td>User typed ctrl-c</td>
    </tr>
    <tr>
        <td>9</td>
        <td>SIGKILL</td>
        <td>Terminate</td>
        <td>Kill program (<b>cannot override or ignore</b>)</td>
    </tr>
    <tr>
        <td>11</td>
        <td>SIGSEGV</td>
        <td>Terminate &amp; Core dump</td>
        <td>Segmentation violation</td>
    </tr>
    <tr>
        <td>14</td>
        <td>SIGALRM</td>
        <td>Terminate</td>
        <td>Timer signal</td>
    </tr>
    <tr>
        <td>17</td>
        <td>SIGCHLD</td>
        <td>Ignore</td>
        <td>Child stopped or terminated</td>
    </tr>
</table>


</li>
</ul>
<p>  我们解释一些上面的信号。</p>
<p>  首先，<code>SIGINT</code> 就是我们对前台运行的程序触发 <code>Ctrl+C</code> 按键后，首先发生 Asynchronous Exception（Interrupt），通知处理器，处理器按照 Exception 处理流程转移到 OS Kernel 中处理 Keyboard Interrupt 的 Exception Handler 中，发现这是个 <code>Ctrl+C</code>，因此向目标进程发送一个 <code>SIGINT</code> 信号，然后把 Control Flow 交还 user mode 的 $I_{next}$；同时，目标进程收到信号会进行默认行为 —— terminated（可以 override，即自己设计接收信号的 procedure）；</p>
<p>  对于 <code>SIGKILL</code> 过程类似上面的情况，但是它一般利用 <code>kill -9</code> 指令，进行了系统调用，通过 <code>trap</code> 来发送信号；</p>
<p>  对于 <code>SIGSEGV</code>，一般是处理器访问非法地址后出现 <code>page fault</code>，可能发送这个信号；</p>
<p>  对于 <code>SIGALRM</code>，一般可以用作自定义信号，利用硬件时钟进行一些任务（例如设置与超时相关的行为）；</p>
<p>  对于 <code>SIGCHILD</code>，一般在<strong>一个进程的子进程的状态改变后</strong>，OS Kernel 会向该父进程发送这条信号，但默认行为是忽略。如果父进程是一个 long-run program 并且不使用阻塞的 <code>waitpid</code>，那么我们在父进程中应该主动捕获这个信号，防止发生子进程的内存泄漏；</p>
<blockquote>
<p>除此之外，我们在前面还见到过 <code>SIGFPE</code>、<code>SIGGPE</code> 等等信号，用到时再查也不迟；</p>
</blockquote>
<h4 id="16-5-3-Implementations-of-Sending-a-Signal"><a href="#16-5-3-Implementations-of-Sending-a-Signal" class="headerlink" title="16.5.3 Implementations of Sending a Signal"></a>16.5.3 Implementations of Sending a Signal</h4><p>那么，通过上面的解释，我们大致知道了，OS Kernel 大多是借助 Exception（Hardware ECF）这个时机来实现信号的发送的，但具体是如何进行的呢？</p>
<p>实际上，OS Kernel 向某个进程发送信号是通过<strong>改变目标进程上下文的状态数据</strong>来实现的。</p>
<blockquote>
<p>Linux 官方文档原文：</p>
<p>Kernel sends a signal to a destination process by updating some state in the context of the destination process.</p>
</blockquote>
<p>对，仅仅是目标进程的上下文的某个数据改变了，仅此而已。</p>
<p>那么，目标进程的响应机制呢？主要有以下几种：</p>
<ul>
<li><p><strong>Ignore</strong>：忽略该信号；</p>
</li>
<li><p><strong>Terminate</strong>：该进程终止，或被迫终止（不是中止，stopped）；</p>
</li>
<li><p><strong>Catch</strong>：捕获信号并处理（这里捕获信号并处理的程序称为 <strong>Signal Handler</strong>，<strong>它与 Exception Handler 不一样，它位于用户态代码中——也就是说，咱可以自己在 C 程序中设计 Signal Handler</strong>）；</p>
<p>对于 catch 这个选项而言，我们还要了解一下 signals 到达目标进程后的过程：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/signal_procedure.png" height="200px"></p>
<p>但是，在<strong>信号到达后、进程 A 收到（就是感知到）并处理之前</strong>的一段时间内，由于<strong>某个给定的时刻，只能有一个类型的待处理信号</strong>（因为信号是一个整型，发送信号就是改变一个数据，没有队列这个数据结构，所以重复发就会覆盖，下面会看到这种数据结构）。所以有两个问题：</p>
<ol>
<li>我们不能继续给这个进程发送信号，那么 OS 应该怎么知道目标进程有没有收到？</li>
<li>进程 A 是按照普通控制流正常运行的，怎么让它去临时接收这个信号呢？</li>
</ol>
<p>实际上，这引入了信号的 2 个概念：<strong>Pending 和 Blocked</strong>；不仅如此，我们还要了解 <strong>进程组的概念</strong>，然后我们才能完整地解释信号的收发过程。</p>
</li>
</ul>
<hr>
<p>下面是 16.5.3 的知识补充：</p>
<h5 id="16-5-3-1-Signal-Concepts-Pending-amp-Blocked"><a href="#16-5-3-1-Signal-Concepts-Pending-amp-Blocked" class="headerlink" title="16.5.3.1 Signal Concepts: Pending &amp; Blocked"></a>16.5.3.1 Signal Concepts: Pending &amp; Blocked</h5><p>其实信号也存在状态，其中两个特殊的状态是 pending 和 blocked：</p>
<ul>
<li>如果一个信号被 OS Kernel 发送，但是还没有被目标进程接收（感知并处理），那么这个信号处于 Pending 状态；（<strong>重复一遍，没有队列数据结构</strong>）</li>
<li>如果一个信号被 OS Kernel 发送，但是目标进程显式地阻塞特定信号的接收（感知但保留信号不处理），那么这个信号处于 Blocked 状态，除非该进程主动 unblock；</li>
</ul>
<p>从这里我们可以知道，<strong>pending 状态的 signals 至多只会被目标进程接收一次，但 blocked 状态的 signals 可以接收多次</strong>；</p>
<p>我们说过，信号只是一个表示信号类型的小整型，存不了其他数据，因此<strong>信号的状态是由 OS Kernel 维护的</strong>。</p>
<p>OS Kernel 中<strong>保存了各进程的 Pending / Blocking bits 组成的 bit vectors</strong>，位于每个进程的上下文虚拟内存的 kernel space 中。维护方法如下。</p>
<p><strong>对于 Pending Signals</strong>；</p>
<ul>
<li>当一个另一个进程的 OS Kernel 向当前（目标）进程发送<strong>第 k 号</strong>信号，那么当前进程的 OS Kernel 会设置当前进程的 Signal Pending Vector 的<strong>第 k 位</strong>为有效位（假设是 1）；</li>
<li>当当前进程接收了这个信号 k，那么当前进程的 OS Kernel 会设置当前进程的 Signal Pending Vector 的第 k 位为无效位（对应是 0）；</li>
</ul>
<p><strong>对于 Blocked Signals</strong>：</p>
<blockquote>
<p>Signal Blocked Vector 相当于是对 Signal Pending Vector 的<strong>掩码</strong>（被称为 <strong>signal mask，信号掩码</strong>）。</p>
</blockquote>
<p>如果 block / unblock 特定信号，那么目标进程会使用 <strong><code>sigprocmask</code>（又一个系统调用）</strong>显式设置掩码位对应的 Pending Signal 是否有效。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Prototype for the glibc wrapper function */</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">sigprocmask</span><span class="params">(<span class="type">int</span> how, <span class="type">const</span> <span class="type">sigset_t</span> *_Nullable <span class="keyword">restrict</span> <span class="built_in">set</span>,</span></span><br><span class="line"><span class="params">                <span class="type">sigset_t</span> *_Nullable <span class="keyword">restrict</span> oldset)</span>;</span><br></pre></td></tr></table></figure>
<p>具体用法见 16.5.5 节；</p>
<h5 id="16-5-3-2-Process-Concept-Process-Groups"><a href="#16-5-3-2-Process-Concept-Process-Groups" class="headerlink" title="16.5.3.2 Process Concept: Process Groups"></a>16.5.3.2 Process Concept: Process Groups</h5><p>在 Linux 下，每个进程都明确属于一个进程组。那么如何为一个新产生的进程分配进程组？</p>
<p>实际上，进程组的分配有专门的系统调用（又来几个系统调用）：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">pid_t</span> <span class="title function_">getpgrp</span><span class="params">(<span class="type">void</span>)</span>;    <span class="comment">/* Equivalent to getpgid(currentPID); */</span></span><br><span class="line"><span class="type">pid_t</span> <span class="title function_">getpgid</span><span class="params">(<span class="type">pid_t</span> pid)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">setpgrp</span><span class="params">(<span class="type">void</span>)</span>;    <span class="comment">/* Equivalent to setpgid(currentPID, currentPID); */</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">setpgid</span><span class="params">(<span class="type">pid_t</span> pid, <span class="type">pid_t</span> pgid)</span>;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>上述函数执行失败返回值均为 -1，均会设置 <code>errno</code>，注意检查。</p>
</blockquote>
<p>注意，进程组号 PGID 和进程 PID 是共用类型 <code>pid_t</code> 的。</p>
<p>此外，创建一个进程，<strong>默认的进程组号与父进程的进程组号相同</strong>；</p>
<p>这样的话，可以方便我们向<strong>在同一进程组中的所有进程都发送信号</strong>。例如，如果我们使用系统调用 <code>kill</code> 来给一个进程或进程组发送信号（以包装好的系统命令为例。当然，C library 也包装了一个系统级函数 <code>kill</code>，能够在 C 中向另一个进程发送信号）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">kill</span> -9 12345</span><br></pre></td></tr></table></figure>
<p>上面的指令就表示请求 bash 调用系统调用 <code>kill</code>，向<strong>进程号</strong>为 <code>12345</code> 的一个进程发送 9 号信号（<code>SIGKILL</code>）；</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">kill</span> -9 -12344</span><br></pre></td></tr></table></figure>
<p>上面的指令由于进程号前加了一个短 dash，因此被解释为 <strong>进程组号</strong>，上面的行为是向<strong>进程组号</strong>为 <code>12344</code> 的所有进程发送 9 号信号。</p>
<p>然后我们回过头解释一下 <code>Ctrl+C/Z</code> 是如何发送信号的。如下图。</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/process_group.png" height="300px"></p>
<p>首先，我们在 bash 中输入的指令和我们之前了解的一样，分为前台和后台任务；bash shell 在 <code>fork</code> + <code>execve</code> 一个指令的时候，会根据指令后面有没有 <code>&amp;</code> 来判断这是条前台还是后台任务。如果是前台任务，那么创建进程后还会进行系统调用，将前台任务放到<strong>前台进程组</strong>中。前台进程在一个 shell 主进程中只有一个，所以一般这个前台进程组由 shell 进程直接管理。</p>
<p>如果我们按下 Ctrl+C/Z，那么 Interrupt Exception Handler 的默认行为就是向 shell 进程发送 <code>SIGINT/SIGSTP</code> 信号；而 shell 定义了对于该信号的 Signal Handler，也就是<strong>向前台进程组中所有进程发送 <code>SIGINT/SIGSTP</code></strong>（不影响后台进程）。这就完成了一次键盘 I/O 信号的发送和传递。</p>
<blockquote>
<p>注：<code>SIGSTP</code> 信号的默认行为是让目标进程的状态 suspend 到 stopped 状态，直到接收到 <code>SIGCONT</code> 信号后才恢复。</p>
</blockquote>
<hr>
<h4 id="Back-to-16-5-3"><a href="#Back-to-16-5-3" class="headerlink" title="Back to 16.5.3"></a>Back to 16.5.3</h4><p>了解了信号的状态和管理的知识 和 进程组的知识，我们再回到 16.5.3，看看<strong>完整的信号处理过程</strong>应该是什么样子的。</p>
<p>考虑一个会经常出现的情形：某一个进程 A 正在执行，进程 B 的 OS Kernel 想向进程 A 发送一个第 k 号信号，怎么办？OS 是这么做的：</p>
<p><code>step 1.</code> 在某次 Process Context Switch 中，OS 的 scheduler 决定切换到 Process B，于是按照 Process Context Switch 的规范进行切换（保存当前进程上下文数据到当前进程的虚拟内存中，读 Process B 的进程上下文数据并加载到处理器中）；<strong>在运行 B 的代码前，OS Kernel 会按照想要发送给 A 的信号（k）来更改  A 的 Kernel space 中的 Pending Vector（将第 k bit 置为有效位 1）</strong> 然后转入用户态，正式运行 Process B 的代码；</p>
<p><code>step 2.</code> 在执行 Process B 一段时间后，处理器触发了 Exception（Interrupt、Trap、Recoverable Fault），于是控制流重新进入内核态。假如 scheduler 决定切换到另一个进程（也就是目标进程）A，<strong>那么在正式切换前，Kernel 会检查进程 A 的 signal 情况：使用 <code>pnb = pending &amp; ~blocked</code> 计算出上次 Kernel 发给这个进程的信号的集合，<code>pnb</code> 就是所有未被阻塞的信号的 bit vector</strong>；</p>
<ul>
<li>如果 <code>pnb == 0</code>，那么说明当前没有收到未阻塞的信号，OS Kernel 会继续进行 Context Switch 操作，切换到 Process A；</li>
<li>否则，OS Kernel 会选择 <code>pnb</code> 中最低非零位的 bit（假设第 k 位）作为信号接收。那么，OS Kernel 将 pending vector 第 k 位置为无效位（0），<strong>并且执行对应 k 号信号的 Signal Handler</strong>，<strong>此后重新回到 step 2 计算并检查 <code>pnb</code>，直至 <code>pnb == 0</code></strong>；</li>
</ul>
<p>这样信号的发送和接收的流程就形成了闭环：</p>
<ul>
<li><strong>信号接收时机：在 Process Context Switch 进入目标进程前统一检查并接收</strong>；</li>
</ul>
<p>于是我们可以说：</p>
<p><strong>信号的发送和接收依靠 Process Context Switch 实现，而 Process Context Switch 又是依靠 Hardware ECF（Exception）来实现的，三者抽象层级依次升高，密不可分，分别构成了硬件与操作系统、操作系统与应用程序间的 ECF 交互机制</strong>。</p>
<h4 id="16-5-4-Signal-Handlers-amp-Default-Action"><a href="#16-5-4-Signal-Handlers-amp-Default-Action" class="headerlink" title="16.5.4 Signal Handlers &amp; Default Action"></a>16.5.4 Signal Handlers &amp; Default Action</h4><p>好了，到目前为止，我们已经大致将信号机制的脉络捋清了。还有一点，我们之前就很想了解的：<strong>怎么自定义 signal handlers 呢？</strong> 这就需要我们更改一个进程收到某个信号的默认行为（Default Action）了。</p>
<p>提供修改信号 Default Action 的还是一个<strong>系统调用</strong>：<code>signal</code>（名字和 <code>kill</code> 一样有误导性。这里 <code>signal</code> 系统调用不是发送信号，而是设置进程对于信号的 default action）；</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">handler_t</span> *<span class="title function_">signal</span><span class="params">(<span class="type">int</span> signum, <span class="type">handler_t</span> *handler)</span>;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注 ：<code>handler_t*</code> 类型被 <code>typedef</code> 为一个函数指针类型 <code>void(*)(int)</code>；</p>
</blockquote>
<ul>
<li><p>第一参数 <code>signum</code>：要修改该进程默认行为的信号编号（在 <code>&lt;signal.h&gt;</code> 中有宏定义可供使用）；</p>
</li>
<li><p>第二参数 <code>handler</code>：类型为 <code>void(*)(int)</code> 的函数指针，即为 signal handler（其参数也为信号编号）；</p>
<blockquote>
<p>如果是要设置 Ignore / Terminate 为默认行为，那么它们（函数指针）在 <code>&lt;signal.h&gt;</code> 还有特定的宏：<code>SIG_IGN</code>、<code>SIG_DFL</code>；</p>
</blockquote>
</li>
<li><p>返回值：如果执行成功，则返回传入的 signal handler 指针；否则返回宏 <code>SIG_ERR</code>（0）；</p>
</li>
</ul>
<p>可是问题又来了。我们知道，signal handler 会在 Process Context Switch 前被调用，调整程序的 control flow。因此，signal handler 用户态代码 和 普通代码一样，都可以作为<strong>并发流（concurrent flow）</strong>。以前我们接触的并发流都是不同进程间的 control flow。不同进程间资源不共享，它们间的切换依靠 Process Context Switch；</p>
<p>但是！一旦引入了 signal handler，<strong>signal handler 本身是和原进程并发的</strong>，而它又会共享原进程的一切资源，这可能出现问题（<strong>什么问题？在 16.5.6 节讨论</strong>）</p>
<p>我们结合 signal handler，顺便复习一下 16.5.3 中的内容，从另一个角度来看<strong>完整的信号收发过程和并发</strong>的情况：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/full_signal_procedure.png" height="300px"></p>
<ul>
<li>首先我们知道，如果有一个进程 B 想要想要给 Process A 发送信号，那么在某次从 Process A  Process Context  Switch 到 Process B <strong>前</strong>（置位操作不一定正好发生在 Process Context Switch 时，可以在此之前），Kernel 就为 Process A 的 Pending Vector 置了有效位（如上图最上面的箭头）；</li>
<li>随后通过 Process Context Switch 后，控制流进入 Process B；</li>
<li>一段时间后，如果再次出现了一个 Process Context Switch，决定向 Process A 跳转，那么在进入 A 正式执行前，会检查其 <code>pnb</code> 向量是否为 0（如上图下面的箭头），然后按 default action 进入位于 user code 中的 <code>handler</code>（signal handler）中；</li>
<li>当 <code>handler</code> 执行完成后，控制流再次进入 kernel code 进行一些准备（例如恢复 $I_{next}$ 数据）；</li>
<li>最后控制流真正回到 user code 的 $I_{next}$ 的位置继续执行；</li>
</ul>
<h4 id="16-5-5-Nested-Signal-Handlers"><a href="#16-5-5-Nested-Signal-Handlers" class="headerlink" title="16.5.5 Nested Signal Handlers"></a>16.5.5 Nested Signal Handlers</h4><p>⚠ 这会出现一种情况 “Nested Signal Handlers”，因为在运行在 signal handler 时，毕竟也是 user code，也有可能发生 process context switch：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/nested_signal_handlers.png" height="250px"></p>
<p>为啥要讨论这种情况？因为 <strong>OS Kernel 对已经正在处理同类型信号时（即位于该信号的 Signal Handler 时），会自动阻塞该进程对同类型信号的接收</strong>。这种信号阻塞方式称为 <strong>Implicit blocking（隐式阻塞）</strong>；</p>
<blockquote>
<p>例如上图，如果程序位于第（4）步，那么它既会阻塞 <code>S</code> 信号，又会阻塞 <code>T</code> 信号的接收。</p>
</blockquote>
<p>而我们之前 16.3.5.1 介绍过的 <code>sigprocmask</code> 系统调用，则是程序可以显式地修改对信号的阻塞情况。</p>
<p>我们再回顾一下它的声明：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Prototype for the glibc wrapper function */</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">sigprocmask</span><span class="params">(<span class="type">int</span> how, <span class="type">const</span> <span class="type">sigset_t</span> *_Nullable <span class="keyword">restrict</span> <span class="built_in">set</span>,</span></span><br><span class="line"><span class="params">                <span class="type">sigset_t</span> *_Nullable <span class="keyword">restrict</span> oldset)</span>;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里的 <code>sigset_t</code> 就是之前我们说的 Pending Bit Vector 的数据；</p>
</blockquote>
<ul>
<li>第一参数 <code>how</code> 可不是信号编号，因为信号编号应该是 <code>set</code> 的 bit 位；它是 <strong><code>sigprocmask</code> 要执行的行为</strong>，具体也是由宏定义的：<ul>
<li><code>SIG_BLOCK</code>：将指定参数 <code>set</code> 的有效位加入现在的 blocking bit vector，阻塞指定信号；</li>
<li><code>SIG_UNBLOCK</code>：将指定参数 <code>set</code> 中的有效位从现在的 blocking bit vector 移除，停止阻塞某种信号；</li>
<li><code>SIG_SETMASK</code>：直接将参数 <code>set</code> 作为 blocking bit vector；</li>
</ul>
</li>
<li>第二参数 <code>set</code> 是一个与 pending bit vector 格式相同的数据，作用在第一参数中能看到，具体我们怎么操作这个向量并且填上去，还有专门设置这个 vector 的函数：<ul>
<li><code>sigemptyset</code>：返回一个空的 pending bit vector 数据；</li>
<li><code>sigfillset</code>：返回一个每个信号位都有效的 pending bit vector 数据；</li>
<li><code>sigaddset</code>：返回一个在输出 pending bit vector 基础上置位指定信号位的新的 pending bit vector 数据；</li>
<li><code>sigdelset</code>：同理，删除；</li>
</ul>
</li>
<li>第三参数在接下来的例子中就能看到。</li>
</ul>
<p><strong>这个虽然很多，但很重要！！！在 Shell Lab 中会用到</strong>。</p>
<p>为什么我们要用到它们呢？直接交给 OS Kernel 隐式阻塞不好吗？<strong>我们不妨考虑一个场景，如果程序中有一串代码不希望被用户用 Ctrl+C 打断，那么我们就需要暂时显式地阻塞 <code>SIGINT</code> 信号</strong>，下面就是例子：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">sigset_t</span> mask, prev_mask;</span><br><span class="line">sigemptyset(&amp;mask);</span><br><span class="line">sigaddset(&amp;mask, SIGINT);</span><br><span class="line"><span class="comment">/* Block SIGINT and save previous blocked set */</span></span><br><span class="line">sigprocmask(SIG_BLOCK, &amp;mask, &amp;prev_mask);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Code region that will not be interrupted by SIGINT */</span></span><br><span class="line"><span class="comment">/* ... */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Restore previous blocked set, unblocking SIGINT */</span></span><br><span class="line">sigprocmask(SIG_SETMASK, &amp;prev_mask, <span class="literal">NULL</span>);</span><br></pre></td></tr></table></figure>
<p>看完这串代码你大概能明白 <code>sigprocmask</code> 的第三个参数的含义了：以指针传入，<strong>存储以前的信号掩码信息，便于之后的恢复工作</strong>。</p>
<h4 id="16-5-6-Safe-Signal-Handling-⚠IMPORTANT"><a href="#16-5-6-Safe-Signal-Handling-⚠IMPORTANT" class="headerlink" title="16.5.6 Safe Signal Handling [⚠IMPORTANT]"></a>16.5.6 Safe Signal Handling [⚠IMPORTANT]</h4><p>讨论完前面的知识，相信大家心里有点数了——信号非常难缠，不仅约定、机制和系统调用接口贼多，而且你必须小心再小心，否则会出大问题：</p>
<ul>
<li><p>不正确地处理信号会导致一些系统级问题，包括但不仅限于：</p>
<ul>
<li><p>内存泄漏（zombie 堆积等原因）；</p>
</li>
<li><p>共享内存访问冲突（<strong>死锁 dead lock、段错误 Segmentation fault 等问题都会出现</strong>。由于 signal handlers 与普通 user code 共享内存，但它们是并发的，很像一对<strong>并发的线程，thread</strong>），<strong>你要像写多线程程序一样小心，保证线程安全性</strong>；</p>
<blockquote>
<p>为什么？这还是因为 signal handlers 和 普通程序构成了<strong>并发流</strong>。</p>
<p>因为在 signal handler 执行前后，原程序都停留在 $I_{current}$ 的位置上，这样在 Logical Control Flow 上看，它们是并发的，<strong>几乎和两个线程的效果一样</strong>。</p>
<p>如果原程序正在改变一个诸如链表一样的数据结构，结果被 Exception 打断，进入了 signal handler；那么如果 signal handler 也改变了这个链表，当控制流回到原程序时，<strong>原程序并不知道自己的链表被改变了，因为从他的角度看，它还一步指令都没执行呢！</strong></p>
<p>⚠ 相信我，这种 Bug 非常难找，因为就算 <code>gdb</code> 也只能逐线程、逐进程地看。</p>
<p>所以在写 signal handlers 的时候，请<strong>一定注意访问全局 / 其他共享变量时的安全问题</strong>！！！</p>
</blockquote>
</li>
</ul>
</li>
<li><p>信号除了类型，没有其他语义。这是因为多个信号可能在接收时发生覆盖。<strong>因此我们不能用信号进行计数（即计信号发送了几次）</strong>！</p>
</li>
<li><p>不同版本的 Linux 中，<strong>信号的语义不同，难以移植</strong>；</p>
<ul>
<li>某些老旧系统在触发自定义的 signal handler 后，会重新变为 default action，需要重新设置。不过在 Linux 上不用担心；</li>
<li>某些系统根本不会在进程处理该类型信号时隐式阻塞；</li>
</ul>
<blockquote>
<p>为了解决这个问题，我们可以利用 <code>sigaction</code> 进行覆写处理。</p>
</blockquote>
</li>
<li><p>某些<strong>慢系统调用</strong>（类似 <code>read</code> 这样一定会触发 Process Context Switch 的）会使得 <code>errno</code> 变为 <code>EINTR</code>；</p>
<blockquote>
<p>因为如果触发慢系统调用的进程先于系统调用退出，那么系统调用会发生错误，并且设置 <code>errno</code> 为 <code>EINTR</code>；</p>
<p><strong>所以如果你在程序中发现这种错误，就重新进行这个系统调用</strong>；</p>
</blockquote>
</li>
</ul>
<p>那么怎样做是安全的呢？</p>
<ol>
<li><p>Signal Handlers 写的越简单越好，尽量能不往里面加代码，就不加；</p>
<blockquote>
<p>比如，你可以在一个信号函数中只是设置一个全局变量，然后立即返回；</p>
</blockquote>
</li>
<li><p>仅使用 <strong>异步信号安全（async-signal-safe）的</strong> 函数；</p>
<blockquote>
<p>什么是<strong>异步信号安全</strong>的函数？</p>
<p>它是指，一种函数是可重入（reentrant）的，也就是说，<strong>它访问的所有变量（包括指针的指向）都在自己的栈帧上</strong>。这样的函数在多线程、进程信号 handle 的时候，一定不会出现共享内存访问冲突，啥时候运行都不会改变语义。</p>
<p>事实上，POSIX 标准中保证了以下几种（共 117 种）函数一定是异步线程安全的：</p>
<p><code>_exit</code>（和 <code>exit</code> 不一样！它是系统调用接口，<code>exit</code> 是 C library 包装的系统级函数）、<code>write</code>、<code>wait</code>、<code>waitpid</code>、<code>sleep</code>、<code>kill</code>、……</p>
<p><strong>但不幸的是</strong>：</p>
<p><code>printf</code>、<code>sprintf</code>、<code>malloc</code>、<code>exit</code> 这些<strong>涉及 I/O 访问的、改变进程状态的系统调用或系统级函数</strong>大多都不是异步信号安全的，请谨慎在 signal handlers 里添加！</p>
<p>为什么它们不安全？因为它们会使用<strong>锁</strong>来对 I/O 设备或者变量进行读写，在 “多线程” 一章你会明白，这样很容易导致经典的死锁。</p>
<p><strong>所以……你一般没法在 signal handlers 里面打印输出内容……</strong>除非你能设计出一个能够对 signal handler 安全的 I/O 库。</p>
</blockquote>
</li>
<li><p>每次进入、退出 signal handlers 时<strong>应该保存、恢复 <code>errno</code> 变量，有助于系统错误追踪</strong>；</p>
<blockquote>
<p>因为在 signal handlers 被中断后，<strong>其他的 signal handlers 可能会更改掉 <code>errno</code></strong>；</p>
</blockquote>
</li>
<li><p><strong>在读写共享 / 全局变量时，请阻塞所有其他信号！！！</strong>这步操作保证当前 Signal Handler 不会被同进程的其他 signal handler 打断，<strong>相当于在多线程程序中加入读写锁</strong>；</p>
</li>
<li><p>如果你的 signal handlers 要用到一个全局变量，<strong>请将它声明为 <code>volatile</code></strong>。这一步也是在多线程编程中常见的。</p>
<blockquote>
<p>我们复习一下 C 中的关键字 <code>volatile</code>，这个关键字可以：<strong>阻止编译器优化由该关键字修饰的变量</strong>，即始终不将它放入寄存器中，<strong>每次读取都从内存中进行</strong>。这样做的好处是，多线程程序中的 <code>volatile</code> 变量不会发生值修改不同步的情况。</p>
<p>我们考虑以下情况：如果一个 signal handler 是修改某全局变量 <code>flag</code> 然后返回；该进程程序主体会定时检查这个 <code>flag</code>，做出相应动作。</p>
<p>如果我们在声明 <code>flag</code> 的时候，不加这个关键字，那么很有可能 <code>flag</code> 的值会被编译器解释成直接放到寄存器中，然后仅仅修改寄存器中的值。这样<strong>主程序可能永远也收不到 signal handler 更改的 <code>flag</code></strong>。</p>
</blockquote>
</li>
<li><p>如果你的全局变量是 <strong>仅读写的简单类型</strong>（数组、标准库中的容器是聚合类型，不是简单类型），除了加上 <code>volatile</code>，还建议使用 <code>sig_atomic_t</code> 类型。<strong>这就相当于多线程编程中的原子操作（<code>atomic&lt;&gt;</code>）</strong>；</p>
</li>
<li><p>对于一些慢系统调用，如果希望提升程序健壮性，应该在执行完检查是否 <code>errno == EINTR</code>，查看中途慢系统调用是否会被 Process Context Switch 阻断产生偶然错误；</p>
</li>
</ol>
<p>那么一个超级有难度的考题就来了——<strong>判断给定程序的异步信号安全性</strong>。来看下面一个程序：</p>
<p>这个 <code>fork14()</code> 想将自己创建的所有子进程通过信号的方式回收。这样做对吗？</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> ccount = <span class="number">0</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">child_handler</span><span class="params">(<span class="type">int</span> sig)</span> &#123;</span><br><span class="line">    <span class="type">pid_t</span> pid;</span><br><span class="line">    <span class="keyword">if</span> ((pid = wait(<span class="literal">NULL</span>)) &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;wait error&quot;</span>);</span><br><span class="line">    ccount--;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Handler reaped child &quot;</span>);</span><br><span class="line">    <span class="built_in">printf</span>((<span class="type">long</span>)pid);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot; \n&quot;</span>);</span><br><span class="line">    sleep(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">fork14</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">pid_t</span> pid[N];</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    ccount = N;</span><br><span class="line">    signal(SIGCHLD, child_handler);</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> ((pid[i] = fork()) == <span class="number">0</span>) &#123;</span><br><span class="line">            sleep(<span class="number">1</span>);</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">0</span>); <span class="comment">/* Child exits */</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (ccount &gt; <span class="number">0</span>) <span class="comment">/* Parent spins */</span></span><br><span class="line">    ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>很遗憾，这样写可以说没有一点异步信号安全性。能够成功回收应该是小概率事件。</p>
<p>我们从简入繁地分析一下：</p>
<ul>
<li>上面的信号处理程序没有保存和恢复 <code>errno</code>，这样会造成不必要的错误追踪的麻烦；</li>
<li>很显然，<code>printf</code> 不是信号安全的，极其容易发生死锁。要么不用，要么换成异步信号安全的函数；</li>
<li><code>ccount</code> 变量没有添加 <code>volatile</code> 关键字，可能被编译器优化，甚至在 <code>child_handler</code> 减少了 <code>ccount</code> 后，<code>main</code> 都无法感知；</li>
<li>最严重的一个问题是，<strong>任何时候，都不应该用收到信号的次数来作为真正发送信号的次数</strong>。因为前面介绍过信号的发送和接收的过程：从信号发送给进程，到进程真正接收，中间至少间隔 2 次 Process Context Switch。在此期间，<strong>由于没有队列数据结构，所有重复的相同信号都会被覆盖成一次信号</strong>。此外，在进程处理该信号的同时，还有隐式阻塞的问题，也会产生相同信号覆盖的情况。</li>
</ul>
<p>现在我们来改正。当我们收到一个 <code>SIGCHILD</code> 信号时，应该假设有多个子进程都结束了（因为无法计数）：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">child_handler2</span><span class="params">(<span class="type">int</span> sig)</span> &#123;</span><br><span class="line">    <span class="type">int</span> oldErrno = errno;</span><br><span class="line">    <span class="type">pid_t</span> pid;</span><br><span class="line">    <span class="keyword">while</span> ((pid = wait(<span class="literal">NULL</span>)) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        ccount--;    <span class="comment">/* 这里改成了回收子进程数，而不是依靠信号数来直接计数 */</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (errno != ECHILD)    <span class="comment">/* 说明上一个 wait 还没等完 */</span></span><br><span class="line">        sio_error(<span class="string">&quot;wait error&quot;</span>);    <span class="comment">/* 安全 I/O 库 */</span></span><br><span class="line">    errno = oldErrno;    <span class="comment">/* 用完 errno 后恢复它 */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再来看一个更难的例子：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">handler</span><span class="params">(<span class="type">int</span> sig)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> olderrno = errno;</span><br><span class="line">    <span class="type">sigset_t</span> mask_all, prev_all;</span><br><span class="line">    <span class="type">pid_t</span> pid;</span><br><span class="line">    sigfillset(&amp;mask_all);</span><br><span class="line">    <span class="keyword">while</span> ((pid = waitpid(<span class="number">-1</span>, <span class="literal">NULL</span>, <span class="number">0</span>)) &gt; <span class="number">0</span>) &#123; <span class="comment">/* Reap child */</span></span><br><span class="line">        sigprocmask(SIG_BLOCK, &amp;mask_all, &amp;prev_all);</span><br><span class="line">        deletejob(pid); <span class="comment">/* Delete the child from the job list */</span></span><br><span class="line">        sigprocmask(SIG_SETMASK, &amp;prev_all, <span class="literal">NULL</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (pid != <span class="number">0</span> &amp;&amp; errno != ECHILD)</span><br><span class="line">        sio_error(<span class="string">&quot;waitpid error&quot;</span>);</span><br><span class="line">    errno = olderrno;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> pid;</span><br><span class="line">    <span class="type">sigset_t</span> mask_all, prev_all;</span><br><span class="line">    <span class="type">int</span> n = N; <span class="comment">/* N = 5 */</span></span><br><span class="line">    sigfillset(&amp;mask_all);</span><br><span class="line">    signal(SIGCHLD, handler);</span><br><span class="line">    initjobs(); <span class="comment">/* Initialize the job list (a queue) */</span></span><br><span class="line">    <span class="keyword">while</span> (n--) &#123;</span><br><span class="line">        <span class="keyword">if</span> ((pid = fork()) == <span class="number">0</span>) &#123; <span class="comment">/* Child */</span></span><br><span class="line">            execve(<span class="string">&quot;/bin/date&quot;</span>, argv, <span class="literal">NULL</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        sigprocmask(SIG_BLOCK, &amp;mask_all, &amp;prev_all); <span class="comment">/* Parent */</span></span><br><span class="line">        addjob(pid); <span class="comment">/* Add the child to the job list */</span></span><br><span class="line">        sigprocmask(SIG_SETMASK, &amp;prev_all, <span class="literal">NULL</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其实这里的错误很难发现。在我们很早以前说 <code>fork</code> 的时候就讲过，<strong>不能保证父子进程的运行的时间顺序</strong>。这里可能会发生一个问题：<strong>在父进程 <code>addjob</code> 之前，<code>execve</code> 的子进程可能已经结束</strong>。这就意味着，父进程将一个已经结束的 job 加入 job list 中，这样任务队列永远不会为空。</p>
<p>如果要想 debug 找出，难点在于，你很难弄清楚各个父子进程间的 interleaving 的执行关系。所以在写信号的时候，一不留神就可能写出一个很恶心的 bug，还找不出来。</p>
<p>改正方法是，<strong>我们没法控制子进程和父进程执行的顺序，但我们可以控制 signal handler 执行的时机</strong>。我们在创建子进程前，阻塞所有信号（<strong>为什么？</strong>）。 在子进程中，在任务开始前，解除阻塞（<strong>又是为什么？</strong>）。</p>
<p>在创建子进程前阻塞所有信号，是为了<strong>让父进程在将任务添加到任务列表后，再考虑信号接收问题，防止 signal handler 在父进程还没加入任务列表时就被触发</strong>；</p>
<p>在创建子进程后，子进程开始后、<code>execve</code> 前解除阻塞，是因为要让 <code>SIGCHILD</code> 信号放出去，否则切换执行程序后就没有机会了。</p>
<p>于是改正后的程序长这样（<code>handler</code> 没有问题）：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> pid;</span><br><span class="line">    <span class="type">sigset_t</span> mask_all, mask_one, prev_one;</span><br><span class="line">    <span class="type">int</span> n = N; <span class="comment">/* N = 5 */</span></span><br><span class="line">    sigfillset(&amp;mask_all);</span><br><span class="line">    sigemptyset(&amp;mask_one);</span><br><span class="line">    sigaddset(&amp;mask_one, SIGCHLD);</span><br><span class="line">    signal(SIGCHLD, handler);</span><br><span class="line">    initjobs(); <span class="comment">/* Initialize the job list*/</span></span><br><span class="line">    <span class="keyword">while</span> (n--) &#123;</span><br><span class="line">        sigprocmask(SIG_BLOCK, &amp;mask_one, &amp;prev_one); <span class="comment">/* Block SIGCHLD */</span></span><br><span class="line">        <span class="keyword">if</span> ((pid = fork()) == <span class="number">0</span>) &#123; <span class="comment">/* Child process */</span></span><br><span class="line">            sigprocmask(SIG_SETMASK, &amp;prev_one, <span class="literal">NULL</span>); <span class="comment">/* Unblock SIGCHLD */</span></span><br><span class="line">            execve(<span class="string">&quot;/bin/date&quot;</span>, argv, <span class="literal">NULL</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        sigprocmask(SIG_BLOCK, &amp;mask_all, <span class="literal">NULL</span>); <span class="comment">/* Parent process */</span></span><br><span class="line">        addjob(pid); <span class="comment">/* Add the child to the job list */</span></span><br><span class="line">        sigprocmask(SIG_SETMASK, &amp;prev_one, <span class="literal">NULL</span>); <span class="comment">/* Unblock SIGCHLD */</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>了解了这个方面的知识，我们可以明白一件事，我们在写一个这样的前后台程序的时候，如果不放心，可以用 <strong>进程图</strong> 模拟一下，确认自己的程序在各种极限情况下都能正常工作。</p>
<p>还有一个问题。在 shell lab 中，其实是不允许在 <code>main</code> 中写 <code>wait</code> 的，因为普通的 shell 程序都会将前台子进程的控制也交给信号，这样可以将前后台的处理方式大致统一。那么，<strong>怎么设计主程序能够显式的等待信号</strong>呢？别看这个好像很好办，实际要考虑的东西多得惊人。例如下面的一个程序：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">volatile</span> <span class="type">sig_atomic_t</span> pid;</span><br><span class="line"><span class="type">void</span> <span class="title function_">sigchild_handler</span><span class="params">(<span class="type">int</span> s)</span> &#123;</span><br><span class="line">    <span class="type">int</span> olderrno = errno;</span><br><span class="line">    pid = waitpid(<span class="number">-1</span>, <span class="literal">NULL</span>, <span class="number">0</span>); <span class="comment">/* Main is waiting for nonzero pid */</span></span><br><span class="line">    errno = olderrno;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">sigint_handler</span><span class="params">(<span class="type">int</span> s)</span> &#123;</span><br><span class="line">    <span class="comment">/* Do something */</span></span><br><span class="line">    <span class="comment">/* ... */</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span> &#123;</span><br><span class="line">    <span class="type">sigset_t</span> mask, prev;</span><br><span class="line">    <span class="type">int</span> n = N; <span class="comment">/* N = 10 */</span></span><br><span class="line">    signal(SIGCHLD, sigchild_handler);</span><br><span class="line">    signal(SIGINT, sigint_handler);</span><br><span class="line">    sigemptyset(&amp;mask);</span><br><span class="line">    sigaddset(&amp;mask, SIGCHLD);</span><br><span class="line">    <span class="keyword">while</span> (n--) &#123;</span><br><span class="line">        sigprocmask(SIG_BLOCK, &amp;mask, &amp;prev); <span class="comment">/* Block SIGCHLD */</span></span><br><span class="line">        <span class="keyword">if</span> (fork() == <span class="number">0</span>) <span class="comment">/* Child: do somthing... */</span></span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        <span class="comment">/* Parent */</span></span><br><span class="line">        pid = <span class="number">0</span>;</span><br><span class="line">        sigprocmask(SIG_SETMASK, &amp;prev, <span class="literal">NULL</span>); <span class="comment">/* Unblock SIGCHLD */</span></span><br><span class="line">        <span class="comment">/* Wait for SIGCHLD to be received (wasteful!) */</span></span><br><span class="line">        <span class="keyword">while</span>(!pid)</span><br><span class="line">            ;</span><br><span class="line">        <span class="comment">/* Do some work after receiving SIGCHLD */</span></span><br><span class="line">        <span class="comment">/* ... */</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果能够写出上面的程序，那么前面的内容你都已经掌握了。这是个正确的程序，但是美中不足的是，父进程在等待子进程的时候，使用 <code>while (!pid);</code>，这样的做法比较低效，大部分 CPU 资源都浪费在无意义的 <code>while</code> 循环中了。</p>
<p>那么这个时候有同学可能会说，这简单，我可以在 <code>while(!pid)</code> 循环中加入一个 <code>pause</code> 系统调用，这样有 <code>SIGCHILD</code> 或者 <code>SIGINT</code> 触发后，程序可以自动从 <code>pause</code> 中退出，然后判断一遍 <code>pid</code>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (!pid) pause();</span><br></pre></td></tr></table></figure>
<p>很可惜，这样<strong>可能会造成死锁</strong>。我们不妨画一个进程图，发现如果子进程向父进程发送信号，而且 Process Context Switch 的位置位于 <code>while (!pid)</code> 和 <code>pause()</code> 之间，那么，程序会先接收并处理 <code>SIGCHILD</code> / <code>SIGINT</code> 然后进入 <code>pause</code>。想象一下，如果这正好是最后一个给父进程发信号的进程呢？那么父进程会永远 stopped 在 <code>pause</code> 中。</p>
<p>同学还想了，那我换成 <code>sleep(1)</code> 不就不会死锁了吗？行是行，但是每隔一秒才检查一次子进程会严重拖慢程序运行速度。而设置为其他的固定时间，要么太慢（速度问题），要么太快（和没有 <code>sleep</code> 的效率一样低下）。</p>
<p>那么我们可不可以不那么快地恢复对 <code>SIGCHILD</code> 的响应（第 25 行）？让 “恢复 <code>SIGCHILD</code> 响应” 和 “<code>pause</code> 执行” 成为一对原子操作。那么答案就是新的系统调用：<strong><code>sigsuspend</code></strong>;</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">sigsuspend</span><span class="params">(<span class="type">const</span> <span class="type">sigset_t</span> *mask)</span>;</span><br></pre></td></tr></table></figure>
<p>它等价于以下 3 条指令的 <strong>整体原子操作</strong>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sigprocmask(SIG_BLOCK, &amp;mask, &amp;prev);</span><br><span class="line">pause();</span><br><span class="line">sigprocmask(SIG_SETMASK, &amp;prev, <span class="literal">NULL</span>);</span><br></pre></td></tr></table></figure>
<p>这样，我们只需要在阻塞 <code>SIGCHILD</code> 的时候，在 <code>while</code> 循环中调用 <code>sigsuspend(&amp;prev)</code>，这样  “取消 <code>SIGCHILD</code> 阻塞” 的行为 和 “<code>pause()</code> 执行” 的行为就原子化了，无需担心中间的死锁问题。这样如果有信号，并且交由 signal handlers 处理后，重新开始对 <code>SIGCHILD</code> 的阻塞，并检查 <code>pid</code>，完美实现要求。于是改进代码如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">volatile</span> <span class="type">sig_atomic_t</span> pid;</span><br><span class="line"><span class="type">void</span> <span class="title function_">sigchild_handler</span><span class="params">(<span class="type">int</span> s)</span> &#123;</span><br><span class="line">    <span class="type">int</span> olderrno = errno;</span><br><span class="line">    pid = waitpid(<span class="number">-1</span>, <span class="literal">NULL</span>, <span class="number">0</span>); <span class="comment">/* Main is waiting for nonzero pid */</span></span><br><span class="line">    errno = olderrno;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">sigint_handler</span><span class="params">(<span class="type">int</span> s)</span> &#123;</span><br><span class="line">    <span class="comment">/* Do something */</span></span><br><span class="line">    <span class="comment">/* ... */</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span> &#123;</span><br><span class="line">    <span class="type">sigset_t</span> mask, prev;</span><br><span class="line">    <span class="type">int</span> n = N; <span class="comment">/* N = 10 */</span></span><br><span class="line">    signal(SIGCHLD, sigchild_handler);</span><br><span class="line">    signal(SIGINT, sigint_handler);</span><br><span class="line">    sigemptyset(&amp;mask);</span><br><span class="line">    sigaddset(&amp;mask, SIGCHLD);</span><br><span class="line">    <span class="keyword">while</span> (n--) &#123;</span><br><span class="line">        sigprocmask(SIG_BLOCK, &amp;mask, &amp;prev); <span class="comment">/* Block SIGCHLD */</span></span><br><span class="line">        <span class="keyword">if</span> (fork() == <span class="number">0</span>) <span class="comment">/* Child: do somthing... */</span></span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">/* Parent */</span></span><br><span class="line">        pid = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">/* Wait for SIGCHLD to be received */</span></span><br><span class="line">        <span class="comment">/* SIGCHILD is still blocked */</span></span><br><span class="line">        <span class="keyword">while</span>(!pid)</span><br><span class="line">            sigsuspend(&amp;prev);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">/* Unblock SIGCHLD (optional) */</span></span><br><span class="line">        sigprocmask(SIG_SETMASK, &amp;prev, <span class="literal">NULL</span>);</span><br><span class="line">        <span class="comment">/* Do some work after receiving SIGCHLD */</span></span><br><span class="line">        <span class="comment">/* ... */</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="16-5-7-Summary-of-Signals"><a href="#16-5-7-Summary-of-Signals" class="headerlink" title="16.5.7 Summary of Signals"></a>16.5.7 Summary of Signals</h4><p>在讨论信号有关概念之前，我们先认识了 Linux 中的 “进程树” 这种进程层次结构。我们了解到，Linux 一号进程是 <code>init</code> 进程，它是所有进程的父进程。<code>init</code> 进程则会启动两类进程，一种是 <code>Daemon</code> 守护进程，另一种是 <code>Login Shell</code> 命令行。</p>
<p>我们利用之前对于进程控制的知识尝试写了一个小的 Demo，却发现对于运行在后台的子进程，我们没有办法 handle 它们。为了解决这个问题，我们引入了 Linux 系统中的信号的概念。</p>
<p>信号是一个小整型，由 OS Kernel 发出，用来通知进程事件发生、要求处理的一种高级 ECF 机制。</p>
<p>信号的发送和接收的非同时性决定了信号必须在 OS Kernel 中以一种数据结构存储起来，以供目标进程对信号的接收。这种数据结构非常朴素，只是一个 Pending bit vector 和一个 Blocked bit vector，这样的存储方式注定了 <strong>信号在接收过程中可能被覆盖</strong>，因此接收信号的次数不能代表信号发送的次数；</p>
<p>信号机制运作的流程看起来很简单：</p>
<ol>
<li><p>某一时刻，位于某个进程的 OS Kernel 向 Process A 发送一个信号，于是改变了 Process A 的 Pending bit vector；</p>
</li>
<li><p>当某次 Process Context Switch 即将切换到 Process A 前，OS Kernel 检查 <code>pnb = pending &amp; ~blocking</code> 的情况；发现有信号，那么对每个信号都进行处理：进入对应的 signal handler 并重置该位 pending bit vector；</p>
<blockquote>
<p>由于 signal handler 位于用户态，共享了原程序的一切内存，因此 signal handler 和 原程序在 Logical Control Flow 上成为一对共享资源的<strong>并行流</strong>，这个情况与多线程等效，但<strong>给信号处理和数据访问带来了极大的不安全性</strong>。</p>
</blockquote>
</li>
<li><p>signal handler 执行中，由于是用户态代码，所以仍然可能会出现 Process Context Switch，因此免不了有 Nested Signals Handlers 的情况。不过，一般的 OS Kernel 会帮助我们将正在处理的相同信号阻塞起来（<strong>隐式阻塞</strong>），防止多次调用相同的 signal handler；</p>
</li>
<li><p>在 signal handlers 调用完成后，控制流先回到 OS Kernel 恢复 $I_{next}$ 等必需数据然后继续原程序 $I_{next}$ 执行。</p>
</li>
</ol>
<p>只是，别小看这个 <strong>同进程并行流的不安全性</strong>，如果在书写 signal handlers 时处理不当，那么可能造成相当大的危害。</p>
<p>我们从处理多线程程序安全性的同样思路出发，提出了以下几点避免<strong>异步信号冲突</strong>的解决方案：</p>
<ol>
<li>signal handlers 尽量保持简洁，使用 <strong>异步信号安全</strong> 的函数；</li>
<li>每次进入、退出 signal handler 时要及时保存、恢复 <code>errno</code>，因为 signal handler 内部可能有系统调用错误，为了防止系统错误难以追踪，我们最好这么做；</li>
<li>在同时被原程序、Signal Handler 使用的共享变量前应该声明 <code>volatile</code> 关键字，对于仅读写的简单类型最好使用 <code>sig_atomic_t</code> 类型；</li>
<li>在原程序、Signal Handler 操作共享变量时，应该阻塞其他所有信号，防止同进程的 interleaving 造成共享资源访问冲突；</li>
<li>不以信号接收次数来计信号发送次数；</li>
<li>对于含有 <code>fork</code> + 信号的程序设计，如果拿不准，建议画进程图，因为你不能假设父子进程的先后顺序，及时进行信号阻塞。这通常是造成共享资源访问冲突的常见点；</li>
<li>最后，对于显式等待信号的问题，我们可以使用 <code>sigsuspend</code> 系统调用，保证 <strong>取消阻塞和暂停等待两步操作的原子性</strong>。</li>
</ol>
<p>此外，我们还认识了进程组，一种关联多个进程，可以同时向进程组中所有进程发送信号的机制。</p>
<h3 id="16-6-Non-local-Jump"><a href="#16-6-Non-local-Jump" class="headerlink" title="16.6 Non-local Jump"></a>16.6 Non-local Jump</h3><blockquote>
<p>Powerful (but dangerous) user-level mechanism for transferring control to an arbitrary location.</p>
</blockquote>
<p>略</p>
<h2 id="Chapter-17-System-Level-I-O"><a href="#Chapter-17-System-Level-I-O" class="headerlink" title="Chapter 17 System Level I/O"></a>Chapter 17 System Level I/O</h2><p>本章将讨论操作系统较为底层的 I/O，在 Unix 和其他类型的操作系统上一样支持。</p>
<h3 id="17-1-Unix-I-O-Overview"><a href="#17-1-Unix-I-O-Overview" class="headerlink" title="17.1 Unix I/O Overview"></a>17.1 Unix I/O Overview</h3><p>我们先讨论 Unix 上的 I/O 的原因是，比起其他的操作系统，Unix 中的 I/O 更加简单并且一致。我们都知道在 Unix 类系统上，<strong>一切皆文件</strong>，而这些文件本质上上一个 m bytes 的<strong>字节序列（a sequence of bytes）</strong>，<strong>不去区分文件的类型</strong>，所以 Unix 操作系统实际上基本不了解文件内部的详细结构。它将文件看作存放在磁盘或外部存储介质上的某段数据，并且提供打开、写入、关闭等标准操作。</p>
<p>正因如此，即使是一些 I/O Device，甚至是操作系统内核也能抽象表示为具体的文件。</p>
<blockquote>
<p><code>/dev/sdaN</code>: Unix 的 N 号磁盘分区；</p>
<p><code>/dev/ttyN</code>：Unix 的 N 号终端（为何叫 TTY？因为早期人们多使用 “电传打字机（teletype）” 用于描述打字机与计算机的接口）；</p>
<p><code>/boot/vmlinuz-xxx-generic</code>：Unix 的内核镜像文件；</p>
<p><code>/proc</code>：Unix 的内核数据结构；</p>
<p><code>/var/run/*.sock</code>、<code>/run/*.sock</code>、<code>/dev/shm/*.sock</code>：Unix 的网络套接字文件；</p>
<p>补充：什么是套接字（socket）？</p>
<p>在网络一章会深入讨论。简单来说，就是在互联网规范中，当机器通过互联网通信时，消息是一段通过写入套接字这个数据结构来发送的，另一端通过读取套接字的内容来接收的。</p>
</blockquote>
<p>这样的简洁明了的抽象（elegant mapping of files to devices）就允许 Unix 类操作系统内核以一套简单的接口完成对文件和设备的访问。<strong>这套简单、核心的接口被成为 Unix I/O</strong>：</p>
<ul>
<li><p>打开、关闭文件：<code>open()</code>、<code>close()</code>；</p>
</li>
<li><p>读写文件：<code>read()</code>、<code>write()</code>；</p>
</li>
<li><p>当前文件位置（注意，<strong>不是当前文件路径</strong>：是 current file position，而不是 current file path）；</p>
<ul>
<li><p>作用：indicates next offset into file to read or write（<strong>提示下一次向文件中写或读的字节偏移量，即下次从哪里读写</strong>）；</p>
</li>
<li><p>接口：<code>lseek()</code>，改变当前文件指针的指向；</p>
</li>
<li><p>特征：<strong>只有某些文件有这个接口</strong>。因为对那些文件而言，没法移动、备份和恢复先前的已读入的数据，也无法提前接收未写入的数据。</p>
<blockquote>
<p>例如 socket 文件就是没有这种接口的，因为它无法在时间上进行跳转，只能在数据包进入时对其读写；</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<p>由于这些文件本质上还是不同的具体事物，在客观上有内在差别（就像一些类都继承于一个公共类，但它们终究需要实现不同功能）。这些文件属性上的差别则可以抽象为<strong>文件类型</strong>。</p>
<p>Unix 中的文件类型有以下几种：</p>
<ul>
<li>Regular file：普通文件（存储于磁盘驱动器上）；</li>
<li>Directory：一组特定文件的索引文件，其中的条目描述了其他文件的位置和属性；</li>
<li>Socket：与另一台机器上的一个进程沟通的文件；</li>
<li>Named pipes（<strong>FIFOs</strong>，先入先出型数据结构）：管道流文件。Unix 上一些程序的输出，同时也是另外一些文件的输入；</li>
<li>Symbolic links：符号链接。Unix 上又称软链接（与硬链接相对）；</li>
<li>Character and block devices：字符设备与块设备。其抽象在操作系统的设备访问层，其名称与实际物理设备特性无必然联系。<ul>
<li>操作系统能够<strong>随机访问固定大小数据块（chunks）</strong>的设备称为块设备（例如磁盘、软盘、CD、flash memory 等）；</li>
<li>操作系统只能<strong>按照字符流的方式有序访问</strong>的设备称为字符设备（例如串口、键盘等）；</li>
</ul>
</li>
</ul>
<p>本章着重讨论前三种文件，因为它们比较常见。</p>
<h3 id="17-2-Unix’s-Files"><a href="#17-2-Unix’s-Files" class="headerlink" title="17.2 Unix’s Files"></a>17.2 Unix’s Files</h3><h4 id="17-2-1-Regular-Files"><a href="#17-2-1-Regular-Files" class="headerlink" title="17.2.1 Regular Files"></a>17.2.1 Regular Files</h4><p>普通文件可以包含任何类型的数据。一般情况下，操作系统并不会试图分析文件内部的细节，因此操作系统内核<strong>并不知道</strong>文本文件（plain text）和二进制文件（binary）之间的差别。</p>
<p>注意，区分文件内容是文本还是二进制数据通常发生在应用程序层级（更高级别）。</p>
<blockquote>
<p>文本文件和二进制文件的差别：<strong>仅含有代表 ASCII / Unicode 字符的数据的文件被称为文本文件，否则被称为二进制文件</strong>；</p>
<p>二进制文件可以是：actual object file、图片音视频文件等等，它们包含<strong>直接以某种形式编码的字节序列</strong>；</p>
</blockquote>
<p>文本文件有个重要特征，就是它们可以看作<strong>由一系列文本行（text lines）构成</strong>的文件。通常情况下，文本行是一个以 <strong>newline 字符</strong>结尾的字符（char）序列。</p>
<blockquote>
<p>事实上，newline 字符在不同操作系统平台上定义不同，例如 Unix 上将 <code>0xa</code>（<code>\n</code>）代表的字符 <strong>line feed（LF）character</strong> 作为换行符，而 Windows 则约定以两个字符 <code>0xd 0xa</code>（<code>\r\n</code>）代表的字符 Carriage Return &amp;&amp; Line Feed（CRLF）character 作为换行符。</p>
<p>二者的区别与历史中的 typewriter（打字机）有关，因为换行（垂直运动，即 Line Feed）和回车（水平复位运动，即 Carriage Return）是打字机作为机械设备在换到下一行必须要做的两个运动，Windows 保留了这层含义。</p>
</blockquote>
<h4 id="17-2-2-Directories"><a href="#17-2-2-Directories" class="headerlink" title="17.2.2 Directories"></a>17.2.2 Directories</h4><p>在 Unix 操作系统（或者说操作系统中的文件系统）中，每个目录文件包含了一个 “链接” 数组，每个 “链接” 建立了一个从文件名到文件的映射关系。</p>
<p>每一个目录文件包含<strong>至少两个 entries</strong>：<code>.</code>（a link to itself，链接到自身）和 <code>..</code>（a link to the parent directory in the directory hierarchy，链接到目录层次中的上层目录）；</p>
<p>Unix 的文件系统层次结构与 Linux 相近，因此 Unix 文件系统层次结构就不再赘述。</p>
<p>而 <strong>当前工作目录（current working directory，<code>cwd</code>）</strong>是由 OS Kernel 维护的数据，每个进程下的不一定一致。可以通过使用 <code>cd</code> 改变当前进程的该数据；</p>
<p>在 Unix 和其他多数操作系统中，<strong>Pathnames（路径名）</strong>是文件层次结构中导向某个特定文件的导航方式，可以由目录文件的链接名称组成。</p>
<h3 id="17-3-Basic-Operations"><a href="#17-3-Basic-Operations" class="headerlink" title="17.3 Basic Operations"></a>17.3 Basic Operations</h3><p>本节的系统级函数和宏大多在 <code>&lt;fcntl.h&gt;</code>（file control）中；</p>
<h4 id="17-3-1-Opening-Files"><a href="#17-3-1-Opening-Files" class="headerlink" title="17.3.1 Opening Files"></a>17.3.1 Opening Files</h4><p>针对各类文件的基本操作方式之一是打开文件。它的实质是<strong>提醒 OS Kernel 已经做好访问该文件的一切准备</strong>。对此 Unix 有一个系统级函数 <code>open</code>，常用声明如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">open</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* pathname, <span class="type">int</span> flags)</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>第一参数可以是绝对路径，也可以是相对路径；</p>
</li>
<li><p>第二参数是 2 的某次幂的标志量（flag），允许按位运算。说明文件的打开方式（结合一些头文件，可以得到相关宏定义，例如 <code>O_RDONLY</code> 只读等）；</p>
</li>
<li><p>返回值体现了一个非常重要的思想：<strong>文件描述符</strong>。如果文件打开错误，则返回 <strong>-1</strong>（I/O 操作的失败情况比普通情况多很多，一定在实际使用描述符前检查是否成功打开）；</p>
<blockquote>
<p>什么是文件描述符（file descriptor）？</p>
<p>文件标识符是<strong>用来标识当前程序正在操作的某个已打开文件的小整型（这个小整型只有 0 ~ 1024 的范围）</strong>。</p>
<p>它们是按照打开顺序依此编号（从运行程序开始编号），所以大部分机器有最大打开文件数量的限制。这意味着打开了超过限制数量的文件将会造成文件资源泄漏。其中机器各方面的限制可以由以下指令查看：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ulimit</span> -a</span><br></pre></td></tr></table></figure>
<p>另外一个值得注意的点是，在<strong>每个进程一创建的时候就会有 3 个已创建的文件：0（<code>stdin</code>）、1（<code>stdout</code>）、2（<code>stderr</code>），它们都是由 Unix Shell 打开并创建的</strong>（请回忆前一章的进程树并考虑为什么）。</p>
<p>其他具体内容将在 <strong>17.5.2</strong> 中讨论。</p>
</blockquote>
</li>
</ul>
<p>注：本章的系统级函数都非常底层，有些函数直接使用整型文件描述符。为了使用规范，如果你想用 <code>stdin/stdout/stderr</code> 这类文件时，请不要直接使用 <code>0/1/2</code>，更建议使用宏 <code>STDIN_FILENO/STDOUT_FILENO/STDERR_FILENO</code>；</p>
<h4 id="17-3-2-Closing-Files"><a href="#17-3-2-Closing-Files" class="headerlink" title="17.3.2 Closing Files"></a>17.3.2 Closing Files</h4><p>关闭文件的系统级函数声明如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">close</span><span class="params">(<span class="type">int</span> file_descriptor)</span>;</span><br></pre></td></tr></table></figure>
<p>你可能会好奇，为什么这个也要有返回值，难道关闭一个文件也会报错？答案是肯定的。</p>
<p>在多线程编程中（就像之前提到的，它们会共享内存和数据结构），可能会出现关闭一个已经被关闭的文件的情况，这种情况也会发生问题。</p>
<h4 id="17-3-3-Reading-Files-amp-Writing-Files"><a href="#17-3-3-Reading-Files-amp-Writing-Files" class="headerlink" title="17.3.3 Reading Files &amp; Writing Files"></a>17.3.3 Reading Files &amp; Writing Files</h4><p>Unix 系统级函数提供了一种块读取和块写入的方式，即从当前文件指针位置开始，向后指定长度的空间的数据读入缓冲区 / 向文件写缓冲区内容，并且更新文件指针：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">ssize_t</span> <span class="title function_">read</span><span class="params">(<span class="type">int</span> file_descriptor, <span class="type">void</span> *buffer, <span class="type">size_t</span> buf_size)</span>;</span><br><span class="line"><span class="type">ssize_t</span> <span class="title function_">write</span><span class="params">(<span class="type">int</span> file_descriptor, <span class="type">void</span> *buffer, <span class="type">size_t</span> buf_size)</span>;</span><br></pre></td></tr></table></figure>
<p>值得注意的是，如果正确运行，那么 <code>read</code> / <code>write</code> 的返回值是<strong>实际读取 / 写入的字节数</strong>（因为从当前文件指针到最后不一定有 <code>buf_size</code> 大小的数据，这种情况称之为 <strong>short read / short write</strong>）；错误则返回 <strong>-1</strong>；而（对于 <code>read</code> 而言）如果返回 0，说明已经到达 <code>EOF</code>；</p>
<blockquote>
<p>这里介绍一个之前提到的非常有名的工具 <code>strace</code>；这个工具的功能非常强大，不过现在我们先介绍一些简单的使用：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">strace &lt;prog&gt;</span><br></pre></td></tr></table></figure>
<p>以上指令在运行指定程序的同时，会跟踪并向  <code>stdout</code> 打印程序使用到的<strong>所有系统调用（system call）情况</strong>；</p>
<p>有时候看到很乱的情况，可能是终端上 <code>stderr</code> 和 <code>stdout</code> 交织输出的原因。</p>
<p>如果加上参数：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">strace -e trace=&lt;syscall_name[,...]&gt; &lt;prog&gt;</span><br></pre></td></tr></table></figure>
<p>那么就仅仅追踪指定名称的系统调用情况。</p>
</blockquote>
<p>那么，什么时候会出现 short read / short write？</p>
<ul>
<li>读文件时遇到 EOF；</li>
<li>从<strong>终端</strong>读一个文本行；</li>
<li>读写网络套接字；</li>
<li>……</li>
</ul>
<p>其实，short read / short write 一直是应用程序层面较为棘手的问题，所以我们一般看到很多涉及 I/O 的库几乎都将这个低层级的 I/O 接口封装起来。</p>
<blockquote>
<p>为什么棘手？</p>
<p>其实，short read / write 在普通程序中的问题还影响不大，因为大多数是向磁盘中写文件，而向磁盘写不会出现 EOF，因此没有 short write；从磁盘读发生 short read 只要跳出读循环就行，影响也不大）。</p>
<p>但是在网络套接字的读写方面影响很大。考虑一个场景，你要用 socket 发一个网络包，但是写不下的值还要判断，而且还有可能因为其他偶然原因触发 <code>EINTR</code>，并且在循环中重新拿出来再发一次。</p>
</blockquote>
<h3 id="17-4-The-RIO-Package"><a href="#17-4-The-RIO-Package" class="headerlink" title="17.4 The RIO Package"></a>17.4 The RIO Package</h3><p>为了解决 short read / short write 对应用程序编程开发带来的麻烦，有一种对 I/O 接口的封装方式是 CMU 教授开发的 RIO Package. 这个包提供了对于底层的 Unix I/O 的包装，能够使得程序在处理 I/O 方面有较强的健壮性（robust）和较好的效率，尤其是后面章节要讨论的、受 short read / write 影响较大的网络编程。</p>
<p>RIO Package 提供了 2 种不同级别的 I/O 文件接口。</p>
<p>其中，较低级别的 I/O 接口只是对上面说到的低级 Unix I/O 进行了简单的封装，以应对 short read / write 的情况；函数 <code>rio_readn</code>  和 <code>rio_writen</code> 就是这样较低级别的封装。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">ssize_t</span> <span class="title function_">rio_readn</span><span class="params">(<span class="type">int</span> fd, <span class="type">void</span> *usrbuf, <span class="type">size_t</span> n)</span>;</span><br><span class="line"><span class="type">ssize_t</span> <span class="title function_">rio_writen</span><span class="params">(<span class="type">int</span> fd, <span class="type">void</span> *usrbuf, <span class="type">size_t</span> n)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* rio_writen 永远不会 short count. */</span></span><br><span class="line"><span class="comment">/* rio_readn 当正常执行时，返回 num 代表实际读取的字节数（和 Unix I/O 不同，这是产生 short count 的唯一情况）；遇到 EOF 返回 0；*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 二者遇到错误都返回 -1，errno 由系统级函数 read/write 设置 */</span></span><br></pre></td></tr></table></figure>
<p>这两个函数属于对二进制数据的非缓冲式的读入和输出（unbuffered input &amp; output of binary data），在未读够 / 未写够指定字节数的数据之前不会返回。对于 <code>rio_readn</code>，如果是处理具有很多数据的网络套接字，那么在当前套接字读完、总体数据未读完的情况下<strong>挂起并等待</strong>；如果是读到了与给定字节数不同的时候出现 EOF，那么会返回错误；</p>
<p>对于 <code>rio_writen</code>，<strong>对于使用者的情况会比 <code>rio_readn</code> 简单些，所以也只需要包装到这个层次即可</strong>，因为使用者只需担心网络问题，这个函数本身会在要求的字节数内通过循环发送套接字（因为一个 socket 规范只有 1500 bytes 左右，具体大小取决于它位于哪个协议层）；</p>
<p>另一类是带缓冲区的 I/O 接口（<code>rio_readinitb</code>、<code>rio_readlineb</code>、<code>rio_readnb</code>），比前一类封装更高级一些，也是很多库对于 Unix I/O 常见的包装形式。它们的做法是在用户代码空间创建一个小型缓冲区（mini-buffer），用来存放已读入但未被应用程序使用的 bytes，或者为程序创建一块空间以便未来输出到文件或网络中；</p>
<blockquote>
<p>这种<strong>缓冲区的思想</strong>也存在与计算机的相当多的方面。</p>
</blockquote>
<p>带缓冲区的 RIO 有两种，一种是基于文本的，另一种是基于字节（二进制数据）的。如下代码注释，可见，在网络套接字的文本行阅读方面，<code>rio_readlineb</code> 非常有用。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">rio_readinitb</span><span class="params">(<span class="type">rio_t</span> *rp, <span class="type">int</span> fd)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Read a text line of up to `maxlen` bytes from file `fd` and store the line in `usrbuf`.</span></span><br><span class="line"><span class="comment"> * Stopping Conditions:</span></span><br><span class="line"><span class="comment"> * - `maxlen` bytes read;</span></span><br><span class="line"><span class="comment"> * - EOF encountered;</span></span><br><span class="line"><span class="comment"> * - Newline (`\n`) encountered</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">ssize_t</span> <span class="title function_">rio_readlineb</span><span class="params">(<span class="type">rio_t</span> *rp, <span class="type">void</span> *usrbuf, <span class="type">size_t</span> maxlen)</span>;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Read up to `n` bytes from file `fd` and store them in `usrbuf`.</span></span><br><span class="line"><span class="comment"> * Stopping Conditions:</span></span><br><span class="line"><span class="comment"> * - `maxlen` bytes read;</span></span><br><span class="line"><span class="comment"> * - EOF encountered;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="type">ssize_t</span> <span class="title function_">rio_readnb</span><span class="params">(<span class="type">rio_t</span> *rp, <span class="type">void</span> *usrbuf, <span class="type">size_t</span> n)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 当正常执行时，返回 num 代表实际读取的字节数（和 Unix I/O 不同，这是产生 short count 的唯一情况）；*/</span></span><br><span class="line"><span class="comment">/*遇到 EOF 返回 0；遇到错误返回 -1，errno 由系统级函数 read 设置 */</span></span><br></pre></td></tr></table></figure>
<p>这种 RIO 库的健壮性还在于，<code>rio_readlineb</code> 和 <code>rio_readnb</code> 允许对一个文件描述符进行交织运行（多线程中对一个文件描述符），但别和 <code>rio_readn</code> 连用；</p>
<p>至于含缓冲区的 RIO 的实现也不难，它的目标就是设计一个读取内容的缓冲地带，让重复的读取内容不至于每次访问 I/O 都使用系统调用；举个例子：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/rio_readnb.png" height="300px"></p>
<p>如上图，假设程序想要读取系统上的一个 Unix file，那么该文件从头至 current file position 就是我们想要的 buffered portion；在读取的时候，<code>rio_readnb/rio_readlineb</code> 会按 buffered portion 的大小在 user code space 中创建一个同等大小的缓冲区（上图 buffer），由 <code>rio_buf</code> 指针管理这片空间的起始地址，由 <code>rio_bufptr</code> 管理当前程序读到 buffer 的哪里；而 <code>rio_cnt</code> 则代表当前还有多少数据没有读入缓冲区；</p>
<p>因此，根据 <code>rio buffer</code> 的使用分析，我们发现维护 <code>rio_t</code> 的结构体应该是这样的：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> rio_fd;</span><br><span class="line">    <span class="type">int</span> rio_cnt;</span><br><span class="line">    <span class="type">char</span> *rio_bufptr;</span><br><span class="line">    <span class="type">char</span> rio_buf[RIO_BUFSIZE];</span><br><span class="line">&#125; <span class="type">rio_t</span>;</span><br></pre></td></tr></table></figure>
<p>更多的内容大家可以通过阅读 RIO Package 的源码获取，并且可以在此基础上包装属于自己的 routines；</p>
<h3 id="17-5-File-Metadata-Sharing-and-Redirection"><a href="#17-5-File-Metadata-Sharing-and-Redirection" class="headerlink" title="17.5 File Metadata, Sharing and Redirection"></a>17.5 File Metadata, Sharing and Redirection</h3><h4 id="17-5-1-Metadata"><a href="#17-5-1-Metadata" class="headerlink" title="17.5.1 Metadata"></a>17.5.1 Metadata</h4><p>几乎所有操作系统平台上，每个文件中都有一个非常重要的部分是文件元数据（file metadata）。所谓 metadata 就是文件中实际包含的数据的信息，例如<strong>应用层级的文件类型信息、文件权限信息（R/W/X）、文件所有权信息、创建/访问/修改时间……</strong></p>
<blockquote>
<p>什么？你说 Windows 上创建一个文本文件，然后把后缀名删了，好像就没有了？其实操作系统在创建文件、在显示到桌面之前就将文件元信息设置好了，不信你看看右击属性。</p>
</blockquote>
<p>在 Unix 系统中，这种 metadata 以一个结构体 <code>stat</code> 进行存储，这种结构体类型也是 C library 函数 <code>stat</code>、<code>fstat</code>（查看文件元数据的函数）的返回值类型：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/stat.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Metadata returned by the stat and fstat functions */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">stat</span> &#123;</span></span><br><span class="line">    <span class="type">dev_t</span>			st_dev; 		<span class="comment">/* Device */</span></span><br><span class="line">    <span class="type">ino_t</span>			st_ino; 		<span class="comment">/* inode */</span></span><br><span class="line">    <span class="type">mode_t</span>			st_mode; 		<span class="comment">/* Protection and file type */</span></span><br><span class="line">    <span class="type">nlink_t</span>			st_nlink; 		<span class="comment">/* Number of hard links */</span></span><br><span class="line">    <span class="type">uid_t</span>			st_uid; 		<span class="comment">/* User ID of owner */</span></span><br><span class="line">    <span class="type">gid_t</span>			st_gid; 		<span class="comment">/* Group ID of owner */</span></span><br><span class="line">    <span class="type">dev_t</span>			st_rdev; 		<span class="comment">/* Device type (if inode device) */</span></span><br><span class="line">    <span class="type">off_t</span>			st_size; 		<span class="comment">/* Total size, in bytes */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> 	st_blksize; 	<span class="comment">/* Blocksize for filesystem I/O */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> 	st_blocks; 		<span class="comment">/* Number of blocks allocated */</span></span><br><span class="line">    <span class="type">time_t</span> 			st_atime; 		<span class="comment">/* Time of last access */</span></span><br><span class="line">    <span class="type">time_t</span> 			st_mtime; 		<span class="comment">/* Time of last modification */</span></span><br><span class="line">    <span class="type">time_t</span> 			st_ctime; 		<span class="comment">/* Time of last change */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">stat</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *pathname, <span class="keyword">struct</span> stat *statbuf)</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">fstat</span><span class="params">(<span class="type">int</span> fd, <span class="keyword">struct</span> stat *statbuf)</span>;    <span class="comment">/* `fd` should be a valid open file descriptor. */</span></span><br></pre></td></tr></table></figure>
<p>如何用这些数据？一般情况下，我们可以借助一些 C library 内置宏来检查数据的含义。这里不多赘述，以一个程序为例：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> *argv[])</span> &#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">stat</span> <span class="title">stat</span>;</span></span><br><span class="line">    <span class="type">char</span> *type, *readok;</span><br><span class="line">    </span><br><span class="line">    Stat(argv[<span class="number">1</span>], &amp;stat);</span><br><span class="line">    <span class="keyword">if</span> (S_ISREG(stat.st_mode))    <span class="comment">/* Determine file type. */</span></span><br><span class="line">        type = <span class="string">&quot;regular&quot;</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (S_ISDIR(stat.st_mode))</span><br><span class="line">        type = <span class="string">&quot;directory&quot;</span>;</span><br><span class="line">    <span class="keyword">else</span> type = <span class="string">&quot;other&quot;</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (stat.st_mode &amp; S_IRUSER)    <span class="comment">/* Check read access. */</span></span><br><span class="line">        readok = <span class="string">&quot;yes&quot;</span>;</span><br><span class="line">    <span class="keyword">else</span> readok = <span class="string">&quot;no&quot;</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;type: %s, read: %s\n&quot;</span>, type, readok);</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>知识补充：Unix 系统中的 man page 的正确使用方法。</p>
<p>我们都知道，Unix 中的 <code>man</code> 指令相当于一个帮助文档，通常情况下，<code>man &lt;fname&gt;</code> 会进入 <code>fname</code> 所添加的帮助文档的<strong>第一章</strong>中。你可以使用 <code>man &lt;chapterN&gt; &lt;fname&gt;</code> 来指定查看第几章的 <code>fname</code> 文档。</p>
<p>在 man 程序管理帮助文档的规范中，每章的内容有明确的使用范围：</p>
<p>man 的第一章通常介绍 <code>fname</code> 作为一个<strong>系统指令</strong>（编译为了一个二进制文件放在系统中）的使用方法，通常包含一些该命令的命令行技巧和参数；</p>
<p>man 的第二章通常介绍 <code>fname</code> 作为一个<strong>系统级函数/系统调用</strong>在源码中的使用方法，通常包含了一些该函数的 API 文档内容和声明；</p>
<p>有些 <code>fname</code> 既在 Unix 中包装成了二进制的程序供命令行使用，又在头文件和系统的链接库中存在，以供源码使用（例如 <code>kill</code>），所有会同时存在这两章。</p>
<p>man 还有更多的章节，一般到第 8 章，其中的含义可以自行搜寻。</p>
</blockquote>
<h4 id="17-5-2-File-Sharing-amp-File-Descriptor"><a href="#17-5-2-File-Sharing-amp-File-Descriptor" class="headerlink" title="17.5.2 File Sharing &amp; File Descriptor"></a>17.5.2 File Sharing &amp; File Descriptor</h4><p>之前我们用了很长时间的 “file descriptor” 这个名词，接下来将讨论一下所有的文件在程序中如何用 file descriptor 进行标识，或者说，背后的机制是怎样的。</p>
<blockquote>
<p>⚠ <strong>这里是考试的难点！！！光听老师讲、看这部分的信息，想把题目做对是不够的！需要自行研究习题和历年考题。</strong></p>
</blockquote>
<p>OS 内部很多内部数据结构都与具体执行中的进程有关，例如前面提到的页表、用户栈、OS Kernel 等等，它们都存放在这个进程对应的虚拟内存中。</p>
<p>文件描述符也不例外，<strong>每个进程都会在其虚拟内存中维护唯一一个描述符表（descriptor table）</strong>。</p>
<p>还有两种非常特殊的数据结构，一种是 <strong>文件表（open file table）</strong>，另一种是 <strong>虚拟结点表（v-node table）</strong>；<strong>它们被计算机中所有进程共享</strong>；</p>
<p>如图所示：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/fd.png"></p>
<p>很早之前我们就了解过，文件描述符为 0、1、2 的特殊含义，这里不再赘述。</p>
<p>我们需要注意以下几点：</p>
<ul>
<li><p>v-Node Table 就是 Unix files 的 <code>stat</code> 结构体的表，每个 v-Node Table 与物理存储器上的文件<strong>一一对应</strong>（双射），无论文件是否被打开；</p>
</li>
<li><p>Descriptor Table 各个 entry 的内容存放的是<strong>指向各个 Open File Table 的指针</strong>，也表示<strong>当前进程已打开但未关闭的文件</strong>。而描述符相当于是对 Descriptor Table 的<strong>索引</strong>；</p>
</li>
<li><p>Open File Tables 由 OS Kernel 维护。每个 Open File Table 的第一个字段即为指向 v-Node Table 的指针，与每个 v-Node Table 的关系<strong>必然是函数关系，但既不是单射也不是满射</strong>；</p>
<blockquote>
<p>即：</p>
<ol>
<li><p>对任意一个 Open File Table 而言，它必然指向一个唯一的 v-Node Table（即物理文件）；</p>
</li>
<li><p>存在两个 Open File Table 它们指向<strong>同一个物理文件（也就是同一个 v-Node Table）</strong>，但他们本身不一定完全相同，因为它们的字段 <strong><code>File pos</code> 是分别由各个打开进程维护的</strong>。</p>
<p><strong>这意味着程序调用了两次 <code>open</code>，但是参数是同一个 filename</strong>（再次强调：<strong>可能在不同的进程中，而且 <code>File pos</code> 不一定相同</strong>），如下图：</p>
</li>
</ol>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/fd_same_open.png" height="300px"></p>
<ol>
<li><p>允许一个 v-Node Table 不被任何 Open File Table 指向。</p>
<p><strong>这意味着这个物理文件还没有被程序的任何进程打开过</strong>。</p>
</li>
</ol>
</blockquote>
</li>
<li><p>每个 Open File Table 的第二个字段是 <code>refcnt</code>（reference count，引用计数），这个字段表明这个 Open File Table 被描述符表中的多少个 entry 指向；</p>
<blockquote>
<p>为什么要有这项数据？</p>
<p>因为在程序中，可能出现多进程（尤其是 <code>fork()</code> 产生）共享文件资源的情况，这时 OS 需要追踪内存分配，如果程序结束时，OS 需要回收这些部分（引用次数为 0 时不会立即清除）。堆的内存管理也有这种机制，不过比这个复杂很多。</p>
</blockquote>
</li>
</ul>
<p>有个相当重要的点，回忆一下，之前讨论 <code>fork</code> 的时候提到，创建的子进程总是可以直接继承使用父进程的文件描述符，达到二者共享文件资源的目的。但是，之前说描述符表是由每个进程的 OS Kernel 单独维护的。</p>
<p>那么这样的情况下，父子进程共享的文件资源是如何实现的？如下图过程：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/file_sharing_before.png" height="300px"></p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/file_sharing_after.png" height="300px"></p>
<p>总结一下父子进程共享文件描述符的要点：</p>
<ul>
<li>子进程<strong>完全复制</strong>父进程的描述符表；</li>
<li>父进程描述符表中指向的所有文件表的引用计数各加 1；</li>
</ul>
<p>因此我们得知，<strong>父子进程共享的不是物理文件，而是 Open File Tables</strong>（共用了文件指针）；这意味着父子进程任意一方读写文件，二者的文件指针一起变化；</p>
<p>⚠ <strong>最重要的是，每个进程都必须显式调用 <code>close</code>（除了 0、1、2 号文件），才能最终使引用计数为 0，操作系统才能回收。</strong></p>
<h4 id="17-5-3-I-O-Redirection"><a href="#17-5-3-I-O-Redirection" class="headerlink" title="17.5.3 I/O Redirection"></a>17.5.3 I/O Redirection</h4><p>再思考一个问题，Unix Shell 是如何实现 I/O 管道流和重定向的功能的呢？实际上，这个功能的实现也与文件描述符表有关。我们以一个例子为例：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ls</span> &gt; foo.txt</span><br></pre></td></tr></table></figure>
<p>这个指令将 <code>ls</code> 命令输出的结果重定向到 <code>foo.txt</code> 文件中，实际在 shell 的源码中应该使用了一个特殊的系统级函数（再次提示，系统级函数是<strong>系统调用的封装</strong>）：<code>dup2</code>；</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">dup2</span><span class="params">(<span class="type">int</span> oldfd, <span class="type">int</span> newfd)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* More: */</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">dup</span><span class="params">(<span class="type">int</span> oldfd)</span>;    <span class="comment">/* uses the lowest-numbered unused descriptor for the new descriptor. */</span></span><br></pre></td></tr></table></figure>
<ul>
<li>作用：<strong>先将描述符为 <code>newfd</code> 的文件关闭以释放资源，再将描述符为 <code>oldfd</code> 的 descriptor table entry 复制到指定描述符为 <code>newfd</code> 的 entry 中</strong>；<ul>
<li>⚠ 如果 <code>oldfd</code> 是无效的描述符（即 descriptor table 在该位置的 entry 不指向有效的 open file table），则 <code>dup2</code> 执行错误，<strong>这个时候 <code>newfd</code> 对应的资源不会关闭</strong>；</li>
<li>⚠ 如果 <code>oldfd</code> 是有效的描述符，但是 <code>newfd == oldfd</code>，<strong>那么 <code>dup2</code> 什么都不会做，直接返回 <code>newfd</code></strong>;</li>
</ul>
</li>
<li>返回值：如果正确执行，则返回更新后的 <code>newfd</code>；如果执行错误，则返回 <strong>-1</strong> 并且设置 <code>errno</code>；</li>
</ul>
<p>切记，这条指令相当危险，除非你是在设计与操作系统层级很近的应用程序（例如 shell），否则不用轻易使用它，因为它能轻易将你绕晕，不知道哪些文件还没有释放。</p>
<h4 id="17-5-4-Standard-I-O"><a href="#17-5-4-Standard-I-O" class="headerlink" title="17.5.4 Standard I/O"></a>17.5.4 Standard I/O</h4><p>这里的库是 C standard library 包装的一些更高层级的 I/O 接口，它和之前我们接触到的 Unix I/O、RIO 的关系如下：</p>
<p><img src="https://cdn.sjtuxhw.top/cover_imgs/lazyload.gif" data-original="imgs/IO_interface.png"></p>
<p>这些标准 I/O 实际上是 C 的一部分。先归一归类，大家都比较熟悉了：</p>
<ul>
<li>Opening and closing files（<code>fopen</code>、<code>fclose</code>）；</li>
<li>Reading and writing files（<code>fread</code>、<code>fwrite</code>）；</li>
<li>Reading and writing text files（<code>fgets</code>、<code>fputs</code>）；</li>
<li>Formatted reading and writing（<code>fscanf</code>、<code>fprintf</code>）；</li>
</ul>
<p>不仅如此，你见到的很多 standard I/O 都带有 buffering，所以规避了很多低层级的操作。</p>
<p>那么 standard I/O 的 buffer 和 RIO 的 buffer 有什么不同呢？</p>
<p><strong>在功能上</strong>，standard I/O 对于终端文件（terminal）或普通文件的访问方面包装显然要远远优于 RIO；但是 standard I/O 没有考虑到一些网络套接字方面的细节和小问题，所以在<strong>网络套接字的读写方面</strong>用起来还是 RIO 更胜一筹。</p>
<p><strong>在 buffer 设计上</strong>，standard I/O buffer 有一套 <strong>flush 机制</strong>。</p>
<p>对于写的情况，standard I/O 的 buffer 仅当出现以下情况之一时，才将 buffer 整体写入 Unix file，这么做可以减少系统调用次数，提升程序性能：</p>
<ul>
<li>标准输出函数（<code>fprintf/sprintf/...</code>）的结尾含有 <code>\n</code> 换行（<strong>换行结尾</strong>）；</li>
<li>Standard I/O 内部的 buffer 已经写满（<strong>缓冲占满</strong>）；</li>
<li>执行标准输出函数的进程从 <code>main</code> 函数退出了（<strong>程序结束</strong>）；</li>
<li>程序显式地调用 <code>fflush(FILE*)</code> 刷新缓冲区（<strong>手动刷新</strong>）；</li>
</ul>
<p>而 RIO 设定了固定大小的 buffer，并根据用户输入的读取或写入的大小分次进行系统调用，二者各有利弊。</p>
<p>综上，RIO 比 standard I/O 更适宜用在网络套接字读写方面，而 standard I/O 则在其他大部分文件读写的情况下表现更加优秀。</p>
<h3 id="17-6-Summary-of-System-I-O"><a href="#17-6-Summary-of-System-I-O" class="headerlink" title="17.6 Summary of System I/O"></a>17.6 Summary of System I/O</h3><p>本章开始，我们介绍了 Unix File 的概念和常见类型。对于 Unix File 的基本操作，则被操作系统抽象成了 Unix I/O（有系统级函数、系统调用），这些操作非常底层，不过有优势也有劣势：</p>
<ul>
<li>Pros<ul>
<li>Unix I/O 是<strong>最通用、开销最小的 I/O 接口形式</strong>（其他所有 I/O 库都基于此）；</li>
<li>Unix I/O 提供了一系列访问文件 metadata 的函数（<code>stat</code>、<code>fstat</code>）；</li>
<li>⚠ <strong>重大优点：它们都是 异步信号安全 的，可以用在 signal handlers 中</strong>；</li>
</ul>
</li>
<li>Cons<ul>
<li>应对 short counts 的处理很麻烦（尤其是应对 <code>EINTR</code> 和网络传输时），容易出错；</li>
<li>想要按照文本行读取出一行也很麻烦，也易错；</li>
</ul>
</li>
</ul>
<p>Standard I/O 非常优秀，同样有它的优缺点：</p>
<ul>
<li>Pros<ul>
<li>使用特殊的 buffer 机制，减少了系统调用的访问次数；</li>
<li>自动解决 short counts 的异常问题；</li>
</ul>
</li>
<li>Cons<ul>
<li>不提供访问文件元信息的接口；</li>
<li>其中的函数几乎<strong>都不是</strong>异步信号安全的函数；</li>
<li>不适宜用在读写网络套接字上，很容易出错；</li>
</ul>
</li>
</ul>
<p>最后，根据各个 I/O 的封装特性和抽象层级，我们可以总结出这些 I/O 库的选择注意事项 和 推荐：</p>
<p><strong>⚠ 注意事项 ⚠</strong></p>
<ol>
<li><p><strong>在条件允许的情况下，尽可能使用抽象层级高的 I/O 库</strong>；</p>
<blockquote>
<p>这样可以避免一些诸如 <code>EINTR</code>（之前提到，这个系统错误码是因为运气不好，重新调用一次就能修复）等底层奇奇怪怪的信息或错误；</p>
</blockquote>
</li>
<li><p><strong>使用 I/O 库的接口前，一定弄清楚接口的具体作用和逻辑</strong>；</p>
<ul>
<li><p>例如<strong>读二进制文件不能用 识别文本信息 的接口</strong>（例如用 <code>rio_readlineb</code> 去读图片、用 <code>strlen/strcpy</code> 去操作 socket 数据）；</p>
<blockquote>
<p>因为大多数识别文本信息的接口，尤其是按行输入的，会识别文本中的换行符（<code>0xa</code> 或 <code>0xd 0xa</code>，即 <code>EOL</code>，end of line），并以此分割读入；</p>
<p>不仅如此，它们还会把 byte value 0 解释为文本结束（end of string），这样会导致读入操作提前结束。而 <code>0x0</code> 只不过是二进制数据中一个数据而已，只有字符串是以 0 结尾的。</p>
</blockquote>
</li>
</ul>
</li>
<li><p><strong>Standard I/O 和 RIO 不应该混合使用！因为二者内部维护的 buffer 不同，在运行中可能出现干扰和错误</strong>；</p>
</li>
</ol>
<p><strong>ℹ 使用建议 ℹ</strong></p>
<ol>
<li>当 I/O 操作的对象是 <strong>disk / terminal files</strong> 的时候，使用 Standard I/O 最佳；</li>
<li>当需要一些尽量底层的操作（例如写 signal handlers 时），或者极其需要程序性能的时候（少见），使用 raw I/O（Unix I/O）；</li>
<li>当 I/O 操作的对象是网络 socket 文件时，最好使用 RIO 来处理一些特殊的情况，例如 <code>EINTR</code> 和针对网络的 short counts 的处理；</li>
</ol>
<hr>
<p>补充知识：操作目录文件</p>
<p><strong>唯一推荐对 directory 的操作：打开、读取 entries</strong>；</p>
<p>看下面的这个例子：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;dirent.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    DIR *directory;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">dirent</span> *<span class="title">de</span>;</span></span><br><span class="line">    <span class="comment">/* ... */</span></span><br><span class="line">    <span class="keyword">if</span> (!(directory = opendir(dir_name)))</span><br><span class="line">        error(<span class="string">&quot;Failed to open directory&quot;</span>);</span><br><span class="line">    <span class="comment">/* ... */</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="number">0</span> != (de = readdir(directory))) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Found file: %s\n&quot;</span>, de-&gt;d_name);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* ... */</span></span><br><span class="line">    closedir(directory);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://sjtuxhw.top">SJTU-XHW</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://sjtuxhw.top/2023/11/11/CSAPP-Notes-Part-2/">https://sjtuxhw.top/2023/11/11/CSAPP-Notes-Part-2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://sjtuxhw.top" target="_blank">SJTU-XHW's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/myBlog/tags/GNU/">GNU</a><a class="post-meta__tags" href="/myBlog/tags/CSAPP/">CSAPP</a><a class="post-meta__tags" href="/myBlog/tags/ICS/">ICS</a><a class="post-meta__tags" href="/myBlog/tags/Programming/">Programming</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.sjtuxhw.top/cover_imgs/csapp_p2.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/myBlog/img/wechat_pay.jpg" target="_blank"><img class="post-qr-code-img" src="/myBlog/img/wechat_pay.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/myBlog/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/myBlog/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/myBlog/2024/01/13/%E6%94%BE%E5%81%87%EF%BC%81%E5%90%90%E6%A7%BD%EF%BC%81/" title="放假！吐槽！"><img class="cover" src="https://cdn.sjtuxhw.top/cover_imgs/tease.jpg" onerror="onerror=null;src='/myBlog/img/404.png'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">放假！吐槽！</div></div></a></div><div class="next-post pull-right"><a href="/myBlog/2023/10/01/%E3%80%8A%E5%8F%AA%E6%9C%89%E6%88%91%E4%B8%8D%E5%9C%A8%E7%9A%84%E5%9F%8E%E5%B8%82%E3%80%8B%E7%95%AA%E8%AF%84/" title="《只有我不在的城市》番评"><img class="cover" src="https://cdn.sjtuxhw.top/cover_imgs/anime_bokumachi.jpg" onerror="onerror=null;src='/myBlog/img/404.png'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">《只有我不在的城市》番评</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/myBlog/2023/09/17/CSAPP-Notes-Part-1/" title="CSAPP Notes Part 1"><img class="cover" src="https://cdn.sjtuxhw.top/cover_imgs/csapp_123.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-17</div><div class="title">CSAPP Notes Part 1</div></div></a></div><div><a href="/myBlog/2023/04/28/GNU-Tutor/" title="GNU-Tutor"><img class="cover" src="https://cdn.sjtuxhw.top/cover_imgs/GNU-Tutor.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-28</div><div class="title">GNU-Tutor</div></div></a></div><div><a href="/myBlog/2023/07/21/CMake-%E8%BF%9B%E9%98%B6/" title="CMake 进阶"><img class="cover" src="https://cdn.sjtuxhw.top/cover_imgs/cmake.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-21</div><div class="title">CMake 进阶</div></div></a></div><div><a href="/myBlog/2023/04/28/Git%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="Git学习笔记"><img class="cover" src="https://cdn.sjtuxhw.top/cover_imgs/git.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-28</div><div class="title">Git学习笔记</div></div></a></div><div><a href="/myBlog/2023/04/28/Java-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="Java 学习笔记（1）"><img class="cover" src="https://cdn.sjtuxhw.top/cover_imgs/java1.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-04-28</div><div class="title">Java 学习笔记（1）</div></div></a></div><div><a href="/myBlog/2023/06/18/Matlab-%E5%A4%8D%E4%B9%A0/" title="Matlab 复习"><img class="cover" src="https://cdn.sjtuxhw.top/cover_imgs/matlab.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-18</div><div class="title">Matlab 复习</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/myBlog/img/favicon.ico" onerror="this.onerror=null;this.src='/myBlog/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">SJTU-XHW</div><div class="author-info__description">A blog to document learning and life</div></div><div class="card-info-data site-data is-center"><a href="/myBlog/archives/"><div class="headline">文章</div><div class="length-num">31</div></a><a href="/myBlog/tags/"><div class="headline">标签</div><div class="length-num">49</div></a><a href="/myBlog/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/SSRVodka"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/SSRVodka" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:sjtuxhw12345@sjtu.edu.cn" rel="external nofollow noreferrer" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="https://sjtuxhw.top/myBlog/atom.xml" target="_blank" title="RSS"><i class="fas fa-rss" style="color: #a200ff;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Thanks for visiting! ‎|•'-'•) ✧</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-8-The-Memory-Hierarchy"><span class="toc-text">Chapter 8. The Memory Hierarchy</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-Storage-Technologies-amp-Trends"><span class="toc-text">8.1 Storage Technologies &amp; Trends</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-1-Random-Access-Memory-RAM"><span class="toc-text">8.1.1 Random-Access Memory (RAM)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-2-Nonvolatile-Memories"><span class="toc-text">8.1.2 Nonvolatile Memories</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#8-1-3-Traditional-Bus-Structure-Connecting-CPU-and-Memory"><span class="toc-text">8.1.3 Traditional Bus Structure Connecting CPU and Memory</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-Locality"><span class="toc-text">8.2 Locality</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-3-Conclusions-for-8-1-amp-8-2"><span class="toc-text">8.3 Conclusions for 8.1 &amp; 8.2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-4-Memory-Hierarchy-amp-Idea-of-Caching"><span class="toc-text">8.4 Memory Hierarchy &amp; Idea of Caching</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-9-Cache-Memories"><span class="toc-text">Chapter 9. Cache Memories</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-General-Cache-Organization"><span class="toc-text">9.1 General Cache Organization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-Read-Cache"><span class="toc-text">9.2 Read Cache</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#9-2-1-Direct-Mapped-Cache-Simulation"><span class="toc-text">9.2.1 Direct-Mapped Cache Simulation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-2-2-E-Way-Set-Associative-Cache-Simulation"><span class="toc-text">9.2.2 E-Way Set Associative Cache Simulation</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-Write-Cache"><span class="toc-text">9.3 Write Cache</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-The-Hierarchy-of-Cache-Memories"><span class="toc-text">9.3 The Hierarchy of Cache Memories</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-Performance-Impact-of-Cache"><span class="toc-text">9.4 Performance Impact of Cache</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#9-4-1-Writing-Cache-Friendly-Code-%E2%85%A0"><span class="toc-text">9.4.1 Writing Cache Friendly Code Ⅰ</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-4-2-The-Memory-Mountain"><span class="toc-text">9.4.2 The Memory Mountain</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-4-3-Writing-Cache-Friendly-Code-%E2%85%A1-Rearranging-loops-to-improve-spacial-locality"><span class="toc-text">9.4.3 Writing Cache Friendly Code Ⅱ - Rearranging loops to improve spacial locality</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-4-4-Writing-Cache-Friendly-Code-%E2%85%A2-Using-blocking-to-improve-temporal-locality"><span class="toc-text">9.4.4 Writing Cache Friendly Code Ⅲ - Using blocking to improve temporal locality</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9-4-5-Cache-Performance-Summary"><span class="toc-text">9.4.5 Cache Performance Summary</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-15-Program-Optimization"><span class="toc-text">Chapter 15. Program Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#15-1-Goals-of-Optimization"><span class="toc-text">15.1 Goals of Optimization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-2-Limits-to-Compiler-Optimization"><span class="toc-text">15.2 Limits to Compiler Optimization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-3-Generally-Useful-Optimizations"><span class="toc-text">15.3 Generally Useful Optimizations</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#15-3-1-Constant-Folding"><span class="toc-text">15.3.1 Constant Folding</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#15-3-2-Dead-Code-Elimination"><span class="toc-text">15.3.2 Dead Code Elimination</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#15-3-3-Common-Subexpression-Elimination"><span class="toc-text">15.3.3 Common Subexpression Elimination</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#15-3-4-Code-Motion"><span class="toc-text">15.3.4 Code Motion</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#15-3-5-Inlining"><span class="toc-text">15.3.5 Inlining</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#15-3-6-Strength-Reduction"><span class="toc-text">15.3.6 Strength Reduction</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-4-Obstacles-for-Compiler-to-Optimization"><span class="toc-text">15.4 Obstacles for Compiler to Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#15-4-1-Optimization-Blocker-1-Procedure-Calls"><span class="toc-text">15.4.1 Optimization Blocker #1: Procedure Calls</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#15-4-2-Optimization-Blocker-2-Memory-Aliasing"><span class="toc-text">15.4.2 Optimization Blocker #2: Memory Aliasing</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-5-Machine-Dependent-Optimization"><span class="toc-text">15.5 Machine-Dependent Optimization</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#15-5-1-Branch-Misprediction-Recovery"><span class="toc-text">15.5.1 Branch Misprediction Recovery</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#15-5-2-Scheduling"><span class="toc-text">15.5.2 Scheduling</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#15-5-3-Benchmark-Example"><span class="toc-text">15.5.3 Benchmark Example</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-6-Summary"><span class="toc-text">15.6 Summary</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-16-Exceptional-Control-Flow"><span class="toc-text">Chapter 16. Exceptional Control Flow</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#16-1-Control-Flow"><span class="toc-text">16.1 Control Flow</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16-2-Exception-Control-Flow-Overview"><span class="toc-text">16.2 Exception Control Flow: Overview</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16-3-Exception-Control-Flow-Exception"><span class="toc-text">16.3 Exception Control Flow: Exception</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#16-3-1-Definitions"><span class="toc-text">16.3.1 Definitions</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-3-2-Process-Procedure"><span class="toc-text">16.3.2 Process Procedure</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-3-3-Implementations-of-Exception"><span class="toc-text">16.3.3 Implementations of Exception</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-3-4-Types-of-Exceptions"><span class="toc-text">16.3.4 Types of Exceptions</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-3-5-Summary-of-Exception"><span class="toc-text">16.3.5 Summary of Exception</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16-4-Exception-Control-Flow-Process-Context-Switch"><span class="toc-text">16.4 Exception Control Flow: Process Context Switch</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#16-4-1-Process"><span class="toc-text">16.4.1 Process</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-4-2-How-does-Multiprocessing-work-on-single-processor"><span class="toc-text">16.4.2 How does Multiprocessing work on single processor ?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-4-3-Concurrency-amp-Parallelism-amp-Interleaving"><span class="toc-text">16.4.3 Concurrency &amp; Parallelism &amp; Interleaving</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-4-4-Concurrent-Process"><span class="toc-text">16.4.4 Concurrent Process</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-4-5-Process-Control"><span class="toc-text">16.4.5 Process Control</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-4-6-Summary-of-Process-amp-Process-Control"><span class="toc-text">16.4.6 Summary of Process &amp; Process Control</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16-5-Exception-Control-Flow-Signals"><span class="toc-text">16.5 Exception Control Flow: Signals</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#16-5-1-Linux-Process-Hierarchy-amp-Shell-Example"><span class="toc-text">16.5.1 Linux Process Hierarchy &amp; Shell Example</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-5-2-The-Features-of-Signals"><span class="toc-text">16.5.2 The Features of Signals</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-5-3-Implementations-of-Sending-a-Signal"><span class="toc-text">16.5.3 Implementations of Sending a Signal</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#16-5-3-1-Signal-Concepts-Pending-amp-Blocked"><span class="toc-text">16.5.3.1 Signal Concepts: Pending &amp; Blocked</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#16-5-3-2-Process-Concept-Process-Groups"><span class="toc-text">16.5.3.2 Process Concept: Process Groups</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Back-to-16-5-3"><span class="toc-text">Back to 16.5.3</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-5-4-Signal-Handlers-amp-Default-Action"><span class="toc-text">16.5.4 Signal Handlers &amp; Default Action</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-5-5-Nested-Signal-Handlers"><span class="toc-text">16.5.5 Nested Signal Handlers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-5-6-Safe-Signal-Handling-%E2%9A%A0IMPORTANT"><span class="toc-text">16.5.6 Safe Signal Handling [⚠IMPORTANT]</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#16-5-7-Summary-of-Signals"><span class="toc-text">16.5.7 Summary of Signals</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16-6-Non-local-Jump"><span class="toc-text">16.6 Non-local Jump</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Chapter-17-System-Level-I-O"><span class="toc-text">Chapter 17 System Level I&#x2F;O</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#17-1-Unix-I-O-Overview"><span class="toc-text">17.1 Unix I&#x2F;O Overview</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-2-Unix%E2%80%99s-Files"><span class="toc-text">17.2 Unix’s Files</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#17-2-1-Regular-Files"><span class="toc-text">17.2.1 Regular Files</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#17-2-2-Directories"><span class="toc-text">17.2.2 Directories</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-3-Basic-Operations"><span class="toc-text">17.3 Basic Operations</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#17-3-1-Opening-Files"><span class="toc-text">17.3.1 Opening Files</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#17-3-2-Closing-Files"><span class="toc-text">17.3.2 Closing Files</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#17-3-3-Reading-Files-amp-Writing-Files"><span class="toc-text">17.3.3 Reading Files &amp; Writing Files</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-4-The-RIO-Package"><span class="toc-text">17.4 The RIO Package</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-5-File-Metadata-Sharing-and-Redirection"><span class="toc-text">17.5 File Metadata, Sharing and Redirection</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#17-5-1-Metadata"><span class="toc-text">17.5.1 Metadata</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#17-5-2-File-Sharing-amp-File-Descriptor"><span class="toc-text">17.5.2 File Sharing &amp; File Descriptor</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#17-5-3-I-O-Redirection"><span class="toc-text">17.5.3 I&#x2F;O Redirection</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#17-5-4-Standard-I-O"><span class="toc-text">17.5.4 Standard I&#x2F;O</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#17-6-Summary-of-System-I-O"><span class="toc-text">17.6 Summary of System I&#x2F;O</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/myBlog/2024/02/20/JavaScript%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/" title="JavaScript入门笔记"><img src="https://cdn.sjtuxhw.top/cover_imgs/javascript.jpg" onerror="this.onerror=null;this.src='/myBlog/img/404.png'" alt="JavaScript入门笔记"/></a><div class="content"><a class="title" href="/myBlog/2024/02/20/JavaScript%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/" title="JavaScript入门笔记">JavaScript入门笔记</a><time datetime="2024-02-20T13:17:09.000Z" title="发表于 2024-02-20 21:17:09">2024-02-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/myBlog/2024/01/15/%E6%B5%85%E6%9E%90-TTY-Subsystem/" title="浅析 TTY Subsystem"><img src="https://cdn.sjtuxhw.top/cover_imgs/tty.jpg" onerror="this.onerror=null;this.src='/myBlog/img/404.png'" alt="浅析 TTY Subsystem"/></a><div class="content"><a class="title" href="/myBlog/2024/01/15/%E6%B5%85%E6%9E%90-TTY-Subsystem/" title="浅析 TTY Subsystem">浅析 TTY Subsystem</a><time datetime="2024-01-14T23:12:02.000Z" title="发表于 2024-01-15 07:12:02">2024-01-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/myBlog/2024/01/13/%E6%94%BE%E5%81%87%EF%BC%81%E5%90%90%E6%A7%BD%EF%BC%81/" title="放假！吐槽！"><img src="https://cdn.sjtuxhw.top/cover_imgs/tease.jpg" onerror="this.onerror=null;this.src='/myBlog/img/404.png'" alt="放假！吐槽！"/></a><div class="content"><a class="title" href="/myBlog/2024/01/13/%E6%94%BE%E5%81%87%EF%BC%81%E5%90%90%E6%A7%BD%EF%BC%81/" title="放假！吐槽！">放假！吐槽！</a><time datetime="2024-01-13T06:33:01.000Z" title="发表于 2024-01-13 14:33:01">2024-01-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/myBlog/2023/11/11/CSAPP-Notes-Part-2/" title="CSAPP Notes Part 2"><img src="https://cdn.sjtuxhw.top/cover_imgs/csapp_p2.png" onerror="this.onerror=null;this.src='/myBlog/img/404.png'" alt="CSAPP Notes Part 2"/></a><div class="content"><a class="title" href="/myBlog/2023/11/11/CSAPP-Notes-Part-2/" title="CSAPP Notes Part 2">CSAPP Notes Part 2</a><time datetime="2023-11-11T01:18:11.000Z" title="发表于 2023-11-11 09:18:11">2023-11-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/myBlog/2023/10/01/%E3%80%8A%E5%8F%AA%E6%9C%89%E6%88%91%E4%B8%8D%E5%9C%A8%E7%9A%84%E5%9F%8E%E5%B8%82%E3%80%8B%E7%95%AA%E8%AF%84/" title="《只有我不在的城市》番评"><img src="https://cdn.sjtuxhw.top/cover_imgs/anime_bokumachi.jpg" onerror="this.onerror=null;this.src='/myBlog/img/404.png'" alt="《只有我不在的城市》番评"/></a><div class="content"><a class="title" href="/myBlog/2023/10/01/%E3%80%8A%E5%8F%AA%E6%9C%89%E6%88%91%E4%B8%8D%E5%9C%A8%E7%9A%84%E5%9F%8E%E5%B8%82%E3%80%8B%E7%95%AA%E8%AF%84/" title="《只有我不在的城市》番评">《只有我不在的城市》番评</a><time datetime="2023-10-01T02:20:47.000Z" title="发表于 2023-10-01 10:20:47">2023-10-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By SJTU-XHW  |  tech SJTU saves the world</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><a href="https://beian.miit.gov.cn" rel="external nofollow noreferrer" id="beian" target="_blank">ICP备案：沪ICP备2023012264-1号</a> <a href="https://www.upyun.com/?utm_source=lianmeng&utm_medium=referral" rel="external nofollow noreferrer" target="_blank"> &nbsp;|&nbsp;&nbsp;本网站由 <img src="/img/upCloud_logo.png" title="upcloud" alt="upcloud" height="30px"> 提供CDN加速/云存储服务 </a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();" rel="external nofollow noreferrer"><i class="fa-solid fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();" rel="external nofollow noreferrer"><i class="fa-solid fa-arrow-rotate-right"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();" rel="external nofollow noreferrer"><i class="fa-solid fa-arrow-right"></i></a><a class="rightMenu-item" id="menu-radompage" href="javascript:window.location.href = window.location.origin;" rel="external nofollow noreferrer"><i class="fa-solid fa-house"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();" rel="external nofollow noreferrer"><i class="fa-solid fa-copy"></i><span>复制</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:rmf.switchDarkMode();" rel="external nofollow noreferrer"><i class="fa-solid fa-circle-half-stroke"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="javascript:rmf.switchReadMode();" rel="external nofollow noreferrer"><i class="fa-solid fa-book"></i><span>阅读模式</span></a></div></div><div><script src="/myBlog/js/utils.js"></script><script src="/myBlog/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.sjtuxhw.top',
      region: '',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(init,0)
    else getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(init)
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.sjtuxhw.top',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else {
      loadTwikoo()
      GLOBAL_CONFIG_SITE.isPost && getCount()
    }
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://twikoo.sjtuxhw.top',
        region: '',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script src="/myBlog/js/jquery-3.7.0.min.js"></script><script src="/myBlog/js/rightmenu.js"></script><div class="aplayer no-destroy" data-id="6898044781" data-server="netease" data-type="playlist" data-fixed="true" data-autoplay="false"></div><script src="/myBlog/js/mourn.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="/myBlog/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener
  btf.removeGlobalFnEvent('pjax')
  btf.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/myBlog/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/myBlog/js/search/local-search.js"></script></div></div>
        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: true,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var e=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,c=a();function a(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(){e&&(c=a());for(var t,o=0;o<c.length;o++)0<=(t=(t=c[o]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,n,a,i=c[o];e=function(){c=c.filter(function(t){return i!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(i)},(t=i).hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(n=new Image,a=t.getAttribute("data-original"),n.onload=function(){t.src=a,t.removeAttribute("data-original"),e&&e()},t.src!==a&&(n.src=a))}()}function i(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",i),r.addEventListener("resize",i),r.addEventListener("orientationchange",i)}(this);</script></body></html>