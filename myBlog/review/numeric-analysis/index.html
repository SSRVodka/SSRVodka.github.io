<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Numeric Analysis for Beginners | SJTU-XHW's blog</title><meta name="author" content="SJTU-XHW,sjtuxhw12345@sjtu.edu.cn"><meta name="copyright" content="SJTU-XHW"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Chapter 1. Basic Concepts 相对误差与绝对误差；  求根问题：$\text{For }f:\mathbf{R}\rightarrow\mathbf{R},\text{ find }x^*\text{ such that }f(x^*)&#x3D;0$； 假设有估计解 $x_{est}$，但是 $0\lt |f(x_{est})|\ll1$，那么我们也许不知道 $|x_{est}-x_">
<meta property="og:type" content="article">
<meta property="og:title" content="Numeric Analysis for Beginners">
<meta property="og:url" content="https://blog.sjtuxhw.top/review/numeric-analysis/index.html">
<meta property="og:site_name" content="SJTU-XHW&#39;s blog">
<meta property="og:description" content="Chapter 1. Basic Concepts 相对误差与绝对误差；  求根问题：$\text{For }f:\mathbf{R}\rightarrow\mathbf{R},\text{ find }x^*\text{ such that }f(x^*)&#x3D;0$； 假设有估计解 $x_{est}$，但是 $0\lt |f(x_{est})|\ll1$，那么我们也许不知道 $|x_{est}-x_">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.sjtuxhw.top/cover_imgs/numeric-analysis.jpg">
<meta property="article:published_time" content="2024-06-12T05:11:56.000Z">
<meta property="article:modified_time" content="2024-10-25T14:00:51.242Z">
<meta property="article:author" content="SJTU-XHW">
<meta property="article:tag" content="Math">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.sjtuxhw.top/cover_imgs/numeric-analysis.jpg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="https://blog.sjtuxhw.top/review/numeric-analysis/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        if (name && globalFn[key][name]) return
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'undefined')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":300,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功 ヾ(≧∇≦*)ゝ',
    error: '复制失败 (#`皿´)',
    noSupport: '浏览器不支持 ╮(╯_╰)╭'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#333","bgDark":"#1f1f1f","position":"top-center"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Numeric Analysis for Beginners',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-10-25 22:00:51'
}</script><link rel="stylesheet" href="/css/mouseConfig.css"/><link rel="stylesheet" href="/css/rightmenu.css"/><link rel="stylesheet" href="/css/custom_music.css"/><link rel="stylesheet" href="/css/addFonts.css"/><link rel="stylesheet" href="/css/titleFonts.css"/><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="SJTU-XHW's blog" type="application/atom+xml">
</head><body><div id="loading-box"><div id="main-loading-bg"><div class="truckWrapper"><div class="truckBody"><svg class="trucksvg" viewBox="0 0 198 93" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M135 22.5H177.264C178.295 22.5 179.22 23.133 179.594 24.0939L192.33 56.8443C192.442 57.1332 192.5 57.4404 192.5 57.7504V89C192.5 90.3807 191.381 91.5 190 91.5H135C133.619 91.5 132.5 90.3807 132.5 89V25C132.5 23.6193 133.619 22.5 135 22.5Z" fill="currentColor" stroke="#282828" stroke-width="3"></path><path d="M146 33.5H181.741C182.779 33.5 183.709 34.1415 184.078 35.112L190.538 52.112C191.16 53.748 189.951 55.5 188.201 55.5H146C144.619 55.5 143.5 54.3807 143.5 53V36C143.5 34.6193 144.619 33.5 146 33.5Z" fill="#7D7C7C" stroke="#282828" stroke-width="3"></path><path d="M150 65C150 65.39 149.763 65.8656 149.127 66.2893C148.499 66.7083 147.573 67 146.5 67C145.427 67 144.501 66.7083 143.873 66.2893C143.237 65.8656 143 65.39 143 65C143 64.61 143.237 64.1344 143.873 63.7107C144.501 63.2917 145.427 63 146.5 63C147.573 63 148.499 63.2917 149.127 63.7107C149.763 64.1344 150 64.61 150 65Z" fill="#282828" stroke="#282828" stroke-width="2"></path><rect x="187" y="63" width="5" height="7" rx="1" fill="#FFFCAB" stroke="#282828" stroke-width="2"></rect><rect x="193" y="81" width="4" height="11" rx="1" fill="#282828" stroke="#282828" stroke-width="2"></rect><rect x="6.5" y="1.5" width="121" height="90" rx="2.5" fill="#DFDFDF" stroke="#282828" stroke-width="3"></rect><rect x="1" y="84" width="6" height="4" rx="2" fill="#DFDFDF" stroke="#282828" stroke-width="2"></rect></svg></div><div class="truckTires"><svg class="tiresvg" viewBox="0 0 30 30" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="15" cy="15" r="13.5" fill="#282828" stroke="#282828" stroke-width="3"></circle><circle cx="15" cy="15" r="7" fill="#DFDFDF"></circle></svg><svg class="tiresvg" viewBox="0 0 30 30" fill="none" xmlns="http://www.w3.org/2000/svg"><circle cx="15" cy="15" r="13.5" fill="#282828" stroke="#282828" stroke-width="3"></circle><circle cx="15" cy="15" r="7" fill="#DFDFDF"></circle></svg></div><div class="road"></div><svg class="lampPost" fill="currentColor" version="1.1" id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 453.459 453.459" xml:space="preserve"><path d="M252.882,0c-37.781,0-68.686,29.953-70.245,67.358h-6.917v8.954c-26.109,2.163-45.463,10.011-45.463,19.366h9.993 c-1.65,5.146-2.507,10.54-2.507,16.017c0,28.956,23.558,52.514,52.514,52.514c28.956,0,52.514-23.558,52.514-52.514 c0-5.478-0.856-10.872-2.506-16.017h9.992c0-9.354-19.352-17.204-45.463-19.366v-8.954h-6.149C200.189,38.779,223.924,16,252.882,16 c29.952,0,54.32,24.368,54.32,54.32c0,28.774-11.078,37.009-25.105,47.437c-17.444,12.968-37.216,27.667-37.216,78.884v113.914 h-0.797c-5.068,0-9.174,4.108-9.174,9.177c0,2.844,1.293,5.383,3.321,7.066c-3.432,27.933-26.851,95.744-8.226,115.459v11.202h45.75 v-11.202c18.625-19.715-4.794-87.527-8.227-115.459c2.029-1.683,3.322-4.223,3.322-7.066c0-5.068-4.107-9.177-9.176-9.177h-0.795 V196.641c0-43.174,14.942-54.283,30.762-66.043c14.793-10.997,31.559-23.461,31.559-60.277C323.202,31.545,291.656,0,252.882,0z M232.77,111.694c0,23.442-19.071,42.514-42.514,42.514c-23.442,0-42.514-19.072-42.514-42.514c0-5.531,1.078-10.957,3.141-16.017 h78.747C231.693,100.736,232.77,106.162,232.77,111.694z"></path></svg></div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
      setTimeout(() => {
        $loadingBox.style.display = 'none'
      }, 800)
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load', preloader.endLoading)

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()
</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/favicon.ico" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">50</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">63</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/dailyQ/"><i class="fa-fw fa-solid fa-pen-to-square"></i><span> DailyQuestion</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-gamepad"></i><span> ACG-Lab</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/ACGLab/MikuTap/"><i class="fa-fw fas fa-music"></i><span> MikuTap</span></a></li><li><a class="site-page child" href="/ACGLab/Live2D/"><i class="fa-fw fa-solid fa-face-kiss-wink-heart"></i><span> Live2D</span></a></li><li><a class="site-page child" href="/ACGLab/Folio-2019/"><i class="fa-fw fa-solid fa-car-side"></i><span> Folio-2019</span></a></li><li><a class="site-page child" href="/ACGLab/Cube/"><i class="fa-fw fa-solid fa-cube"></i><span> Cube</span></a></li><li><a class="site-page child" href="/ACGLab/TowerBlocks/"><i class="fa-fw fa-solid fa-gopuram"></i><span> TBlocks</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/friend-links/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fa fa-camera"></i><span> Gallery</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://cdn.sjtuxhw.top/cover_imgs/numeric-analysis.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/head_icon.png" alt="Logo"><span class="site-name">SJTU-XHW's blog</span></a><a class="nav-page-title" href="/"><span class="site-name">Numeric Analysis for Beginners</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/dailyQ/"><i class="fa-fw fa-solid fa-pen-to-square"></i><span> DailyQuestion</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-gamepad"></i><span> ACG-Lab</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/ACGLab/MikuTap/"><i class="fa-fw fas fa-music"></i><span> MikuTap</span></a></li><li><a class="site-page child" href="/ACGLab/Live2D/"><i class="fa-fw fa-solid fa-face-kiss-wink-heart"></i><span> Live2D</span></a></li><li><a class="site-page child" href="/ACGLab/Folio-2019/"><i class="fa-fw fa-solid fa-car-side"></i><span> Folio-2019</span></a></li><li><a class="site-page child" href="/ACGLab/Cube/"><i class="fa-fw fa-solid fa-cube"></i><span> Cube</span></a></li><li><a class="site-page child" href="/ACGLab/TowerBlocks/"><i class="fa-fw fa-solid fa-gopuram"></i><span> TBlocks</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/friend-links/"><i class="fa-fw fas fa-link"></i><span> Links</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><i class="fa-fw fa fa-camera"></i><span> Gallery</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Numeric Analysis for Beginners</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-06-12T05:11:56.000Z" title="发表于 2024-06-12 13:11:56">2024-06-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-10-25T14:00:51.242Z" title="更新于 2024-10-25 22:00:51">2024-10-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/review/">review</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">7.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>30分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/review/numeric-analysis/#post-comment"><span id="twikoo-count"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Chapter-1-Basic-Concepts"><a href="#Chapter-1-Basic-Concepts" class="headerlink" title="Chapter 1. Basic Concepts"></a>Chapter 1. Basic Concepts</h1><ul>
<li><p>相对误差与绝对误差；</p>
</li>
<li><p>求根问题：$\text{For }f:\mathbf{R}\rightarrow\mathbf{R},\text{ find }x^*\text{ such that }f(x^*)=0$；</p>
<p>假设有估计解 $x_{est}$，但是 $0\lt |f(x_{est})|\ll1$，那么我们也许不知道 $|x_{est}-x_0|$，但是我们一定知道 $|f(x_{est})-f(x_0)|\equiv|f(x_{est})|$；</p>
<ul>
<li><p>前向误差：估计解与实际解的差值（就是上面的 $|x_{est}-x_0|$，一般我们不知道）；</p>
</li>
<li><p>后向误差：使得估计值正确所要让 problem statement 改变的 delta（就是上面的 $|f(x_{est})-f(x_0)|\equiv|f(x_{est})|$，一般我们能算出来）；</p>
</li>
<li><p>Well-Conditioned（insensitive）：$\text{Small backward error}\Rightarrow\text{Small forward error}$；</p>
</li>
<li><p>Poor-Conditioned（sensitive/stiff）：$\text{Small backward error}\nRightarrow\text{Small forward error}$；</p>
</li>
<li><p>Condition Number：$CN=\dfrac{\text{Forword Error}}{\text{Backward Error}}$；</p>
<blockquote>
<p>在寻根问题中，很容易得到 $CN=\dfrac{1}{|f^\prime(x^*)|}$；</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Carefully Implementation</p>
<ul>
<li>防止溢出的方法：Element Scaling（例如求 $||\vec{x}||_2$）；</li>
</ul>
</li>
</ul>
<h1 id="Chapter-2-Linear-System-and-LU"><a href="#Chapter-2-Linear-System-and-LU" class="headerlink" title="Chapter 2. Linear System and LU"></a>Chapter 2. Linear System and LU</h1><h2 id="2-1-Review"><a href="#2-1-Review" class="headerlink" title="2.1 Review"></a>2.1 Review</h2><ul>
<li><p>Over Determined / Under Determined / Completely Determined.</p>
<blockquote>
<p>“高” 的矩阵可能是 over determined（更多限制条件）；</p>
<p>“宽” 的矩阵可能是 under determined（解更可能有无限个）；</p>
</blockquote>
</li>
<li><p>线性方程组的结论复习：一个线性方程组 $A\vec{x}=\vec{b}$ 有两个不同解 $\vec{x_0},\vec{x_1}$，则它有无穷多解；</p>
<blockquote>
<p> $\vec{x_0},\vec{x_1}$ 都是线性方程组的解，则它们的线性组合都是该线性方程组的解；</p>
</blockquote>
</li>
<li><p>经验结论：解线性方程组 $A\vec{x}=\vec{b}$ 能不解 $A^{-1}$ 就不解它（计算量和准确性）；</p>
</li>
<li><p>初等行变换：左乘初等矩阵；</p>
<blockquote>
<p>初等矩阵是指由单位矩阵经过一次基本行/列变换得到的矩阵。基本行/列变换包括以下三种操作：</p>
<ul>
<li><p><strong>交换型初等矩阵</strong>：形式为单位矩阵的两行（或列）交换得到的矩阵。例如，在3阶方阵中，交换第一行和第二行的单位矩阵为：</p>
<script type="math/tex; mode=display">
\left[\begin{matrix}0&1&0\\1&0&0\\0&0&1\end{matrix}\right]</script></li>
<li><p><strong>倍加型初等矩阵</strong>：单位矩阵的某一行（或列）乘以非零常数后加到另一行（或列）得到的矩阵。例如，在3阶方阵中，将第一行的两倍加到第三行的单位矩阵为：</p>
<script type="math/tex; mode=display">
\left[\begin{matrix}1&0&0\\0&1&0\\2&0&1\end{matrix}\right]</script></li>
</ul>
<ul>
<li><strong>倍乘型初等矩阵</strong>：单位矩阵的某一行（或列）乘以非零常数得到的矩阵。例如，在3阶方阵中，将第三行的元素都乘以2的单位矩阵为：<script type="math/tex; mode=display">
\left[\begin{matrix}1&0&0\\0&1&0\\0&0&2\end{matrix}\right]</script></li>
</ul>
<p>将一个矩阵左乘对应的初等矩阵就是在对行进行对应的变换；</p>
<p>将一个矩阵右乘对应的初等矩阵就是在对列进行对应的变换；</p>
</blockquote>
</li>
<li><p>高斯消元：先 forward substitution（将第 i 行的前 i - 1 个元素清零、第 i 个元素置 1），再 back substitution（向之前代入）；</p>
</li>
</ul>
<h2 id="2-2-LU-Factorization"><a href="#2-2-LU-Factorization" class="headerlink" title="2.2 LU Factorization"></a>2.2 LU Factorization</h2><p>LU 分解：当参数矩阵不变，只有 $\vec{b}$ 不同时，我们可以节省重复计算的步骤。这种方法就是 $LU$ 分解。</p>
<ul>
<li>我们先将 $A$ 矩阵使用高斯消元为 $A=LU$（$U$ 是高斯消元的 forward substitution 的结果）；</li>
<li>这样可以分开计算 $L\vec{y}=b$ 中的 $\vec{y}$、$U\vec{x}=\vec{y}$ 解得 $\vec{x}$，每一步都是 $O(n^2)$；并且得到上/下三角矩阵的逆要比一般的 $A$ 简单；</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="imgs2/LU.png"></p>
<h2 id="2-3-Linear-System"><a href="#2-3-Linear-System" class="headerlink" title="2.3 Linear System"></a>2.3 Linear System</h2><ul>
<li><p>线性回归预测</p>
</li>
<li><p>线性系统拟合曲线：n 次试验构建一个线性方程组；</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="imgs2/linear-fit.png" height="150px"></p>
<blockquote>
<p>线性系统拟合非线性曲线：可以让 $f$ 是非线性的，构建一个非线性函数 $f_{ij}$ 的矩阵；</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="imgs2/ffit.png" height="200px"></p>
<p>一个特殊的例子是范特蒙德系统 $f=a_0+a_1x+a_2x^2+\cdots$；</p>
<p>我们还可以借助傅里叶展开 $f=a\cos(x+\phi)$；</p>
</blockquote>
</li>
<li><p>$A\vec{x}=\vec{b}$ 无解情况如何接近？凸优化：$\min\limits_{\vec{x}}||A\vec{x}-\vec{b}||_2^2$；</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="imgs2/ms.png" height="300px"></p>
</li>
<li><p>Tikhonov regularization：这种正则化可以向 under determined 的情况加入限制，有助于防止过拟合、数据抖动、减轻数据噪声影响（对高斯白噪声效果好）等问题：</p>
<script type="math/tex; mode=display">
\min\limits_{\vec{x}}||A\vec{x}-\vec{b}||_2^2+\alpha||\vec{x}||_2^2\quad(0\lt\alpha\le1)\\
\Longrightarrow0=2A^TA\vec{x}-2A^T\vec{b}+2\alpha\vec{x}\\
\Longrightarrow(A^TA+\alpha I_{n\times n})\vec{x}=A^T\vec{b}</script></li>
<li></li>
<li><p>稀疏矩阵存储：变换为低维数据（压缩信息的相关性）；</p>
<ul>
<li>普通有规律的矩阵，可以通过一些变换转换为稀疏矩阵；</li>
</ul>
</li>
</ul>
<h2 id="2-5-Cholesky-Factorization"><a href="#2-5-Cholesky-Factorization" class="headerlink" title="2.5 Cholesky Factorization"></a>2.5 Cholesky Factorization</h2><p>注意到重要的矩阵 $A^TA$ 有如下性质：</p>
<ul>
<li>正定对称阵（Positive definite Matrix）其中 $A\ne0$；</li>
</ul>
<p>而我们又发现正定对称矩阵的 LU 分解非常特殊，$U=L^T$，所以所有正定对称阵可以分解为 $A=LL^T$，这就是 Cholesky 分解；</p>
<ul>
<li><p>在阶数较小的情况，直接可以使用待定系数法求解 $L$；</p>
</li>
<li><p>在阶数较大的情况，使用迭代法求解 $L$，算法如下：</p>
<ol>
<li><p>初始化 $L=0$（全零矩阵，同时是下三角矩阵）；</p>
</li>
<li><p>对矩阵的每一列 $j$：</p>
<ul>
<li><p>先计算该列上的对角元 $L_{jj}=\sqrt{A_{jj}-\sum\limits_{k=1}^{j-1}L_{jk}^2}$（$j\gt1$），其中 $L_{11}=\sqrt{A_{11}}$；</p>
<blockquote>
<p>不难发现，$L$ 每行对角元只与 $A_{jj}$ 和当前行排在 $L_{jj}$ 之前的元素平方和有关；</p>
<p>可以将 $A$ 分块，即可推出这个结论；</p>
</blockquote>
</li>
<li><p>在第 $j$ 列中，继续对第 $j$ 行之后的每一行 $i\gt j$，计算 $L_{ij}=\dfrac{1}{L_{jj}}(A_{ij}-\sum\limits_{k=1}^{j-1}L_{ik}L_{jk})$，</p>
<blockquote>
<p>结论，$L_{ij}$ 与 $A_{ij}$ 和：排在 $L_{jj}$ 前面的元素向量 与 排在 $L_{ij}$ 前面的元素向量的点积有关；</p>
</blockquote>
</li>
</ul>
<p>完成上面两个步骤后，矩阵的第 $j$ 列全部计算完成；</p>
</li>
</ol>
</li>
</ul>
<h1 id="Chapter-3-Norms-Sensitivity-amp-Conditioning-in-Matrix"><a href="#Chapter-3-Norms-Sensitivity-amp-Conditioning-in-Matrix" class="headerlink" title="Chapter 3. Norms, Sensitivity &amp; Conditioning in Matrix"></a>Chapter 3. Norms, Sensitivity &amp; Conditioning in Matrix</h1><h2 id="3-1-Definitions-of-Norms-in-Matrix"><a href="#3-1-Definitions-of-Norms-in-Matrix" class="headerlink" title="3.1 Definitions of Norms in Matrix"></a>3.1 Definitions of Norms in Matrix</h2><p>引入：在浮点数计算时，如果在处理 $||A\vec{x_0}-\vec{b}||$ 时，它距离 0 有多接近才能相信 $x_0$ 是解？</p>
<p>也就是说，如何衡量 $(A+\delta A)\vec{x}=\vec{b}+\delta\vec{b}$ 求解下 $\vec{x}$ 解的变换幅度？</p>
<p>我们再次引入向量的范数：$||\vec{x}||_p=(\sum\limits_{i=1}^nx_i^p)^{1/p}$；</p>
<blockquote>
<ul>
<li>注意到 $p\rightarrow\infty$ 是 $||\vec{x}||=\max\{|x_1|,|x_2|,\ldots,|x_n|\}$；</li>
<li>$||\vec{x}||=0\quad\text{iff}\quad \vec{x}=0$；</li>
<li>$||c\vec{x}||=|c|||\vec{x}||,\space c\in\mathbf{R},\vec{x}\in\mathbf{R^n}$；</li>
<li>$||\vec{x}+\vec{y}||\le||\vec{x}||+||\vec{y}||,\space\forall\vec{x},\vec{y}\in\mathbf{R}$；</li>
</ul>
</blockquote>
<p>我们定义两个范数等价（$||\cdot||_p\equiv||\cdot||_q$） 当且仅当 对于任意 $\vec{x}\in\mathbf{R^n}$，都存在 $c_{low}||\vec{x}||\le||\vec{x}||\le c_{high}||\vec{x}||$（同阶）；</p>
<blockquote>
<p>推论：$\mathbf{R^n}$ 上的任意范式等价；</p>
</blockquote>
<p>我们再定义矩阵的范数：</p>
<ul>
<li><p>定义方法 1，“unrolled construction”（元素形式范数，entrywise norm）：将矩阵 $A_{m\times n}$ 按列展开（第 $n+1$ 列排在第 $n$ 列下方），得到一个 $\vec{a}\in\mathbf{R^{mn}}$ 的向量，而向量 $\vec{a}$ 的范数就是 $A$ 的范数；</p>
<script type="math/tex; mode=display">
||A_{m\times n}||_p=(\sum\limits_{i=1}^m\sum\limits_{j=1}^n|a_{ij}|^p)^{1/p}</script><ul>
<li>二维元素形式范数又称 “Frobenius Norm”，记作 $||A||_{Fro}$；注意到 $||A||_F=\sqrt{\text{tr}(AA^T)}$；</li>
</ul>
</li>
<li><p>定义方法 2，“induced construction”（诱导范数，又称算子范数，operator norm）：描述了矩阵代表的线性变换 $A$ 对 $\vec{x}$ 作用最长伸展的比例。即：</p>
<script type="math/tex; mode=display">
||A||=\max_{\vec{x}\ne0}\dfrac{||A\vec{x}||}{||\vec{x}||}=\max\limits_{||\vec{x}||=1}||A\vec{x}||</script><p>诱导范数的常用结论如下：</p>
<ul>
<li><p>$||A||_1=\max\limits_{1\le j\le n}\sum\limits_{i=1}^m|a_{ij}|$（1-诱导范数就是一列中的元素模之和，再取最大值）；</p>
</li>
<li><p>$||A||_\infty=\max\limits_{1\le i\le m}\sum\limits_{j=1}^n|a_{ij}|$（$\infty$-诱导范数就是一行中的元素模之和，再取最大值）；</p>
</li>
<li><p>$||A||_2=\sqrt{\max\limits_{k}\lambda_k}$（2-诱导范数，又称谱范数，是 $A$ 的最大奇异值的开根号。也就是说，当 $A$ 不可逆时就是 $A^TA$ 的最大特征值开根号）；</p>
<blockquote>
<p>可以从图形方法理解：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="imgs2/matrix-norm2.png" width="400px"></p>
</blockquote>
</li>
</ul>
</li>
<li><p>定义方法 3，“eigenvalue construction”（schatten 范数，使用矩阵奇异值定义），具体定义较为复杂，不进一步了解；</p>
</li>
</ul>
<h2 id="3-2-Definition-of-Condition-Number-in-Matrix"><a href="#3-2-Definition-of-Condition-Number-in-Matrix" class="headerlink" title="3.2 Definition of Condition Number in Matrix"></a>3.2 Definition of Condition Number in Matrix</h2><p>我们还要定义一个矩阵的条件数。一般条件数想要看的是一个矩阵构成的线性方程组随误差的变化情况。于是我们需要构建建模一个公式：$(A+\varepsilon\delta A)\vec{x}(\varepsilon)=\vec{b}+\varepsilon\delta\vec{b}$，于是可以得到在误差 $\varepsilon$ 下，</p>
<ul>
<li><p>$\vec{x}(\varepsilon)$ 表示在误差 $\varepsilon$ 下的 $\vec{x}$ 测量值；</p>
</li>
<li><p>$\dfrac{d\vec{x}}{d\varepsilon}|_{\varepsilon=0}=A^{-1}(\delta\vec{b}-\delta A\vec{x}(0))$ 表示 $\vec{x}$ 随误差的变化率；</p>
</li>
<li><p>$||\vec{x}(\varepsilon)-\vec{x}(0)||$ 表示前向误差，$\dfrac{||\vec{x}(\varepsilon)-\vec{x}(0)||}{||\vec{x}(0)||}\le|\varepsilon|||A^{-1}||||A||(\dfrac{||\delta\vec{b}||}{||\vec{b}||}+\dfrac{||\delta A||}{||A||})+O(\varepsilon^2)$ 表示归一化的前向误差；</p>
<blockquote>
<p>泰勒展开证明上式；</p>
</blockquote>
</li>
<li><p>于是我们定义方阵 $A\in\mathbf{R^{n\times n}}$ 的条件数为：$\text{cond}\space A\equiv\kappa\equiv||A||||A^{-1}||$；</p>
<p>如果 $A$ <u>不可逆</u>，则条件数为 $\infty$；</p>
<blockquote>
<p>得出结论：$\dfrac{||\vec{x}(\varepsilon)-\vec{x}(0)||}{||\vec{x}(0)||}\le\varepsilon\cdot D\cdot\kappa+O(\varepsilon^2)$；</p>
</blockquote>
<p>可以知道，一个矩阵的条件数描述的性质和行列式不一样，条件数与常系数缩放无关；</p>
</li>
<li><p><strong>重要推论 1</strong>：$\text{cond}\space A=\dfrac{\max\limits_{\vec{x}\ne0}\frac{||A\vec{x}||}{||\vec{x}||}}{\min\limits_{\vec{y}\ne0}\frac{||A\vec{y}||}{||\vec{y}||}}$（可以使用诱导范数直接推得）；</p>
</li>
</ul>
<p>几何上这么理解：在 $A$ 代表的线性变换下，对任意 $\vec{x}$ 作用<u>伸长最长的比例 与 伸长最短的比例 之比</u>；</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="imgs2/matrix-cond.png" height="200px"></p>
<p>由这个几何关系，我们可以推出第二个推论：</p>
<ul>
<li><strong>重要推论 2</strong>：$||A^{-1}\vec{x}||\le||A^{-1}||||\vec{x}||$，因为 $||A^{-1}||$ 就是所有向量拉伸最长的比例了；</li>
</ul>
<blockquote>
<p>注：</p>
<ul>
<li>可以知道，一个矩阵的条件数越大，它所构成的线性方程组代表的线性系统对微小扰动越敏感的（解周围小范围变化自变量，总体值变化很大）；而一个矩阵的条件数越接近 1，则这个线性系统对微小扰动越不敏感；</li>
<li>由于很难求一个矩阵的逆，因此一般对条件数的讨论是讨论其上下界；</li>
</ul>
</blockquote>
<h1 id="Chapter-4-Column-Spaces-amp-QR"><a href="#Chapter-4-Column-Spaces-amp-QR" class="headerlink" title="Chapter 4. Column Spaces &amp; QR"></a>Chapter 4. Column Spaces &amp; QR</h1><p>考虑特殊矩阵的条件数 $\text{cond}\space A^TA\approx(\text{cond}\space A)^2$（在 $A$ 可逆的情况下）；</p>
<script type="math/tex; mode=display">
\begin{aligned}
\text{cond}\space A^TA&=||A^TA||\space||(A^TA)^{-1}||\\
&\approx||A^T||\space||A||\space||A^{-1}||\space||(A^T)^{-1}||\\
&=||A||^2||A^{-1}||^2\\
&=(\text{cond}\space A)^2
\end{aligned}</script><p>所以，我们对于一般的矩阵可以认为 $A^TA$ 越接近单位矩阵 $I_{n\times n}$，$A\vec{x}=\vec{b}$ 更容易解；</p>
<p>此外，$A^TA$ 的计算可以这么理解：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="imgs2/AtA.png" height="200px"></p>
<p>所以等价于我们希望 $A$ 是正交矩阵（各个列向量正交归一），而且<u>恰好正交矩阵代表的变换不改变向量的长度（所以正交矩阵的条件数是 1）</u>；</p>
<p>现在再回来看 $A^TA\vec{x}=A^T\vec{b}$，我们知道这个线性方程组的解就是 $\min\limits_{\vec{x}}||A\vec{x}-\vec{b}||$ 的解，就相当于将 $A$ 拆成列向量 $(\alpha_1,\alpha_2,\ldots,\alpha_n)$，将 $x_1\alpha_1+x_2\alpha_2+\cdots+x_n\alpha_n$ 逼近 $\vec{b}$（将 $\vec{b}$ 投影到 $A$ 列向量做基向量的线性空间上）；</p>
<blockquote>
<p>回忆线性代数的性质：</p>
<p>对任何实矩阵 $A\in\mathbf{R^{m\times n}}$ 和可逆方阵 $B\in\mathbf{R^{n\times n}}$，有 $\text{col}\space A=\text{col}\space AB$，即<u>对任意矩阵进行初等行变换不影响矩阵的列空间</u>；</p>
</blockquote>
<p>那么有没有办法对 $A$ 一直进行初等行变换，使得 $A$ 变成正交阵？这样 $A$ 的列空间不变（即原问题的解不变），但是 $A$ 成正交阵后非常好求解。</p>
<p>这种方法就是 QR 分解。我们将一般矩阵分解为一个正交阵（$A$ 的一组正交基）和上三角矩阵的乘积（上三角矩阵 $R$ 可以理解为一系列初等行变换）。</p>
<blockquote>
<p>显然，对于任意一个 $A$，若 $r(A_{m\times n})=n$（$m\ge n$），则 $A$ 都能进行 QR 分解。</p>
</blockquote>
<p>一旦我们将 $A^TA\vec{x}=A^T\vec{b}$ 进行 QR 分解：$A=QR$，那么 $\vec{x}=R^{-1}Q^T\vec{b}$，我们发现 $R$ 上三角矩阵容易求逆，就不需要计算 $A^TA$ 的逆了。</p>
<p>现在，QR 分解有 2 种方法。</p>
<ul>
<li><p>一种是通过 施密特正交化。这很好理解：</p>
<p><strong>现在回忆线性代数的 施密特正交化。这就是得到 $A=QR$ 的一种方法：</strong></p>
<ol>
<li>先对 $A$ 施密特正交化，再归一化就能得到基向量相同的正交矩阵 $Q$；</li>
<li>反解出 $R$：因为正交矩阵 $Q^TQ=I$，因此 $R=Q^TA$；</li>
</ol>
<blockquote>
<p>那么怎么 Gram-Schmidt 正交化？</p>
<p>对 $A$ 拆成的一组基 $(\alpha_1,\alpha_2,\ldots,\alpha_n)$，可以这么取正交基：</p>
<ul>
<li>$v_1=\alpha_1$，第一个向量随便取；</li>
<li>$v_2=\alpha_2-\dfrac{\alpha_2\cdot v_1}{v_1\cdot v_1}v_1$，第二个向量取 $\alpha_2$ 的时候，需要剔除第一个取得的基向量相关方向的分量：$\dfrac{\alpha_2\cdot v_1}{v_1\cdot v_1}$ 就是 $\alpha_2$ 在 $v_1$ 上的<u>投影长度</u>！</li>
<li>$v_3=\alpha_3-\dfrac{\alpha_3\cdot v_2}{v_2\cdot v_2}v_2-\dfrac{\alpha_3\cdot v_1}{v_1\cdot v_1}v_1$，第三个向量就减去 $\alpha_3$ 在 $v_1,v_2$ 上的投影分量就行。</li>
<li>……（依此类推）</li>
</ul>
<p>最后别忘了归一化。</p>
<p>不难发现，这种操作实际上在不断地对 $A$ 右乘上三角矩阵 $R_i$（进行初等列变换），使得：$AR_1R_2\cdots R_n=Q$；</p>
<p>相对地，下面的 Householder 变换方法，就是不断地进行正交变换（特别地，镜像变换），调整某一列的其他元素为 0，即不断地对 $A$ 左乘 Householder 矩阵（一种正交阵）$H_i$，使得：$H_nH_{n-1}\cdots H_1=R$；</p>
</blockquote>
</li>
<li><p>另一种是通过 Householder 变换（这是一个著名的变换，它代表了镜像变换，显然是一种正交变换），它所对应的矩阵就是 Householder 矩阵。</p>
<p>如图：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="imgs2/householder.png" width="300px"></p>
<p>假设已知一个向量 $\eta$，想要关于某个法线方向 $l$ 对称。为了方便，我们记与 $l$ 正交的一个从 $\eta$ 一边指向另一边的<u>单位向量</u>为 $\omega$，则由几何关系可知对称后的向量 $\xi$ 满足：$\xi-\eta=2\omega(\omega^T\xi)$，其中 $\omega^T\xi$ 就是 $\omega$ 和 $\xi$ 的点积（投影长度）；</p>
<p>因此 $\eta=(I-2\omega\omega^T)\xi$，我们发现，这镜面变换的矩阵就是 $H=I-2\omega\omega^T$，左乘它会将列向量变换到 $\omega$ 对应法线的 $\omega$ 指向的另一侧。</p>
<p>紧接着，我们发现这个矩阵 $H$ 有这个性质：</p>
<p>若 $H$ 为 Householder 矩阵，则 $\left[\begin{matrix}I_r&amp;0\\0&amp;H\end{matrix}\right]$ 也是 Householder 矩阵；</p>
<p>于是我们可以这么进行迭代：</p>
<ul>
<li><p>写 $A$ 的基向量 $(\alpha_1,\alpha_2,\ldots,\alpha_n)$，做第一次 householder 变换，使得 $\omega_1=\dfrac{\alpha_1-||\alpha_1||_2\cdot e_1}{||\alpha_1-||\alpha_1||_2\cdot e_1||_2}$，得到第一个 householder 矩阵 $H_1=I-2\omega_1\omega_1^T$，这样 $H_1A$ 的第一列除了第一个元素全部归 0：</p>
<blockquote>
<p>$\omega_1$ 可以理解为 $\alpha_1$ 减去在 $e_1$ 的分量（要镜像的方向已经得到了），再归一化，得到单位的镜像向量；</p>
<p><strong>$H_1\alpha_1$ 的变换就将 $\alpha_1$ 变换到与 $e_1$ 同一个方向上了。</strong></p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="imgs2/householder-step1.png" width="500px"></p>
</li>
<li><p>记 $H_1A$ （注意是变换后的矩阵）关于 $a_{11}$ 的余子式为 $B_1$，则写 $B$ 的基向量 $(\beta_1,\beta_2,\ldots,\beta_{n-1})$，那么同理 $\omega_2=\dfrac{\beta_2-||\beta_2||_2\cdot e_1}{||\beta_2-||\beta_2||_2\cdot e_1||_2}$，得到第二个 householder 矩阵 $H_2=I-2\omega_2\omega_2^T$，这样 $H_2H_1A$ 的第一列和 $H_1A$ 一样、第二列除了前两个元素，后面的元素全部归 0:</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="imgs2/householder-step2.png" width="400px"></p>
<blockquote>
<p>注意，$e_1$ 总是第一个元素为 1、其他元素为 0 的单位向量；</p>
</blockquote>
</li>
<li><p>重复上面的操作，最后 $H_{n-1}H_{n-2}\cdots H_1A=R$，$R$ 是一个上三角矩阵：</p>
</li>
<li><p>这样，我们得到了 $A$ 分解出的 $R$，最后反代 $Q=H_1H_2\cdots H_{n-1}$（注意正交阵的性质）；</p>
</li>
</ul>
</li>
</ul>
<h1 id="Chapter-5-Eigenvalue-amp-Eigenvector"><a href="#Chapter-5-Eigenvalue-amp-Eigenvector" class="headerlink" title="Chapter 5. Eigenvalue &amp; Eigenvector"></a>Chapter 5. Eigenvalue &amp; Eigenvector</h1><h2 id="5-1-Overview"><a href="#5-1-Overview" class="headerlink" title="5.1 Overview"></a>5.1 Overview</h2><p>在采集多维数据时，需要考虑各个维度间的相关性，以降低数据的维度。</p>
<p>举个例子，假设有组（该组有 $m$ 个数据） $n$ 维数据 $(v_1,v_2,\ldots,v_m),\space v_i\in\mathbf{R^n}$。</p>
<p>如果我们只知道某些维度上的确切数据，于是我们就像想将任意一个 $n$ 维数据用某几个维度去拟合整体数据。这样可以非常方便地讨论数据的整体特性。</p>
<p>这样，数据矩阵的特征值就能派上用场了。</p>
<p>除了这个问题，还有其他一些问题可以借助特征值进行解决，例如：</p>
<ul>
<li>Optimize $||A\vec{x}||_2$，固定 $||\vec{x}||_2=1$；</li>
<li>ODE/PDE（常微分方程、偏微分方程）的近似解：$\vec{y}^\prime=B\vec{y}$；</li>
<li>Rayleigh quotient（瑞利商）：$\dfrac{\vec{x}^TA\vec{x}}{||\vec{x}||_2^2}$；</li>
</ul>
<p>回忆下线性代数中对于特征向量/特征值的重要结论：</p>
<ul>
<li>每个 $n$ 阶方阵至少有一个特征向量（复向量），最多有 $n$ 个不同的特征值；</li>
<li>对应不同特征值的特征向量是线性无关的；</li>
</ul>
<h2 id="5-2-Review-Diagonalizable-Matrix"><a href="#5-2-Review-Diagonalizable-Matrix" class="headerlink" title="5.2 Review: Diagonalizable Matrix"></a>5.2 Review: Diagonalizable Matrix</h2><p>这里再复习一下矩阵对角化的知识：</p>
<p><strong>矩阵对角化的意义？</strong></p>
<ul>
<li><p>可快速计算 $A^k$；</p>
</li>
<li><p>可计算 Markov 过程中的平稳分布 $\pi$；</p>
</li>
<li>可计算差分方程 $u_{k+1}=Au_k$ 描述的离散动力系统的长期行为；</li>
<li>……</li>
</ul>
<p><strong>矩阵对角化的方法？</strong></p>
<ol>
<li><p>求出矩阵 $A$ 的所有特征值 $\lambda_i$；</p>
</li>
<li><p>通过 $A$ 的每个特征值，以及特征值的代数重数，来判断 $A$ 是否可对角化。具体来说：</p>
<p>代数重数就是在判断特征值重复的次数、几何重数就是在描述特征向量重复的维数（就是零空间的维数）。注意<u>每个特征值的几何重数一定小于等于代数重数</u>（因为对应不同特征值的特征向量是线性无关的，而特征值可以重复）。</p>
<p>这里 $A$ 要可对角化，就必须满足下面两种情况之一：</p>
<ul>
<li><strong>$A$ 的所有 $n$ 个特征值互不相等（代数重数 $n$）</strong>。而由于对于不同特征值的特征向量必然线性无关，所以几何重数一定也为 $n$；</li>
<li><strong>$A$ 所有重根下，$k$ 重特征值是否有 $k$ 个线性无关的特征向量</strong>。这里就是在要求这个代数重数为 $k$ 的特征值的几何重数是不是也是 $k$；</li>
</ul>
<p>所以上面的两个要求总体在说：$A$ 的<u><strong>几何重数和代数重数是否相等</strong></u>？</p>
<p>如果相等，表示 $A$ 所代表的线性变换没有改变被变换方的维度，因此 $A$ 可以分解为 $n$ 个线性无关的正交基向量。也就是可以相似对角化。如果不满足，则无法相似对角化。</p>
</li>
<li><p>最后将特征向量与特征值对应起来：$\Lambda=\text{diag}(\lambda_1,\lambda_2,\ldots,\lambda_n)$，$P=(\alpha_1,\alpha_2,\ldots,\alpha_n)$，则 $P^{-1}AP=\Lambda$；</p>
</li>
</ol>
<h2 id="5-3-Definition-of-Spectrum-Radius-in-Matrix"><a href="#5-3-Definition-of-Spectrum-Radius-in-Matrix" class="headerlink" title="5.3 Definition of Spectrum Radius in Matrix"></a>5.3 Definition of Spectrum Radius in Matrix</h2><p>引入一个新的定义：矩阵的谱半径（或称 “矩阵的谱”）。</p>
<p><strong>谱半径的意义？</strong></p>
<ul>
<li>估计一个矩阵的特征值；</li>
<li>计算一个不可逆矩阵的广义逆矩阵；</li>
<li>……</li>
</ul>
<p><strong>谱半径的计算？</strong></p>
<p>$\rho(A)=\max\limits_i|\lambda_i|$（矩阵 $A$ 的谱半径等于其<u>所有特征值的模的最大值</u>。<strong>注意特征值包含复数！</strong>）；</p>
<p><strong>谱半径和范数的关系？</strong></p>
<p>谱半径和矩阵范数一样，都是矩阵的函数：$f:R^{m\times n}\rightarrow R$；</p>
<p>但是它们二者本质上真的不一样，一定要和 2-诱导范数（也就是谱范数）区分开。</p>
<p>二者间有一些重要结论：</p>
<ul>
<li><p>任意复数域上的矩阵 $A$，其谱半径 $\rho(A)$ 不大于 $A$ 的任何一种诱导范数，即：$\rho(A)\le||A||$；</p>
<blockquote>
<p>含义：<u>矩阵的谱半径是其任意一种范数的下界</u>；</p>
<p>作用：使用方便求解的范数对谱半径进行估算；</p>
</blockquote>
</li>
<li><p><code>Gelfand</code> 定理：$\rho(A)=\lim\limits_{k\rightarrow\infty}||A^k||^{1/k}$；</p>
<ul>
<li>矩阵序列 $I,A,A^2,\ldots,A^k,\ldots$ 收敛于 0 的充要条件：$\rho(A)\lt1$；</li>
<li>级数 $I+A+A^2+\cdots$ 收敛于 $(I-A)^{-1}$ 的充要条件：$\rho(A)\lt1$；</li>
</ul>
</li>
</ul>
<h2 id="5-4-Extend-to-mathbf-C-m-times-n"><a href="#5-4-Extend-to-mathbf-C-m-times-n" class="headerlink" title="5.4 Extend to $\mathbf{C^{m\times n}}$"></a>5.4 Extend to $\mathbf{C^{m\times n}}$</h2><p>现在将线性空间扩展到复数域，我们多出如下定义：</p>
<ul>
<li><p>共轭转置 $A^H$；</p>
</li>
<li><p>厄密矩阵（Hermitian Matrix）：$A^H=A$；</p>
<blockquote>
<p>注意和实对称矩阵不一样。</p>
<p>由量子力学的厄密算符可以得到如下所有结论（量子力学考题）：</p>
<ul>
<li>厄密矩阵所有特征值为实数；</li>
<li>厄密矩阵属于不同特征值的特征向量相互正交；</li>
<li>……</li>
</ul>
</blockquote>
<p>厄密矩阵因为是复数域上，和实数域上的实对称矩阵很相似（不如说实对称矩阵是厄密矩阵的特殊情况），所以厄密矩阵和实对称矩阵一样，二者一定可以相似对角化（几何重数一定等于代数重数，或者说一定有 $n$ 个线性无关的基向量）；</p>
<p>它们相似对角化很简单：$A=X^{-1}\Lambda X=X^T\Lambda X$（显然 $X$ 是正交矩阵）；</p>
</li>
</ul>
<p>再引入一些 “奇怪” 的运算：</p>
<p>对于一个 半正定/正定 的对称矩阵 $A\in S_{+}$，定义其平方根：$A^{1/2}$，因为一定能找到 $P$ 使得 $P^2=A$；</p>
<h2 id="5-5-Application-Use-Matrices-to-Solve-Problems"><a href="#5-5-Application-Use-Matrices-to-Solve-Problems" class="headerlink" title="5.5 Application: Use Matrices to Solve Problems"></a>5.5 Application: Use Matrices to Solve Problems</h2><ul>
<li><p>例如 $\vec{y}^\prime=\lambda\vec{y}$，可以看成一个求导变换 $D\vec{y}=\lambda\vec{y}$，求 $D$ 的特征向量就是 $\vec{y}$ 的解；</p>
</li>
<li><p>照片曝光的例子：数据集中有 $n$ 个数据，$\omega_{ij}\ge0$ 表示第 $i$ 和 $j$ 数据集之间的某个指标的相似性，$\omega_{ij}=\omega_{ji}$；我们想将这些数据集以这个指标 $x_i$ 衡量起来，要求相似性越高的数据，$x_i$ 的值也应该相近；</p>
<p>为了完成这个任务，可以定义一个目标函数 $\sum\limits_{ij}\omega_{ij}(x_i-x_j)^2$，对它最小化优化就行。</p>
<p>但是需要一些限制条件，防止 $x_i\equiv const$ 无意义的情况，例如 2-范数为 1 $||\vec{x}||_2^2=1$（归一化）、$\vec{1}\cdot\vec{x}=0$（指标 $x_i$ 均值为 0，方便统计）；</p>
<p>所以目标函数可以简化为：$2x^T(A-W)x$，其中 $W=(\omega_{ij})_{n\times n}$；找到 $A-W$ 的第二小特征值（最小特征值是 0，已经被限制条件排除了）对应的特征向量就是解。</p>
</li>
</ul>
<ul>
<li>计算 $A^k$：</li>
</ul>
<p>对一个实对称阵 $A$，假设其特征值 $\lambda_1,\ldots,\lambda_n$ 从大到小排列（$\lambda_{i+1}\ge\lambda_{i}$），那么它由实对称阵特征向量的完备性，我们可以用 $A$ 特征向量 $(x_1,\ldots,x_n)$ 来表示任意 $n$ 维向量：$A\vec{v}=c_1A\vec{x_1}+\cdots+c_nA\vec{x_n}=c_1\lambda_1\vec{x_1}+\cdots+c_n\lambda_n\vec{x_n}$（和量子力学将力学量使用它对应的算符的本征函数展开是一样的）；</p>
<p>因此我们发现，$A^k$ 对 $\vec{v}$ 作用的效果就取决于最大的特征值及其特征向量了：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="imgs2/spec.png" width="500px"></p>
<p>$A^k\vec{v}\approx c_1\lambda_1^k\vec{x_1},\space\text{assume that}\space c_1\ne0,\lambda_1\gt\lambda_2$（$k$ 要求足够大）；</p>
<blockquote>
<p>问题是，如果 $|\lambda_1|\gt1$ 时，$A^k\vec{v}\rightarrow\infty$，所以每次迭代都做一次归一化即可：</p>
<p>$\vec{\omega_k}=A\vec{v_{k-1}},\space\text{ where }\vec{\omega_{k}}=\dfrac{\vec{v_{k-1}}}{||\vec{v_{k-1}}||}$；</p>
<p>所以通过这个 power iteration 方法我们就能估计出 $A$ 的最大特征值；</p>
</blockquote>
<p>又注意到 $A$ 特征值的倒数，<strong>正好是</strong> $A^{-1}$ 对应的特征值：$A\vec{v}=\lambda\vec{v}\Rightarrow A^{-1}\vec{v}=\dfrac{1}{\lambda}\vec{v}$；</p>
<p>那么对 $A^{-1}$ 进行 power iteration，就能得到 $A$ 的最小特征值。</p>
<blockquote>
<p>$A^{-1}$ 的 power iteration 可以借助 $LU$ 分解加速。</p>
</blockquote>
<p>另外，由于正确结果收敛较慢，因此我们可以使用 “shifted inverse iteration”：</p>
<p>$A\vec{v}=\lambda\vec{v}\Rightarrow(A-\sigma I)\vec{v}=(\lambda-\sigma)\vec{v}$，可以得到如下的迭代过程（猜测 $\sigma_k\approx\lambda_k$）：</p>
<script type="math/tex; mode=display">
\vec{\omega_k}=(A-\sigma_k I)^{-1}\vec{v_{k-1}},\space\vec{v_k}=\dfrac{\vec{\omega_k}}{||\vec{\omega_k}||},\space \sigma_{k+1}=\dfrac{\vec{v_{k}}^TA\vec{v_k}}{||\vec{v_k}||_2^2}</script><h2 id="5-6-Similarity-Transformations"><a href="#5-6-Similarity-Transformations" class="headerlink" title="5.6 Similarity Transformations"></a>5.6 Similarity Transformations</h2><ul>
<li><p>借助 QR 分解进行相似变换：$A=QR$，则 $Q^{-1}AQ=RQ$，所以可以迭代：$A_{k+1}=R_kQ_k,\space A_k=Q_kR_k$；</p>
<p>好的结论：$A_\infty=Q_\infty R_\infty=R_\infty Q_\infty$；</p>
</li>
</ul>
<h2 id="5-7-SVD-Singular-Value-Decomposition"><a href="#5-7-SVD-Singular-Value-Decomposition" class="headerlink" title="5.7 SVD (Singular Value Decomposition)"></a>5.7 SVD (Singular Value Decomposition)</h2><p>回忆一个矩阵的诱导范数：</p>
<script type="math/tex; mode=display">
||A||=\max_{\vec{x}\ne0}\dfrac{||A\vec{x}||}{||\vec{x}||}=\max\limits_{||\vec{x}||=1}||A\vec{x}||</script><p>注意到 $||\vec{v}||=1$ 时，$||A||^2=||A\vec{v}||^2=\vec{v}A^TA\vec{v}$，因此只需要</p>
<p>特征值只有方阵才能讨论。有没有一种研究矩阵更普遍特征性质的分解呢？它就是奇异值分解。</p>
<p>可以证明，任何矩阵可以分解为：$A=U\Sigma V^{-1}$，其中 $U,V$ 为正交矩阵，$\Sigma$ 为对角矩阵（可以不是方阵）；</p>
<p>在物理上 $U,V$ 表示旋转变换（rotation），$\Sigma$ 表示伸缩变换（scale）；</p>
<p>那么 $U$、$V$ 代表什么？</p>
<p>我们发现：$A^TA=V(\Sigma^T\Sigma)V^T$，显然 $\Sigma^T\Sigma$ 是个对角方阵。而 $A^TA$ 有很好的性质：它是半正定、对称矩阵。</p>
<p>因此我们惊喜地发现，这就相当于对 $A^TA$ 完成了相似对角化。$\Sigma^T\Sigma$ 对角元存放的是 $A^TA$ 的特征值，$V$ 的列存放的是 $A^TA$ 对应的特征向量；</p>
<p>同理，$AA^T=U(\Sigma^T\Sigma)U^T$，所以，我们得出以下结论：</p>
<ul>
<li>$U$ 和 $V$ 分别是 $AA^T$ 和 $A^TA$ 的归一化特征向量组成的正定矩阵；</li>
<li>$U$ 和 $V$ 特征值<u>按序相同</u>（从大到小排列），对于实矩阵而言都大于等于 0；</li>
</ul>
<p>SVD 分解还可以写成一系列 $U,V$ 向量的外积线性组合：$A=\sum\sigma_i\vec{u_i}\vec{v_i}^T$；</p>
<p>SVD 可以有哪些用处？比如定义一个一般矩阵的 “伪逆”（pseudo inversion）：</p>
<script type="math/tex; mode=display">
A^{+}=V\Sigma^{+}U^T</script><p>注意，对不一定为方阵的对角阵的伪逆：$\Sigma^{+}$ 就是将 $\Sigma$ 对角元的元素求倒数，放在对角位置，并且转置矩阵的长宽。</p>
<p>伪逆有一些很好的性质：</p>
<ul>
<li>当 $A$ 为可逆方阵时，$A^+=A^{-1}$；</li>
<li>当 $A$ 的行秩大于列秩时（overdetermined），$A^+\vec{b}$ 给出了最小二乘结果；</li>
<li>当 $A$ 的列秩大于行秩时（underdetermined），$A^+\vec{b}$ 给出了 $A\vec{x}\approx\vec{b}$ 的最小二乘结果；</li>
</ul>
<h3 id="5-7-1-Application-Orthogonal-Procrustes-Theorem"><a href="#5-7-1-Application-Orthogonal-Procrustes-Theorem" class="headerlink" title="5.7.1 Application: Orthogonal Procrustes Theorem"></a>5.7.1 Application: Orthogonal Procrustes Theorem</h3><p>考虑一个问题：将一组向量 $A$ 通过正交变换的方式映射到新的一组向量 $QA$，让这组新的向量与给定的一组向量 $B$ 的差异尽可能的小（使用 Frobenius 范数衡量）。这在图像处理领域比较常用。</p>
<p>用数学方法表达就是，求正交阵：$\hat{Q}=\arg\min\{||QA-B||_{F}\}$（易知，$A,B$ 规模相同）；</p>
<p>由于 Frobenius 范数可以表达为 $||C||_F=\sqrt{\mathrm{tr}(C^TC)}$，故上式可计算：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\hat{Q}&=\arg\min\{\mathrm{tr}((QA-B)^T(QA-B))\}\\
&=\arg\min\{\mathrm{tr}(((QA)^T-B^T)(QA-B))\}\\
&=\arg\min\{\mathrm{tr}((A^TQ^T-B^T)(QA-B))\}\\
&=\arg\min\{\mathrm{tr}(A^TQ^TQA-BA^TQ^T-B^TQA+B^TB)\}\\
&=\arg\min\{\mathrm{tr}(A^TA+B^TB-A^TQ^TB-(A^TQ^TB)^T)\}\\
&=\arg\min\{\mathrm{tr}(A^TA)+\mathrm{tr}(B^TB)-2\mathrm{tr}(A^TQ^TB)\}\\
\end{aligned}</script><p>注意到前两项在确定问题时就已知，所以最小化问题直接转换为最大化问题：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\hat{Q}&=\arg\max\{\mathrm{tr}(A^TQ^TB)\}\\
&=\arg\max\{\mathrm{tr}(Q^TBA^T)\}\\
\end{aligned}</script><p>（注意 $\mathrm{tr}(PQ)=\mathrm{tr}(QP)$）</p>
<p>下面利用 SVD 分解做一个巧妙变换（假设 $BA^T=U\Sigma V^T$）：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\hat{Q}&=\arg\max\{\mathrm{tr}(Q^TBA^T)\}\\
&=\arg\max\{\mathrm{tr}(Q^TU\Sigma V^T)\}\\
&=\arg\max\{\mathrm{tr}(V^TQ^TU\Sigma)\}\\
\end{aligned}</script><p>这样 $V,Q,U$ 都是正交阵，所以 $V^TQ^TU$ 也是正交阵。</p>
<p>可以简单地证明，$\mathrm{tr}(QA)$ 最大（$Q$ 正交阵）时，$Q=I$；</p>
<p>此时 $\hat{Q}^T=VU^T$，$\hat{Q}=UV^T$；</p>
<p>所以这里我们利用 SVD 解出了正交普鲁克定理：</p>
<p>当 $Q=UV^T$（其中 $BA^T=U\Sigma V^T$）时，$||QA-B||_F$ 有最小值。</p>
<h3 id="5-7-2-Application-Principal-Component-Analysis-PCA"><a href="#5-7-2-Application-Principal-Component-Analysis-PCA" class="headerlink" title="5.7.2 Application: Principal Component Analysis (PCA)"></a>5.7.2 Application: Principal Component Analysis (PCA)</h3><p>再考虑一个问题，对于相当大的一个数据集，它包含很多维度，我们基于以下目的需要降维：</p>
<ul>
<li>使得数据集更易使用；</li>
<li>降低算法的计算开销；</li>
<li>去除噪声；</li>
<li>使得结果容易理解；</li>
</ul>
<p>有一种降维方法就是主成分分析方法（PCA），其主要思想是将 $n$ 维特征映射到 $k$ 维上，这k维是全新的正交特征也被称为主成分，是在原有 $n$ 维特征的基础上重新构造出来的 $k$ 维特征；</p>
<p>可以证明：</p>
<p>最小化 $||X-CC^TX||_F$（其中 $C\in\mathbf{R^{n\times k}}$，$C^TC=I_{k\times k}$，$C$ 是 $U$ 的前 $k$ 列向量，$X=U\Sigma V^T$）取得的 $C$ 就是 $X$ 的主成分。</p>
<h1 id="Chapter-6-Non-linear-System"><a href="#Chapter-6-Non-linear-System" class="headerlink" title="Chapter 6. Non-linear System"></a>Chapter 6. Non-linear System</h1><h2 id="6-1-Root-Finding"><a href="#6-1-Root-Finding" class="headerlink" title="6.1 Root Finding"></a>6.1 Root Finding</h2><p>作出一些假设：</p>
<ul>
<li><p>连续性；</p>
<blockquote>
<p>连续函数满足的定理：中值定理；</p>
</blockquote>
</li>
<li><p>Lipschitz 特性：绝对值增长速率不快于一阶线性函数；</p>
</li>
<li><p>$k$ 阶导存在且连续；</p>
</li>
</ul>
<p><strong><u>方法一：二分法（bisection）</u></strong>，利用中值定理锁定根的区间（高中内容），直到根的区间小于一定范围就停止迭代。</p>
<ul>
<li><p>优点：无条件收敛（unconditionally converge）；</p>
<blockquote>
<p>收敛速度？指数速度减小。</p>
<p>$|x-x^*|\lt E_k$，其中 $E_k$ 为第 $k$ 轮迭代时的区间宽度（$E_k\le\dfrac{1}{2}E_{k-1},\space E_k=|r_k-l_k|$）；</p>
</blockquote>
</li>
<li><p>缺点：对函数性质要求严格。</p>
</li>
</ul>
<p><strong><u>方法二：不动点法（fixed point）</u></strong>，通过迭代求解 $g(x^<em>)=x^</em>$ 来得到 $f(x)=g(x)-x$ 的零点。</p>
<p>怎么迭代？方法比较多，但是常用的是最简单的策略：</p>
<p>simple strategy：将 $g(x_{k-1})$ 作为下一轮迭代的 $x_k$ 的值，直至 $|g(x_k)-x_k|$ 小于一定范围；</p>
<ul>
<li><p>优点：计算简单；</p>
</li>
<li><p>缺点：$g$ 必须满足 Lipschitz 特性，或者在根 $x^*$ 及迭代范围附近满足 Lipschitz 局部特性，否则迭代发散。</p>
<blockquote>
<p>对于满足 Lipschitz 特性的情况，$E_k\le cE_{k-1}$（linear）；</p>
<p>对于其他一般情况：$E_k=|x_k-x^<em>|=|g(x_{k-1})-g(x^</em>)|\le\dfrac{1}{2}(|g^{\prime\prime}(x^*)|+\varepsilon)E_{k-1}^2$（quadratic）； </p>
</blockquote>
</li>
</ul>
<p><strong><u>方法三：牛顿法（Newton’s method）</u></strong>，这个方法作出了一个假设，认为函数在零点附近近似线性，可以给出一个猜测值 $x_0$，求该点处切线 $l_0$，取得 $l_0$ 与 x 轴交点为 “更接近零点的点” $x_1$，重复迭代直至稳定。</p>
<script type="math/tex; mode=display">
x_{k+1}=x_k-\dfrac{f(x_k)}{f^\prime(x_k)}</script><p>可以看作求 $g(x)=x-\dfrac{f(x_k)}{f^\prime(x_k)}$ 的不动点。</p>
<ul>
<li>优点：在简单情况下收敛很快；</li>
<li>缺点：<ol>
<li>$g$ 需要满足局部 Lipschitz 特性，否则不收敛（收敛速度和不动点法同理）；</li>
<li>$f^\prime(x^*)\ne0$，否则永远无法得到正确解；</li>
<li>某些函数难以求导数。</li>
</ol>
</li>
</ul>
<p><strong><u>方法四：割线法（secant method）</u></strong>，利用两相近点间的割线近似为切线的思想（$f^\prime(x)\approx\dfrac{f(x_1)-f(x_2)}{x_1-x_2},\space |x_1-x_2|\rightarrow0$），可以借助两次猜测的点的连线（割线）视作切线：$f^\prime(x_k)\approx\dfrac{f(x_k)-f(x_{k-1})}{x_k-x_{k-1}}$，结合牛顿法解决：</p>
<script type="math/tex; mode=display">
x_{k+1}=x_k-\dfrac{f(x_k)}{f^\prime(x_k)}\approx x_k-\dfrac{f(x_k)(x_k-x_{k-1})}{f(x_k)-f(x_{k-1})}</script><ul>
<li>优点：计算稍微简单一点；</li>
<li>缺点：和牛顿法一样存在收敛问题。</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blog.sjtuxhw.top">SJTU-XHW</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.sjtuxhw.top/review/numeric-analysis/">https://blog.sjtuxhw.top/review/numeric-analysis/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://blog.sjtuxhw.top" target="_blank">SJTU-XHW's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Math/">Math</a></div><div class="post-share"><div class="social-share" data-image="https://cdn.sjtuxhw.top/cover_imgs/numeric-analysis.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat_pay.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/wechat_pay.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/review/convex-opt/" title="Convex &amp; Optimizations"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.sjtuxhw.top/cover_imgs/convex.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Convex & Optimizations</div></div><div class="info-2"><div class="info-item-1">Chapter 1. Overview进入本章前复习基础的数学知识：  Vector Norms（范数）：对于向量 $x=(x_1,x_2,\ldots,x_n)$，$l_p$-norm 定义为：  ||x||_p={}^p\sqrt{|x|_1^p+|x|_2^p+\cdots+|x|_n^p}正定性：$||x||_p\ge0,\space||x||_p=0\space\iff x=0$； 非线性性：$||tx||=|t|\space||x||,\space t\in\mathbf{R}$，$||x+y||\le||x||+||y||$（这个不等式并不好证。好证的三角不等式仅限于范数为 2 的特殊情况）；  正交阵 $A^TA=I$，因此一定满秩。此外正交阵列向量（或行）一定是相互正交的向量组，且模长为 1（单位正交向量，否则 $A^TA$ 就不是单位向量了）。 正交阵可以进行对角化 $A=P^{-1}BP$（$B$ 为对角阵，$P$ 为满秩矩阵）。所谓对角化可以感性理解为将这些正交向量组移动到与给定坐标轴的单位向量方向一致的方向上。 正交变换非常好的性质是...</div></div></div></a><a class="pagination-related" href="/technical/rabbit-mq/" title="Introduction to Rabbit MQ"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.sjtuxhw.top/cover_imgs/rabbit.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Introduction to Rabbit MQ</div></div><div class="info-2"><div class="info-item-1">Chapter 0. 背景0.1 同步消息和异步消息微服务架构下存在很多服务间相互调用的情况。 我们知道可以通过 OpenFeign 的方式来获取远程服务的响应，但是 OpenFeign 的远程调用是同步的，其优点是同步调用时效强，等待结果返回。但同时会导致：  代码可扩展性差。 性能堪忧。相较于相同项目实现的单体架构，同步的微服务调用方式会多出网络等待时间。  于是我们需要异步调用的方式，这里使用到了发布-订阅者模式。 异步调用的优势是，  模块间进一步解耦（发布者和订阅者间无需知道相互之间的信息）； 可拓展性强（scalable），添加实例无需更改代码； 异步性能有明显提升； 故障隔离（最终一致性保证）； 缓存消息，实现流量削峰填谷；  但是缺点也很明显：  异步实现无法立即得到结果，时效性差，可能导致数据不一致性； 不作额外措施，则不能保证最终一致性（下游业务是否成功）。所以业务安全依赖于 broker 的可靠性；  0.2 Message Queue...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/review/convex-opt/" title="Convex &amp; Optimizations"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.sjtuxhw.top/cover_imgs/convex.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-15</div><div class="info-item-2">Convex &amp; Optimizations</div></div><div class="info-2"><div class="info-item-1">Chapter 1. Overview进入本章前复习基础的数学知识：  Vector Norms（范数）：对于向量 $x=(x_1,x_2,\ldots,x_n)$，$l_p$-norm 定义为：  ||x||_p={}^p\sqrt{|x|_1^p+|x|_2^p+\cdots+|x|_n^p}正定性：$||x||_p\ge0,\space||x||_p=0\space\iff x=0$； 非线性性：$||tx||=|t|\space||x||,\space t\in\mathbf{R}$，$||x+y||\le||x||+||y||$（这个不等式并不好证。好证的三角不等式仅限于范数为 2 的特殊情况）；  正交阵 $A^TA=I$，因此一定满秩。此外正交阵列向量（或行）一定是相互正交的向量组，且模长为 1（单位正交向量，否则 $A^TA$ 就不是单位向量了）。 正交阵可以进行对角化 $A=P^{-1}BP$（$B$ 为对角阵，$P$ 为满秩矩阵）。所谓对角化可以感性理解为将这些正交向量组移动到与给定坐标轴的单位向量方向一致的方向上。 正交变换非常好的性质是...</div></div></div></a><a class="pagination-related" href="/technical/matlab-review/" title="Matlab 复习"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.sjtuxhw.top/cover_imgs/matlab.jpeg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-18</div><div class="info-item-2">Matlab 复习</div></div><div class="info-2"><div class="info-item-1">Written by SJTU_XHW Version: Matlab R2020b References: MATLAB Documentation (mathworks.com)   Chapter0 Matlab is a 1-index languageChapter1 Basic Operations1.1 operators: numerical { +-*/^() } ；logical { ~ || &amp;&amp; &gt; &lt; ==（按位运算须函数） }；1.2 variables: do not need to be declaed before assignment (类似Python)1.3 numeric variable type：logical、char、numeric、cell、struct、scalar1.4 constants：ans，i/j，Inf，eps（2.2204e-016），NaN，pi1.5 keywords：iskeyword1.6 calling priority local variable $\gt$...</div></div></div></a><a class="pagination-related" href="/technical/python-sci-starter/" title="Python 科学计算入门"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.sjtuxhw.top/cover_imgs/python_sci.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-11-03</div><div class="info-item-2">Python 科学计算入门</div></div><div class="info-2"><div class="info-item-1">0.1 NumPyNumpy 库是 Python 科学计算的核心。 Numpy Array 是一个存放相同数据类型的数组（类型 numpy.ndarray），可以使用非负元组（Non-negative tuple）来索引。 我们称 Rank 为数组的维数，Shape 表示数组的各个维度的大小，使用整型元组表示。 0.1.1 Array Creation初始化 Numpy Array 的方法如下： 1234567891011121314151617import numpy as npa = np.array([1, 2, 3])print(type(a))print(a.shape)print(a[0], a[1], a[2])# Reference Modificationa[0] = 5print(a)b = np.array(    [[1, 2, 3],     [4, 5, 6]])print(b.shape)print(len(b))print(b[0, 0], b[1, 0], b[0, 1]) 类似...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/favicon.ico" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">SJTU-XHW</div><div class="author-info-description">A blog to document learning and life</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">50</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">63</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/SSRVodka"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/SSRVodka" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:sjtuxhw12345@sjtu.edu.cn" rel="external nofollow noreferrer" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="https://blog.sjtuxhw.top/atom.xml" target="_blank" title="RSS"><i class="fas fa-rss" style="color: #a200ff;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Thanks for visiting! |•'-'•) ✧</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-1-Basic-Concepts"><span class="toc-text">Chapter 1. Basic Concepts</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-2-Linear-System-and-LU"><span class="toc-text">Chapter 2. Linear System and LU</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-Review"><span class="toc-text">2.1 Review</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-LU-Factorization"><span class="toc-text">2.2 LU Factorization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-Linear-System"><span class="toc-text">2.3 Linear System</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-5-Cholesky-Factorization"><span class="toc-text">2.5 Cholesky Factorization</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-3-Norms-Sensitivity-amp-Conditioning-in-Matrix"><span class="toc-text">Chapter 3. Norms, Sensitivity &amp; Conditioning in Matrix</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-Definitions-of-Norms-in-Matrix"><span class="toc-text">3.1 Definitions of Norms in Matrix</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-Definition-of-Condition-Number-in-Matrix"><span class="toc-text">3.2 Definition of Condition Number in Matrix</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-4-Column-Spaces-amp-QR"><span class="toc-text">Chapter 4. Column Spaces &amp; QR</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-5-Eigenvalue-amp-Eigenvector"><span class="toc-text">Chapter 5. Eigenvalue &amp; Eigenvector</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-Overview"><span class="toc-text">5.1 Overview</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-Review-Diagonalizable-Matrix"><span class="toc-text">5.2 Review: Diagonalizable Matrix</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-Definition-of-Spectrum-Radius-in-Matrix"><span class="toc-text">5.3 Definition of Spectrum Radius in Matrix</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-4-Extend-to-mathbf-C-m-times-n"><span class="toc-text">5.4 Extend to $\mathbf{C^{m\times n}}$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-5-Application-Use-Matrices-to-Solve-Problems"><span class="toc-text">5.5 Application: Use Matrices to Solve Problems</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-6-Similarity-Transformations"><span class="toc-text">5.6 Similarity Transformations</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-7-SVD-Singular-Value-Decomposition"><span class="toc-text">5.7 SVD (Singular Value Decomposition)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-7-1-Application-Orthogonal-Procrustes-Theorem"><span class="toc-text">5.7.1 Application: Orthogonal Procrustes Theorem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-7-2-Application-Principal-Component-Analysis-PCA"><span class="toc-text">5.7.2 Application: Principal Component Analysis (PCA)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Chapter-6-Non-linear-System"><span class="toc-text">Chapter 6. Non-linear System</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1-Root-Finding"><span class="toc-text">6.1 Root Finding</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/technical/redis-starter/" title="Redis 入门：从实践到理论"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.sjtuxhw.top/cover_imgs/redis.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Redis 入门：从实践到理论"/></a><div class="content"><a class="title" href="/technical/redis-starter/" title="Redis 入门：从实践到理论">Redis 入门：从实践到理论</a><time datetime="2024-11-12T13:05:37.000Z" title="发表于 2024-11-12 21:05:37">2024-11-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/technical/python-sci-starter/" title="Python 科学计算入门"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.sjtuxhw.top/cover_imgs/python_sci.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python 科学计算入门"/></a><div class="content"><a class="title" href="/technical/python-sci-starter/" title="Python 科学计算入门">Python 科学计算入门</a><time datetime="2024-11-03T11:08:13.000Z" title="发表于 2024-11-03 19:08:13">2024-11-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/technical/hilog-paper/" title="OpenHarmony Hilog 架构趣读"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.sjtuxhw.top/cover_imgs/hilog-paper.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="OpenHarmony Hilog 架构趣读"/></a><div class="content"><a class="title" href="/technical/hilog-paper/" title="OpenHarmony Hilog 架构趣读">OpenHarmony Hilog 架构趣读</a><time datetime="2024-10-29T05:14:04.000Z" title="发表于 2024-10-29 13:14:04">2024-10-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/review/makefile-again/" title="Makefile 快速上手 (again)"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.sjtuxhw.top/cover_imgs/makefile-again.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Makefile 快速上手 (again)"/></a><div class="content"><a class="title" href="/review/makefile-again/" title="Makefile 快速上手 (again)">Makefile 快速上手 (again)</a><time datetime="2024-10-11T02:05:34.000Z" title="发表于 2024-10-11 10:05:34">2024-10-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/technical/xss/" title="XSS 是什么？"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.sjtuxhw.top/cover_imgs/xss.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="XSS 是什么？"/></a><div class="content"><a class="title" href="/technical/xss/" title="XSS 是什么？">XSS 是什么？</a><time datetime="2024-10-04T04:15:33.000Z" title="发表于 2024-10-04 12:15:33">2024-10-04</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By SJTU-XHW  |  tech SJTU saves the world</div><div class="framework-info"><span>Built With love &amp; </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Powered By </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><div style="display:flex;flex-flow:row;justify-content:center;align-items:center;"> <a href="https://beian.miit.gov.cn" rel="external nofollow noreferrer" id="beian" target="_blank">ICP备案：沪ICP备2023012264-1号</a> <span class="footer-separator">|</span> <a style="display:flex;flex-flow:row;align-items:center;" href="https://www.upyun.com/?utm_source=lianmeng&utm_medium=referral" rel="external nofollow noreferrer" target="_blank"> 本网站由 <img style="margin:0 3px;" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/upCloud_logo_blue.png" title="upcloud" alt="upcloud" height="30px"> 提供CDN加速/云存储服务 </a></div></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();" rel="external nofollow noreferrer"><i class="fa-solid fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();" rel="external nofollow noreferrer"><i class="fa-solid fa-arrow-rotate-right"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();" rel="external nofollow noreferrer"><i class="fa-solid fa-arrow-right"></i></a><a class="rightMenu-item" id="menu-radompage" href="javascript:window.location.href = window.location.origin;" rel="external nofollow noreferrer"><i class="fa-solid fa-house"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();" rel="external nofollow noreferrer"><i class="fa-solid fa-copy"></i><span>复制</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item" href="javascript:rmf.switchDarkMode();" rel="external nofollow noreferrer"><i class="fa-solid fa-circle-half-stroke"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="javascript:rmf.switchReadMode();" rel="external nofollow noreferrer"><i class="fa-solid fa-book"></i><span>阅读模式</span></a></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }
      
      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script><script>(() => {
  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.sjtuxhw.top',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.sjtuxhw.top',
      region: '',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))

    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(init,0)
    else btf.getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(init)
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script src="/js/rightmenu.js"></script><script src="/js/mourn.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>